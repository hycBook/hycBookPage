<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>深度学习在图像领域的应用 | 兼一书虫</title><meta name="keywords" content="深度学习"><meta name="author" content="narutohyc"><meta name="copyright" content="narutohyc"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="必读！计算机视觉四大基本任务(分类、定位、检测、分割)  模型介绍 模型可视化netron工具库 pytorch模型转onnx模型的方法详解  图像分类 Stable Diffusion总共包含三个主要的组件 人工智能Ai画画——stable diffusion 原理和使用方法详解！  1）Clip Text用于文本编码。输入：文本输出：77个token嵌入向量，其中每个向量包含768个维度">
<meta property="og:type" content="article">
<meta property="og:title" content="深度学习在图像领域的应用">
<meta property="og:url" content="https://study.hycbook.com/article/35455.html">
<meta property="og:site_name" content="兼一书虫">
<meta property="og:description" content="必读！计算机视觉四大基本任务(分类、定位、检测、分割)  模型介绍 模型可视化netron工具库 pytorch模型转onnx模型的方法详解  图像分类 Stable Diffusion总共包含三个主要的组件 人工智能Ai画画——stable diffusion 原理和使用方法详解！  1）Clip Text用于文本编码。输入：文本输出：77个token嵌入向量，其中每个向量包含768个维度">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://pic.hycbook.com/i/hexo/post_cover/%E8%95%BE%E5%A7%861.webp">
<meta property="article:published_time" content="2023-02-23T03:12:40.000Z">
<meta property="article:modified_time" content="2023-08-12T11:55:54.708Z">
<meta property="article:author" content="narutohyc">
<meta property="article:tag" content="深度学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://pic.hycbook.com/i/hexo/post_cover/%E8%95%BE%E5%A7%861.webp"><link rel="shortcut icon" href="https://pic.hycbook.com/i//hexo/config_imgs/网站图标.webp"><link rel="canonical" href="https://study.hycbook.com/article/35455"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="manifest" href="/manifest.json"/><meta name="msapplication-TileColor" content="#c6ff7a"/><link rel="apple-touch-icon" sizes="180x180" href="https://pic.hycbook.com/i//hexo/source/img/siteicon/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="https://pic.hycbook.com/i//hexo/source/img/siteicon/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="https://pic.hycbook.com/i//hexo/source/img/siteicon/favicon-16x16.png"/><link rel="mask-icon" href="https://pic.hycbook.com/i//hexo/source/img/siteicon/safari-pinned-tab.svg" color="#5bbad5"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?68340394dfd808cea9826e8a57f87aa6";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: {"defaultEncoding":1,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: {"limitDay":120,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":400},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":200,"languages":{"author":"作者: narutohyc","link":"链接: ","source":"来源: 兼一书虫","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '深度学习在图像领域的应用',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-08-12 19:55:54'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/hyc_udf.css"><link rel="stylesheet" href="/css/udf_css.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/js-heo@1.0.11/mainColor/heoMainColor.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/js-heo@1.0.11/404/404.css"><script src="https://npm.elemecdn.com/echarts@4.9.0/dist/echarts.min.js"></script><link href="https://cdn.bootcdn.net/ajax/libs/toastr.js/2.1.4/toastr.min.css" rel="stylesheet"><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.cbd.int/hexo-butterfly-tag-plugins-plus@latest/lib/assets/font-awesome-animation.min.css" media="defer" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.cbd.int/hexo-butterfly-tag-plugins-plus@latest/lib/tag_plugins.css" media="defer" onload="this.media='all'"><script src="https://cdn.cbd.int/hexo-butterfly-tag-plugins-plus@latest/lib/assets/carousel-touch.js"></script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="兼一书虫" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i/hexo/person_img/兼一头像.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">114</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">168</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">9</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-fangwu"></use></svg><span> 首页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-wenzhang1">             </use></svg><span> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-guidang">                   </use></svg><span> 归档</span></a></li><li><a class="site-page child" href="/categories"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-fenlei">                   </use></svg><span> 分类</span></a></li><li><a class="site-page child" href="/tags"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-biaoqian">                   </use></svg><span> 标签</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-xuegao">             </use></svg><span> 娱乐</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-yinle">                   </use></svg><span> 音乐</span></a></li><li><a class="site-page child" href="/bangumis"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-wodezhuifan">                   </use></svg><span> 追番</span></a></li><li><a class="site-page child" href="/gallery"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-xiangce">                   </use></svg><span> 相册</span></a></li><li><a class="site-page child" href="/video"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-shipin">                   </use></svg><span> 视频</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/charts"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-xigua"></use></svg><span> 统计图</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-suannai">             </use></svg><span> 网盘</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://pan.hycbook.com/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-guidang">                   </use></svg><span> 私月盘</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://share.hycbook.com/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-zhifengche">                   </use></svg><span> 共享盘</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-zhifeiji">             </use></svg><span> 导航</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/comments"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-TIFFANYSROOM_huaban">                   </use></svg><span> 留言板</span></a></li><li><a class="site-page child" href="/link"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-changyonglianjie">                   </use></svg><span> 友链</span></a></li><li><a class="site-page child" href="/about"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-aixin">                   </use></svg><span> 关于</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://pic.hycbook.com/i/hexo/post_imgs/蕾姆1.webp')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">兼一书虫</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-fangwu"></use></svg><span> 首页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-wenzhang1">             </use></svg><span> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-guidang">                   </use></svg><span> 归档</span></a></li><li><a class="site-page child" href="/categories"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-fenlei">                   </use></svg><span> 分类</span></a></li><li><a class="site-page child" href="/tags"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-biaoqian">                   </use></svg><span> 标签</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-xuegao">             </use></svg><span> 娱乐</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-yinle">                   </use></svg><span> 音乐</span></a></li><li><a class="site-page child" href="/bangumis"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-wodezhuifan">                   </use></svg><span> 追番</span></a></li><li><a class="site-page child" href="/gallery"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-xiangce">                   </use></svg><span> 相册</span></a></li><li><a class="site-page child" href="/video"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-shipin">                   </use></svg><span> 视频</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/charts"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-xigua"></use></svg><span> 统计图</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-suannai">             </use></svg><span> 网盘</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://pan.hycbook.com/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-guidang">                   </use></svg><span> 私月盘</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://share.hycbook.com/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-zhifengche">                   </use></svg><span> 共享盘</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-zhifeiji">             </use></svg><span> 导航</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/comments"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-TIFFANYSROOM_huaban">                   </use></svg><span> 留言板</span></a></li><li><a class="site-page child" href="/link"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-changyonglianjie">                   </use></svg><span> 友链</span></a></li><li><a class="site-page child" href="/about"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-aixin">                   </use></svg><span> 关于</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">深度学习在图像领域的应用</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-02-23T03:12:40.000Z" title="发表于 2023-02-23 11:12:40">2023-02-23</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-08-12T11:55:54.708Z" title="更新于 2023-08-12 19:55:54">2023-08-12</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/deep-learning/">deep_learning</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">3.9k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>13分钟</span></span><span class="post-meta-separator">|</span><span id="" data-flag-title="深度学习在图像领域的应用"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="twikoo_visitors"><i class="fa-solid fa-spinner fa-spin"></i></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/article/35455.html#post-comment"><span id="twikoo-count"><i class="fa-solid fa-spinner fa-spin"></i></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><hr>
<blockquote>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://mp.weixin.qq.com/s?__biz=MzU2NjU3OTc5NA==&amp;mid=2247553356&amp;idx=1&amp;sn=62d14b0f722f98c949d12b68a8472be7&amp;chksm=fca81671cbdf9f678b9c21eb321afd95b40236e87f41d54ca973868167b8841487edf818540d&amp;scene=27">必读！计算机视觉四大基本任务(分类、定位、检测、分割)</a></p>
</blockquote>
<h1 id="模型介绍"><a href="#模型介绍" class="headerlink" title="模型介绍"></a>模型介绍</h1><blockquote>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://netron.app/">模型可视化netron工具库</a></p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.jb51.net/article/261136.htm">pytorch模型转onnx模型的方法详解</a></p>
</blockquote>
<h2 id="图像分类"><a href="#图像分类" class="headerlink" title="图像分类"></a>图像分类</h2><blockquote>
<p>Stable Diffusion总共包含三个主要的组件</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://zhuanlan.zhihu.com/p/610094594?utm_id=0">人工智能Ai画画——stable diffusion 原理和使用方法详解！</a></p>
</blockquote>
<p>1）Clip Text用于文本编码。输入：文本输出：77个token嵌入向量，其中每个向量包含768个维度</p>
<p>2）UNet + Scheduler在信息（潜）空间中逐步处理/扩散信息。输入：文本嵌入和一个由噪声组成的初始多维数组（结构化的数字列表，也叫张量tensor）。输出：一个经过处理的信息阵列</p>
<p>3）自编码解码器（Autoencoder Decoder），使用处理过的信息矩阵绘制最终图像的解码器。</p>
<hr>
<p>Clip Text 是一种自然语言处理模型，由 OpenAI 开发。它基于 CLIP（Contrastive Language-Image Pretraining）模型，旨在将文本和图像联系起来。Clip Text 模型可以理解和处理文本数据，以便进行各种任务，例如文本分类、情感分析、命名实体识别等。通过训练 Clip Text 模型，可以使其具备对文本的理解能力，从而支持在自然语言处理领域进行各种应用和研究。</p>
<p>UNet 是一种用于图像分割的卷积神经网络模型。它最初由 Olaf Ronneberger 等人在 2015 年提出，旨在解决医学图像分割任务中的问题。UNet 的设计灵感来自于生物学中的神经元结构，它具有一个特殊的 U 形结构，因此得名 UNet。</p>
<p>UNet 的特点是具有对称的编码器-解码器结构，其中编码器部分由多个卷积和池化层组成，用于逐步提取图像的特征。解码器部分则通过上采样和卷积操作逐步将特征映射恢复到原始图像的尺寸，用于生成分割结果。此外，UNet 还通过跳跃连接（skip connections）在编码器和解码器之间建立了直接连接，以便保留和利用不同层级的特征信息。</p>
<p>UNet 在医学图像分割任务中取得了很好的效果，并且在其他领域的图像分割任务中也得到了广泛应用。它的网络结构简单、易于实现和训练，并且能够处理不同尺度和形状的目标物体，因此成为图像分割领域的重要模型之一。</p>
<h2 id="目标检测和跟踪"><a href="#目标检测和跟踪" class="headerlink" title="目标检测和跟踪"></a>目标检测和跟踪</h2><h2 id="图像分割"><a href="#图像分割" class="headerlink" title="图像分割"></a>图像分割</h2><ul>
<li>语义分割</li>
<li>实例分割</li>
<li></li>
</ul>
<h2 id="图像处理"><a href="#图像处理" class="headerlink" title="图像处理"></a>图像处理</h2><ul>
<li>超分辨率</li>
<li>除雾</li>
</ul>
<h2 id="图像生成"><a href="#图像生成" class="headerlink" title="图像生成"></a>图像生成</h2><h2 id="动作识别"><a href="#动作识别" class="headerlink" title="动作识别"></a>动作识别</h2><h2 id="风格转换"><a href="#风格转换" class="headerlink" title="风格转换"></a>风格转换</h2><h2 id="人脸识别"><a href="#人脸识别" class="headerlink" title="人脸识别"></a>人脸识别</h2><h2 id="图像描述"><a href="#图像描述" class="headerlink" title="图像描述"></a>图像描述</h2><h2 id="OCR"><a href="#OCR" class="headerlink" title="OCR"></a>OCR</h2><blockquote>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.bilibili.com/read/cv22100576">深入了解视觉语言模型</a></p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://arxiv.org/pdf/2106.08254.pdf">BEiT: BERT Pre-Training of Image Transformers 2022</a></p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://blog.csdn.net/qq_39478403/article/details/128125376">【深度学习】详解 BEiT</a></p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://zhuanlan.zhihu.com/p/438726362">《BEIT》-基于图像重建进行预训练！微软提出BEIT，Top-1准确率达86.3%！代码已开源！</a></p>
</blockquote>
<p>与其他模型不同，<code>VisionEncoderDecoderModel</code> 是一个标准化的模型，可用于初始化任意图像转文本模型，这类模型可以使用任何预训练的基于Transformer的视觉模型作为编码器(例如ViT(子监督训练)、<span class="bubble-content">BEiT</span><span class="bubble-notation"><span class="bubble-item" style="background-color: #de4489;"> 预训练BEiT(自监督训练): 掩码图像建模(MIM)任务，随机mask一定百分比的图像patches，然后预测masked patches对应的视觉tokens</span></span>、DeiT、Swin)以及任何预训练的语言模型作为解码器(例如RoBERTa、GPT2、BERT、DistilBERT)。事实上，TrOCR是这个标准类的一个实例</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i/hexo/bk_resources/deep_learning/dl_in_vision_field/VisionEncoderDecoderModel模型结构图.svg" alt="VisionEncoderDecoderModel模型结构图"></p>
<blockquote>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://arxiv.org/pdf/2109.10282v4.pdf">TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models 2022</a></p>
</blockquote>
<p>微软亚洲研究院的研究员们展开了深入研究，提出了<strong>首个利用预训练模型的端到端基于Transformer的文本识别OCR模型</strong>：TrOCR。该模型简单有效，可以使用大规模合成数据进行预训练，并且能够在人工标注的数据上进行微调。实验证明，TrOCR在打印数据和手写数据上均超过了当前最先进的模型</p>
<p>一般的光学字符识别包含两个部分：<strong>文本检测和文本识别</strong></p>
<ul>
<li><p><strong>文本检测</strong>: 用于在文本图像中定位文本块，粒度可以是单词级别或是文本行级别</p>
<p>目前的解决方案大多是将该任务视为物体检测问题，并采用了如YoLOv5和DBNet的传统物体检测模型</p>
</li>
<li><p><strong>文本识别</strong>: 致力于理解文本图像并将视觉信号转换为自然语言符号，该任务通常使用编码器-解码器架构</p>
<p>现有方法采用了基于CNN网络的编码器进行图像理解，以及基于RNN网络的解码器进行文本生成</p>
</li>
</ul>
<p>为了更有效的训练TrOCR模型，研究员们使用了ViT模式的预训练模型和BERT模式的预训练模型，来分别初始化编码器和解码器</p>
<blockquote>
<p>TrOCRForCausalLM</p>
</blockquote>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://huggingface.co/docs/transformers/v4.14.1/en/model_doc/trocr#transformers.TrOCRForCausalLM">huggingface TrOCRForCausalLM</a></p>
<p>翻译：The ViTFeatureExtractor class is responsible for preprocessing the input image and RobertaTokenizer decodes the generated target tokens to the target string. <strong>The TrOCRProcessor wraps ViTFeatureExtractor and RobertaTokenizer into a single instance to both extract the input features and decode the predicted token ids</strong>.</p>
<p>ViTFeatureExtractor类负责预处理输入图像，而RobertaTokenizer则将生成的目标标记解码为目标字符串。TrOCRProcessor将ViTFeatureExtractor和RobertaTokenizer封装为单个实例，既可以提取输入特征，又可以解码预测的标记ID</p>
<p>翻译：The VisionEncoderDecoderModel can be used to initialize an image-to-text-sequence model with any pretrained vision autoencoding model as the encoder (e.g. ViT, BEiT, DeiT) and any pretrained language model as the decoder (e.g. RoBERTa, GPT2, BERT). The effectiveness of initializing image-to-text-sequence models with pretrained checkpoints has been shown in (for example) TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Minghao Li, Tengchao Lv, Lei Cui, Yijuan Lu, Dinei Florencio, Cha Zhang, Zhoujun Li, Furu Wei. An example of how to use a VisionEncoderDecoderModel for inference can be seen in TrOCR.</p>
<p>VisionEncoderDecoderModel可以用于初始化一个图像到文本序列模型，其中编码器可以是任何预训练的图像自编码模型（例如ViT、BEiT、DeiT），解码器可以是任何预训练的语言模型（例如RoBERTa、GPT2、BERT）</p>
<p>初始化图像到文本序列模型时使用预训练的检查点已经被证明是有效的，例如在《TrOCR：基于预训练模型的基于Transformer的光学字符识别》一文中，作者Minghao Li、Tengchao Lv、Lei Cui、Yijuan Lu、Dinei Florencio、Cha Zhang、Zhoujun Li、Furu Wei展示了这一点</p>
<p>关于如何使用VisionEncoderDecoderModel进行推断的示例可以在TrOCR中找到</p>
<blockquote>
<p>图像特定的归纳偏差</p>
</blockquote>
<p>图像特定的归纳偏差是指在处理图像数据时，机器学习算法或人类大脑对图像的处理和理解中存在的偏好或倾向性。这种偏差可能导致算法或人类在处理图像时出现系统性的错误或误解。</p>
<p>图像特定的归纳偏差可能源自以下几个方面：</p>
<ol>
<li>形状偏差：人类和机器学习算法在处理图像时，可能更容易关注物体的形状和轮廓。这可能导致对于形状特征较强的物体更敏感，而对于纹理、颜色等其他特征的重要性较低。</li>
<li>颜色偏差：颜色是图像中的重要特征之一，但人类和机器学习算法可能对不同颜色的感知和辨别能力存在差异。某些颜色的辨别可能更容易，而对于其他颜色的辨别可能相对较差。</li>
<li>尺度偏差：图像中的物体尺度可能对于算法或人类的视觉处理产生影响。例如，较大尺度的物体可能更容易被注意到和理解，而较小尺度的物体可能容易被忽略或误解。</li>
<li>视角偏差：视角对于理解图像中的物体和场景也具有重要作用。不同的视角可能导致物体的外观发生变化，从而影响算法或人类对物体的认知和解释。</li>
</ol>
<p>这些图像特定的归纳偏差可能会对计算机视觉任务（如物体检测、图像分类等）的性能产生影响，并导致一些常见的误分类或误解。为了减少这些偏差的影响，研究人员和开发者通常会采取一系列的方法，例如使用更丰富的特征表示、进行数据增强、多角度训练等，以提高算法在处理图像数据时的准确性和鲁棒性。</p>
<hr>
<p>基于TrOCR 提一些面试题</p>
<p>当涉及到TrOCR（Transformer-based Optical Character Recognition）的面试问题时，可以考虑以下几个方面的问题：</p>
<ol>
<li>什么是TrOCR？它与传统的OCR方法有何不同？</li>
<li>TrOCR中使用的是哪种Transformer模型？请描述其结构和主要组成部分。</li>
<li>在TrOCR中，图像是如何被处理和输入到Transformer模型中的？</li>
<li>TrOCR如何实现对文本的自回归生成？它采用了哪些技术和策略？</li>
<li>TrOCR中的预训练和微调是如何进行的？使用了哪些数据集和训练方法？</li>
<li>TrOCR在哪些任务和数据集上取得了优秀的性能？可以谈谈其在印刷体和手写体识别任务上的表现。</li>
<li>TrOCR的优势和局限性是什么？相对于传统的OCR方法，它有哪些潜在的应用前景和挑战？</li>
<li>在TrOCR中，是否存在一些常见的问题或挑战？可以谈谈对应的解决方法或改进思路。</li>
<li>TrOCR在实际应用中可能面临的计算资源和效率方面的问题有哪些？如何解决或优化这些问题？</li>
<li>除了TrOCR，还有哪些基于Transformer的图像处理任务和应用？可以举例说明。</li>
</ol>
<p>这些问题将涵盖TrOCR的基本概念、模型结构、训练和应用等方面，有助于评估面试者对TrOCR的理解和熟悉程度。根据具体情况，你还可以进一步展开讨论相关的深入问题。</p>
<hr>
<p>回答下你提的十个问题</p>
<p>当涉及到TrOCR（Transformer-based Optical Character Recognition）的面试问题时，以下是对你提出的十个问题的简要回答：</p>
<ol>
<li>TrOCR是一种基于Transformer的光学字符识别方法，与传统的OCR方法相比，它利用Transformer模型实现了端到端的文本生成和理解，具有更好的建模能力和上下文理解能力。</li>
<li>TrOCR使用的是Transformer模型，它由编码器和解码器组成。编码器采用自注意力机制来处理输入图像的特征表示，解码器采用自回归生成的方式逐步生成输出文本。</li>
<li>在TrOCR中，图像经过预处理步骤，如分割为固定大小的图像块，并进行线性嵌入，然后添加位置编码。处理后的图像表示被输入到Transformer编码器中进行处理。</li>
<li>TrOCR采用自回归生成的方式对文本进行生成，即逐个生成每个字符或词汇。它使用了类似于语言建模的技术，通过上文的信息来预测下一个字符或词汇。</li>
<li>TrOCR的预训练阶段通常使用大规模的合成数据进行训练，以学习图像和文本之间的对应关系。然后，可以通过微调阶段使用真实标注的数据来优化模型的性能。</li>
<li>TrOCR在印刷体和手写体识别任务上取得了优秀的性能。它在大规模的OCR数据集上进行了评估，并在准确性和泛化能力方面超过了传统的OCR方法。</li>
<li>TrOCR的优势包括能够对长文本进行建模、上下文理解能力强、适应不同语种和字体样式等。然而，TrOCR可能对计算资源要求较高，并且在处理一些特定的复杂场景（如低质量图像或特殊字体）时可能面临挑战。</li>
<li>在TrOCR中，一些常见的问题包括文本重复生成、模糊图像的处理、长文本的生成和训练数据的标注质量。解决这些问题的方法可能涉及使用更复杂的解码策略、改进的图像预处理和增强技术以及更好的数据标注和清洗方法。</li>
<li>TrOCR在实际应用中可能面临的计算资源和效率方面的问题包括模型大小和推理速度。为了解决这些问题，可以采用模型压缩和加速技术，如剪枝、量化和模型并行化等。</li>
<li>除了TrOCR，还有许多基于Transformer的图像处理任务和应用。例如，图像分类、目标检测</li>
</ol>
<blockquote>
<p>OCR识别手写文字(中文+英文)</p>
</blockquote>
<p>参考文献：</p>
<ul>
<li><p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://arxiv.org/pdf/2109.10282v4.pdf">TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models 2022</a></p>
<p>该论文提出了一种名为TrOCR的基于Transformer的光学字符识别(OCR)模型，通过利用预训练模型进行特征提取和文本生成，实现端到端的文本识别任务</p>
<p>TrOCR模型的关键创新点包括以下几个方面：</p>
<ol>
<li>基于Transformer的架构：TrOCR采用了Transformer架构作为其基础模型，其中包括编码器和解码器。<strong>编码器用于提取图像特征</strong>，<strong>解码器用于生成识别的文本序列</strong></li>
<li>预训练模型的应用：TrOCR利用预训练的图像和文本模型作为编码器和解码器，如ViT、RoBERTa等。这些预训练模型能够提供丰富的视觉和语言表示能力，有助于提高OCR的准确性</li>
<li>大规模合成数据集：为了进行预训练和微调，TrOCR使用了大规模的合成数据集，包括数百万张打印文本图像和手写文本图像。这样可以增加模型在不同领域和样式的文本上的泛化能力</li>
</ol>
<p>实验证明，TrOCR模型在打印文本、手写文本和场景文本识别任务上取得了优异的性能表现，超过了当前的state-of-the-art模型。该论文的贡献在于将Transformer应用于OCR任务，并且通过预训练模型的利用提高了OCR的准确性和泛化能力</p>
</li>
<li></li>
</ul>
<p>架构：</p>
<p>model(VisionEncoderDecoderModel) = encoder(DeiT)+decoder(TrOCRForCausalLM)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">DeiTModel(</span><br><span class="line">  (embeddings): DeiTEmbeddings(</span><br><span class="line">    (patch_embeddings): DeiTPatchEmbeddings(</span><br><span class="line">      (projection): Conv2d(<span class="number">3</span>, <span class="number">384</span>, kernel_size=(<span class="number">16</span>, <span class="number">16</span>), stride=(<span class="number">16</span>, <span class="number">16</span>))</span><br><span class="line">    )</span><br><span class="line">    (dropout): Dropout(p=<span class="number">0.0</span>, inplace=<span class="literal">False</span>)</span><br><span class="line">  )</span><br><span class="line">  (encoder): DeiTEncoder(</span><br><span class="line">    (layer): ModuleList(</span><br><span class="line">      (<span class="number">0</span>): DeiTLayer(</span><br><span class="line">        (attention): DeiTAttention(</span><br><span class="line">          (attention): DeiTSelfAttention(</span><br><span class="line">            (query): Linear(in_features=<span class="number">384</span>, out_features=<span class="number">384</span>, bias=<span class="literal">True</span>)</span><br><span class="line">            (key): Linear(in_features=<span class="number">384</span>, out_features=<span class="number">384</span>, bias=<span class="literal">True</span>)</span><br><span class="line">            (value): Linear(in_features=<span class="number">384</span>, out_features=<span class="number">384</span>, bias=<span class="literal">True</span>)</span><br><span class="line">            (dropout): Dropout(p=<span class="number">0.0</span>, inplace=<span class="literal">False</span>)</span><br><span class="line">          )</span><br><span class="line">          (output): DeiTSelfOutput(</span><br><span class="line">            (dense): Linear(in_features=<span class="number">384</span>, out_features=<span class="number">384</span>, bias=<span class="literal">True</span>)</span><br><span class="line">            (dropout): Dropout(p=<span class="number">0.0</span>, inplace=<span class="literal">False</span>)</span><br><span class="line">          )</span><br><span class="line">        )</span><br><span class="line">        (intermediate): DeiTIntermediate(</span><br><span class="line">          (dense): Linear(in_features=<span class="number">384</span>, out_features=<span class="number">1536</span>, bias=<span class="literal">True</span>)</span><br><span class="line">          (intermediate_act_fn): GELUActivation()</span><br><span class="line">        )</span><br><span class="line">        (output): DeiTOutput(</span><br><span class="line">          (dense): Linear(in_features=<span class="number">1536</span>, out_features=<span class="number">384</span>, bias=<span class="literal">True</span>)</span><br><span class="line">          (dropout): Dropout(p=<span class="number">0.0</span>, inplace=<span class="literal">False</span>)</span><br><span class="line">        )</span><br><span class="line">        (layernorm_before): LayerNorm((<span class="number">384</span>,), eps=<span class="number">1e-12</span>, elementwise_affine=<span class="literal">True</span>)</span><br><span class="line">        (layernorm_after): LayerNorm((<span class="number">384</span>,), eps=<span class="number">1e-12</span>, elementwise_affine=<span class="literal">True</span>)</span><br><span class="line">      ) * <span class="number">12</span></span><br><span class="line">    )</span><br><span class="line">  )</span><br><span class="line">  (layernorm): LayerNorm((<span class="number">384</span>,), eps=<span class="number">1e-12</span>, elementwise_affine=<span class="literal">True</span>)</span><br><span class="line">  (pooler): DeiTPooler(</span><br><span class="line">    (dense): Linear(in_features=<span class="number">384</span>, out_features=<span class="number">384</span>, bias=<span class="literal">True</span>)</span><br><span class="line">    (activation): Tanh()</span><br><span class="line">  )</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过线性层将编码器和解码器连接到了一起</span></span><br><span class="line">enc_to_dec_proj = nn.Linear(self.encoder.config.hidden_size, self.decoder.config.hidden_size)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">TrOCRForCausalLM(</span><br><span class="line">  (model): TrOCRDecoderWrapper(</span><br><span class="line">    (decoder): TrOCRDecoder(</span><br><span class="line">      (embed_tokens): Embedding(<span class="number">11318</span>, <span class="number">256</span>, padding_idx=<span class="number">1</span>)</span><br><span class="line">      (embed_positions): TrOCRLearnedPositionalEmbedding(<span class="number">514</span>, <span class="number">256</span>)</span><br><span class="line">      (layernorm_embedding): LayerNorm((<span class="number">256</span>,), eps=<span class="number">1e-05</span>, elementwise_affine=<span class="literal">True</span>)</span><br><span class="line">      (layers): ModuleList(</span><br><span class="line">        (<span class="number">0</span>): TrOCRDecoderLayer(</span><br><span class="line">          (self_attn): TrOCRAttention(</span><br><span class="line">            (k_proj): Linear(in_features=<span class="number">256</span>, out_features=<span class="number">256</span>, bias=<span class="literal">True</span>)</span><br><span class="line">            (v_proj): Linear(in_features=<span class="number">256</span>, out_features=<span class="number">256</span>, bias=<span class="literal">True</span>)</span><br><span class="line">            (q_proj): Linear(in_features=<span class="number">256</span>, out_features=<span class="number">256</span>, bias=<span class="literal">True</span>)</span><br><span class="line">            (out_proj): Linear(in_features=<span class="number">256</span>, out_features=<span class="number">256</span>, bias=<span class="literal">True</span>)</span><br><span class="line">          )</span><br><span class="line">          (activation_fn): ReLU()</span><br><span class="line">          (self_attn_layer_norm): LayerNorm((<span class="number">256</span>,), eps=<span class="number">1e-05</span>, elementwise_affine=<span class="literal">True</span>)</span><br><span class="line">          (encoder_attn): TrOCRAttention(</span><br><span class="line">            (k_proj): Linear(in_features=<span class="number">384</span>, out_features=<span class="number">256</span>, bias=<span class="literal">True</span>)</span><br><span class="line">            (v_proj): Linear(in_features=<span class="number">384</span>, out_features=<span class="number">256</span>, bias=<span class="literal">True</span>)</span><br><span class="line">            (q_proj): Linear(in_features=<span class="number">256</span>, out_features=<span class="number">256</span>, bias=<span class="literal">True</span>)</span><br><span class="line">            (out_proj): Linear(in_features=<span class="number">256</span>, out_features=<span class="number">256</span>, bias=<span class="literal">True</span>)</span><br><span class="line">          )</span><br><span class="line">          (encoder_attn_layer_norm): LayerNorm((<span class="number">256</span>,), eps=<span class="number">1e-05</span>, elementwise_affine=<span class="literal">True</span>)</span><br><span class="line">          (fc1): Linear(in_features=<span class="number">256</span>, out_features=<span class="number">1024</span>, bias=<span class="literal">True</span>)</span><br><span class="line">          (fc2): Linear(in_features=<span class="number">1024</span>, out_features=<span class="number">256</span>, bias=<span class="literal">True</span>)</span><br><span class="line">          (final_layer_norm): LayerNorm((<span class="number">256</span>,), eps=<span class="number">1e-05</span>, elementwise_affine=<span class="literal">True</span>)</span><br><span class="line">        ) * <span class="number">6</span></span><br><span class="line">      )</span><br><span class="line">    )</span><br><span class="line">  )</span><br><span class="line">  (output_projection): Linear(in_features=<span class="number">256</span>, out_features=<span class="number">11318</span>, bias=<span class="literal">False</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>实现细节:</p>
<p>数据集:</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/narutohyc">narutohyc</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://study.hycbook.com/article/35455.html">https://study.hycbook.com/article/35455.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="external nofollow noreferrer" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://study.hycbook.com" target="_blank">兼一书虫</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></div><div class="post_share"><div class="social-share" data-image="https://pic.hycbook.com/i/hexo/post_cover/蕾姆1.webp" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><link rel="stylesheet" href="/" media="defer" onload="this.media='all'"/><div class="post-reward"><button class="tip-button reward-button"><span class="tip-button__text">打赏</span><div class="coin-wrapper"><div class="coin"><div class="coin__middle"></div><div class="coin__back"></div><div class="coin__front"></div></div></div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="https://pic.hycbook.com/i//hexo/qr_codes/hyc_wechat.webp" rel="external nofollow noreferrer" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i//hexo/qr_codes/hyc_wechat.webp" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="https://pic.hycbook.com/i//hexo/qr_codes/hyc_alipay.webp" rel="external nofollow noreferrer" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i//hexo/qr_codes/hyc_alipay.webp" alt="alipay"/></a><div class="post-qr-code-desc">alipay</div></li></ul></div></button></div><audio id="coinAudio" src="https://s1.vika.cn/space/2022/10/29/6db0ad2bccf949f09054b3b206dcc66f?attname=马里奥游戏投币叮当.mp3"></audio><script defer="defer" src="/"></script><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/article/44700.html"><img class="prev-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i/hexo/post_cover/蕾姆0.webp" onerror="onerror=null;src='https://pic.hycbook.com/i/hexo/config_imgs/404.svg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">transformer学习</div></div></a></div><div class="next-post pull-right"><a href="/article/31546.html"><img class="next-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i/hexo/post_cover/蕾姆10.webp" onerror="onerror=null;src='https://pic.hycbook.com/i/hexo/config_imgs/404.svg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">python常用库学习</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/article/53377.html" title="深度学习模型压缩技术"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i/hexo/post_cover/蕾姆11.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-06-04</div><div class="title">深度学习模型压缩技术</div></div></a></div><div><a href="/article/24897.html" title="LLM模型部署调试推理"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i/hexo/post_cover/蕾姆12.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-06-12</div><div class="title">LLM模型部署调试推理</div></div></a></div><div><a href="/article/42898.html" title="nlp关键词和摘要提取技术整理"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i/hexo/post_cover/蕾姆1.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-06-22</div><div class="title">nlp关键词和摘要提取技术整理</div></div></a></div><div><a href="/article/46832.html" title="深度学习核心之损失函数"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i/hexo/post_cover/蕾姆8.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-05-26</div><div class="title">深度学习核心之损失函数</div></div></a></div><div><a href="/article/22410.html" title="深度学习核心之激活函数"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i/hexo/post_cover/蕾姆7.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-05-26</div><div class="title">深度学习核心之激活函数</div></div></a></div><div><a href="/article/36065.html" title="深度学习核心之优化器"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i/hexo/post_cover/蕾姆9.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-05-26</div><div class="title">深度学习核心之优化器</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div><div id="comment-switch"><span class="first-comment">Twikoo</span><span class="switch-btn"></span><span class="second-comment">Valine</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D"><span class="toc-number">1.</span> <span class="toc-text">模型介绍</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB"><span class="toc-number">1.1.</span> <span class="toc-text">图像分类</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E5%92%8C%E8%B7%9F%E8%B8%AA"><span class="toc-number">1.2.</span> <span class="toc-text">目标检测和跟踪</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2"><span class="toc-number">1.3.</span> <span class="toc-text">图像分割</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86"><span class="toc-number">1.4.</span> <span class="toc-text">图像处理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90"><span class="toc-number">1.5.</span> <span class="toc-text">图像生成</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8A%A8%E4%BD%9C%E8%AF%86%E5%88%AB"><span class="toc-number">1.6.</span> <span class="toc-text">动作识别</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A3%8E%E6%A0%BC%E8%BD%AC%E6%8D%A2"><span class="toc-number">1.7.</span> <span class="toc-text">风格转换</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB"><span class="toc-number">1.8.</span> <span class="toc-text">人脸识别</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%BE%E5%83%8F%E6%8F%8F%E8%BF%B0"><span class="toc-number">1.9.</span> <span class="toc-text">图像描述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#OCR"><span class="toc-number">1.10.</span> <span class="toc-text">OCR</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer" style="background-image: url('https://pic.hycbook.com/i/hexo/config_imgs/footer_bg.webp')"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2023 By narutohyc</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener external nofollow noreferrer" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text"><p><a target="_blank" href="https://hexo.io/" rel="external nofollow noreferrer"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&logo=hexo" title="博客框架为Hexo"></a>&nbsp;<a target="_blank" href="https://demo.jerryc.me/" rel="external nofollow noreferrer"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&logo=bitdefender" title="主题采用butterfly"></a>&nbsp;<a target="_blank" href="https://vercel.com/ " rel="external nofollow noreferrer"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Hosted-Vervel-brightgreen?style=flat&logo=Vercel" title="本站采用双线部署，默认线路托管于Vercel"></a>&nbsp;<a target="_blank" href="https://github.com/" rel="external nofollow noreferrer"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&logo=GitHub" title="本站项目由Gtihub托管"></a>&nbsp;<a target="_blank" href="https://zixiaoyun.com" rel="external nofollow noreferrer"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/图床-薄荷图床-green" title="薄荷图床"></a></p><a target="_blank" href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=35020502000647" rel="external nofollow noreferrer"><img style="position:relative;top:4px" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i//hexo/config_imgs//备案图标.webp" alt="ICP"/>闽公网安备35020502000647号  </a><a href="https://beian.miit.gov.cn/" rel="external nofollow noreferrer" target="_blank">闽ICP备2022013843号-1</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">简</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div id="rightMenu"><div class="rightMenu-group rightMenu-small"><div class="rightMenu-item" id="menu-backward"><i class="fa-solid fa-arrow-left"></i></div><div class="rightMenu-item" id="menu-forward"><i class="fa-solid fa-arrow-right"></i></div><div class="rightMenu-item" id="menu-refresh"><i class="fa-solid fa-arrow-rotate-right"></i></div><div class="rightMenu-item" id="menu-home"><i class="fa-solid fa-house"></i></div></div><div class="rightMenu-group rightMenu-line hide" id="menu-text"><a class="rightMenu-item" href="javascript:window.open(&quot;https://www.baidu.com/s?wd=&quot;+window.getSelection().toString());window.location.reload();" rel="external nofollow noreferrer"><i class="fas fa-comment"></i><span>百度搜索</span></a></div><div class="rightMenu-group rightMenu-line rightMenuOther"><a class="rightMenu-item menu-link" href="/archives/"><i class="fa-solid fa-archive"></i><span>文章归档</span></a><a class="rightMenu-item menu-link" href="/categories/"><i class="fa-solid fa-folder-open"></i><span>文章分类</span></a><a class="rightMenu-item menu-link" href="/tags/"><i class="fa-solid fa-tags"></i><span>文章标签</span></a></div><div class="rightMenu-group rightMenu-line rightMenuNormal"><a class="rightMenu-item menu-link" id="menu-radompage"><i class="fa-solid fa-shoe-prints"></i><span>随便逛逛</span></a><div class="rightMenu-item" id="menu-translate"><i class="fa-solid fa-earth-asia"></i><span>繁简切换</span></div><div class="rightMenu-item" id="menu-darkmode"><i class="fa-solid fa-moon"></i><span>切换模式</span></div></div></div><div id="rightmenu-mask"></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script>(() => {
  const $mermaidWrap = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaidWrap.length) {
    window.runMermaid = () => {
      window.loadMermaid = true
      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? '' : ''

      Array.from($mermaidWrap).forEach((item, index) => {
        const mermaidSrc = item.firstElementChild
        const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
        const mermaidID = 'mermaid-' + index
        const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent
        mermaid.mermaidAPI.render(mermaidID, mermaidDefinition, (svgCode) => {
          mermaidSrc.insertAdjacentHTML('afterend', svgCode)
        })
      })
    }

    const loadMermaid = () => {
      window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
    }

    window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
  }
})()</script><script>(()=>{
  const init = () => {
    twikoo.init(Object.assign({
      el: '#twikoo-wrap',
      envId: 'https://vercel.hycbook.com',
      region: '',
      onCommentLoaded: function () {
        btf.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.tk-owo-emotion)'))
      }
    }, null))
  }

  const getCount = () => {
    const countELement = document.getElementById('twikoo-count')
    if(!countELement) return
    twikoo.getCommentsCount({
      envId: 'https://vercel.hycbook.com',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      countELement.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const runFn = () => {
    init()
    GLOBAL_CONFIG_SITE.isPost && getCount()
  }

  const loadTwikoo = () => {
    if (typeof twikoo === 'object') {
      setTimeout(runFn,0)
      return
    } 
    getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(runFn)
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo()
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script><script>function loadValine () {
  function initValine () {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: 'ncn88uooQf0IO2rrGE7Vniwp-gzGzoHsz',
      appKey: 'Yghpzg1QfBMFJ0MxxHubVzKL',
      avatar: 'monsterid',
      serverURLs: '',
      emojiMaps: "",
      path: window.location.pathname,
      visitor: true
    }, null))
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
}

if ('Twikoo' === 'Valine' || !false) {
  if (false) btf.loadComment(document.getElementById('vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script></div><script>window.addEventListener('load', () => {
  const changeContent = (content) => {
    if (content === '') return content

    content = content.replace(/<img.*?src="(.*?)"?[^\>]+>/ig, '[图片]') // replace image link
    content = content.replace(/<a[^>]+?href=["']?([^"']+)["']?[^>]*>([^<]+)<\/a>/gi, '[链接]') // replace url
    content = content.replace(/<pre><code>.*?<\/pre>/gi, '[代码]') // replace code
    content = content.replace(/<[^>]+>/g,"") // remove html tag

    if (content.length > 150) {
      content = content.substring(0,150) + '...'
    }
    return content
  }

  const getComment = () => {
    const runTwikoo = () => {
      twikoo.getRecentComments({
        envId: 'https://vercel.hycbook.com',
        region: '',
        pageSize: 3,
        includeReply: true
      }).then(function (res) {
        const twikooArray = res.map(e => {
          return {
            'content': changeContent(e.comment),
            'avatar': e.avatar,
            'nick': e.nick,
            'url': e.url + '#' + e.id,
            'date': new Date(e.created).toISOString()
          }
        })

        saveToLocal.set('twikoo-newest-comments', JSON.stringify(twikooArray), 10/(60*24))
        generateHtml(twikooArray)
      }).catch(function (err) {
        const $dom = document.querySelector('#card-newest-comments .aside-list')
        $dom.innerHTML= "无法获取评论，请确认相关配置是否正确"
      })
    }

    if (typeof twikoo === 'object') {
      runTwikoo()
    } else {
      getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(runTwikoo)
    }
  }

  const generateHtml = array => {
    let result = ''

    if (array.length) {
      for (let i = 0; i < array.length; i++) {
        result += '<div class=\'aside-list-item\'>'

        if (true) {
          const name = 'data-lazy-src'
          result += `<a href='${array[i].url}' class='thumbnail'><img ${name}='${array[i].avatar}' alt='${array[i].nick}'></a>`
        }
        
        result += `<div class='content'>
        <a class='comment' href='${array[i].url}' title='${array[i].content}'>${array[i].content}</a>
        <div class='name'><span>${array[i].nick} / </span><time datetime="${array[i].date}">${btf.diffDate(array[i].date, true)}</time></div>
        </div></div>`
      }
    } else {
      result += '没有评论'
    }

    let $dom = document.querySelector('#card-newest-comments .aside-list')
    $dom.innerHTML= result
    window.lazyLoadInstance && window.lazyLoadInstance.update()
    window.pjax && window.pjax.refresh($dom)
  }

  const newestCommentInit = () => {
    if (document.querySelector('#card-newest-comments .aside-list')) {
      const data = saveToLocal.get('twikoo-newest-comments')
      if (data) {
        generateHtml(JSON.parse(data))
      } else {
        getComment()
      }
    }
  }

  newestCommentInit()
  document.addEventListener('pjax:complete', newestCommentInit)
})</script><script defer src="https://npm.elemecdn.com/jquery@latest/dist/jquery.min.js"></script><script defer data-pjax src="/js/rightMenu.js"></script><script defer data-pjax src="/js/udf_mouse.js"></script><script defer data-pjax src="/js/udf_js.js"></script><script defer data-pjax src="/zhheo/random.js"></script><script data-pjax src="/js/coin.js"></script><script defer src="https://npm.elemecdn.com/vue@2.6.11"></script><script async src="//at.alicdn.com/t/c/font_3670467_a0sijt8frxo.js"></script><script defer src="/live2d-widget/autoload.js"></script><script defer src="/js/udf_js.js"></script><script defer src="https://cdnjs.cloudflare.com/ajax/libs/toastr.js/latest/toastr.min.js"></script><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-fluttering-ribbon.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = false;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-heart.min.js" async="async" mobile="true"></script><script>window.$crisp = [];
window.CRISP_WEBSITE_ID = "561b80db-3f0f-45cb-b3b1-aae7355939e6";
(function () {
  d = document;
  s = d.createElement("script");
  s.src = "https://client.crisp.chat/l.js";
  s.async = 1;
  d.getElementsByTagName("head")[0].appendChild(s);
})();
$crisp.push(["safe", true])

if (false) {
  $crisp.push(["do", "chat:hide"])
  $crisp.push(["on", "chat:closed", function() {
    $crisp.push(["do", "chat:hide"])
  }])
  var chatBtnFn = () => {
    var chatBtn = document.getElementById("chat_btn")
    chatBtn.addEventListener("click", function(){
      $crisp.push(["do", "chat:show"])
      $crisp.push(["do", "chat:open"])

    });
  }
  chatBtnFn()
} else {
  if (false) {
    function chatBtnHide () {
      $crisp.push(["do", "chat:hide"])
    }
    function chatBtnShow () {
      $crisp.push(["do", "chat:show"])
    }
  }
}</script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener scroll 
  window.tocScrollFn && window.removeEventListener('scroll', window.tocScrollFn)
  window.scrollCollect && window.removeEventListener('scroll', scrollCollect)

  typeof preloader === 'object' && preloader.initLoading()
  document.getElementById('rightside').style.cssText = "opacity: ''; transform: ''"
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

  typeof disqusjs === 'object' && disqusjs.destroy()
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()

  typeof preloader === 'object' && preloader.endLoading()
})

document.addEventListener('pjax:error', (e) => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div class="app-refresh" id="app-refresh" style="position: fixed;top: -2.2rem;left: 0;right: 0;z-index: 99999;padding: 0 1rem;font-size: 15px;height: 2.2rem;transition: all 0.3s ease;"><div class="app-refresh-wrap" style=" display: flex;color: #fff;height: 100%;align-items: center;justify-content: center;"><label>✨ 兼一书虫上新啦！ 👉</label><a href="javascript:void(0)" rel="external nofollow noreferrer" onclick="location.reload()"><span style="color: #fff;text-decoration: underline;cursor: pointer;">🍭查看新品🍬</span></a></div></div><script>if ('serviceWorker' in navigator) {
  if (navigator.serviceWorker.controller) {
    navigator.serviceWorker.addEventListener('controllerchange', function() {
      showNotification()
    })
  }
  window.addEventListener('load', function() {
    navigator.serviceWorker.register('/sw.js')
  })
}

function showNotification() {
  if (GLOBAL_CONFIG.Snackbar) {
    var snackbarBg =
      document.documentElement.getAttribute('data-theme') === 'light' ?
      GLOBAL_CONFIG.Snackbar.bgLight :
      GLOBAL_CONFIG.Snackbar.bgDark
    var snackbarPos = GLOBAL_CONFIG.Snackbar.position
    Snackbar.show({
      text: '✨ 兼一书虫上新啦！ 👉',
      backgroundColor: snackbarBg,
      duration: 500000,
      pos: snackbarPos,
      actionText: '🍭查看新品🍬',
      actionTextColor: '#fff',
      onActionClick: function(e) {
        location.reload()
      },
    })
  } else {
    var showBg =
      document.documentElement.getAttribute('data-theme') === 'light' ?
      '#49b1f5' :
      '#1f1f1f'
    var cssText = `top: 0; background: ${showBg};`
    document.getElementById('app-refresh')
      .style.cssText = cssText
  }
}</script></div><!-- hexo injector body_end start --><script async src="//at.alicdn.com/t/font_2032782_8d5kxvn09md.js"></script><!-- hexo injector body_end end --></body></html>