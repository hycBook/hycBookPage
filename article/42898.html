<!DOCTYPE html><html lang="zh-CN" data-theme="dark"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>nlp关键词和摘要提取技术整理 | 兼一书虫</title><meta name="keywords" content="深度学习,关键词提取,摘要生成|提取"><meta name="author" content="narutohyc"><meta name="copyright" content="narutohyc"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#0d0d0d"><meta name="description" content="nlp关键词和摘要提取技术整理">
<meta property="og:type" content="article">
<meta property="og:title" content="nlp关键词和摘要提取技术整理">
<meta property="og:url" content="https://study.hycbook.com/article/42898.html">
<meta property="og:site_name" content="兼一书虫">
<meta property="og:description" content="nlp关键词和摘要提取技术整理">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://pic.hycbook.com/i/hexo/post_cover/%E8%95%BE%E5%A7%861.webp">
<meta property="article:published_time" content="2023-06-22T06:08:17.000Z">
<meta property="article:modified_time" content="2024-02-03T04:30:18.165Z">
<meta property="article:author" content="narutohyc">
<meta property="article:tag" content="深度学习">
<meta property="article:tag" content="关键词提取">
<meta property="article:tag" content="摘要生成|提取">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://pic.hycbook.com/i/hexo/post_cover/%E8%95%BE%E5%A7%861.webp"><link rel="shortcut icon" href="https://pic.hycbook.com/i//hexo/config_imgs/网站图标.webp"><link rel="canonical" href="https://study.hycbook.com/article/42898"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="manifest" href="/manifest.json"/><meta name="msapplication-TileColor" content="#c6ff7a"/><link rel="apple-touch-icon" sizes="180x180" href="https://pic.hycbook.com/i//hexo/source/img/siteicon/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="https://pic.hycbook.com/i//hexo/source/img/siteicon/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="https://pic.hycbook.com/i//hexo/source/img/siteicon/favicon-16x16.png"/><link rel="mask-icon" href="https://pic.hycbook.com/i//hexo/source/img/siteicon/safari-pinned-tab.svg" color="#5bbad5"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?68340394dfd808cea9826e8a57f87aa6";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: {"defaultEncoding":1,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: {"limitDay":120,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":400},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":200,"languages":{"author":"作者: narutohyc","link":"链接: ","source":"来源: 兼一书虫","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'nlp关键词和摘要提取技术整理',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-02-03 12:30:18'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/js-heo@1.0.11/mainColor/heoMainColor.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/js-heo@1.0.11/404/404.css"><script src="https://npm.elemecdn.com/echarts@4.9.0/dist/echarts.min.js"></script><link href="https://cdn.bootcdn.net/ajax/libs/toastr.js/2.1.4/toastr.min.css" rel="stylesheet"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/js-heo@1.0.11/categoryBar/categoryBar.css"><link rel="stylesheet" href="/css/hyc_udf.css"><link rel="stylesheet" href="/css/udf_css.css"><link rel="stylesheet" href="/css/year.css"><svg aria-hidden="true" style="position:absolute; overflow:hidden; width:0; height:0"><symbol id="icon-sun" viewBox="0 0 1024 1024"><path d="M960 512l-128 128v192h-192l-128 128-128-128H192v-192l-128-128 128-128V192h192l128-128 128 128h192v192z" fill="#FFD878" p-id="8420"></path><path d="M736 512a224 224 0 1 0-448 0 224 224 0 1 0 448 0z" fill="#FFE4A9" p-id="8421"></path><path d="M512 109.248L626.752 224H800v173.248L914.752 512 800 626.752V800h-173.248L512 914.752 397.248 800H224v-173.248L109.248 512 224 397.248V224h173.248L512 109.248M512 64l-128 128H192v192l-128 128 128 128v192h192l128 128 128-128h192v-192l128-128-128-128V192h-192l-128-128z" fill="#4D5152" p-id="8422"></path><path d="M512 320c105.888 0 192 86.112 192 192s-86.112 192-192 192-192-86.112-192-192 86.112-192 192-192m0-32a224 224 0 1 0 0 448 224 224 0 0 0 0-448z" fill="#4D5152" p-id="8423"></path></symbol><symbol id="icon-moon" viewBox="0 0 1024 1024"><path d="M611.370667 167.082667a445.013333 445.013333 0 0 1-38.4 161.834666 477.824 477.824 0 0 1-244.736 244.394667 445.141333 445.141333 0 0 1-161.109334 38.058667 85.077333 85.077333 0 0 0-65.066666 135.722666A462.08 462.08 0 1 0 747.093333 102.058667a85.077333 85.077333 0 0 0-135.722666 65.024z" fill="#FFB531" p-id="11345"></path><path d="M329.728 274.133333l35.157333-35.157333a21.333333 21.333333 0 1 0-30.165333-30.165333l-35.157333 35.157333-35.114667-35.157333a21.333333 21.333333 0 0 0-30.165333 30.165333l35.114666 35.157333-35.114666 35.157334a21.333333 21.333333 0 1 0 30.165333 30.165333l35.114667-35.157333 35.157333 35.157333a21.333333 21.333333 0 1 0 30.165333-30.165333z" fill="#030835" p-id="11346"></path></symbol></svg><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.cbd.int/hexo-butterfly-tag-plugins-plus@latest/lib/assets/font-awesome-animation.min.css" media="defer" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.cbd.int/hexo-butterfly-tag-plugins-plus@latest/lib/tag_plugins.css" media="defer" onload="this.media='all'"><script src="https://cdn.cbd.int/hexo-butterfly-tag-plugins-plus@latest/lib/assets/carousel-touch.js"></script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i/hexo/person_img/兼一头像.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">122</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">171</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">9</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-fangwu"></use></svg><span> 首页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-wenzhang1">             </use></svg><span> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-guidang">                   </use></svg><span> 归档</span></a></li><li><a class="site-page child" href="/categories"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-fenlei">                   </use></svg><span> 分类</span></a></li><li><a class="site-page child" href="/tags"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-biaoqian">                   </use></svg><span> 标签</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-yuedu">             </use></svg><span> gitbook版</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://common.hycbook.com"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-guidang">                   </use></svg><span> common</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://dl.hycbook.com"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-biaoqian">                   </use></svg><span> deep learning</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://python.hycbook.com"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-fenlei">                   </use></svg><span> python</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://snooby.hycbook.com"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-zhifengche">                   </use></svg><span> snooby</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://hycbook.flowus.cn"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-wenzhang">                   </use></svg><span> flowus</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-xuegao">             </use></svg><span> 娱乐</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-yinle">                   </use></svg><span> 音乐</span></a></li><li><a class="site-page child" href="/bangumis"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-wodezhuifan">                   </use></svg><span> 追番</span></a></li><li><a class="site-page child" href="/gallery"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-xiangce">                   </use></svg><span> 相册</span></a></li><li><a class="site-page child" href="/video"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-shipin">                   </use></svg><span> 视频</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/charts"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-xigua"></use></svg><span> 统计图</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-suannai">             </use></svg><span> 网盘</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://pan.hycbook.com"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-guidang">                   </use></svg><span> 私月盘</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://share.hycbook.com"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-zhifengche">                   </use></svg><span> 共享盘</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-zhifeiji">             </use></svg><span> 导航</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/comments"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-TIFFANYSROOM_huaban">                   </use></svg><span> 留言板</span></a></li><li><a class="site-page child" href="/link"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-friends">                   </use></svg><span> 友链</span></a></li><li><a class="site-page child" href="/about"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-aixin">                   </use></svg><span> 关于</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://pic.hycbook.com/i/hexo/post_imgs/蕾姆1.webp')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">兼一书虫</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-fangwu"></use></svg><span> 首页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-wenzhang1">             </use></svg><span> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-guidang">                   </use></svg><span> 归档</span></a></li><li><a class="site-page child" href="/categories"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-fenlei">                   </use></svg><span> 分类</span></a></li><li><a class="site-page child" href="/tags"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-biaoqian">                   </use></svg><span> 标签</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-yuedu">             </use></svg><span> gitbook版</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://common.hycbook.com"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-guidang">                   </use></svg><span> common</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://dl.hycbook.com"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-biaoqian">                   </use></svg><span> deep learning</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://python.hycbook.com"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-fenlei">                   </use></svg><span> python</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://snooby.hycbook.com"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-zhifengche">                   </use></svg><span> snooby</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://hycbook.flowus.cn"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-wenzhang">                   </use></svg><span> flowus</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-xuegao">             </use></svg><span> 娱乐</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-yinle">                   </use></svg><span> 音乐</span></a></li><li><a class="site-page child" href="/bangumis"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-wodezhuifan">                   </use></svg><span> 追番</span></a></li><li><a class="site-page child" href="/gallery"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-xiangce">                   </use></svg><span> 相册</span></a></li><li><a class="site-page child" href="/video"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-shipin">                   </use></svg><span> 视频</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/charts"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-xigua"></use></svg><span> 统计图</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-suannai">             </use></svg><span> 网盘</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://pan.hycbook.com"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-guidang">                   </use></svg><span> 私月盘</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://share.hycbook.com"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-zhifengche">                   </use></svg><span> 共享盘</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-zhifeiji">             </use></svg><span> 导航</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/comments"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-TIFFANYSROOM_huaban">                   </use></svg><span> 留言板</span></a></li><li><a class="site-page child" href="/link"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-friends">                   </use></svg><span> 友链</span></a></li><li><a class="site-page child" href="/about"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-aixin">                   </use></svg><span> 关于</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">nlp关键词和摘要提取技术整理</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-06-22T06:08:17.000Z" title="发表于 2023-06-22 14:08:17">2023-06-22</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-02-03T04:30:18.165Z" title="更新于 2024-02-03 12:30:18">2024-02-03</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/deep-learning/">deep-learning</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">7k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>24分钟</span></span><span class="post-meta-separator">|</span><span id="" data-flag-title="nlp关键词和摘要提取技术整理"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="twikoo_visitors"><i class="fa-solid fa-spinner fa-spin"></i></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/article/42898.html#post-comment"><span id="twikoo-count"><i class="fa-solid fa-spinner fa-spin"></i></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><hr>
<h1 id="切词"><a href="#切词" class="headerlink" title="切词"></a>切词</h1><p>等待…</p>
<h1 id="关键词提取"><a href="#关键词提取" class="headerlink" title="关键词提取"></a>关键词提取</h1><blockquote>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.jos.org.cn/html/2017/9/5301.htm#outline_anchor_17">自动关键词抽取研究综述2017</a></p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="http://html.rhhz.net/rjxb/html/5538.htm">特征驱动的关键词提取算法综述2018</a></p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://manu44.magtech.com.cn/Jwk_infotech_wk3/CN/10.11925/infotech.2096-3467.2020.1103">关键词提取研究综述2021</a></p>
</blockquote>
<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><blockquote>
<p>概念</p>
</blockquote>
<p>关键词提取技术是一种自然语言处理技术，旨在从给定的文本中自动识别出最具代表性和重要性的关键词或短语</p>
<p>关键词通常是文本中具有特殊含义、能够概括文本主题或内容的词语或短语</p>
<blockquote>
<p>使用场景</p>
</blockquote>
<p>关键词提取技术的目标是对文本进行语义分析和内容抽取，从而提取出最能代表文本主题和内容的关键词</p>
<p>这些关键词可以用于文本分类、信息检索、文本摘要、主题建模、信息过滤等自然语言处理任务</p>
<blockquote>
<p>经典方法</p>
</blockquote>
<p>关键词提取技术通常结合了文本的语言统计特征、词频分布、词性、上下文关系、语义相似度等多种信息源，以识别并提取出最相关和具有区分度的关键词</p>
<p>常见的关键词提取方法包括基于词频、TF-IDF、文本图结构、语言模型、图模型、深度学习等多种技术手段</p>
<p>关键词提取技术在信息处理、文本挖掘、自动化文档处理等领域具有重要应用价值，能够帮助人们更快速、准确地理解和处理大量文本信息</p>
<h2 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h2><blockquote>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://mp.weixin.qq.com/s?__biz=MzI1MjQ2OTQ3Ng==&amp;mid=2247545032&amp;idx=2&amp;sn=fca791422e59e91b174ce7ed5bc0e7b6&amp;chksm=e9e13943de96b0553d1644ce9e2e1173bb379ec6dbd87350eb62d0509c407b7bd3867e2e3e6c&amp;scene=27">NLP中关键字提取方法总结和概述</a></p>
</blockquote>
<h1 id="基于统计"><a href="#基于统计" class="headerlink" title="基于统计"></a>基于统计</h1><p>统计方法是最简单的。他们计算关键字的统计数据并使用这些统计数据对它们进行评分。一些最简单的统计方法是词频、词搭配和共现</p>
<p>也有一些更复杂的，例如TF-IDF和YAKE!</p>
<h2 id="tf-idf"><a href="#tf-idf" class="headerlink" title="tf-idf"></a>tf-idf</h2><blockquote>
<p>概述</p>
</blockquote>
<p><code>TF-IDF</code>或<code>term frequency–inverse document frequency</code>，会计算文档中单词相对于整个语料库(更多文档集)的重要性</p>
<p>它计算文档中每个词的频率，并通过词在整个语料库中的频率的倒数对其进行加权。最后，选择得分最高的词作为关键词，TF-IDF有两层意思</p>
<ul>
<li><strong>词频</strong>: Term Frequency，缩写为TF，通常来说，一个分词出现的次数越多，代表越重要</li>
<li><strong>逆文档频率</strong>: Inverse Document Frequency，缩写为IDF，在现实生活中，出现次数最多的词是一些无意义的词，比如停用词，对搜索结果毫无帮助，必须通过分词器提前过滤掉的词</li>
</ul>
<blockquote>
<p>公式 - <a target="_blank" rel="noopener external nofollow noreferrer" href="https://towardsdatascience.com/tf-idf-for-document-ranking-from-scratch-in-python-on-real-world-dataset-796d339a4089">TF-IDF from scratch in python on a real-world dataset.</a></p>
</blockquote>
<div class="table-container">
<table>
<thead>
<tr>
<th>术语</th>
<th>t</th>
<th>d</th>
<th>N</th>
<th>corpus</th>
</tr>
</thead>
<tbody>
<tr>
<td>释义</td>
<td>term(word)</td>
<td>document(set of words)<br />一篇文档中的词集合</td>
<td>count of corpus<br />语料数量</td>
<td>the total document set<br />总体文档集合</td>
</tr>
</tbody>
</table>
</div>
<script type="math/tex; mode=display">
\begin{array}{c}

tf(t,d) = \frac{count\ of\ t\ in\ d}{number\ of\ words\ in\ d} = \frac {单词t在文档d中出现的频次}{文档d的词频总数}

\\\\

df(t) = occurrence\ of\ t\ in\ N\ documents = 单词t在N篇文档中多少篇中出现

\\\\

idf(t) = \frac {N}{df} = log(\frac {N}{df+1})

\\\\

tf\_idf(t, d) = tf(t, d) * idf(t)

\end{array}</script><p>一个分词Term的相关性由tf*idf公式简化表达。tf-idf模型包含了二个简单事实：</p>
<ul>
<li>某个term分词在一个文档中出现次数(tf)越多，这个词与文档越相关</li>
<li>某个索引中包含某个term分词的文档数量越少(idf)，这个term分词越重要</li>
</ul>
<blockquote>
<p>例子</p>
</blockquote>
<p>考虑一个包含100个单词的文档，其中<strong>Leon</strong>这个分词出现了10次。这个时候TF=(10/100)=0.1</p>
<p>并且假设Lucene索引中有1000W份文档数量，其中有1000份文档中出现了<strong>Leon</strong>这个分词，此时逆文档频率(IDF)计算为IDF=log(10,000,000/1,000)=4</p>
<p>因此，TD-IDF计算为TF*IDF=0.1 * 4=0.4</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"><span class="keyword">import</span> jieba.analyse</span><br><span class="line"></span><br><span class="line">sentence = <span class="string">&#x27;中华蜜蜂原产于中国，是中国的土著蜂，适应中国各地的气候和蜜源条件，适于定地饲养且稳产，尤其是在南方山区，有着其他蜂种不可替代的地位&#x27;</span></span><br><span class="line"></span><br><span class="line">seg_list = jieba.cut(sentence, cut_all=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;, &quot;</span>.join(seg_list))</span><br><span class="line">keywords = jieba.analyse.extract_tags(sentence, topK=<span class="number">20</span>, withWeight=<span class="literal">True</span>, allowPOS=(<span class="string">&#x27;n&#x27;</span>, <span class="string">&#x27;nr&#x27;</span>, <span class="string">&#x27;ns&#x27;</span>))</span><br><span class="line"><span class="built_in">print</span>(keywords)</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">中华, 蜜蜂, 原产, 产于, 中国, ，, 是, 中国, 的, 土著, 蜂, ，, 适应, 中国, 各地, 的, 气候, 和, 蜜源, 条件, ，, 适于, 定, 地, 饲养, 且, 稳产, ，, 尤其, 是, 在, 南方, 方山, 山区, ，, 有着, 其他, 蜂, 种, 不可, 替代, 的, 地位</span><br><span class="line">[(<span class="string">&#x27;定地&#x27;</span>, <span class="number">0.7969</span>), (<span class="string">&#x27;蜂种&#x27;</span>, <span class="number">0.7969</span>), (<span class="string">&#x27;稳产&#x27;</span>, <span class="number">0.7340</span>), (<span class="string">&#x27;蜜源&#x27;</span>, <span class="number">0.66725</span>), (<span class="string">&#x27;中国&#x27;</span>, <span class="number">0.60546</span>), (<span class="string">&#x27;蜜蜂&#x27;</span>, <span class="number">0.5859</span>), (<span class="string">&#x27;土著&#x27;</span>, <span class="number">0.55968</span>), (<span class="string">&#x27;原产&#x27;</span>, <span class="number">0.544705</span>), (<span class="string">&#x27;替代&#x27;</span>, <span class="number">0.484315</span>), (<span class="string">&#x27;山区&#x27;</span>, <span class="number">0.44390</span>), (<span class="string">&#x27;气候&#x27;</span>, <span class="number">0.38804</span>), (<span class="string">&#x27;地位&#x27;</span>, <span class="number">0.34710</span>), (<span class="string">&#x27;条件&#x27;</span>, <span class="number">0.32636</span>)]</span><br></pre></td></tr></table></figure>
<blockquote>
<p>优缺点</p>
</blockquote>
<ul>
<li><strong>速度快</strong>: TF-IDF的优点是速度快</li>
<li><strong>语言无关</strong>: TF-IDF与语言无关</li>
<li><strong>需要语料</strong>: 需要至少几十个文档的语料库</li>
<li><strong>不够全面</strong>: 缺点是单纯于词频来判断一个分词的重要性，不够全面</li>
<li><strong>无法捕获语义</strong>: 缺点是不能捕捉分词Term在文档中的位置</li>
</ul>
<blockquote>
<p>变种</p>
</blockquote>
<p>TF-IDF 的4大常见变种<br>变种1: 对数函数变换 TF，解决TF现行增长问题<br>变种2: 对 TF 进行标准化，解决长短文档问题<br>变种3: 对数函数变换 IDF，解决IDF 现行增长问题<br>变种4: 查询词及文档向量标准化，解决长短文档问题</p>
<h2 id="YAKE"><a href="#YAKE" class="headerlink" title="YAKE"></a>YAKE</h2><blockquote>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://repositorio.inesctec.pt/server/api/core/bitstreams/90459f60-012f-4aa2-88cf-6af2a3a12559/content">2018ECIR的最佳短论文奖 A Text Feature Based Automatic Keyword Extraction Method for Single Documents</a></p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/LIAAD/yake">github Yet Another Keyword Extractor (Yake)</a></p>
</blockquote>
<h3 id="概述-1"><a href="#概述-1" class="headerlink" title="概述"></a>概述</h3><p><code>YAKE(Yet Another Keyword Extractor)</code>是一种关键字提取方法，它利用单个文档的统计特征来提取关键字</p>
<p>它通过五个步骤提取关键字，旨在从文本中自动提取最相关的关键词和关键短语</p>
<p>YAKE算法的工作原理如下：</p>
<ol>
<li>文本预处理：将输入文本进行预处理，包括分词、去除停用词等</li>
<li>特征提取：使用词频、位置权重、长度等特征来衡量单词和短语的重要性</li>
<li>关键词候选生成：根据特征权重，生成候选关键词和关键短语</li>
<li>关键词权重计算：根据候选关键词的特征权重，计算它们的最终权重</li>
<li>关键词筛选：根据设定的阈值或排序方法，筛选出具有高权重的关键词和关键短语作为最终结果</li>
</ol>
<p>YAKE算法与传统的基于统计和语言模型的关键词提取方法不同，它采用了基于特征权重的方法，使得算法更加灵活和可定制</p>
<p>此外，YAKE还支持多语言关键词提取，并能够处理领域特定的文本</p>
<p>总体而言，YAKE算法通过综合考虑单词和短语的特征权重，以及它们在文本中的频率和位置等信息，来提取与文本内容相关的关键词和关键短语</p>
<p><strong>官方实现仅支持英文</strong></p>
<h1 id="基于图技术"><a href="#基于图技术" class="headerlink" title="基于图技术"></a>基于图技术</h1><h2 id="TextRank"><a href="#TextRank" class="headerlink" title="TextRank"></a>TextRank</h2><blockquote>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://blog.csdn.net/asialee_bird/article/details/96894533">TextRank算法介绍及实现</a></p>
</blockquote>
<p><code>TextRank</code>是一种基于图的算法，用于关键词提取和文本摘要。它基于PageRank算法的思想，将文本表示为一个图，其中节点表示文本中的单词或短语，边表示它们之间的关系</p>
<p>通过计算节点之间的权重和连接关系，TextRank可以确定文本中最重要的单词或短语。</p>
<p><strong>TextRank的步骤如下</strong>：</p>
<ol>
<li><strong>分割文本</strong>：将文本分割成句子或单词</li>
<li><strong>构建图</strong>：根据文本中的句子或单词构建一个图，其中每个句子或单词作为一个节点，边表示它们之间的关系。常见的关系可以是共现关系或语义关系</li>
<li><strong>计算权重</strong>：为图中的每个节点计算权重。通常使用词频或TF-IDF作为初始权重</li>
<li><strong>迭代计算</strong>：通过迭代计算节点之间的权重，更新每个节点的权重值。迭代过程中，节点的权重将考虑其相邻节点的权重值</li>
<li><strong>排序节点</strong>：根据节点的权重值对节点进行排序，得到关键词或摘要</li>
</ol>
<p>TextRank算法在关键词提取和文本摘要等任务中表现良好，它不需要依赖预训练模型，可以直接应用于各种领域的文本处理任务</p>
<h3 id="PageRank"><a href="#PageRank" class="headerlink" title="PageRank"></a>PageRank</h3><blockquote>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="http://ilpubs.stanford.edu:8090/422/1/1999-66.pdf">The PageRank Citation Ranking: Bringing Order to the Web 1999</a></p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://zhuanlan.zhihu.com/p/126733456">关键词提取和摘要算法TextRank详解与实战</a></p>
</blockquote>
<p>PageRank算法通过计算网页链接的数量和质量来粗略估计网页的重要性，算法创立之初即应用在谷歌的搜索引擎中，对网页进行排名。</p>
<p>PageRank算法的核心思想如下：</p>
<ul>
<li><p><strong>链接数量</strong>：如果一个网页被越多的其他网页链接，说明这个网页越重要，即该网页的PR值(PageRank值)会相对较高</p>
</li>
<li><p><strong>链接质量</strong>：如果一个网页被一个越高权值的网页链接，也能表明这个网页越重要，即一个PR值很高的网页链接到一个其他网页，那么被链接到的网页的PR值会相应地因此而提高</p>
</li>
</ul>
<p>PageRank算法计算公式</p>
<script type="math/tex; mode=display">
S\left(V_{i}\right)=(1-\mathrm{d})+\mathrm{d} * \sum_{j \in \operatorname{In}\left(V_{i}\right)} \frac{1}{\left|O u t\left(V_{j}\right)\right|} S\left(V_{j}\right)</script><p>其中，<script type="math/tex">S\left(V_{i}\right)</script>是网页<script type="math/tex">i</script>的重要性(PR值)，<script type="math/tex">\mathrm{d}</script>是阻尼系数，一般为0.85，<script type="math/tex">\operatorname{In}\left(V_{i}\right)</script>是整个互联网中所存在的有指同网页<script type="math/tex">i</script>的链接的网页集合，<script type="math/tex">Out\left(V_{j}\right)</script>是网页<script type="math/tex">j</script>中存在的指向所有外部网页的链辖的集合，<script type="math/tex">|Out \left(V_{j}\right) \mid</script>是该集合中元素的个数</p>
<blockquote>
<p>例子</p>
</blockquote>
<p>等待…</p>
<blockquote>
<p>PageRank算法与TextRank算法的区别</p>
</blockquote>
<ul>
<li>PageRank算法根据网页之间的链接关系构造网络，TextRank算法根据词之间的共现关系构造网络</li>
<li>PageRank算法构造的网络中的边是有向无权边，TextRank算法构造的网络中的边是无向有权边</li>
</ul>
<h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><blockquote>
<p>基于Textrank4zh的TextRank算法实现</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> textrank4zh <span class="keyword">import</span> TextRank4Keyword, TextRank4Sentence</span><br><span class="line"><span class="keyword">import</span> jieba.analyse</span><br><span class="line"><span class="keyword">from</span> snownlp <span class="keyword">import</span> SnowNLP</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"> </span><br><span class="line"><span class="comment">#关键词抽取</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">keywords_extraction</span>(<span class="params">text</span>):</span><br><span class="line">    tr4w = TextRank4Keyword(allow_speech_tags=[<span class="string">&#x27;n&#x27;</span>, <span class="string">&#x27;nr&#x27;</span>, <span class="string">&#x27;nrfg&#x27;</span>, <span class="string">&#x27;ns&#x27;</span>, <span class="string">&#x27;nt&#x27;</span>, <span class="string">&#x27;nz&#x27;</span>])</span><br><span class="line">    <span class="comment"># allow_speech_tags   --词性列表，用于过滤某些词性的词</span></span><br><span class="line">    tr4w.analyze(text=text, window=<span class="number">2</span>, lower=<span class="literal">True</span>, vertex_source=<span class="string">&#x27;all_filters&#x27;</span>, edge_source=<span class="string">&#x27;no_stop_words&#x27;</span>,</span><br><span class="line">                 pagerank_config=&#123;<span class="string">&#x27;alpha&#x27;</span>: <span class="number">0.85</span>, &#125;)</span><br><span class="line">    <span class="comment"># text    --  文本内容，字符串</span></span><br><span class="line">    <span class="comment"># window  --  窗口大小，int，用来构造单词之间的边。默认值为2</span></span><br><span class="line">    <span class="comment"># lower   --  是否将英文文本转换为小写，默认值为False</span></span><br><span class="line">    <span class="comment"># vertex_source  -- 选择使用words_no_filter, words_no_stop_words, words_all_filters中的哪一个来构造pagerank对应的图中的节点</span></span><br><span class="line">    <span class="comment">#                -- 默认值为`&#x27;all_filters&#x27;`，可选值为`&#x27;no_filter&#x27;, &#x27;no_stop_words&#x27;, &#x27;all_filters&#x27;</span></span><br><span class="line">    <span class="comment"># edge_source  -- 选择使用words_no_filter, words_no_stop_words, words_all_filters中的哪一个来构造pagerank对应的图中的节点之间的边</span></span><br><span class="line">    <span class="comment">#              -- 默认值为`&#x27;no_stop_words&#x27;`，可选值为`&#x27;no_filter&#x27;, &#x27;no_stop_words&#x27;, &#x27;all_filters&#x27;`。边的构造要结合`window`参数</span></span><br><span class="line"> </span><br><span class="line">    <span class="comment"># pagerank_config  -- pagerank算法参数配置，阻尼系数为0.85</span></span><br><span class="line">    keywords = tr4w.get_keywords(num=<span class="number">6</span>, word_min_len=<span class="number">2</span>)</span><br><span class="line">    <span class="comment"># num           --  返回关键词数量</span></span><br><span class="line">    <span class="comment"># word_min_len  --  词的最小长度，默认值为1</span></span><br><span class="line">    <span class="keyword">return</span> keywords</span><br><span class="line"> </span><br><span class="line"><span class="comment">#关键短语抽取</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">keyphrases_extraction</span>(<span class="params">text</span>):</span><br><span class="line">    tr4w = TextRank4Keyword()</span><br><span class="line">    tr4w.analyze(text=text, window=<span class="number">2</span>, lower=<span class="literal">True</span>, vertex_source=<span class="string">&#x27;all_filters&#x27;</span>, edge_source=<span class="string">&#x27;no_stop_words&#x27;</span>,</span><br><span class="line">                 pagerank_config=&#123;<span class="string">&#x27;alpha&#x27;</span>: <span class="number">0.85</span>, &#125;)</span><br><span class="line">    keyphrases = tr4w.get_keyphrases(keywords_num=<span class="number">6</span>, min_occur_num=<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># keywords_num    --  抽取的关键词数量</span></span><br><span class="line">    <span class="comment"># min_occur_num   --  关键短语在文中的最少出现次数</span></span><br><span class="line">    <span class="keyword">return</span> keyphrases</span><br><span class="line"> </span><br><span class="line"><span class="comment">#关键句抽取</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">keysentences_extraction</span>(<span class="params">text</span>):</span><br><span class="line">    tr4s = TextRank4Sentence()</span><br><span class="line">    tr4s.analyze(text, lower=<span class="literal">True</span>, source=<span class="string">&#x27;all_filters&#x27;</span>)</span><br><span class="line">    <span class="comment"># text    -- 文本内容，字符串</span></span><br><span class="line">    <span class="comment"># lower   -- 是否将英文文本转换为小写，默认值为False</span></span><br><span class="line">    <span class="comment"># source  -- 选择使用words_no_filter, words_no_stop_words, words_all_filters中的哪一个来生成句子之间的相似度。</span></span><br><span class="line">    <span class="comment"># 		  -- 默认值为`&#x27;all_filters&#x27;`，可选值为`&#x27;no_filter&#x27;, &#x27;no_stop_words&#x27;, &#x27;all_filters&#x27;</span></span><br><span class="line">    <span class="comment"># sim_func -- 指定计算句子相似度的函数</span></span><br><span class="line"> </span><br><span class="line">    <span class="comment"># 获取最重要的num个长度大于等于sentence_min_len的句子用来生成摘要</span></span><br><span class="line">    keysentences = tr4s.get_key_sentences(num=<span class="number">3</span>, sentence_min_len=<span class="number">6</span>)</span><br><span class="line">    <span class="keyword">return</span> keysentences</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">keywords_textrank</span>(<span class="params">text</span>):</span><br><span class="line">    keywords = jieba.analyse.textrank(text, topK=<span class="number">6</span>)</span><br><span class="line">    <span class="keyword">return</span> keywords</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    text = <span class="string">&quot;来源：中国科学报本报讯（记者肖洁）又有一位中国科学家喜获小行星命名殊荣！4月19日下午，中国科学院国家天文台在京举行“周又元星”颁授仪式，&quot;</span> \</span><br><span class="line">           <span class="string">&quot;我国天文学家、中国科学院院士周又元的弟子与后辈在欢声笑语中济济一堂。国家天文台党委书记、&quot;</span> \</span><br><span class="line">           <span class="string">&quot;副台长赵刚在致辞一开始更是送上白居易的诗句：“令公桃李满天下，何须堂前更种花。”&quot;</span> \</span><br><span class="line">           <span class="string">&quot;据介绍，这颗小行星由国家天文台施密特CCD小行星项目组于1997年9月26日发现于兴隆观测站，&quot;</span> \</span><br><span class="line">           <span class="string">&quot;获得国际永久编号第120730号。2018年9月25日，经国家天文台申报，&quot;</span> \</span><br><span class="line">           <span class="string">&quot;国际天文学联合会小天体联合会小天体命名委员会批准，国际天文学联合会《小行星通报》通知国际社会，&quot;</span> \</span><br><span class="line">           <span class="string">&quot;正式将该小行星命名为“周又元星”。&quot;</span></span><br><span class="line">    <span class="comment">#关键词抽取</span></span><br><span class="line">    keywords=keywords_extraction(text)</span><br><span class="line">    <span class="built_in">print</span>(keywords)</span><br><span class="line"> </span><br><span class="line">    <span class="comment">#关键短语抽取</span></span><br><span class="line">    keyphrases=keyphrases_extraction(text)</span><br><span class="line">    <span class="built_in">print</span>(keyphrases)</span><br><span class="line"> </span><br><span class="line">    <span class="comment">#关键句抽取</span></span><br><span class="line">    keysentences=keysentences_extraction(text)</span><br><span class="line">    <span class="built_in">print</span>(keysentences)</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">[&#123;<span class="string">&#x27;word&#x27;</span>: <span class="string">&#x27;小行星&#x27;</span>, <span class="string">&#x27;weight&#x27;</span>: <span class="number">0.05808</span>&#125;, &#123;<span class="string">&#x27;word&#x27;</span>: <span class="string">&#x27;天文台&#x27;</span>, <span class="string">&#x27;weight&#x27;</span>: <span class="number">0.05721</span>&#125;, &#123;<span class="string">&#x27;word&#x27;</span>: <span class="string">&#x27;命名&#x27;</span>, <span class="string">&#x27;weight&#x27;</span>: <span class="number">0.048517</span>&#125;, &#123;<span class="string">&#x27;word&#x27;</span>: <span class="string">&#x27;中国&#x27;</span>, <span class="string">&#x27;weight&#x27;</span>: <span class="number">0.045716</span>&#125;, &#123;<span class="string">&#x27;word&#x27;</span>: <span class="string">&#x27;中国科学院&#x27;</span>, <span class="string">&#x27;weight&#x27;</span>: <span class="number">0.037818</span>&#125;, &#123;<span class="string">&#x27;word&#x27;</span>: <span class="string">&#x27;国家&#x27;</span>, <span class="string">&#x27;weight&#x27;</span>: <span class="number">0.03438</span>&#125;]</span><br><span class="line">[<span class="string">&#x27;小行星命名&#x27;</span>]</span><br><span class="line">[&#123;<span class="string">&#x27;index&#x27;</span>: <span class="number">4</span>, <span class="string">&#x27;sentence&#x27;</span>: <span class="string">&#x27;2018年9月25日，经国家天文台申报，国际天文学联合会小天体联合会小天体命名委员会批准，国际天文学联合会《小行星通报》通知国际社会，正式将该小行星命名为“周又元星”&#x27;</span>, <span class="string">&#x27;weight&#x27;</span>: <span class="number">0.2281</span>&#125;, &#123;<span class="string">&#x27;index&#x27;</span>: <span class="number">3</span>, <span class="string">&#x27;sentence&#x27;</span>: <span class="string">&#x27;”据介绍，这颗小行星由国家天文台施密特CCD小行星项目组于1997年9月26日发现于兴隆观测站，获得国际永久编号第120730号&#x27;</span>, <span class="string">&#x27;weight&#x27;</span>: <span class="number">0.2106</span>&#125;, &#123;<span class="string">&#x27;index&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;sentence&#x27;</span>: <span class="string">&#x27;4月19日下午，中国科学院国家天文台在京举行“周又元星”颁授仪式，我国天文学家、中国科学院院士周又元的弟子与后辈在欢声笑语中济济一堂&#x27;</span>, <span class="string">&#x27;weight&#x27;</span>: <span class="number">0.20209</span>&#125;]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<blockquote>
<p>基于jieba的TextRank算法实现</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    text = <span class="string">&quot;来源：中国科学报本报讯（记者肖洁）又有一位中国科学家喜获小行星命名殊荣！4月19日下午，中国科学院国家天文台在京举行“周又元星”颁授仪式，&quot;</span> \</span><br><span class="line">           <span class="string">&quot;我国天文学家、中国科学院院士周又元的弟子与后辈在欢声笑语中济济一堂。国家天文台党委书记、&quot;</span> \</span><br><span class="line">           <span class="string">&quot;副台长赵刚在致辞一开始更是送上白居易的诗句：“令公桃李满天下，何须堂前更种花。”&quot;</span> \</span><br><span class="line">           <span class="string">&quot;据介绍，这颗小行星由国家天文台施密特CCD小行星项目组于1997年9月26日发现于兴隆观测站，&quot;</span> \</span><br><span class="line">           <span class="string">&quot;获得国际永久编号第120730号。2018年9月25日，经国家天文台申报，&quot;</span> \</span><br><span class="line">           <span class="string">&quot;国际天文学联合会小天体联合会小天体命名委员会批准，国际天文学联合会《小行星通报》通知国际社会，&quot;</span> \</span><br><span class="line">           <span class="string">&quot;正式将该小行星命名为“周又元星”。&quot;</span></span><br><span class="line"> </span><br><span class="line">    <span class="comment"># 基于jieba的textrank算法实现</span></span><br><span class="line">    keywords=keywords_textrank(text)</span><br><span class="line">    <span class="built_in">print</span>(keywords)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">[<span class="string">&#x27;小行星&#x27;</span>, <span class="string">&#x27;命名&#x27;</span>, <span class="string">&#x27;国际&#x27;</span>, <span class="string">&#x27;中国&#x27;</span>, <span class="string">&#x27;国家&#x27;</span>, <span class="string">&#x27;天文学家&#x27;</span>]</span><br></pre></td></tr></table></figure>
<h2 id="RAKE"><a href="#RAKE" class="headerlink" title="RAKE"></a>RAKE</h2><p>RAKE和TextRank的主要区别在于RAKE考虑候选关键字内的共现而不是固定窗口。它使用更简单、更具统计性的评分程序。该算法对每个文档分别进行，因此不需要文档语料库来进行关键词提取</p>
<h1 id="基于深度学习"><a href="#基于深度学习" class="headerlink" title="基于深度学习"></a>基于深度学习</h1><p>深度学习的出现使基于嵌入的方法成为可能。研究人员开发了几种使用文档嵌入的关键字提取方法(例如Bennani等人)</p>
<p>这些方法主要查找候选关键字列表(例如，Bennani等人只考虑由名词和形容词组成的关键字)</p>
<p>他们将文档和候选关键字嵌入到相同的嵌入空间中，并测量文档和关键字嵌入之间的相似度(例如余弦相似度)。他们根据相似度度量选择与文档文本最相似的关键字</p>
<h2 id="SIFRank"><a href="#SIFRank" class="headerlink" title="SIFRank"></a>SIFRank</h2><blockquote>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8954611">SIFRank: A New Baseline for Unsupervised Keyphrase Extraction Based on Pre-Trained Language Model 2019</a></p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://blog.csdn.net/init__/article/details/121011012">论文阅读笔记： SIFRank and BERT-KPE</a></p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/sunyilgdx/SIFRank_zh">github sunyilgdx/SIFRank_zh</a></p>
</blockquote>
<p><code>SIFRank</code>比较适合短文本的关键词抽取，而<code>SIFRank+</code>大幅增加了长文本的关键词抽取效果</p>
<blockquote>
<p>步骤</p>
</blockquote>
<ol>
<li>人工标注：分词+标词性</li>
<li>获取候选关键词列表：利用正则表达式确定名词短语(例如：形容词+名词)，将名词短语作为候选关键短语</li>
<li>通过预训练语言模型，得到关键词的embedding</li>
<li>同样地，得到句子或文档的embedding</li>
<li>计算3与4结果的余弦相似度，选取topN作为其最终提取的关键词</li>
</ol>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i/hexo/bk_resources/deep_learning/nlp关键词和摘要提取技术整理/SIFRank模型架构图.webp" alt="SIFRank模型架构图"></p>
<blockquote>
<p>NP chunker</p>
</blockquote>
<p>在SIFRank方法中，NP chunker是一种用于识别和提取名词短语(Noun Phrase)的工具或组件。NP chunker的目标是从给定的文本中定位和提取出包含一个或多个名词的短语。名词短语通常由一个名词作为核心词，并可能包含其他修饰词或限定词</p>
<p>NP chunker使用一系列语法规则或机器学习模型来识别名词短语的边界，并将它们标记为一个单独的短语单元</p>
<p>这个过程有助于更好地理解文本的结构和语义，特别是在文本中涉及到名词短语的关键短语提取任务中。在SIFRank方法中，NP chunker用于提取候选关键短语，并为后续的关键短语排序和评分提供基础</p>
<h3 id="SIF模型"><a href="#SIF模型" class="headerlink" title="SIF模型"></a>SIF模型</h3><p>句子嵌入模型SIF(Smooth Inverse Frequency)是一种用于将句子转换为连续向量表示的方法</p>
<p>它旨在捕捉句子的语义信息，并将句子表示为稠密的低维向量。SIF模型的<strong>关键思想</strong>是<strong>结合词频信息来调整词向量的权重，以降低高频词的重要性，同时提高低频词的重要性</strong>。这样可以减轻一些常见词对句子表示的影响，使得句子表示更加注重那些在语义上更具区分度的词语。SIF模型通过简单的数学运算，如减法和加权平均，来计算句子的嵌入表示</p>
<p>它在自然语言处理任务中被广泛应用，如文本分类、情感分析和句子相似度计算等</p>
<p><strong>sentence embedding</strong>的假设是：文章是由一个topic生成的，文章中的每个句子亦是如此，因此，句子的embedding应该与文章embedding的期望值(topic embedding)相近</p>
<h2 id="Bert-KPE"><a href="#Bert-KPE" class="headerlink" title="Bert-KPE"></a>Bert-KPE</h2><blockquote>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://arxiv.org/pdf/2004.13639.pdf">Capturing Global Informativeness in Open Domain Keyphrase Extraction 2021</a></p>
</blockquote>
<p><code>BERT-KPE</code>是最近由thunlp提出的方法，在OpenKP和KP20K上都达到了state-of-the-art和良好的鲁棒性</p>
<p><strong>有监督的方式</strong></p>
<h2 id="KeyBert"><a href="#KeyBert" class="headerlink" title="KeyBert"></a>KeyBert</h2><blockquote>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://maartengr.github.io/KeyBERT/">KeyBERT</a></p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://grootendorst.netlify.app/blog/keybert/">Keyword Extraction with BERT</a></p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.zhihu.com/question/21104071/answer/2848388587">「关键词」提取都有哪些方案？</a></p>
</blockquote>
<p>当我们想要从特定文档中了解关键信息时，通常会使用关键词提取。关键词提取是一种自动化的过程，用于提取与输入文本最相关的单词和短语</p>
<p>通过使用Rake和YAKE!等方法，我们已经可以使用易于使用的软件包来提取关键词和关键短语。然而，这些模型通常基于文本的统计特性而不是语义相似性进行工作</p>
<p>于是BERT登场。BERT是一个双向变换器模型，可以将短语和文档转化为能够捕捉其意义的向量</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i/hexo/bk_resources/deep_learning/nlp关键词和摘要提取技术整理/无监督文本关键词抽取流程图.svg" alt="无监督文本关键词抽取流程图"></p>
<p>使用BERT提取文档向量(嵌入)以获取文档级表示。然后，针对N元语法词/短语提取词向量。最后，我们使用余弦相似度来查找与文档最相似的词/短语。然后，可以将最相似的词识定义为最能描述整个文档的词</p>
<h3 id="概述-2"><a href="#概述-2" class="headerlink" title="概述"></a>概述</h3><blockquote>
<p>什么是Keybert</p>
</blockquote>
<p>Keybert是一种<strong>基于无监督学习</strong>的关键词抽取技术，不仅效果好，而且易于使用</p>
<p>Keybert主要通过Bert获取文档和候选词的embedding，然后使用余弦相似度计算得到文档中最相似的候选词作为关键词</p>
<h3 id="多样性"><a href="#多样性" class="headerlink" title="多样性"></a>多样性</h3><p>在关键词提取中，多样性问题指的是关键词列表中存在大量相似或重复的关键词，缺乏多样性和代表性。这可能导致关键信息的丢失或重复，并降低关键词提取的效果</p>
<h4 id="MSS"><a href="#MSS" class="headerlink" title="MSS"></a>MSS</h4><p><code>最大总距离</code>(Max Sum Distance)：通过将文档中最相似的关键词/短语与候选关键词/短语进行组合，找到<strong>彼此之间相似性最低的组合</strong>，这样可以确保关键词之间的差异性</p>
<h4 id="MMR"><a href="#MMR" class="headerlink" title="MMR"></a>MMR</h4><p><code>最大边际相关性</code>（Maximal Marginal Relevance，MMR)：通过使用余弦相似度来创建关键词/短语，基于相似性的排序</p>
<p>然后，从排序后的结果中选择与文档最相关的关键词/短语，并选择与已选择关键词/短语<strong>最不相似的候选</strong>关键词/短语，这样可以确保结果具有高度的多样性</p>
<h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://maartengr.github.io/KeyBERT/guides/quickstart.html">KeyBert Quickstart</a></p>
<blockquote>
<p>安装</p>
</blockquote>
<figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 默认hugging face</span><br><span class="line">pip install keybert</span><br><span class="line"></span><br><span class="line"># 其他后端</span><br><span class="line">pip install keybert[flair]</span><br><span class="line">pip install keybert[gensim]</span><br><span class="line">pip install keybert[spacy]</span><br><span class="line">pip install keybert[use]</span><br></pre></td></tr></table></figure>
<h4 id="基础KeyBERT"><a href="#基础KeyBERT" class="headerlink" title="基础KeyBERT"></a>基础KeyBERT</h4><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i/hexo/bk_resources/deep_learning/nlp关键词和摘要提取技术整理/keyBert示例图.svg" alt="keyBert示例图"></p>
<blockquote>
<p>基础用法</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keybert <span class="keyword">import</span> KeyBERT</span><br><span class="line"></span><br><span class="line">doc = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">         Supervised learning is the machine learning task of learning a function that</span></span><br><span class="line"><span class="string">         maps an input to an output based on example input-output pairs.[1] It infers a</span></span><br><span class="line"><span class="string">         function from labeled training data consisting of a set of training examples.[2]</span></span><br><span class="line"><span class="string">         In supervised learning, each example is a pair consisting of an input object</span></span><br><span class="line"><span class="string">         (typically a vector) and a desired output value (also called the supervisory signal).</span></span><br><span class="line"><span class="string">         A supervised learning algorithm analyzes the training data and produces an inferred function,</span></span><br><span class="line"><span class="string">         which can be used for mapping new examples. An optimal scenario will allow for the</span></span><br><span class="line"><span class="string">         algorithm to correctly determine the class labels for unseen instances. This requires</span></span><br><span class="line"><span class="string">         the learning algorithm to generalize from the training data to unseen situations in a</span></span><br><span class="line"><span class="string">         &#x27;reasonable&#x27; way (see inductive bias).</span></span><br><span class="line"><span class="string">      &quot;&quot;&quot;</span></span><br><span class="line">kw_model = KeyBERT()</span><br><span class="line">keywords = kw_model.extract_keywords(doc)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置keyphrase_ngram_range来确定生成的关键词/关键短语的长度范围</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>kw_model.extract_keywords(doc, keyphrase_ngram_range=(<span class="number">1</span>, <span class="number">1</span>), stop_words=<span class="literal">None</span>)</span><br><span class="line">[(<span class="string">&#x27;learning&#x27;</span>, <span class="number">0.4604</span>),</span><br><span class="line"> (<span class="string">&#x27;algorithm&#x27;</span>, <span class="number">0.4556</span>),</span><br><span class="line"> (<span class="string">&#x27;training&#x27;</span>, <span class="number">0.4487</span>),</span><br><span class="line"> (<span class="string">&#x27;class&#x27;</span>, <span class="number">0.4086</span>),</span><br><span class="line"> (<span class="string">&#x27;mapping&#x27;</span>, <span class="number">0.3700</span>)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 要提取关键短语，只需将keyphrase_ngram_range设置为(1, 2)或更高，具体取决于您希望在生成的关键短语中包含的单词数量</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>kw_model.extract_keywords(doc, keyphrase_ngram_range=(<span class="number">1</span>, <span class="number">2</span>), stop_words=<span class="literal">None</span>)</span><br><span class="line">[(<span class="string">&#x27;learning algorithm&#x27;</span>, <span class="number">0.6978</span>),</span><br><span class="line"> (<span class="string">&#x27;machine learning&#x27;</span>, <span class="number">0.6305</span>),</span><br><span class="line"> (<span class="string">&#x27;supervised learning&#x27;</span>, <span class="number">0.5985</span>),</span><br><span class="line"> (<span class="string">&#x27;algorithm analyzes&#x27;</span>, <span class="number">0.5860</span>),</span><br><span class="line"> (<span class="string">&#x27;learning function&#x27;</span>, <span class="number">0.5850</span>)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置highlight来在文档中突出显示关键词</span></span><br><span class="line">keywords = kw_model.extract_keywords(doc, highlight=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>关键词多样化</p>
</blockquote>
<p>默认情况下，KeyBERT仅基于余弦相似度比较文档和候选关键词/关键短语。然而，这可能导致非常相似的单词出现在最准确的关键词/关键短语列表中</p>
<p>为了确保它们<strong>更加多样化</strong>，我们可以采取两种方法来微调输出结果，即<code>最大总距离</code>(Max Sum Distance)和<code>最大边际相关性</code>(Maximal Marginal Relevance)</p>
<ol>
<li><p><strong>最大总距离</strong>: 为了使结果多样化，我们选取文档中与前top_n个最相似的单词/短语。然后，我们从这2 x top_n个单词中选取所有top_n个组合，并提取彼此之间最不相似的组合，通过余弦相似度进行比较</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>kw_model.extract_keywords(doc, keyphrase_ngram_range=(<span class="number">3</span>, <span class="number">3</span>), stop_words=<span class="string">&#x27;english&#x27;</span>,</span><br><span class="line">                              use_maxsum=<span class="literal">True</span>, nr_candidates=<span class="number">20</span>, top_n=<span class="number">5</span>)</span><br><span class="line">[(<span class="string">&#x27;set training examples&#x27;</span>, <span class="number">0.7504</span>),</span><br><span class="line"> (<span class="string">&#x27;generalize training data&#x27;</span>, <span class="number">0.7727</span>),</span><br><span class="line"> (<span class="string">&#x27;requires learning algorithm&#x27;</span>, <span class="number">0.5050</span>),</span><br><span class="line"> (<span class="string">&#x27;supervised learning algorithm&#x27;</span>, <span class="number">0.3779</span>),</span><br><span class="line"> (<span class="string">&#x27;learning machine learning&#x27;</span>, <span class="number">0.2891</span>)]</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>最大边际相关性</strong>: 为了使结果多样化，我们可以使用最大边际相关性（Maximal Marginal Relevance，MMR）来创建关键词/关键短语，它也基于余弦相似度</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 具有高多样性的结果</span></span><br><span class="line">kw_model.extract_keywords(doc, keyphrase_ngram_range=(<span class="number">3</span>, <span class="number">3</span>), stop_words=<span class="string">&#x27;english&#x27;</span>,</span><br><span class="line">                          use_mmr=<span class="literal">True</span>, diversity=<span class="number">0.7</span>)</span><br><span class="line">[(<span class="string">&#x27;algorithm generalize training&#x27;</span>, <span class="number">0.7727</span>),</span><br><span class="line"> (<span class="string">&#x27;labels unseen instances&#x27;</span>, <span class="number">0.1649</span>),</span><br><span class="line"> (<span class="string">&#x27;new examples optimal&#x27;</span>, <span class="number">0.4185</span>),</span><br><span class="line"> (<span class="string">&#x27;determine class labels&#x27;</span>, <span class="number">0.4774</span>),</span><br><span class="line"> (<span class="string">&#x27;supervised learning algorithm&#x27;</span>, <span class="number">0.7502</span>)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 具有低多样性的结果</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>kw_model.extract_keywords(doc, keyphrase_ngram_range=(<span class="number">3</span>, <span class="number">3</span>), stop_words=<span class="string">&#x27;english&#x27;</span>,</span><br><span class="line">                              use_mmr=<span class="literal">True</span>, diversity=<span class="number">0.2</span>)</span><br><span class="line">[(<span class="string">&#x27;algorithm generalize training&#x27;</span>, <span class="number">0.7727</span>),</span><br><span class="line"> (<span class="string">&#x27;supervised learning algorithm&#x27;</span>, <span class="number">0.7502</span>),</span><br><span class="line"> (<span class="string">&#x27;learning machine learning&#x27;</span>, <span class="number">0.7577</span>),</span><br><span class="line"> (<span class="string">&#x27;learning algorithm analyzes&#x27;</span>, <span class="number">0.7587</span>),</span><br><span class="line"> (<span class="string">&#x27;learning algorithm generalize&#x27;</span>, <span class="number">0.7514</span>)]</span><br></pre></td></tr></table></figure>
</li>
</ol>
<blockquote>
<p>其他关键词算法生成的候选关键词</p>
</blockquote>
<p>在某些情况下，您可能希望使用其他关键词算法生成的候选关键词或从可能的关键词/关键短语列表中检索的候选关键词</p>
<p>在KeyBERT中，您可以轻松使用这些候选关键词进行关键词提取</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> yake</span><br><span class="line"><span class="keyword">from</span> keybert <span class="keyword">import</span> KeyBERT</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create candidates</span></span><br><span class="line">kw_extractor = yake.KeywordExtractor(top=<span class="number">50</span>)</span><br><span class="line">candidates = kw_extractor.extract_keywords(doc)</span><br><span class="line">candidates = [candidate[<span class="number">0</span>] <span class="keyword">for</span> candidate <span class="keyword">in</span> candidates]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Pass candidates to KeyBERT</span></span><br><span class="line">kw_model = KeyBERT()</span><br><span class="line">keywords = kw_model.extract_keywords(doc, candidates=candidates)</span><br></pre></td></tr></table></figure>
<h4 id="Guided-KeyBERT"><a href="#Guided-KeyBERT" class="headerlink" title="Guided KeyBERT"></a>Guided KeyBERT</h4><p><code>Guided KeyBERT</code>(引导式KeyBERT)与引导式主题建模类似，它试图将训练引导到一组种子术语上。当应用KeyBERT时，它会自动提取与特定文档最相关的关键词。然而，有时利益相关者和用户正在寻找特定类型的关键词。例如，当通过contentful在您的网站上发布一篇文章时，您通常已经了解与该文章相关的全局关键词。但是，文章中可能存在您希望通过关键词提取出来的特定主题。为了实现这一点，我们只需给KeyBERT提供一组相关的<strong>种子关键词</strong>(可以是单个关键词)，并搜索与文档和种子关键词都相似的关键词</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i/hexo/bk_resources/deep_learning/nlp关键词和摘要提取技术整理/Guided KeyBERT示例图.svg" alt="Guided KeyBERT示例图"></p>
<p>使用这个功能非常简单，只需定义一个种子关键词列表并将其传递给KeyBERT即可</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keybert <span class="keyword">import</span> KeyBERT</span><br><span class="line">kw_model = KeyBERT()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define our seeded term</span></span><br><span class="line">seed_keywords = [<span class="string">&quot;information&quot;</span>]</span><br><span class="line">keywords = kw_model.extract_keywords(doc, seed_keywords=seed_keywords)</span><br></pre></td></tr></table></figure>
<p>当你有一个大型数据集，并且想要微调诸如多样性之类的参数时，每次更改参数时重新计算文档和单词嵌入可能需要很长时间。相反，我们可以预先计算这些嵌入，并将它们传递给.extract_keywords，这样我们只需计算一次即可</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keybert <span class="keyword">import</span> KeyBERT</span><br><span class="line"></span><br><span class="line">kw_model = KeyBERT()</span><br><span class="line">doc_embeddings, word_embeddings = kw_model.extract_embeddings(docs)</span><br></pre></td></tr></table></figure>
<p>然后，你可以使用这些嵌入并将它们传递给.extract_keywords来加快模型的调整</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keywords = kw_model.extract_keywords(docs, doc_embeddings=doc_embeddings, word_embeddings=word_embeddings)</span><br></pre></td></tr></table></figure>
<p>.extract_embeddings中有几个参数定义了如何生成候选关键词/关键短语的列表：</p>
<ul>
<li><code>candidates</code></li>
<li><code>keyphrase_ngram_range</code></li>
<li><code>stop_words</code></li>
<li><code>min_df</code></li>
<li><code>vectorizer</code></li>
</ul>
<p>这些参数的值在.extract_embeddings和.extract_keywords中需要完全相同，换句话说，以下内容将起作用，因为它们使用相同的参数子集</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keybert <span class="keyword">import</span> KeyBERT</span><br><span class="line"></span><br><span class="line">kw_model = KeyBERT()</span><br><span class="line">doc_embeddings, word_embeddings = kw_model.extract_embeddings(docs, min_df=<span class="number">1</span>, stop_words=<span class="string">&quot;english&quot;</span>)</span><br><span class="line">keywords = kw_model.extract_keywords(docs, min_df=<span class="number">1</span>, stop_words=<span class="string">&quot;english&quot;</span>, </span><br><span class="line">                                     doc_embeddings=doc_embeddings, </span><br><span class="line">                                     word_embeddings=word_embeddings)</span><br></pre></td></tr></table></figure>
<p>然而，以下内容将抛出错误，因为我们没有为min_df和stop_words使用相同的值</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keybert <span class="keyword">import</span> KeyBERT</span><br><span class="line"></span><br><span class="line">kw_model = KeyBERT()</span><br><span class="line">doc_embeddings, word_embeddings = kw_model.extract_embeddings(docs, min_df=<span class="number">3</span>, stop_words=<span class="string">&quot;dutch&quot;</span>)</span><br><span class="line">keywords = kw_model.extract_keywords(docs, min_df=<span class="number">1</span>, stop_words=<span class="string">&quot;english&quot;</span>, </span><br><span class="line">                                     doc_embeddings=doc_embeddings, </span><br><span class="line">                                     word_embeddings=word_embeddings)</span><br></pre></td></tr></table></figure>
<h1 id="摘要提取"><a href="#摘要提取" class="headerlink" title="摘要提取"></a>摘要提取</h1><p>等待…</p>
<p>生成式 + 抽取式</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/narutohyc">narutohyc</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://study.hycbook.com/article/42898.html">https://study.hycbook.com/article/42898.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="external nofollow noreferrer" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://study.hycbook.com" target="_blank">兼一书虫</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><a class="post-meta__tags" href="/tags/%E5%85%B3%E9%94%AE%E8%AF%8D%E6%8F%90%E5%8F%96/">关键词提取</a><a class="post-meta__tags" href="/tags/%E6%91%98%E8%A6%81%E7%94%9F%E6%88%90-%E6%8F%90%E5%8F%96/">摘要生成|提取</a></div><div class="post_share"><div class="social-share" data-image="https://pic.hycbook.com/i/hexo/post_cover/蕾姆1.webp" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><link rel="stylesheet" href="/" media="defer" onload="this.media='all'"/><div class="post-reward"><button class="tip-button reward-button"><span class="tip-button__text">打赏</span><div class="coin-wrapper"><div class="coin"><div class="coin__middle"></div><div class="coin__back"></div><div class="coin__front"></div></div></div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="https://pic.hycbook.com/i//hexo/qr_codes/hyc_wechat.webp" rel="external nofollow noreferrer" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i//hexo/qr_codes/hyc_wechat.webp" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="https://pic.hycbook.com/i//hexo/qr_codes/hyc_alipay.webp" rel="external nofollow noreferrer" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i//hexo/qr_codes/hyc_alipay.webp" alt="alipay"/></a><div class="post-qr-code-desc">alipay</div></li></ul></div></button></div><audio id="coinAudio" src="https://s1.vika.cn/space/2022/10/29/6db0ad2bccf949f09054b3b206dcc66f?attname=马里奥游戏投币叮当.mp3"></audio><script defer="defer" src="/"></script><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/article/59381.html"><img class="prev-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i/hexo/post_cover/蕾姆0.webp" onerror="onerror=null;src='https://pic.hycbook.com/i/hexo/config_imgs/404.svg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">LLM模型微调系列</div></div></a></div><div class="next-post pull-right"><a href="/article/47450.html"><img class="next-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i/hexo/post_cover/蕾姆2.webp" onerror="onerror=null;src='https://pic.hycbook.com/i/hexo/config_imgs/404.svg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">图神经网络</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/article/47450.html" title="图神经网络"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i/hexo/post_cover/蕾姆2.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-08-16</div><div class="title">图神经网络</div></div></a></div><div><a href="/article/53377.html" title="深度学习模型压缩技术"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i/hexo/post_cover/蕾姆11.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-06-04</div><div class="title">深度学习模型压缩技术</div></div></a></div><div><a href="/article/24897.html" title="LLM模型部署调试推理"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i/hexo/post_cover/蕾姆12.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-06-12</div><div class="title">LLM模型部署调试推理</div></div></a></div><div><a href="/article/35455.html" title="深度学习在图像领域的应用"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i/hexo/post_cover/蕾姆1.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-02-23</div><div class="title">深度学习在图像领域的应用</div></div></a></div><div><a href="/article/46832.html" title="深度学习核心之损失函数"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i/hexo/post_cover/蕾姆8.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-05-26</div><div class="title">深度学习核心之损失函数</div></div></a></div><div><a href="/article/22410.html" title="深度学习核心之激活函数"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i/hexo/post_cover/蕾姆7.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-05-26</div><div class="title">深度学习核心之激活函数</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div><div id="comment-switch"><span class="first-comment">Twikoo</span><span class="switch-btn"></span><span class="second-comment">Valine</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%88%87%E8%AF%8D"><span class="toc-number">1.</span> <span class="toc-text">切词</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%85%B3%E9%94%AE%E8%AF%8D%E6%8F%90%E5%8F%96"><span class="toc-number">2.</span> <span class="toc-text">关键词提取</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A6%82%E8%BF%B0"><span class="toc-number">2.1.</span> <span class="toc-text">概述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%86%E7%B1%BB"><span class="toc-number">2.2.</span> <span class="toc-text">分类</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E7%BB%9F%E8%AE%A1"><span class="toc-number">3.</span> <span class="toc-text">基于统计</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#tf-idf"><span class="toc-number">3.1.</span> <span class="toc-text">tf-idf</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#YAKE"><span class="toc-number">3.2.</span> <span class="toc-text">YAKE</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A6%82%E8%BF%B0-1"><span class="toc-number">3.2.1.</span> <span class="toc-text">概述</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E5%9B%BE%E6%8A%80%E6%9C%AF"><span class="toc-number">4.</span> <span class="toc-text">基于图技术</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#TextRank"><span class="toc-number">4.1.</span> <span class="toc-text">TextRank</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#PageRank"><span class="toc-number">4.1.1.</span> <span class="toc-text">PageRank</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0"><span class="toc-number">4.1.2.</span> <span class="toc-text">实现</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#RAKE"><span class="toc-number">4.2.</span> <span class="toc-text">RAKE</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0"><span class="toc-number">5.</span> <span class="toc-text">基于深度学习</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#SIFRank"><span class="toc-number">5.1.</span> <span class="toc-text">SIFRank</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#SIF%E6%A8%A1%E5%9E%8B"><span class="toc-number">5.1.1.</span> <span class="toc-text">SIF模型</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Bert-KPE"><span class="toc-number">5.2.</span> <span class="toc-text">Bert-KPE</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#KeyBert"><span class="toc-number">5.3.</span> <span class="toc-text">KeyBert</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A6%82%E8%BF%B0-2"><span class="toc-number">5.3.1.</span> <span class="toc-text">概述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%9A%E6%A0%B7%E6%80%A7"><span class="toc-number">5.3.2.</span> <span class="toc-text">多样性</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#MSS"><span class="toc-number">5.3.2.1.</span> <span class="toc-text">MSS</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#MMR"><span class="toc-number">5.3.2.2.</span> <span class="toc-text">MMR</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%A4%BA%E4%BE%8B"><span class="toc-number">5.3.3.</span> <span class="toc-text">示例</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9F%BA%E7%A1%80KeyBERT"><span class="toc-number">5.3.3.1.</span> <span class="toc-text">基础KeyBERT</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Guided-KeyBERT"><span class="toc-number">5.3.3.2.</span> <span class="toc-text">Guided KeyBERT</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%91%98%E8%A6%81%E6%8F%90%E5%8F%96"><span class="toc-number">6.</span> <span class="toc-text">摘要提取</span></a></li></ol></div></div></div></div></main><footer id="footer" style="background-image: url('https://pic.hycbook.com/i/hexo/config_imgs/footer_bg.webp')"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2024 By narutohyc</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener external nofollow noreferrer" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text"><p><a target="_blank" href="https://hexo.io/" rel="external nofollow noreferrer"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&logo=hexo" title="博客框架为Hexo"></a>&nbsp;<a target="_blank" href="https://demo.jerryc.me/" rel="external nofollow noreferrer"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&logo=bitdefender" title="主题采用butterfly"></a>&nbsp;<a target="_blank" href="https://vercel.com/ " rel="external nofollow noreferrer"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Hosted-Vervel-brightgreen?style=flat&logo=Vercel" title="本站采用双线部署，默认线路托管于Vercel"></a>&nbsp;<a target="_blank" href="https://github.com/" rel="external nofollow noreferrer"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&logo=GitHub" title="本站项目由Gtihub托管"></a>&nbsp;<a target="_blank" href="https://zixiaoyun.com" rel="external nofollow noreferrer"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/图床-薄荷图床-green" title="薄荷图床"></a></p><a target="_blank" href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=35020502000647" rel="external nofollow noreferrer"><img style="position:relative;top:4px" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i//hexo/config_imgs//备案图标.webp" alt="ICP"/>闽公网安备35020502000647号  </a><a href="https://beian.miit.gov.cn/" rel="external nofollow noreferrer" target="_blank">闽ICP备2023021562号-1</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">简</button><!-- button#darkmode(type="button" title=_p('rightside.night_mode_title'))--><!--  i.fas.fa-adjust--><a class="icon-V hidden" onclick="switchNightMode()" title="浅色和深色模式转换"><svg width="25" height="25" viewBox="0 0 1024 1024"><use id="modeicon" xlink:href="#icon-moon"></use></svg></a><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div id="rightMenu"><div class="rightMenu-group rightMenu-small"><div class="rightMenu-item" id="menu-backward"><i class="fa-solid fa-arrow-left"></i></div><div class="rightMenu-item" id="menu-forward"><i class="fa-solid fa-arrow-right"></i></div><div class="rightMenu-item" id="menu-refresh"><i class="fa-solid fa-arrow-rotate-right"></i></div><div class="rightMenu-item" id="menu-home"><i class="fa-solid fa-house"></i></div></div><div class="rightMenu-group rightMenu-line hide" id="menu-text"><a class="rightMenu-item" href="javascript:window.open(&quot;https://www.baidu.com/s?wd=&quot;+window.getSelection().toString());window.location.reload();" rel="external nofollow noreferrer"><i class="fas fa-comment"></i><span>百度搜索</span></a></div><div class="rightMenu-group rightMenu-line rightMenuOther"><a class="rightMenu-item menu-link" href="/archives/"><i class="fa-solid fa-archive"></i><span>文章归档</span></a><a class="rightMenu-item menu-link" href="/categories/"><i class="fa-solid fa-folder-open"></i><span>文章分类</span></a><a class="rightMenu-item menu-link" href="/tags/"><i class="fa-solid fa-tags"></i><span>文章标签</span></a></div><div class="rightMenu-group rightMenu-line rightMenuNormal"><a class="rightMenu-item menu-link" id="menu-radompage"><i class="fa-solid fa-shoe-prints"></i><span>随便逛逛</span></a><div class="rightMenu-item" id="menu-translate"><i class="fa-solid fa-earth-asia"></i><span>繁简切换</span></div><div class="rightMenu-item" id="menu-darkmode"><i class="fa-solid fa-moon"></i><span>切换模式</span></div></div></div><div id="rightmenu-mask"></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script>(() => {
  const $mermaidWrap = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaidWrap.length) {
    window.runMermaid = () => {
      window.loadMermaid = true
      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? '' : ''

      Array.from($mermaidWrap).forEach((item, index) => {
        const mermaidSrc = item.firstElementChild
        const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
        const mermaidID = 'mermaid-' + index
        const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent
        mermaid.mermaidAPI.render(mermaidID, mermaidDefinition, (svgCode) => {
          mermaidSrc.insertAdjacentHTML('afterend', svgCode)
        })
      })
    }

    const loadMermaid = () => {
      window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
    }

    window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
  }
})()</script><script>(()=>{
  const init = () => {
    twikoo.init(Object.assign({
      el: '#twikoo-wrap',
      envId: 'https://vercel.hycbook.com',
      region: '',
      onCommentLoaded: function () {
        btf.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.tk-owo-emotion)'))
      }
    }, null))
  }

  const getCount = () => {
    const countELement = document.getElementById('twikoo-count')
    if(!countELement) return
    twikoo.getCommentsCount({
      envId: 'https://vercel.hycbook.com',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      countELement.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const runFn = () => {
    init()
    GLOBAL_CONFIG_SITE.isPost && getCount()
  }

  const loadTwikoo = () => {
    if (typeof twikoo === 'object') {
      setTimeout(runFn,0)
      return
    } 
    getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(runFn)
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo()
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script><script>function loadValine () {
  function initValine () {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: 'ncn88uooQf0IO2rrGE7Vniwp-gzGzoHsz',
      appKey: 'Yghpzg1QfBMFJ0MxxHubVzKL',
      avatar: 'monsterid',
      serverURLs: '',
      emojiMaps: "",
      path: window.location.pathname,
      visitor: true
    }, null))
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
}

if ('Twikoo' === 'Valine' || !false) {
  if (false) btf.loadComment(document.getElementById('vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script></div><script>window.addEventListener('load', () => {
  const changeContent = (content) => {
    if (content === '') return content

    content = content.replace(/<img.*?src="(.*?)"?[^\>]+>/ig, '[图片]') // replace image link
    content = content.replace(/<a[^>]+?href=["']?([^"']+)["']?[^>]*>([^<]+)<\/a>/gi, '[链接]') // replace url
    content = content.replace(/<pre><code>.*?<\/pre>/gi, '[代码]') // replace code
    content = content.replace(/<[^>]+>/g,"") // remove html tag

    if (content.length > 150) {
      content = content.substring(0,150) + '...'
    }
    return content
  }

  const getComment = () => {
    const runTwikoo = () => {
      twikoo.getRecentComments({
        envId: 'https://vercel.hycbook.com',
        region: '',
        pageSize: 3,
        includeReply: true
      }).then(function (res) {
        const twikooArray = res.map(e => {
          return {
            'content': changeContent(e.comment),
            'avatar': e.avatar,
            'nick': e.nick,
            'url': e.url + '#' + e.id,
            'date': new Date(e.created).toISOString()
          }
        })

        saveToLocal.set('twikoo-newest-comments', JSON.stringify(twikooArray), 10/(60*24))
        generateHtml(twikooArray)
      }).catch(function (err) {
        const $dom = document.querySelector('#card-newest-comments .aside-list')
        $dom.innerHTML= "无法获取评论，请确认相关配置是否正确"
      })
    }

    if (typeof twikoo === 'object') {
      runTwikoo()
    } else {
      getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(runTwikoo)
    }
  }

  const generateHtml = array => {
    let result = ''

    if (array.length) {
      for (let i = 0; i < array.length; i++) {
        result += '<div class=\'aside-list-item\'>'

        if (true) {
          const name = 'data-lazy-src'
          result += `<a href='${array[i].url}' class='thumbnail'><img ${name}='${array[i].avatar}' alt='${array[i].nick}'></a>`
        }
        
        result += `<div class='content'>
        <a class='comment' href='${array[i].url}' title='${array[i].content}'>${array[i].content}</a>
        <div class='name'><span>${array[i].nick} / </span><time datetime="${array[i].date}">${btf.diffDate(array[i].date, true)}</time></div>
        </div></div>`
      }
    } else {
      result += '没有评论'
    }

    let $dom = document.querySelector('#card-newest-comments .aside-list')
    $dom.innerHTML= result
    window.lazyLoadInstance && window.lazyLoadInstance.update()
    window.pjax && window.pjax.refresh($dom)
  }

  const newestCommentInit = () => {
    if (document.querySelector('#card-newest-comments .aside-list')) {
      const data = saveToLocal.get('twikoo-newest-comments')
      if (data) {
        generateHtml(JSON.parse(data))
      } else {
        getComment()
      }
    }
  }

  newestCommentInit()
  document.addEventListener('pjax:complete', newestCommentInit)
})</script><script defer src="https://npm.elemecdn.com/jquery@latest/dist/jquery.min.js"></script><script defer data-pjax src="/zhheo/random.js"></script><script data-pjax src="/js/coin.js"></script><script defer src="https://npm.elemecdn.com/vue@2.6.11"></script><script async src="//at.alicdn.com/t/c/font_3670467_a0sijt8frxo.js"></script><script defer src="/live2d-widget/autoload.js"></script><script defer src="https://cdnjs.cloudflare.com/ajax/libs/toastr.js/latest/toastr.min.js"></script><script data-pjax defer src="https://npm.elemecdn.com/tzy-blog/lib/js/theme/chocolate.js"></script><script defer data-pjax src="/js/rightMenu.js"></script><script defer data-pjax src="/js/udf_mouse.js"></script><script defer data-pjax src="/js/udf_js.js"></script><script defer src="/js/udf_js.js"></script><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-fluttering-ribbon.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = false;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-heart.min.js" async="async" mobile="true"></script><script>window.$crisp = [];
window.CRISP_WEBSITE_ID = "561b80db-3f0f-45cb-b3b1-aae7355939e6";
(function () {
  d = document;
  s = d.createElement("script");
  s.src = "https://client.crisp.chat/l.js";
  s.async = 1;
  d.getElementsByTagName("head")[0].appendChild(s);
})();
$crisp.push(["safe", true])

if (false) {
  $crisp.push(["do", "chat:hide"])
  $crisp.push(["on", "chat:closed", function() {
    $crisp.push(["do", "chat:hide"])
  }])
  var chatBtnFn = () => {
    var chatBtn = document.getElementById("chat_btn")
    chatBtn.addEventListener("click", function(){
      $crisp.push(["do", "chat:show"])
      $crisp.push(["do", "chat:open"])

    });
  }
  chatBtnFn()
} else {
  if (false) {
    function chatBtnHide () {
      $crisp.push(["do", "chat:hide"])
    }
    function chatBtnShow () {
      $crisp.push(["do", "chat:show"])
    }
  }
}</script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener scroll 
  window.tocScrollFn && window.removeEventListener('scroll', window.tocScrollFn)
  window.scrollCollect && window.removeEventListener('scroll', scrollCollect)

  typeof preloader === 'object' && preloader.initLoading()
  document.getElementById('rightside').style.cssText = "opacity: ''; transform: ''"
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

  typeof disqusjs === 'object' && disqusjs.destroy()
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()

  typeof preloader === 'object' && preloader.endLoading()
})

document.addEventListener('pjax:error', (e) => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div class="app-refresh" id="app-refresh" style="position: fixed;top: -2.2rem;left: 0;right: 0;z-index: 99999;padding: 0 1rem;font-size: 15px;height: 2.2rem;transition: all 0.3s ease;"><div class="app-refresh-wrap" style=" display: flex;color: #fff;height: 100%;align-items: center;justify-content: center;"><label>✨ 兼一书虫上新啦！ 👉</label><a href="javascript:void(0)" rel="external nofollow noreferrer" onclick="location.reload()"><span style="color: #fff;text-decoration: underline;cursor: pointer;">🍭查看新品🍬</span></a></div></div><script>if ('serviceWorker' in navigator) {
  if (navigator.serviceWorker.controller) {
    navigator.serviceWorker.addEventListener('controllerchange', function() {
      showNotification()
    })
  }
  window.addEventListener('load', function() {
    navigator.serviceWorker.register('/sw.js')
  })
}

function showNotification() {
  if (GLOBAL_CONFIG.Snackbar) {
    var snackbarBg =
      document.documentElement.getAttribute('data-theme') === 'light' ?
      GLOBAL_CONFIG.Snackbar.bgLight :
      GLOBAL_CONFIG.Snackbar.bgDark
    var snackbarPos = GLOBAL_CONFIG.Snackbar.position
    Snackbar.show({
      text: '✨ 兼一书虫上新啦！ 👉',
      backgroundColor: snackbarBg,
      duration: 500000,
      pos: snackbarPos,
      actionText: '🍭查看新品🍬',
      actionTextColor: '#fff',
      onActionClick: function(e) {
        location.reload()
      },
    })
  } else {
    var showBg =
      document.documentElement.getAttribute('data-theme') === 'light' ?
      '#49b1f5' :
      '#1f1f1f'
    var cssText = `top: 0; background: ${showBg};`
    document.getElementById('app-refresh')
      .style.cssText = cssText
  }
}</script></div><!-- hexo injector body_end start --><script async src="//at.alicdn.com/t/font_2032782_8d5kxvn09md.js"></script><!-- hexo injector body_end end --></body></html>