<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>机器学习_线性代数与矩阵论(2) | 兼一书虫</title><meta name="keywords" content="机器学习数学,线性代数,矩阵论"><meta name="author" content="narutohyc"><meta name="copyright" content="narutohyc"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="机器学习的数学基础入门知识">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习_线性代数与矩阵论(2)">
<meta property="og:url" content="https://study.hycbook.com/article/58496.html">
<meta property="og:site_name" content="兼一书虫">
<meta property="og:description" content="机器学习的数学基础入门知识">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://pic.hycbook.com/i/hexo/post_cover/%E8%95%BE%E5%A7%865.webp">
<meta property="article:published_time" content="2023-09-08T01:42:38.000Z">
<meta property="article:modified_time" content="2023-09-08T01:50:08.186Z">
<meta property="article:author" content="narutohyc">
<meta property="article:tag" content="机器学习数学">
<meta property="article:tag" content="线性代数">
<meta property="article:tag" content="矩阵论">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://pic.hycbook.com/i/hexo/post_cover/%E8%95%BE%E5%A7%865.webp"><link rel="shortcut icon" href="https://pic.hycbook.com/i//hexo/config_imgs/网站图标.webp"><link rel="canonical" href="https://study.hycbook.com/article/58496"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="manifest" href="/manifest.json"/><meta name="msapplication-TileColor" content="#c6ff7a"/><link rel="apple-touch-icon" sizes="180x180" href="https://pic.hycbook.com/i//hexo/source/img/siteicon/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="https://pic.hycbook.com/i//hexo/source/img/siteicon/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="https://pic.hycbook.com/i//hexo/source/img/siteicon/favicon-16x16.png"/><link rel="mask-icon" href="https://pic.hycbook.com/i//hexo/source/img/siteicon/safari-pinned-tab.svg" color="#5bbad5"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?68340394dfd808cea9826e8a57f87aa6";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: {"defaultEncoding":1,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: {"limitDay":120,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":400},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":200,"languages":{"author":"作者: narutohyc","link":"链接: ","source":"来源: 兼一书虫","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '机器学习_线性代数与矩阵论(2)',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-09-08 09:50:08'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/hyc_udf.css"><link rel="stylesheet" href="/css/udf_css.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/js-heo@1.0.11/mainColor/heoMainColor.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/js-heo@1.0.11/404/404.css"><script src="https://npm.elemecdn.com/echarts@4.9.0/dist/echarts.min.js"></script><link href="https://cdn.bootcdn.net/ajax/libs/toastr.js/2.1.4/toastr.min.css" rel="stylesheet"><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.cbd.int/hexo-butterfly-tag-plugins-plus@latest/lib/assets/font-awesome-animation.min.css" media="defer" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.cbd.int/hexo-butterfly-tag-plugins-plus@latest/lib/tag_plugins.css" media="defer" onload="this.media='all'"><script src="https://cdn.cbd.int/hexo-butterfly-tag-plugins-plus@latest/lib/assets/carousel-touch.js"></script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i/hexo/person_img/兼一头像.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">118</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">169</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">9</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-fangwu"></use></svg><span> 首页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-wenzhang1">             </use></svg><span> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-guidang">                   </use></svg><span> 归档</span></a></li><li><a class="site-page child" href="/categories"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-fenlei">                   </use></svg><span> 分类</span></a></li><li><a class="site-page child" href="/tags"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-biaoqian">                   </use></svg><span> 标签</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-wenzhang1">             </use></svg><span> gitbook版</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://common.hycbook.com"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-guidang">                   </use></svg><span> common</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://python.hycbook.com"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-fenlei">                   </use></svg><span> python</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://dl.hycbook.com"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-biaoqian">                   </use></svg><span> 深度学习</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-xuegao">             </use></svg><span> 娱乐</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-yinle">                   </use></svg><span> 音乐</span></a></li><li><a class="site-page child" href="/bangumis"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-wodezhuifan">                   </use></svg><span> 追番</span></a></li><li><a class="site-page child" href="/gallery"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-xiangce">                   </use></svg><span> 相册</span></a></li><li><a class="site-page child" href="/video"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-shipin">                   </use></svg><span> 视频</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/charts"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-xigua"></use></svg><span> 统计图</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-suannai">             </use></svg><span> 网盘</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://pan.hycbook.com"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-guidang">                   </use></svg><span> 私月盘</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://share.hycbook.com"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-zhifengche">                   </use></svg><span> 共享盘</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-zhifeiji">             </use></svg><span> 导航</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/comments"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-TIFFANYSROOM_huaban">                   </use></svg><span> 留言板</span></a></li><li><a class="site-page child" href="/link"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-changyonglianjie">                   </use></svg><span> 友链</span></a></li><li><a class="site-page child" href="/about"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-aixin">                   </use></svg><span> 关于</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://pic.hycbook.com/i/hexo/post_imgs/蕾姆5.webp')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">兼一书虫</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-fangwu"></use></svg><span> 首页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-wenzhang1">             </use></svg><span> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-guidang">                   </use></svg><span> 归档</span></a></li><li><a class="site-page child" href="/categories"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-fenlei">                   </use></svg><span> 分类</span></a></li><li><a class="site-page child" href="/tags"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-biaoqian">                   </use></svg><span> 标签</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-wenzhang1">             </use></svg><span> gitbook版</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://common.hycbook.com"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-guidang">                   </use></svg><span> common</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://python.hycbook.com"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-fenlei">                   </use></svg><span> python</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://dl.hycbook.com"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-biaoqian">                   </use></svg><span> 深度学习</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-xuegao">             </use></svg><span> 娱乐</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-yinle">                   </use></svg><span> 音乐</span></a></li><li><a class="site-page child" href="/bangumis"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-wodezhuifan">                   </use></svg><span> 追番</span></a></li><li><a class="site-page child" href="/gallery"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-xiangce">                   </use></svg><span> 相册</span></a></li><li><a class="site-page child" href="/video"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-shipin">                   </use></svg><span> 视频</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/charts"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-xigua"></use></svg><span> 统计图</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-suannai">             </use></svg><span> 网盘</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://pan.hycbook.com"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-guidang">                   </use></svg><span> 私月盘</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://share.hycbook.com"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-zhifengche">                   </use></svg><span> 共享盘</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-zhifeiji">             </use></svg><span> 导航</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/comments"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-TIFFANYSROOM_huaban">                   </use></svg><span> 留言板</span></a></li><li><a class="site-page child" href="/link"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-changyonglianjie">                   </use></svg><span> 友链</span></a></li><li><a class="site-page child" href="/about"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-aixin">                   </use></svg><span> 关于</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">机器学习_线性代数与矩阵论(2)</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-09-08T01:42:38.000Z" title="发表于 2023-09-08 09:42:38">2023-09-08</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-09-08T01:50:08.186Z" title="更新于 2023-09-08 09:50:08">2023-09-08</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/math/">math</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">925</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>3分钟</span></span><span class="post-meta-separator">|</span><span id="" data-flag-title="机器学习_线性代数与矩阵论(2)"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="twikoo_visitors"><i class="fa-solid fa-spinner fa-spin"></i></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/article/58496.html#post-comment"><span id="twikoo-count"><i class="fa-solid fa-spinner fa-spin"></i></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><hr>
<h1 id="线性方程组"><a href="#线性方程组" class="headerlink" title="线性方程组"></a>线性方程组</h1><h2 id="高斯消元法"><a href="#高斯消元法" class="headerlink" title="高斯消元法"></a>高斯消元法</h2><p><code>高斯消元法</code>(Gaussian Elimination Method)即<code>加减消元法</code>，是求解线性方程组的经典方法</p>
<p>通过将一个方程减掉另一个方程的倍数消掉末知数，得到<code>阶梯型方程组</code>，然后依次解出每一个末知数</p>
<p>下面用一个简单的例子进行说明，对于如下的线性方程组</p>
<script type="math/tex; mode=display">
\left\{\begin{array}{l}
2 x_{1}+x_{2}+x_{3}=1 \\
6 x_{1}+2 x_{2}+x_{3}=-1 \\
-2 x_{1}+2 x_{2}+x_{3}=7
\end{array}\right.</script><p>先消去方程2和方程3的第一个末知数，将方程2减去方程1的3倍，将方程3加上方程1，消掉方程2和方程3中的$x_{1}$，得</p>
<script type="math/tex; mode=display">
\left\{\begin{array}{l}
2 x_{1}+x_{2}+x_{3}=1 \\
-x_{2}-2 x_{3}=-4 \\
3 x_{2}+2 x_{3}=8
\end{array}\right.</script><p>然后将方程3加上方程2的3倍，消掉方程3中的$x_{2}$，得</p>
<script type="math/tex; mode=display">
\left\{\begin{array}{l}
2 x_{1}+x_{2}+x_{3}=1 \\
-x_{2}-2 x_{3}=-4 \\
-4 x_{3}=-4
\end{array}\right.</script><p>可以解得</p>
<script type="math/tex; mode=display">
x_{1}=-1 \qquad x_{2}=2 \qquad x_{3}=1</script><p>下面用矩阵的形式描述这一求解过程，如下所示</p>
<script type="math/tex; mode=display">
\left(\begin{array}{cccc}
2 & 1 & 1 & 1 \\
6 & 2 & 1 & -1 \\
-2 & 2 & 1 & 7
\end{array}\right) \stackrel{r_{2}-3 \times r_{1}, r_{3}+r_{1}}{\longrightarrow}\left(\begin{array}{cccc}
2 & 1 & 1 & 1 \\
0 & -1 & -2 & -4 \\
0 & 3 & 2 & 8
\end{array}\right) \stackrel{r_{3}+3 \times r_{2}}{\longrightarrow}\left(\begin{array}{cccc}
2 & 1 & 1 & 1 \\
0 & -1 & -2 & -4 \\
0 & 0 & -4 & -4
\end{array}\right)</script><p>下面将这种消元法进行推广，对于任意的线性方程组，采用如下的初等变换对其进行变形，方程组的解不变</p>
<ol>
<li>交换两个方程的位置</li>
<li>用非0的常数乘以某方程的两端</li>
<li>将一个方程的常数倍加到另一个方程上去</li>
</ol>
<p>采用这种初等变换，每次消掉一个末知数，最后得到一个阶梯形方程组，即可求出方程的解</p>
<h2 id="齐次方程组"><a href="#齐次方程组" class="headerlink" title="齐次方程组"></a>齐次方程组</h2><p><code>齐次线性方程组</code>(Homogeneous Linear Equations)是常数项全部为0的线性方程组，可以写成如下形式</p>
<script type="math/tex; mode=display">
\boldsymbol{A x}=\mathbf{0}</script><p>其中$\boldsymbol{A} \in \mathbb{R}^{m \times n}, \boldsymbol{x} \in \mathbb{R}^{n}$ </p>
<p>将系数矩阵$\boldsymbol{A}$按列分块为<script type="math/tex">\left(\boldsymbol{a}_{1} \cdots \boldsymbol{a}_{n}\right)</script>，齐次方程可以写成</p>
<script type="math/tex; mode=display">
x_{1} \boldsymbol{a}_{1}+\cdots+x_{n} \boldsymbol{a}_{n}=\mathbf{0}</script><p>以解向量<script type="math/tex">\boldsymbol{x}=\left(x_{1} \cdots x_{n}\right)^{\mathrm{T}}</script>为组合系数，向量组<script type="math/tex">\boldsymbol{a}_{1}, \cdots, \boldsymbol{a}_{n}</script>的线性组合为0向量</p>
<p>显然$\boldsymbol{x}=\mathbf{0}$是方程组的解，因此齐次方程一定有解，更重要的是，除$\boldsymbol{x}=\mathbf{0}$ 外的解，称为<code>非0解</code>，下面讨论这种解的存在性</p>
<p>根据线性相关性的定义，如果向量组<script type="math/tex">\boldsymbol{a}_{1}, \cdots, \boldsymbol{a}_{n}</script>线性无关，则不存在一组不全为0的系数<script type="math/tex">\boldsymbol{x}</script>使得其线性组合为0</p>
<p>如果向量组<script type="math/tex">a_{1}, \cdots, a_{n}</script>线性相关，则存在一组不全为0的系数<script type="math/tex">x</script>使得其线性组合为0，这就是方程组的非0解</p>
<p>前者对应于矩阵$A$的秩为$n$，后者秩小于$n$，由此得到齐次方程组解的存在性判定条件，分下面两种情况</p>
<ol>
<li>如果$r(\boldsymbol{A})=n$，方程组只有0解</li>
<li>如果$r(\boldsymbol{A}) \lt n$，方程组有非0解</li>
</ol>
<p>方程组有非$\boldsymbol{0}$解的充分必要条件是$r(\boldsymbol{A})&lt;n$</p>
<p>如果$\boldsymbol{A}$是方阵，$r(\boldsymbol{A})&lt;n$等同于$\boldsymbol{A}$不可逆， 如果$m&lt;n$，即(方程的数量)小于未知数的数量，则有</p>
<script type="math/tex; mode=display">
r(\boldsymbol{A}) \leqslant \min (m, n) \leqslant m<n</script><p>此时方程组必定有非$\boldsymbol{0}$解，对于如下的线性方程组</p>
<script type="math/tex; mode=display">
\left\{\begin{array}{l}
x_{1}-x_{2}+x_{3}=0 \\
-x_{1}+x_{2}+x_{3}=0 \\
x_{1}+x_{2}-x_{3}=0
\end{array}\right.</script><p>其系数矩阵的秩为</p>
<script type="math/tex; mode=display">
r\left(\left(\begin{array}{ccc}
1 & -1 & 1 \\
-1 & 1 & 1 \\
1 & 1 & -1
\end{array}\right)\right)=3</script><p>因此方程组只有$\mathbf{0}$解，对于如下的方程组</p>
<script type="math/tex; mode=display">
\left\{\begin{array}{l}
x_{1}+x_{2}+x_{3}=0 \\
2 x_{1}+2 x_{2}+2 x_{3}=0
\end{array}\right.</script><p>其系数矩阵的秩为</p>
<script type="math/tex; mode=display">
r\left(\left(\begin{array}{lll}
1 & 1 & 1 \\
2 & 2 & 2
\end{array}\right)\right)=1</script><p>也是方程组的解，证明如下</p>
<script type="math/tex; mode=display">
\boldsymbol{A}\left(\sum_{i=1}^{l} k_{i} \boldsymbol{x}_{i}\right)=\sum_{i=1}^{l} k_{i} \boldsymbol{A} \boldsymbol{x}_{i}=\sum_{i=1}^{l} k_{i} \mathbf{0}=\mathbf{0}</script><p>假设<script type="math/tex">x_{1}, \cdots, x_{l}</script>都是方程组的解，如果这组解线性无关且方程组的任意一个解都可以由这组解线性表示，则称<script type="math/tex">x_{1}, \cdots, x_{l}</script>是方程组的一个<code>基础解系</code></p>
<p>如果$r(\boldsymbol{A})&lt;n$，则存在基础解系，且基础解系中包含$n-r(\boldsymbol{A})$个解</p>
<blockquote>
<p>齐次线性方程组的求解方法</p>
</blockquote>
<p>通常采用的是初等行变换法，对应<code>高斯消元法</code>，经过初等行变换将系数矩阵化为阶梯形矩阵之后</p>
<p>如果出现自由未知数，可以将它们设为特殊值，形成基础解系，然后得到方程组的<code>通解</code>(General Solution)</p>
<p>如果<script type="math/tex">x_{r+1}, \cdots, x_{n}</script>是自由末知数，通常将它们的值依次设为</p>
<script type="math/tex; mode=display">
\left(\begin{array}{llll}1 & 0 & \cdots & 0\end{array}\right) \qquad
\left(\begin{array}{llll}0 & 1 & \cdots & 0\end{array}\right) \qquad \cdots \qquad
\left(\begin{array}{llll}0 & 0 & \cdots & 1\end{array}\right)</script><p>这是$\mathbb{R}^{n-r}$空间一组最简单的<code>标准正交基</code>，然后根据它们的值解出其他的末知数，对于如下的方程组</p>
<script type="math/tex; mode=display">
\left\{\begin{array}{l}
x_{1}+2 x_{2}+2 x_{3}+x_{4}=0 \\
2 x_{1}+x_{2}-2 x_{3}-2 x_{4}=0 \\
x_{1}-x_{2}-4 x_{3}-3 x_{4}=0
\end{array}\right.</script><p>对其系数矩阵进行初等行变换</p>
<script type="math/tex; mode=display">
\begin{array}{l} 
A=\left(\begin{array}{cccc}
1 & 2 & 2 & 1 \\
2 & 1 & -2 & -2 \\
1 & -1 & -4 & -3
\end{array}\right) \stackrel{r_{2}-2 r_{1}, r_{3}-r_{1}}{\longrightarrow} \\
\stackrel{r_{3}-r_{2}, r_{2} \times(-1 / 3)}{\longrightarrow}\left(\begin{array}{cccc}
1 & 2 & 2 & 1 \\
0 & 1 & 2 & 4 / 3 \\
0 & -3 & -6 & -4 \\
0 & -3 & -6 & -4
\end{array}\right) \stackrel{r_{1}-2 \times r_{2}}{\longrightarrow}\left(\begin{array}{cccc}
1 & 0 & -2 & -5 / 3 \\
0 & 1 & 2 & 4 / 3 \\
0 & 0 & 0 & 0
\end{array}\right)
\end{array}</script><p>由于$r(\boldsymbol{A})=2&lt;4$，因此方程组有非$\mathbf{0}$解，最后丙个末知数为自由变量</p>
<p>令<script type="math/tex">x_{3}=1, x_{4}=0</script>，得到基础解系的第一个解</p>
<script type="math/tex; mode=display">
x_{1}=\left(\begin{array}{llll}
2 & -2 & 1 & 0
\end{array}\right)^{T}</script><p>令<script type="math/tex">x_{3}=0, x_{4}=1</script>，得到基础解系的第二个解</p>
<script type="math/tex; mode=display">
x_{2}=\left(\begin{array}{llll}
5 / 3 & -4 / 3 & 0 & 1
\end{array}\right)^{\mathrm{T}}</script><p>方程组的通解为</p>
<script type="math/tex; mode=display">
\boldsymbol{x}=k_{1} x_{1}+k_{2} x_{2}</script><p>其中<script type="math/tex">k_{1}, k_{2}</script>为任意常数</p>
<h2 id="非齐次方程组"><a href="#非齐次方程组" class="headerlink" title="非齐次方程组"></a>非齐次方程组</h2><p><code>非齐次线性方程组</code>(Non-homogeneous Linear Equations)的常数项不全为0，可写成如下形式</p>
<script type="math/tex; mode=display">
\boldsymbol{A} \boldsymbol{x}=\boldsymbol{b}</script><p>这与一元一次方程$a x=0$在形式上是统一的，方程组的增广矩阵是系数矩阵和常数向量合并构成的矩阵</p>
<script type="math/tex; mode=display">
\boldsymbol{B}=\left(\begin{array}{ll}
\boldsymbol{A} & \boldsymbol{b}
\end{array}\right)</script><p>对于如下的线性方程组</p>
<script type="math/tex; mode=display">
\left\{\begin{array}{l}
2 x_{1}-3 x_{2}+x_{3}=1 \\
4 x_{1}-2 x_{2}+x_{3}=2 \\
3 x_{1}+3 x_{2}+x_{3}=0
\end{array}\right.</script><p>其系数矩阵为</p>
<script type="math/tex; mode=display">
\left(\begin{array}{ccc}
2 & -3 & 1 \\
4 & -2 & 1 \\
3 & 3 & 1
\end{array}\right)</script><p>增广矩阵为</p>
<script type="math/tex; mode=display">
\left(\begin{array}{cccc}
2 & -3 & 1 & 1 \\
4 & -2 & 1 & 2 \\
3 & 3 & 1 & 0
\end{array}\right)</script><p>假设$\boldsymbol{A} \in \mathbb{R}^{m \times n}, \boldsymbol{x} \in \mathbb{R}^{n}$ ，系数矩阵$\boldsymbol{A}$扩列分块为<script type="math/tex">\left(\boldsymbol{a}_{1} \cdots \boldsymbol{a}_{n}\right)</script>，非齐次方程可以写成</p>
<script type="math/tex; mode=display">
x_{1} a_{1}+\cdots+x_{n} a_{n}=b</script><p>以$x$为组合系数，向量组<script type="math/tex">a_{1}, \cdots, a_{n}</script>的线性组合为向量<script type="math/tex">b</script>，如果<script type="math/tex">b</script>可以由<script type="math/tex">A</script>的列向量线性表示，则方程组有解，否则方程组无解</p>
<p>用初等行变换将增广矩阵化为阶梯矩阵</p>
<script type="math/tex; mode=display">
\left(\begin{array}{ccccccc}
1 & \cdots & c_{1 r} & c_{1, r+1} & \cdots & c_{1 n} & d_{1} \\
\vdots & & \vdots & \vdots & & \vdots & \vdots \\
0 & \cdots & 1 & c_{r, r+1} & \cdots & c_{r n} & d_{r} \\
0 & \cdots & 0 & 0 & \cdots & 0 & d_{r+1} \\
0 & \cdots & 0 & 0 & \cdots & 0 & 0 \\
\vdots & & \vdots & \vdots & & \vdots & \vdots \\
0 & \cdots & 0 & 0 & \cdots & 0 & 0
\end{array}\right)</script><p>如果<script type="math/tex">d_{r+1} \neq 0</script>，则意味着出现矛盾方程，方程无解，如果<script type="math/tex">d_{r+1}=0</script>，则方程组有解，对于第二种情况，增广矩阵的秩与系数矩阵的秩小于增广矩阵的秩，且</p>
<script type="math/tex; mode=display">
r(\boldsymbol{B})=r(\boldsymbol{A})+1</script><p>由此得到非齐次方程组解的存在性判定条件</p>
<ol>
<li>如果$r(\boldsymbol{A})=r(\boldsymbol{B})$，那么方程组的解存在</li>
<li>如果$r(\boldsymbol{A})&lt;r(\boldsymbol{B})$，那么方程组的解不存在</li>
</ol>
<p>对于第一种情况，如果$r(\boldsymbol{A})=n$，那么方程组有唯一解，如果$r(\boldsymbol{A})&lt;n$，那么方程组有无穷多组解</p>
<blockquote>
<p>解的性质与结构</p>
</blockquote>
<p>如果<script type="math/tex">x_{1}, \cdots, x_{l}</script>是非齐次方程组所对应的齐次方程的一组解，<script type="math/tex">x^{*}</script>是非齐次方程的一个解，则<script type="math/tex">\sum_{i=1}^{1} k_{i} x_{i}+x^{*}</script>是非齐次方程的解，显然</p>
<script type="math/tex; mode=display">
\boldsymbol{A}\left(\sum_{i=1}^{l} k_{i} \boldsymbol{x}_{i}+\boldsymbol{x}^{*}\right)=\sum_{i=1}^{l} k_{i} \boldsymbol{A} \boldsymbol{x}_{i}+\boldsymbol{A} \boldsymbol{x}^{*}=\sum_{i=1}^{l} k_{i} \mathbf{0}+\boldsymbol{b}=\boldsymbol{b}</script><p>如果<script type="math/tex">x_{1}, \cdots, x_{l}</script>是齐次方程组的基础解系，<script type="math/tex">x^{*}</script>是非齐次方程组的一个解，则非齐次方程组的解可以表示为</p>
<script type="math/tex; mode=display">
\sum_{i=1}^{l} k_{i} x_{i}+x^{*}</script><p>同样可以用初等行变换求解非齐次方程组，其解为对应的齐次方程组的通解加上它的一个<code>特解</code>(Particular Solution)</p>
<p>齐次方程组通解的求解方法在前面已经介绍，非齐次方程组的特解可以任意选取，通常令自由末知数的值全为0</p>
<p>用初等行变换解下面的非齐次线性方程组</p>
<script type="math/tex; mode=display">
\left\{\begin{array}{l}
x_{1}+5 x_{2}-x_{3}-x_{4}=-1 \\
x_{1}-2 x_{2}+x_{3}+3 x_{4}=3 \\
3 x_{1}+8 x_{2}-x_{3}+x_{4}=1 \\
x_{1}-9 x_{2}+3 x_{3}+7 x_{4}=7
\end{array}\right.</script><p>对其增广矩阵进行初等行变换</p>
<script type="math/tex; mode=display">
\left(\begin{array}{ccccc}1 & 5 & -1 & -1 & -1 \\ 1 & -2 & 1 & 3 & 3 \\ 3 & 8 & -1 & 1 & 1 \\ 1 & -9 & 3 & 7 & 7\end{array}\right) \rightarrow\left(\begin{array}{ccccc}1 & 5 & -1 & -1 & -1 \\ 0 & -7 & 2 & 4 & 4 \\ 0 & 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 & 0\end{array}\right) \rightarrow\left(\begin{array}{ccccc}1 & 5 & -1 & -1 & -1 \\ 0 & 1 & -2 / 7 & -4 / 7 & -4 / 7 \\ 0 & 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 & 0\end{array}\right)</script><p>这里<script type="math/tex">x_{3}, x_{4}</script>是自由未知数，令<script type="math/tex">x_{3}=x_{4}=0</script>，得到一个特解</p>
<script type="math/tex; mode=display">
\boldsymbol{x}^{*}=\left(\begin{array}{c}
13 / 7 \\
-4 / 7 \\
0 \\
0
\end{array}\right)</script><p>方次方程组的基础解系为</p>
<script type="math/tex; mode=display">
\boldsymbol{x}_{1}=\left(\begin{array}{c}
-3 / 7 \\
2 / 7 \\
1 \\
0
\end{array}\right), \boldsymbol{x}_{2}=\left(\begin{array}{c}
-13 / 7 \\
4 / 7 \\
0 \\
1
\end{array}\right)</script><p>因此方程的解为</p>
<script type="math/tex; mode=display">
\boldsymbol{x}=\boldsymbol{x}^{*}+k_{1} \boldsymbol{x}_{1}+k_{2} \boldsymbol{x}_{2}</script><p>其中<script type="math/tex">k_{1}, k_{2}</script>为任意常数</p>
<p>Python中linalg的solve函数提供了求解非齐次线性方程组的功能，函数的传人参数为系数矩阵$A$，以及常数向量$\boldsymbol{b}$，返回值是方程组$\boldsymbol{A x}=\boldsymbol{b}$的解向量$x$，对于方程组</p>
<script type="math/tex; mode=display">
\begin{array}{l}
3 x_{1}+x_{2}=9 \\
x_{1}+2 x_{2}=8
\end{array}</script><p>下面是求解该方程组的代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">A = np.array([<span class="number">3</span>,<span class="number">1</span>], [<span class="number">1</span>,<span class="number">2</span>])</span><br><span class="line">b = np.array([<span class="number">9</span>,<span class="number">8</span>])</span><br><span class="line">x = np.linalg.solve(A, b)</span><br><span class="line"><span class="built_in">print</span>(x)</span><br></pre></td></tr></table></figure>
<p>程序运行结果为$[2,3]$</p>
<h1 id="特征值和特征向量"><a href="#特征值和特征向量" class="headerlink" title="特征值和特征向量"></a>特征值和特征向量</h1><p><code>特征值</code>(Eigenvalue，也称为本征值)与<code>特征向量</code>(Eigenvector，也称为<code>本征向量</code>)决定了矩阵的很多性质</p>
<p>从几何的角度来看，持征向量是经过矩阵的线性变换仍然处于同一条直线上的向量</p>
<h2 id="特征值与特征向量"><a href="#特征值与特征向量" class="headerlink" title="特征值与特征向量"></a>特征值与特征向量</h2><blockquote>
<p>特征值与特征向量</p>
</blockquote>
<p>对于$n$阶矩阵$A$，其特征向量是经过这个矩阵的线性变换之后仍然处于同一条直线上的向量，新向量的方向可能会相反，长度可能会改变，即存在一个数$\lambda$以及非$0$向量$x$，满足</p>
<script type="math/tex; mode=display">
\boldsymbol{A} \boldsymbol{x}=\lambda \boldsymbol{x}</script><p>则称$\lambda$为矩阵$A$的<code>特征值</code>，$x$为该特征值对应的<code>特征向量</code></p>
<p>特征值是特征向量在矩阵的线性变换下的缩放代，如果持征值大于0，那么经过线性变换之后特征向量的方向不变；如果特征值小于0，那么经过线性变换之后特征向量的方向相反，如果特征值为0，则经过线性变换之后特征向量收缩回原点</p>
<blockquote>
<p>特征矩阵和特征方程</p>
</blockquote>
<p>上式变形后可以得到</p>
<script type="math/tex; mode=display">
(A-\lambda I) x=0</script><p>$A-\lambda I$ 称为<code>特征矩阵</code>，按照线性方程组的理论，上面的齐次方程有非0解的条件是系数矩阵的行列式必须为0，即</p>
<script type="math/tex; mode=display">
|\boldsymbol{A}-\lambda \boldsymbol{I}|=0</script><p>式子称为<code>特征方程</code>(Eigenvalue Equation)</p>
<p>对于矩阵</p>
<script type="math/tex; mode=display">
\boldsymbol{A}=\left(\begin{array}{cccc}
a_{11} & a_{12} & \cdots & a_{1 n} \\
a_{21} & a_{22} & \cdots & a_{2 n} \\
\vdots & \vdots & & \vdots \\
a_{n 1} & a_{n 2} & \cdots & a_{n n}
\end{array}\right)</script><p>其特征方程为</p>
<script type="math/tex; mode=display">
|\boldsymbol{A}-\lambda \boldsymbol{I}|=\left|\begin{array}{cccc}
a_{11}-\lambda & a_{12} & \cdots & a_{1 n} \\
a_{21} & a_{22}-\lambda & \cdots & a_{2 n} \\
\vdots & \vdots & & \vdots \\
a_{n 1} & a_{n 2} & \cdots & a_{n n}-\lambda
\end{array}\right|=0</script><blockquote>
<p>特征多项式</p>
</blockquote>
<p>上面的行列式展开之后是$\lambda$的$n$次多项式，称为矩阵的<code>特征多项式</code>(Characteristic Polynomial)，为如下形式</p>
<script type="math/tex; mode=display">
c_{n} \lambda^{n}+c_{n-1} \lambda^{n-1}+c_{n-2} \lambda^{n-2}+\cdots+c_{1} \lambda+c_{0}</script><p>求解这个特征多项式对应的特征方程可以得到所有特征值，方程的根可能是复数，此时的特征值为复数，特征向量为复向量</p>
<p>根据对角行列式的计算公式，对角矩阵的特征为其主对角线元素，对于如下对角矩阵</p>
<script type="math/tex; mode=display">
\boldsymbol{A}=\left(\begin{array}{cccc}
a_{11} & 0 & \cdots & 0 \\
0 & a_{22} & \cdots & 0 \\
\vdots & \vdots & & \vdots \\
0 & 0 & \cdots & a_{n n}
\end{array}\right)</script><p>其特征方程为</p>
<script type="math/tex; mode=display">
\left|\begin{array}{cccc}a_{11}-\lambda & 0 & \cdots & 0 \\ 0 & a_{22}-\lambda & \cdots & 0 \\ \vdots & \vdots & & \vdots \\ 0 & 0 & \cdots & a_{n n}-\lambda\end{array}\right|=\left(a_{11}-\lambda\right) \cdots\left(a_{n n}-\lambda\right)=0</script><p>类似地，上三角矩阵的特征值为其主对角线元素，对于如下的上三角矩阵</p>
<script type="math/tex; mode=display">
\boldsymbol{A}=\left(\begin{array}{cccc}
a_{11} & a_{12} & \cdots & a_{1 n} \\
0 & a_{22} & \cdots & a_{2 n} \\
\vdots & \vdots & & \vdots \\
0 & 0 & \cdots & a_{n n}
\end{array}\right)</script><p>其特征方程为</p>
<script type="math/tex; mode=display">
\left|\begin{array}{cccc}
a_{11}-\lambda & a_{12} & \cdots & a_{1 n} \\
0 & a_{22}-\lambda & \cdots & a_{2 n} \\
\vdots & \vdots & & \vdots \\
0 & 0 & \cdots & a_{n n}-\lambda
\end{array}\right|=\left(a_{11}-\lambda\right) \cdots\left(a_{n n}-\lambda\right)=0</script><p>对于下三角矩阵有相同的结论，一种计算特征值的方法是通过相似变换将矩阵变为上三角矩阵</p>
<blockquote>
<p>代数重数、谱</p>
</blockquote>
<p>根据多项式分解定理，特征方程可以写成</p>
<script type="math/tex; mode=display">
\left(\lambda-\lambda_{1}\right)^{n_{1}}\left(\lambda-\lambda_{2}\right)^{n_{2}} \cdots\left(\lambda-\lambda_{N_{\lambda}}\right)^{n_{N_{\lambda}}}=0</script><p>其中<script type="math/tex">n_{i}</script>称为特征值<script type="math/tex">\lambda_{i}</script>的<code>代数重数</code>(Algebraic Multiplicity)，根据代数方程的理论，有</p>
<script type="math/tex; mode=display">
\sum_{i=1}^{N_{\lambda}} n_{i}=n</script><p>所有$N_{\lambda}$个不同的特征值构成的集合称为矩阵的<code>谱</code>(Spectrum)</p>
<p>矩阵的<code>谱半径</code>(Spectral Radius)定义为所有特征值绝对值的最大值，记为</p>
<script type="math/tex; mode=display">
\rho(\boldsymbol{A})=\max \left\{\left|\lambda_{1}\right|, \cdots,\left|\lambda_{N_{\lambda}}\right|\right\}</script><p>如果矩阵$\boldsymbol{A}$不可逆，则</p>
<script type="math/tex; mode=display">
|\boldsymbol{A}|=|\boldsymbol{A}-0 \boldsymbol{I}|=0</script><p>因此0是它的特征值，反之，如果可逆，则0不是它的特征值</p>
<blockquote>
<p>几何重数</p>
</blockquote>
<p>得到每个特征值$\lambda_{i}$之后，解下面的线性方程组</p>
<script type="math/tex; mode=display">
(A - \lambda _i I)x = 0</script><p>即可得到其对应的特征向量，此方程组有$1 \leq m_i \leq n_i$，个线性无关的解，称$m_i$为$\lambda _i$的<code>几何重数</code>(Geometric Multiplicity)</p>
<p>这些线性无关的解构成的空间称为矩阵$\boldsymbol{A}$关于特征值<script type="math/tex">\lambda_{i}</script>的特征子空间，记为<script type="math/tex">V_{\lambda _i}</script></p>
<p>根据齐次线性方程组解的理论，特征子空间的维数为</p>
<script type="math/tex; mode=display">
m_{i}=n-r\left(\boldsymbol{A}-\lambda_{i} \boldsymbol{I}\right)</script><p>属于不同特征值的特征向量线性无关，矩阵所有线性无关的特征向量的数量为</p>
<script type="math/tex; mode=display">
N_{x}=\sum_{i=1}^{N_{ \lambda}} m_{i}</script><p>显然有$N_{x} \leqslant n$</p>
<blockquote>
<p>特征值与特征向量的计算</p>
</blockquote>
<p>下面用一个例子来说明特征值与特征向量的计算，对于如下矩阵</p>
<script type="math/tex; mode=display">
\boldsymbol{A}=\left(\begin{array}{cc}
1 & 2 \\
0 & -1
\end{array}\right)</script><p>其特征多项式为</p>
<script type="math/tex; mode=display">
|\boldsymbol{A}-\lambda \boldsymbol{I}|=\left|\begin{array}{cc}
1-\lambda & 2 \\
0 & -1-\lambda
\end{array}\right|=-(1-\lambda)(1+\lambda)</script><p>特征方程$-(1-\lambda)(1+\lambda)=0$的根为$\lambda=1$与$\lambda=-1$，因此该矩阵的特征值为1与-1</p>
<p>将特征值1代人，可得</p>
<script type="math/tex; mode=display">
(\boldsymbol{A}-\lambda I) \boldsymbol{x}=\left(\begin{array}{cc}
0 & 2 \\
0 & -2
\end{array}\right) \boldsymbol{x}=\mathbf{0}</script><p>该齐次方程的解为</p>
<script type="math/tex; mode=display">
\boldsymbol{x}=\left(\begin{array}{l}
1 \\
0
\end{array}\right)</script><p>此即特征值1对应的特征向量</p>
<p>将另外一个特征值-1代人，可得</p>
<script type="math/tex; mode=display">
(\boldsymbol{A}-\lambda I) \boldsymbol{x}=\left(\begin{array}{ll}
2 & 2 \\
0 & 0
\end{array}\right) \boldsymbol{x}=\mathbf{0}</script><p>该齐次方程的解为</p>
<script type="math/tex; mode=display">
\boldsymbol{x}=\left(\begin{array}{c}
1 \\
-1
\end{array}\right)</script><p>即特征值-1对应的特征向量</p>
<p>上三角矩阵的特征值为其主对角线元素，对于如下矩阵</p>
<script type="math/tex; mode=display">
\boldsymbol{A}=\left(\begin{array}{lll}
1 & 1 & 1 \\
0 & 2 & 2 \\
0 & 0 & 3
\end{array}\right)</script><p>根据前面的结论，其特征多项式为</p>
<script type="math/tex; mode=display">
|\boldsymbol{A}-\lambda \boldsymbol{I}|=\left|\begin{array}{ccc}
1-\lambda & 1 & 1 \\
0 & 2-\lambda & 2 \\
0 & 0 & 3-\lambda
\end{array}\right|=(1-\lambda)(2-\lambda)(3-\lambda)</script><p>其特征值为 $1 、 2 、 3$</p>
<p>对于不超过4阶的矩阵，可通过解特征方程得到特征值</p>
<p>但更高次方程的求根存在困难，阿贝尔-鲁菲尼(Abel-Ruffini)定理指出，4次以上的代数方程没有公式解，对于一般的高次方程，方程系数的有限次四则运算、开方运算的结果均不可能是方程的根，因此<strong>高阶矩阵的特征值只能求近似解</strong></p>
<p>直接求解特征方程并不是一种好的选择，更有效的方法是迭代法</p>
<p>Python中linalg的eig函数实现了计算矩阵的特征值与特征向量的功能，函数的输入为方阵，输出为所有的特征值以及这些特征值对应的特征向量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">A = np.array([[<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">0</span>,<span class="number">5</span>]])</span><br><span class="line">eigvalues, eigvectors = np<span class="number">.1</span>inalg.eig(A)</span><br><span class="line"><span class="built_in">print</span>(eigvalues)</span><br><span class="line"><span class="built_in">print</span>(eigvectors)</span><br></pre></td></tr></table></figure>
<p>程序运行结果为</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#  特征值</span></span><br><span class="line">[<span class="number">1.</span> <span class="number">1.</span> <span class="number">5.</span>]</span><br><span class="line"><span class="comment"># 特征向量</span></span><br><span class="line">[[<span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">1.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span>]]</span><br></pre></td></tr></table></figure>
<blockquote>
<p>矩阵的迹</p>
</blockquote>
<p>下面介绍特征值与矩阵主对角线元素以及行列式的关系，矩阵的<code>迹</code>(Trace)定义为其主对角线元素之和</p>
<script type="math/tex; mode=display">
\operatorname{tr}(\boldsymbol{A})=\sum_{i=1}^{n} a_{i i}</script><p>对于如下矩阵</p>
<script type="math/tex; mode=display">
\boldsymbol{A}=\left(\begin{array}{lll}
1 & 2 & 3 \\
4 & 5 & 6 \\
7 & 8 & 9
\end{array}\right)</script><p>其迹为</p>
<script type="math/tex; mode=display">
\operatorname{tr}(\boldsymbol{A})=a_{11}+a_{22}+a_{33}=1+5+9=15</script><p>关于矩阵的迹，有下面的公式成立</p>
<script type="math/tex; mode=display">
\operatorname{tr}(\boldsymbol{A}+\boldsymbol{B})=\operatorname{tr}(\boldsymbol{A})+\operatorname{tr}(\boldsymbol{B})
\qquad \operatorname{tr}(k \boldsymbol{A})= k \cdot \operatorname{tr}(\boldsymbol{A}) 
\qquad \operatorname{tr}(\boldsymbol{A} \boldsymbol{B})=\operatorname{tr}(\boldsymbol{B} \boldsymbol{A})</script><p>根据<code>韦达定理</code>，下面的$n$次方程</p>
<script type="math/tex; mode=display">
x^{n}+c_{n-1} x^{n-1}+\cdots+c_{1} x+c_{0}=0</script><p>所有根之和为</p>
<script type="math/tex; mode=display">
x_{1}+x_{2}+\cdots+x_{n}=-c_{n-1}</script><p>所有根的乘积为</p>
<script type="math/tex; mode=display">
x_{1} x_{2} \cdots x_{n}=(-1)^{n} c_{0}</script><p>下面计算$n$阶矩阵的特征多项式，首先将行列式写成下面的形式</p>
<script type="math/tex; mode=display">
|\boldsymbol{A}-\lambda \boldsymbol{I}|=\left|\begin{array}{cccc}
a_{11}-\lambda & a_{12}-0 & \cdots & a_{1 n}-0 \\
a_{21}-0 & a_{22}-\lambda & \cdots & a_{2 n}-0 \\
\vdots & \vdots & & \vdots \\
a_{n 1}-0 & a_{n 2}-0 & \cdots & a_{n n}-\lambda
\end{array}\right|</script><p>然后按照第1列拆开、变为两个行列式之和</p>
<script type="math/tex; mode=display">
|\boldsymbol{A}-\lambda \boldsymbol{I}|=\left|\begin{array}{cccc}
a_{11} & a_{12}-0 & \cdots & a_{1 n}-0 \\
a_{21} & a_{22}-\lambda & \cdots & a_{2 n}-0 \\
\vdots & \vdots & & \vdots \\
a_{n 1} & a_{n 2}-0 & \cdots & a_{n n}-\lambda
\end{array}\right|+\left|\begin{array}{cccc}
-\lambda & a_{12}-0 & \cdots & a_{1 n}-0 \\
-0 & a_{22}-\lambda & \cdots & a_{2 n}-0 \\
\vdots & \vdots & & \vdots \\
-0 & a_{n 2}-0 & \cdots & a_{n n}-\lambda
\end{array}\right|</script><p>接下来将这两个行列式均按照第2列拆开，变为4个行列式之和</p>
<script type="math/tex; mode=display">
\begin{aligned}
|\boldsymbol{A}-\lambda I|= & \left|\begin{array}{cccc}
a_{11} & a_{12} & \cdots & a_{1 n}-0 \\
a_{21} & a_{22} & \cdots & a_{2 n}-0 \\
\vdots & \vdots & & \vdots \\
a_{n 1} & a_{n 2} & \cdots & a_{n n}-\lambda
\end{array}\right|+\left|\begin{array}{cccc}
a_{11} & -0 & \cdots & a_{1 n}-0 \\
a_{21} & -\lambda & \cdots & a_{2 n}-0 \\
\vdots & \vdots & & \vdots \\
a_{n 1} & -0 & \cdots & a_{n n}-\lambda
\end{array}\right| \\
& +\left|\begin{array}{cccc}
-\lambda & a_{12} & \cdots & a_{1 n}-0 \\
-0 & a_{22} & \cdots & a_{2 n}-0 \\
\vdots & \vdots & & \vdots \\
-0 & a_{n 2} & \cdots & a_{n n}-\lambda
\end{array}\right|+\left|\begin{array}{cccc}
-\lambda & -0 & \cdots & a_{1 n}-0 \\
-0 & -\lambda & \cdots & a_{2 n}-0 \\
\vdots & \vdots & & \vdots \\
-0 & -0 & \cdots & a_{n n}-\lambda
\end{array}\right|
\end{aligned}</script><p>依此类推，将上一步的结果中所有行列式按照下一列拆开，最后可以得到$2^{n}$个行列式，特征值多项式是它们之和</p>
<p>这些行列式的展开结果中，含有$\lambda^{n}$的只有</p>
<script type="math/tex; mode=display">
\left|\begin{array}{ccc}
-\lambda & \cdots & 0 \\
\vdots & & \vdots \\
0 & \cdots & -\lambda
\end{array}\right|</script><p>因此特征多项式的首次项就是$(-1)^{n} \lambda^{n}$ ，含有$\lambda^{n-1}$的是下面$n$个行列式</p>
<script type="math/tex; mode=display">
\left|\begin{array}{cccc}
a_{11} & -0 & \cdots & -0 \\
a_{21} & -\lambda & \cdots & -0 \\
\vdots & \vdots & & \vdots \\
a_{n 1} & -0 & \cdots & -\lambda
\end{array}\right|,\left|\begin{array}{cccc}
-\lambda & a_{12} & \cdots & -0 \\
-0 & a_{22} & \cdots & -0 \\
\vdots & \vdots & & \vdots \\
-0 & a_{n 2} & \cdots & -\lambda
\end{array}\right| \cdots</script><p>它们之和为</p>
<script type="math/tex; mode=display">
(-1)^{n-1}\left(a_{11}+\cdots+a_{n n}\right) \lambda^{n-1}</script><p>因此特征多项式的$\lambda^{n-1}$项系数是<script type="math/tex">(-1)^{n-1} \sum_{i=1}^{n} a_{i i}</script>，不含<script type="math/tex">\lambda</script>的只有下面一个行列式</p>
<script type="math/tex; mode=display">
\left|\begin{array}{cccc}
a_{11} & a_{12} & \cdots & a_{1 n} \\
a_{21} & a_{22} & \cdots & a_{2 n} \\
\vdots & \vdots & & \vdots \\
a_{n 1} & a_{n 2} & \cdots & a_{n n}
\end{array}\right|</script><p>因此特征多项式中常数项的系数为$|\boldsymbol{A}|$，由此可以得到特征多项式为</p>
<script type="math/tex; mode=display">
(-1)^{n} \lambda^{n}+(-1)^{n-1} \operatorname{tr}(\boldsymbol{A}) \lambda^{n-1}+c_{n-2} \lambda^{n-2}+\cdots+c_{1} \lambda+|\boldsymbol{A}|</script><p>将特征多项式乘以$(-1)^{n}$可以变为</p>
<script type="math/tex; mode=display">
\lambda^{n}-\operatorname{tr}(\boldsymbol{A}) \lambda^{n-1}+c_{n-2} \lambda^{n-2}+\cdots+c_{1} \lambda+(-1)^{n}|\boldsymbol{A}|</script><p>因此矩阵所有特征值的和为矩阵的迹</p>
<script type="math/tex; mode=display">
\sum_{i=1}^{n} \lambda_{i}=\operatorname{tr}(\boldsymbol{A})</script><p>所有特征值的积为矩阵的行列式</p>
<script type="math/tex; mode=display">
\prod_{i=1}^{n} \lambda_{i}=(-1)^{n}(-1)^{n}|\boldsymbol{A}|=|\boldsymbol{A}|</script><blockquote>
<p>特征值的若干重要性质</p>
</blockquote>
<p>1️⃣如果矩阵<script type="math/tex">A</script>可逆且<script type="math/tex">\lambda</script>为它的特征值，则<script type="math/tex">\lambda^{-1}</script>是<script type="math/tex">A^{-1}</script>的特征值，根据特征值与特征向量的定义有</p>
<script type="math/tex; mode=display">
\boldsymbol{A x}=\lambda \boldsymbol{x}</script><p>上式两边同时左乘$A^{-1}$，可以得到</p>
<script type="math/tex; mode=display">
A^{-1} A x=x=\lambda A^{-1} x</script><p>即</p>
<script type="math/tex; mode=display">
\boldsymbol{A}^{-1} x=\lambda^{-1} x</script><p>因此<script type="math/tex">\lambda^{-1}</script>是<script type="math/tex">A^{-1}</script>的特征值，<script type="math/tex">x</script>为对应的特征向量</p>
<p>2️⃣如果$\lambda$是矩阵$A$的特征值，则$\lambda^{n}$是$\boldsymbol{A}^{n}$的特征值，根据特征值与特征向量的定义有</p>
<script type="math/tex; mode=display">
A x=\lambda x</script><p>反复利用此式，有</p>
<script type="math/tex; mode=display">
A^{n} x=A^{n-1} A x=A^{n-1} \lambda x=\lambda A^{n-2} A x=\lambda A^{n-2} \lambda x=\cdots=\lambda^{n} x</script><p>因此$\lambda^{n}$是$\boldsymbol{A}^{n}$的特征值，类似地可以证明如果$\lambda$是矩阵$\boldsymbol{A}$的特征值，则$k \lambda$是$k \boldsymbol{A}$的特征值，对于如下的多项式</p>
<script type="math/tex; mode=display">
f(x)=a_{n} x^{n}+a_{n-1} x^{n-1}+\cdots+a_{1} x</script><p>3️⃣如果$\lambda$是矩阵$\boldsymbol{A}$的特征值，则$f(\lambda)$是$f(\boldsymbol{A})$的特征值</p>
<p>4️⃣矩阵$A$与$A^{\mathrm{T}}$有相同的特征值，显然</p>
<script type="math/tex; mode=display">
(\boldsymbol{A}-\lambda I)^{\mathrm{T}}=A^{\mathrm{T}}-(\lambda I)^{\mathrm{T}}=A^{\mathrm{T}}-\lambda I</script><p>因此</p>
<script type="math/tex; mode=display">
|A-\lambda I|=\left|A^{\mathrm{T}}-\lambda I\right|</script><blockquote>
<p>特征向量的若干重要性</p>
</blockquote>
<p>1️⃣如果向量<script type="math/tex">x_{1}, \cdots, x_{1}</script>都是矩阵<script type="math/tex">A</script>关于同一个特征值<script type="math/tex">\lambda</script>的特征向量，则它们的非$\mathbf{0}$线性组合</p>
<script type="math/tex; mode=display">
\sum_{i=1}^{l} k_{i} x_{i}</script><p>也是矩阵$\boldsymbol{A}$关于$\lambda$的特征向量，根据特征值与特征向量的定义有</p>
<script type="math/tex; mode=display">
\boldsymbol{A}\left(\sum_{i=1}^{l} k_{i} x_{i}\right)=\sum_{i=1}^{l} k_{i} \boldsymbol{A} x_{i}=\sum_{i=1}^{l} k_{i} \lambda x_{i}=\lambda \sum_{i=1}^{l} k_{i} x_{i}</script><p>因此<script type="math/tex">\sum_{i=1}^{1} k_{i} x_{i}</script>是关于<script type="math/tex">\lambda</script>的特征向量</p>
<p>2️⃣矩阵属于不同特征值的特征向量线性无关</p>
<p>假设矩阵$A$的$l$个不同特征值为<script type="math/tex">\lambda_{1}, \cdots, \lambda_{l}</script>，它们对应的特征向量为<script type="math/tex">x_{1}, \cdots, x_{l}</script>，下面用归纳法进行证明</p>
<p>当$l=1$时结论成立，因为<script type="math/tex">x_{1} \neq \mathbf{0}</script>，如果<script type="math/tex">k_{1} x_{1}=\mathbf{0}</script>，则必定有<script type="math/tex">k_{1}=0</script></p>
<p>假设当$l=m$时结论成立，当$l=m+1$时，有</p>
<script type="math/tex; mode=display">
k_{1} x_{1}+\cdots+k_{m} x_{m}+k_{m+1} x_{m+1}=\mathbf{0}</script><p>式子两边左乘$\boldsymbol{A}$，有</p>
<script type="math/tex; mode=display">
\boldsymbol{A}\left(k_{1} x_{1}+\cdots+k_{m} \boldsymbol{x}_{m}+k_{m+1} \boldsymbol{x}_{m+1}\right)=\mathbf{0}</script><p>由于</p>
<script type="math/tex; mode=display">
A x_{i}=\lambda_{i} x_{i}</script><p>因此</p>
<script type="math/tex; mode=display">
k_{1} \lambda_{1} x_{1}+\cdots+k_{m} \lambda_{m} \boldsymbol{x}_{m}+k_{m+1} \lambda_{m+1} \boldsymbol{x}_{m+1}=\mathbf{0}</script><p>将第一个式子乘以$\lambda_{m+1}$，然后减去上式，可得</p>
<script type="math/tex; mode=display">
k_{1}\left(\lambda_{m+1}-\lambda_{1}\right) \boldsymbol{x}_{1}+\cdots+k_{m}\left(\lambda_{m+1}-\lambda_{m}\right) \boldsymbol{x}_{m}=\mathbf{0}</script><p>由于<script type="math/tex">x_{1}, \cdots, x_{m}</script>线性无关，因此</p>
<script type="math/tex; mode=display">
{i}\left(\lambda_{m+1}-\lambda_{i}\right)=0, i=1, \cdots, m</script><p>而<script type="math/tex">\lambda_{m+1} \neq \lambda_{i}, i=1, \cdots, m</script>，因此<script type="math/tex">k_{i}=0, i=1, \cdots, m</script>，将<script type="math/tex">k_{i}=0, i=1, \cdots, m</script>代入第一个式子可得</p>
<script type="math/tex; mode=display">
k_{m+1} x_{m+1}=\mathbf{0}</script><p>由于是特征向量，因此<script type="math/tex">\boldsymbol{x}_{m+1} \neq \mathbf{0}</script>，故<script type="math/tex">k_{m+1}=0</script>，因此<script type="math/tex">\boldsymbol{x}_{1}, \cdots, \boldsymbol{x}_{m+1}</script>线性无关</p>
<p>3️⃣实对称矩阵的特征值均为实数</p>
<p>首先定义矩阵的<code>共轭</code>运算，复数矩阵$\boldsymbol{A}$的共轭$\overline{\boldsymbol{A}}$为将其所有元素共轭后形成的矩阵，例如对于下面的矩阵</p>
<script type="math/tex; mode=display">
\boldsymbol{A}=\left(\begin{array}{cc}
1-i & 1 \\
1 & 1+i
\end{array}\right)</script><p>其共轭矩阵为</p>
<script type="math/tex; mode=display">
\bar{A}=\left(\begin{array}{cc}
1+i & 1 \\
1 & 1-i
\end{array}\right)</script><p>可以证明共轭运算满足下面的性质</p>
<script type="math/tex; mode=display">
\overline{A+B}=\bar{A}+\bar{B} \qquad \overline{k A}=\bar{k} \bar{B} \qquad \overline{A B}=\bar{A} \bar{B} \qquad \overline{(A B)^{T}}=\bar{B}^{T} \bar{A}^{T}</script><p>显然对于实矩阵有</p>
<script type="math/tex; mode=display">
\bar{A}=A</script><p>假设$\lambda$是实对称矩阵$\boldsymbol{A}$的特征值，$x$是对应的特征向量</p>
<p>由于是实对称矩阵，因此$\bar{A}^{\mathrm{T}}=A$，由于$A x=\lambda x$，因此</p>
<script type="math/tex; mode=display">
\overline{A x}^{\mathrm{T}}=\overline{\lambda x}^{\mathrm{T}}</script><p>上式两边同时右乘$\boldsymbol{x}$可以得到</p>
<script type="math/tex; mode=display">
\overline{\boldsymbol{A} \boldsymbol{x}}^{\mathrm{T}} \boldsymbol{x}=\overline{\boldsymbol{x}^{\mathrm{T}} \boldsymbol{A}^{\mathrm{T}}} \boldsymbol{x}=\overline{\lambda \boldsymbol{x}}^{\mathrm{T}} \boldsymbol{x}=\overline{\boldsymbol{\lambda}^{\mathrm{T}}} \boldsymbol{x}</script><p>从而有</p>
<script type="math/tex; mode=display">
\overline{\boldsymbol{x}}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{x}=\overline{\boldsymbol{x}}^{\mathrm{T}} \lambda \boldsymbol{x}=\lambda \overline{\boldsymbol{x}^{\mathrm{T}}} \boldsymbol{x}=\bar{\lambda} \overline{\boldsymbol{x}^{\mathrm{T}}} \boldsymbol{x}</script><p>由于$x \neq 0$，因此$\overline{x^T} x&gt;0$，可以得到 $\lambda=\bar{\lambda}$，这意呠着$\lambda$是实数</p>
<p>4️⃣实对称矩阵属于不同特征值的特征向量相互正交</p>
<p>假设$A$为实对称矩阵，<script type="math/tex">\lambda_{1}, \lambda_{2}</script>是它的两个不同的特征值，<script type="math/tex">x_{1}, x_{2}</script>分别为属于<script type="math/tex">\lambda_{1}, \lambda_{2}</script>的特征向量，则有</p>
<script type="math/tex; mode=display">
\begin{array}{l}
\boldsymbol{A} \boldsymbol{x}_{1}=\lambda_{1} \boldsymbol{x}_{1} \qquad
\boldsymbol{A} \boldsymbol{x}_{2}=\lambda_{2} \boldsymbol{x}_{2}
\end{array}</script><p>上式的第一式两边左乘$x_{2}^{\mathrm{T}}$可以得到</p>
<script type="math/tex; mode=display">
\boldsymbol{x}_{2}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{x}_{1}=\lambda_{1} \boldsymbol{x}_{2}^{\mathrm{T}} \boldsymbol{x}_{1}</script><p>而</p>
<script type="math/tex; mode=display">
\boldsymbol{x}_{2}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{x}_{1}=\left(\boldsymbol{A}^{\mathrm{T}} \boldsymbol{x}_{2}\right)^{\mathrm{T}} \boldsymbol{x}_{1}=\left(\boldsymbol{A} \boldsymbol{x}_{2}\right)^{\mathrm{T}} \boldsymbol{x}_{1}=\lambda_{2} \boldsymbol{x}_{2}^{\mathrm{T}} \boldsymbol{x}_{1}</script><p>因此有</p>
<script type="math/tex; mode=display">
\lambda_{1} x_{2}^{\mathrm{T}} x_{1}=\lambda_{2} x_{2}^{\mathrm{T}} x_{1}</script><p>由于<script type="math/tex">\lambda_{1} \neq \lambda_{2}</script>，因此<script type="math/tex">x_{2}^{\mathrm{T}} x_{1}=0</script></p>
<p><strong>机器学习中使用的矩阵一般为实对称矩阵，因此特征值均为实数，且不同特征值的特征向量正交</strong></p>
<p>特征值和特征向量被大量用于机器学习算法，典型的包括<code>主成分分析</code>(PCA)，<code>线性判别分析</code>(LDA)，<code>流形学习</code>等降维算法</p>
<h2 id="相似变换"><a href="#相似变换" class="headerlink" title="相似变换"></a>相似变换</h2><p>通过相似变换可以将一个矩阵变为对角矩阵</p>
<blockquote>
<p>定义</p>
</blockquote>
<p>如果有两个矩阵$A$、$B$以及一个可逆矩阵$P$满足</p>
<script type="math/tex; mode=display">
\boldsymbol{P}^{-1} \boldsymbol{A P}=\boldsymbol{B}</script><p>则称矩阵$A$，$B$相似，记为$A \sim B$，上式称为<code>相似变换</code>，$P$为<code>相似变换矩阵</code></p>
<blockquote>
<p>性质</p>
</blockquote>
<p>相似具有自反性，矩阵与其自身相似，即$A \sim A$，显然</p>
<script type="math/tex; mode=display">
I^{-1} A I=A</script><p>相似具有对称性，如果$A \sim B$，则$B \sim A$，由于</p>
<script type="math/tex; mode=display">
P^{-1} A P=B</script><p>上式两边左乘$P$，右乘$P^{-1}$，可以得到</p>
<script type="math/tex; mode=display">
\boldsymbol{A}=\boldsymbol{P B} \boldsymbol{P}^{-1}=\left(\boldsymbol{P}^{-1}\right)^{-1} \boldsymbol{B} \boldsymbol{P}^{-1}</script><p>相似具有传递性，如果$A \sim B$且$B \sim C$，则$A \sim C$，由于$A \sim B$且$B \sim C$，因此有</p>
<script type="math/tex; mode=display">
\boldsymbol{P}_{1}^{-1} \boldsymbol{A} \boldsymbol{P}_{1}=\boldsymbol{B}  \qquad

\boldsymbol{P}_{2}^{-1} \boldsymbol{B} \boldsymbol{P}_{2}=\boldsymbol{C}</script><p>从而有</p>
<script type="math/tex; mode=display">
\boldsymbol{P}_{2}^{-1} \boldsymbol{B} \boldsymbol{P}_{2}=\boldsymbol{P}_{2}^{-1}\left(\boldsymbol{P}_{1}^{-1} \boldsymbol{A P} \boldsymbol{P}_{1}\right) \boldsymbol{P}_{2}=\left(\boldsymbol{P}_{1} \boldsymbol{P}_{2}\right)^{-1} A\left(P_{1} P_{2}\right)=C</script><p>相似矩阵有相同的特征值，这意昩着相似变换保持矩阵的特征值不变</p>
<p>假设$A \sim B$，则存在可逆矩阵$\boldsymbol{P}$使得</p>
<script type="math/tex; mode=display">
P^{-1} A P=B</script><p>因此</p>
<script type="math/tex; mode=display">
\begin{aligned}
|B-\lambda I| & =|P^{-1} A P-\lambda I|=|P^{-1} A P-\lambda P^{-1} I P|=|P^{-1}(A-\lambda I) P| \\
& =|P^{-1}||A-\lambda I||P|=|A-\lambda I|
\end{aligned}</script><p>这一性质可用于求解特征值，通过相似变换将矩阵$A$变为对角矩阵或三角矩阵</p>
<p>特征值不变，对角矩阵或三角矩阵的主对角线元素即为$A$的特征值</p>
<p>如果矩阵满足一定的条件，通过相似变换可将其转为对角矩阵</p>
<p>假设<script type="math/tex">\lambda _1, \cdots , \lambda _n</script>是$n$阶矩阵$A$的$n$个特佂值，<script type="math/tex">x_{1}, \cdots, x_{n}</script>是它们对应的特征向量根据特征值与特征向量的定义有</p>
<script type="math/tex; mode=display">
\left(\begin{array}{lll}
A x_{1} & \cdots & A x_{n}
\end{array}\right)=\left(\lambda_{1} x_{1} \cdots \lambda_{n} x_{n}\right)</script><p>如果令矩阵<script type="math/tex">P=\left(x_{1} \cdots x_{n}\right)</script>，对角矩阵</p>
<script type="math/tex; mode=display">
\Lambda=\left(\begin{array}{ccc}
\lambda_{1} & \cdots & 0 \\
\vdots & & \vdots \\
0 & \cdots & \lambda_{n}
\end{array}\right)</script><p>根据右乘对角矩阵的性质有</p>
<script type="math/tex; mode=display">
\left(\begin{array}{llll}
\boldsymbol{A} \boldsymbol{x}_{1} & \cdots & \boldsymbol{A} \boldsymbol{x}_{n}
\end{array}\right)=\boldsymbol{A P}=\left(\begin{array}{llll}
\lambda_{1} \boldsymbol{x}_{1} & \cdots & \lambda_{n} \boldsymbol{x}_{n}
\end{array}\right)=\boldsymbol{P} \boldsymbol{\Lambda}</script><p>即</p>
<script type="math/tex; mode=display">
A P=P A</script><p>如果矩阵$P$可逆，那么上式两边同时左乘$P^{-1}$可以得到</p>
<script type="math/tex; mode=display">
\boldsymbol{P}^{-1} A P=P^{-1} P \boldsymbol{\Lambda}=\boldsymbol{\Lambda}</script><p>通过这种相似变换可以将矩阵化为对角矩阵，称为矩阵的<code>相似对角化</code></p>
<script type="math/tex; mode=display">
\boldsymbol{P}^{-1} A P=\Lambda</script><p>式子意味着可以以矩阵$A$的特征向量为列构造一个矩阵$P$，通过它将矩阵对角化，得到以$A$的特征值为主对角线的对角矩阵$\boldsymbol{\Lambda}$</p>
<p>这种做法成立的条件是矩阵$\boldsymbol{P}$可逆，即矩阵$A$有$n$个线性无关的特征向量</p>
<h2 id="正交变换"><a href="#正交变换" class="headerlink" title="正交变换"></a>正交变换</h2><p>对于实对称矩阵，我们可以构造一个正交的相似变换将其对角化</p>
<blockquote>
<p>用归纳法证明实对称矩阵一定可以对角化</p>
</blockquote>
<p>这意味着$n$阶实对称矩阵有$n$个线性无关的特征向量，实对称矩阵$A$属于不同特征值的特征向量是相互正交的</p>
<p>如果用<code>格拉姆-施密特</code>正交化将同一个特征值的所有特征向量正交化，然后将所有特征向量单位化，可以得到一组标准正交基<script type="math/tex">\boldsymbol{p}_{1}, \cdots, \boldsymbol{p}_{n}</script></p>
<p>以它们为列构造相似变换矩阵$\boldsymbol{P}$，则矩阵$\boldsymbol{P}$是正交矩阵，可通过正交变换(Orthogonal Transformation)将矩阵化为对角阵</p>
<script type="math/tex; mode=display">
P^{\mathrm{T}} A P=\Lambda</script><p>由于$P^{T}=P^{-1}$，因此这是一种更特殊的相似变换，实现时只需要对同一个特征值的不同特征向量正交化，然后将所有正交化之后的特征向量进行标准化即可</p>
<blockquote>
<p>例子</p>
</blockquote>
<p>将矩阵通过正交变换化为对角矩阵。对于下面的矩阵</p>
<script type="math/tex; mode=display">
\boldsymbol{A}=\left(\begin{array}{lll}
0 & 1 & 1 \\
1 & 0 & 1 \\
1 & 1 & 0
\end{array}\right)</script><p>其特征多项式为</p>
<script type="math/tex; mode=display">
|\boldsymbol{A}-\lambda \boldsymbol{I}|=\left|\begin{array}{ccc}
-\lambda & 1 & 1 \\
1 & -\lambda & 1 \\
1 & 1 & -\lambda
\end{array}\right|=-(\lambda-2)(\lambda+1)^{2}</script><p>因此其特征值为$2,-1 ，-1$，当$\lambda=2$时，有</p>
<script type="math/tex; mode=display">
(\boldsymbol{A}-2 \boldsymbol{I}) \boldsymbol{x}=\mathbf{0}</script><p>解得</p>
<script type="math/tex; mode=display">
\boldsymbol{x}_{1}=\left(\begin{array}{lll}
1 & 1 & 1
\end{array}\right)^{\mathrm{T}}</script><p>当$\lambda=-1$时，有</p>
<script type="math/tex; mode=display">
(\boldsymbol{I}+\boldsymbol{A}) \boldsymbol{x}=\mathbf{0}</script><p>解得</p>
<script type="math/tex; mode=display">
\begin{array}{llll}
x_{2}=\left(\begin{array}{lll}
-1 & 1 & 0
\end{array}\right)^{\mathrm{T}} \qquad x_{3}=\left(\begin{array}{lll}
-1 & 0 & 1
\end{array}\right)^{\mathrm{T}}
\end{array}</script><p>正交单位化之后为</p>
<script type="math/tex; mode=display">
\begin{array}{l} 
p_{1}=\frac{1}{\sqrt{3}}\left(\begin{array}{llll}
1 & 1 & 1
\end{array}\right)^{\mathrm{T}} \qquad p_{2}=\frac{1}{\sqrt{2}}\left(\begin{array}{ccc}
-1 & 1 & 0
\end{array}\right)^{\mathrm{T}} \qquad p_{3}=\frac{1}{\sqrt{6}}(-1 & -1 & 2)^T
\end{array}</script><p>令</p>
<script type="math/tex; mode=display">
\begin{array}{l} 
\boldsymbol{P}=\left(\begin{array}{lll}
p_{1} & \boldsymbol{p}_{2} & \boldsymbol{p}_{3}
\end{array}\right)=\left(\begin{array}{ccc}
\frac{1}{\sqrt{3}} & -\frac{1}{\sqrt{2}} & -\frac{1}{\sqrt{6}} \\
\frac{1}{\sqrt{3}} & \frac{1}{\sqrt{2}} & -\frac{1}{\sqrt{6}} \\
\frac{1}{\sqrt{3}} & 0 & \frac{2}{\sqrt{6}}
\end{array}\right)
\end{array}</script><p>则有</p>
<script type="math/tex; mode=display">
\boldsymbol{P}^{-1} \boldsymbol{A P}=\boldsymbol{P}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{P}=\left(\begin{array}{ccc}
2 & 0 & 0 \\
0 & -1 & 0 \\
0 & 0 & -1
\end{array}\right)</script><p><strong>正交变换具有一个优良的性质，它可以保持矩阵的对称性</strong></p>
<p>假设$A$是对称矩阵，$P$是正交矩阵，使用下面的正交变换</p>
<script type="math/tex; mode=display">
\boldsymbol{B}=\boldsymbol{P}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{P}</script><p>$B$仍然是对称矩阵，下面给出证明，显然有</p>
<script type="math/tex; mode=display">
\boldsymbol{B}^{\mathrm{T}}=\left(\boldsymbol{P}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{P}\right)^{\mathrm{T}}=\boldsymbol{P}^{\mathrm{T}} \boldsymbol{A}^{\mathrm{T}}\left(\boldsymbol{P}^{\mathrm{T}}\right)^{\mathrm{T}}=\boldsymbol{P}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{P}=\boldsymbol{B}</script><blockquote>
<p>豪斯霍尔德(Householder)变换</p>
</blockquote>
<p>特殊的正交变换<code>豪斯霍尔德</code>(Householder)变换，它在QR算法以及其他矩阵算法中有重要的应用</p>
<p>首先定义Householder矩阵，为如下形式</p>
<script type="math/tex; mode=display">
P=I-2 w \boldsymbol{w}^{\mathrm{T}}</script><p>其中$\boldsymbol{w}$是$n$维非0列向量，且有$|\boldsymbol{w}|=1$，显然矩阵$\boldsymbol{P}$是对称矩阵，并且是正交矩阵</p>
<p>由于$P$是对称矩阵，因此有</p>
<script type="math/tex; mode=display">
P^{\mathrm{T}} \boldsymbol{P}=\boldsymbol{P P}=\left(\boldsymbol{I}-2 \boldsymbol{w} \boldsymbol{w}^{\mathrm{T}}\right)\left(\boldsymbol{I}-2 \boldsymbol{w} \boldsymbol{w}^{\mathrm{T}}\right)=\boldsymbol{I}-4 \boldsymbol{w} \boldsymbol{w}^{\mathrm{T}}+4 \boldsymbol{w}\left(\boldsymbol{w}^{\mathrm{T}} \boldsymbol{w}\right) \boldsymbol{w}^{\mathrm{T}}=\boldsymbol{I}</script><p>故该矩阵是正交矩阵，通常将$P$写成如下形式</p>
<script type="math/tex; mode=display">
\boldsymbol{P}=\boldsymbol{I}-\frac{\boldsymbol{u} \boldsymbol{u}^{\mathrm{T}}}{H}</script><p>其中$u$为任意非$\mathbf{0}$向量且</p>
<script type="math/tex; mode=display">
H=\frac{1}{2}\|\boldsymbol{u}\|^{2}</script><p>这里用$H$对$u$进行了标准化</p>
<p>对于$n$维列向量$\boldsymbol{x}$，构造下面的向量</p>
<script type="math/tex; mode=display">
\boldsymbol{u}=\boldsymbol{x} \mp\|x\| \boldsymbol{e}_{1}</script><p>其中单位向量$\boldsymbol{e}_{1}=\left(\begin{array}{llll}1 &amp; 0 &amp; \cdots &amp; 0\end{array}\right)^{\mathrm{T}}$</p>
<p>根据$\boldsymbol{u}$用上面的式子构造Householder矩阵$\boldsymbol{P}$，下面将向量$x$左乘$P$的结果</p>
<script type="math/tex; mode=display">
\begin{aligned}
\boldsymbol{P} \boldsymbol{x} & =\left(\boldsymbol{I}-\frac{\boldsymbol{u} u^{\mathrm{T}}}{H}\right) \boldsymbol{x}=\boldsymbol{x}-\frac{\boldsymbol{u}}{H}\left(\boldsymbol{x} \mp\|\boldsymbol{x}\| \boldsymbol{e}_{1}\right)^{\mathrm{T}} \boldsymbol{x}=\boldsymbol{x}-\frac{2 \boldsymbol{u}\left(\|\boldsymbol{x}\|^{2} \mp\|\boldsymbol{x}\| x_{1}\right)}{\left(\boldsymbol{x} \mp\|\boldsymbol{x}\| \boldsymbol{e}_{1}\right)^{\mathrm{T}}\left(\boldsymbol{x} \mp\|\boldsymbol{x}\| \boldsymbol{e}_{1}\right)} \\
& =\boldsymbol{x}-\frac{2 \boldsymbol{u}\left(\|\boldsymbol{x}\|^{2} \mp\|\boldsymbol{x}\| x_{1}\right)}{2\|\boldsymbol{x}\|^{2} \mp 2\|x\| x_{1}}=\boldsymbol{x}-\boldsymbol{u}=\pm\|\boldsymbol{x}\| \boldsymbol{e}_{1}
\end{aligned}</script><p>其中$x_{1}$是$x$的第1个分量</p>
<p>这表明将列向量$\boldsymbol{x}$左乘$\boldsymbol{P}$之后将零化$\boldsymbol{x}$除第1个元素之外的所有元素，同时保持向量的长度不变，将行向量右乘该矩阵之后有类似的效果</p>
<p>根据这一特性，我们可以构造以Householder矩阵为基础的正交变换，将矩阵转化为类似对角矩阵的形式，零化主对角线之外的元素</p>
<p>对于对称矩阵$\boldsymbol{A}$，使用它的第1列计算向量$u$，按照上面的式子构造Householder矩阵$P$</p>
<p>然后对$A$进行正交变换，这里的正交变换通过将矩阵$A$先左乘$P$，然后右乘$P$实现</p>
<script type="math/tex; mode=display">
\boldsymbol{P}^{\mathrm{T}} \boldsymbol{A P}=\boldsymbol{P A P}</script><p>左乘$P$实现$A$的第1列的零化，右乘$P$实现$A$的第1行的零化</p>
<p>下面来看矩阵$P$的构造</p>
<p>如果用$A$的整个第1列作为向量，按照上面的式子构造$P$，虽然可在左乘$P$之后将$A$的第1列除第1个元素之外的所有元素全部零化，但会改变$A$的第1行所有元素的值</p>
<p>接下来在右乘$P$的时候无法保证将$P A$的第1行零化，因此$P$需要保证将$A$的第1列的元素零化的同时确保$A$的第1行的元素不变，以便在右乘$P$的时候将这个行零化</p>
<p>我们可以按照下面的形式构造$P$</p>
<script type="math/tex; mode=display">
\boldsymbol{P}=\left(\begin{array}{ccccc}
1 & 0 & 0 & \cdots & 0 \\
0 & p_{22} & p_{23} & \cdots & p_{2 n} \\
0 & p_{32} & p_{33} & \cdots & p_{3 n} \\
\cdots & \cdots & \cdots & & \cdots \\
0 & p_{n 2} & p_{n 3} & \cdots & p_{n n}
\end{array}\right)=\left(\begin{array}{cc}
\boldsymbol{I}_{1 \times 1} & \mathbf{0}_{1 \times(n-1)} \\
\mathbf{0}_{(n-1) \times 1} & \boldsymbol{P}_{(n-1) \times(n-1)}
\end{array}\right)</script><p>其中</p>
<script type="math/tex; mode=display">
\left(\begin{array}{cccc}
p_{22} & p_{23} & \cdots & p_{2 n} \\
p_{32} & p_{33} & \cdots & p_{3 n} \\
\vdots & \vdots & \vdots & \vdots \\
p_{n 2} & p_{n 3} & \cdots & p_{n n}
\end{array}\right)</script><p>是用$\boldsymbol{A}$的第1列的后面$n-1$个元素按照上面式子构造的</p>
<p>我们将上上式的矩阵作为第1次豪斯霍尔德变换的矩阵，记为<script type="math/tex">P_{1}</script>，将<script type="math/tex">A</script>左乘<script type="math/tex">P_{1}</script>之后可以保证<script type="math/tex">A</script>的第1行元素不变，同时将<script type="math/tex">A</script>的第1列的后面<script type="math/tex">n-1</script>个元素全部变为0</p>
<p>接下来右乘<script type="math/tex">P_{1}</script>，由于<script type="math/tex">A</script>是对称矩阵，因此第1列和第1行相同，右乘<script type="math/tex">P_{1}</script>可以将第1行后面<script type="math/tex">n-2</script>个元素全部变为0，并且不改变第1列所有元素的值，因此不会破坏前面的列零化结果</p>
<script type="math/tex; mode=display">
\begin{aligned}
\boldsymbol{A}_{1}=\boldsymbol{P}_{1} \boldsymbol{A} \boldsymbol{P}_{1} & =\left(\begin{array}{ccccc}
a_{11} & a_{12} & a_{13} & \cdots & a_{1 n} \\
k & * & * & \cdots & * \\
0 & * & * & \cdots & * \\
\vdots & \vdots & \vdots & & \vdots \\
0 & * & * & \cdots & *
\end{array}\right)\left(\begin{array}{ccccc}
1 & 0 & 0 & \cdots & 0 \\
0 & p_{22} & p_{23} & \cdots & p_{2 n} \\
0 & p_{32} & p_{33} & \cdots & p_{3 n} \\
\cdots & \cdots & \cdots & \cdots & \cdots \\
0 & p_{n 2} & p_{n 3} & \cdots & p_{n n}
\end{array}\right) \\
& =\left(\begin{array}{ccccc}
a_{11} & k & 0 & \cdots & 0 \\
k & * & * & \cdots & * \\
0 & * & * & \cdots & * \\
\vdots & \vdots & \vdots & & \vdots \\
0 & * & * & \cdots & *
\end{array}\right)
\end{aligned}</script><p>然后进行第2次豪斯霍尔德变换</p>
<p>由于正交变换可以保持矩阵的对称性，因此<script type="math/tex">\boldsymbol{A}_{1}</script>仍然是对称矩阵，用<script type="math/tex">A_{1}</script>的第2列的后面<script type="math/tex">n-2</script>个元素构造<script type="math/tex">P_{2}</script></p>
<script type="math/tex; mode=display">
p_{2}=\left(\begin{array}{ccccc}
1 & 0 & 0 & \cdots & 0 \\
0 & 1 & 0 & \cdots & 0 \\
0 & 0 & p_{33} & \cdots & p_{3 n} \\
\vdots & \vdots & \vdots & & \vdots \\
0 & 0 & p_{n 3} & \cdots & p_{n n}
\end{array}\right)=\left(\begin{array}{cc}
\boldsymbol{I}_{2 \times 2} & \mathbf{0}_{2 \times(n-2)} \\
\mathbf{0}_{(n-2) \times 2} & \boldsymbol{P}_{(n-2) \times(n-2)}
\end{array}\right)</script><p>其中</p>
<script type="math/tex; mode=display">
\left(\begin{array}{ccc}
p_{33} & \cdots & p_{3 n} \\
\vdots & & \vdots \\
p_{n 3} & \cdots & p_{n n}
\end{array}\right)</script><p>根据$A_{1}$的第2列的后面$n-2$个元素按照上面的式子构造</p>
<p>经过第2次豪斯霍尔德变换可以将$A_{1}$的第2列的后面$n-3$个元素，第2行的后面$n-3$个元素全部变为0</p>
<script type="math/tex; mode=display">
\boldsymbol{A}_{2}=\boldsymbol{P}_{2} \boldsymbol{A}_{1} \boldsymbol{P}_{2}=\left(\begin{array}{ccccc}
a_{11} & k & 0 & \ldots & 0 \\
k & s & t & \ldots & 0 \\
0 & t & * & \ldots & * \\
\vdots & \vdots & \vdots & \vdots & \vdots \\
0 & 0 & * & \ldots & *
\end{array}\right)</script><p>依此类推，经过$n-2$次豪斯霍尔德变换，可以将对称矩阵化为如下的对称三对角矩阵(Tridiagonal Matrix)</p>
<script type="math/tex; mode=display">
\left(\begin{array}{ccccc}
b_{11} & b_{12} & \cdots & \cdots & 0 \\
b_{21} & b_{22} & b_{23} & \cdots & 0 \\
0 & b_{32} & b_{33} & \cdots & 0 \\
\cdots & \cdots & \cdots & \cdots & \cdots \\
0 & 0 & \cdots & b_{n, n-1} & b_{n n}
\end{array}\right)</script><p>这种矩阵除主对角线、主对角线以上及以下的对角线之外，其他元素均为0</p>
<p>对于一般的$n$阶矩阵$\boldsymbol{A}$，用同样的方法构造豪斯霍尔德矩阵</p>
<p>左乘$P$之后将$A$的第1列后面$n-2$个元素零化，同时保持$\boldsymbol{A}$的第1行元素不变</p>
<p>由于$\boldsymbol{A}$不是对角矩阵，其行和列不相等，因此右乘$\boldsymbol{P}$ 时候无法将其第1行元素零化</p>
<p>同样不能用完整的列构造豪斯霍尔德变换矩 阵，否则右乘该矩阵的时候会破坏前面零化的结果</p>
<p>用和对称矩阵相同的方法构造变换矩阵，第一次豪斯霍尔德变换之后的结果为</p>
<script type="math/tex; mode=display">
A_{1}=P_{1} A P_{1}=\left(\begin{array}{ccccc}
a_{11} & * & * & \cdots & * \\
k & * & * & \cdots & * \\
0 & * & * & \cdots & * \\
\vdots & \vdots & \vdots & & \vdots \\
0 & * & * & \cdots & *
\end{array}\right)</script><p>第二次豪斯霍尔德变换可以将第2列的后面$n-3$个元素零化，变换之后的结果为</p>
<script type="math/tex; mode=display">
\boldsymbol{A}_{2}=\boldsymbol{P}_{2} \boldsymbol{A}_{1} \boldsymbol{P}_{2}=\left(\begin{array}{cccccc}
a_{11} & * & * & * & \cdots & * \\
k & * & * & * & \cdots & * \\
0 & s & * & * & \cdots & * \\
0 & 0 & * & * & \cdots & * \\
\vdots & \vdots & \vdots & \vdots & & \vdots \\
0 & 0 & * & * & \cdots & *
\end{array}\right)</script><p>依次类推，通过$n-2$次豪斯霍尔德变换可以将$A$化为如下形式的<code>上海森堡矩阵</code>(upper-Hessenberg form)</p>
<script type="math/tex; mode=display">
\left(\begin{array}{cccccc}
b_{11} & b_{12} & b_{13} & b_{14} & \cdots & b_{1 n} \\
b_{21} & b_{22} & b_{23} & b_{24} & \cdots & b_{2 n} \\
0 & b_{32} & b_{33} & b_{34} & \cdots & b_{3 n} \\
0 & 0 & b_{43} & b_{44} & \cdots & b_{4 n} \\
\vdots & \vdots & \vdots & \vdots & & \vdots \\
0 & 0 & 0 & 0 & \cdots & b_{n n}
\end{array}\right)</script><p>这种矩阵除主对角线及以上，主对角线下面的对角线的元素外，其他的元素均为0</p>
<h2 id="QR-算法"><a href="#QR-算法" class="headerlink" title="QR 算法"></a>QR 算法</h2><p>下面介绍求解高阶矩阵特征值的<code>QR筫法</code>，它被誉为20世纪十大算法之一</p>
<p>它依赖于$\mathrm{QR}$分解，对于一个矩阵$A$，$\mathrm{QR}$分解将其化为一个正交矩阵$Q$与一个上三角矩阵$R$的乘积</p>
<script type="math/tex; mode=display">
\boldsymbol{A}=\boldsymbol{Q R}</script><p>$\mathrm{QR}$算法是一种迭代法，从矩阵<script type="math/tex">\boldsymbol{A}_{0}=\boldsymbol{A}</script>开始，每次构造一个相似变换，将<script type="math/tex">\boldsymbol{A}_{k-1}</script>变换为<script type="math/tex">\boldsymbol{A}_{k}</script>，最后<script type="math/tex">A_{k}</script>收敛到一个上角矩阵，主对角线元素即为其特征值</p>
<p>由于矩阵<script type="math/tex">A</script>与<script type="math/tex">A_{k}</script>相似，因此它们有相同的特征值，得到了<script type="math/tex">A_{k}</script>的特征值即得到了<script type="math/tex">A</script>的特征值</p>
<p>问题的核心是如何构造这种相似变换，这借助于$\mathrm{QR}$分解实现，每次迭代时，首先对$\boldsymbol{A}_{k}$进行$\mathrm{QR}$分解</p>
<script type="math/tex; mode=display">
\boldsymbol{A}_{k}=\boldsymbol{Q}_{k} \boldsymbol{R}_{k}</script><p>然后用分解结果构造一个新的矩阵$\boldsymbol{A}_{k+1}$，这里将$\mathrm{QR}$分解的结果矩阵交换顺序后相乘</p>
<script type="math/tex; mode=display">
\boldsymbol{A}_{k+1}=\boldsymbol{R}_{k} \boldsymbol{Q}_{k}</script><p>上面两个式子给出了根据当前矩阵构造下一个矩阵的方式，称为$\mathrm{QR}$迭代</p>
<p>因为<script type="math/tex">A_{k}</script>与<script type="math/tex">A_{k+1}</script>是相似的，式<script type="math/tex">A_k</script>两边同时左乘<script type="math/tex">Q_{k}^{-1}</script>可以得到</p>
<script type="math/tex; mode=display">
\boldsymbol{R}_{k}=\boldsymbol{Q}_{k}^{-1} \boldsymbol{A}_{k}</script><p>将其代人式$A_{k+1}$可得</p>
<script type="math/tex; mode=display">
\boldsymbol{A}_{k+1}=\boldsymbol{R}_{k} \boldsymbol{Q}_{k}=\boldsymbol{Q}_{k}^{-1} \boldsymbol{A}_{k} \boldsymbol{Q}_{k}</script><p>由于相似具有传递性，因此$A$与$A_{k}, k=1, \cdots, n$相似</p>
<p>如果$\boldsymbol{A}$满足一定的条件，那么$\mathrm{QR}$迭代所产生的矩阵序列${\boldsymbol{A}_{k}}$将收敛到一个上三角矩阵，主对角线元素即为$\boldsymbol{A}$的特征值</p>
<p>$Q R$迭代是正交变换，如果$A$是对称矩阵，这种变换将保持对称性，且收敛到上三角矩阵，因此最终会收敛到对角矩阵</p>
<p>对于实对称矩阵$A$，$Q R$迭代代产生的所有正交矩阵$Q_{k}$的乘积的所有列，即为$\boldsymbol{A}$的特征向量，由于</p>
<script type="math/tex; mode=display">
\boldsymbol{A}_{k+1}=Q_{k}^{-1} A_{k} Q_{k}</script><p>因此</p>
<script type="math/tex; mode=display">
\begin{aligned}
\Lambda & =A_{k}=Q_{k-1}^{-1} A_{k-1} Q_{k-1}=Q_{k-1}^{-1} Q_{k-2}^{-1} A_{k-2} Q_{k-2} Q_{k-1}=\cdots \\
& =Q_{k-1}^{-1} Q_{k-2}^{-1} \cdots Q_{0}^{-1} A_{0} Q_{0} \cdots Q_{k-2} Q_{k-1}=\left(Q_{0} \cdots Q_{k-2} Q_{k-1}\right)^{-1} A_{0}\left(Q_{0} \cdots Q_{k-2} Q_{k-1}\right) \\
& =\left(Q_{0} \cdots Q_{k-2} Q_{k-1}\right)^{-1} A\left(Q_{0} \cdots Q_{k-2} Q_{k-1}\right)
\end{aligned}</script><p>如果令</p>
<script type="math/tex; mode=display">
P=Q_{0} \ldots Q_{k-2} Q_{k-1}</script><p>则</p>
<script type="math/tex; mode=display">
\Lambda=P^{-1} A P</script><p>因此$P$的列为$A$的特征向量<br>下面来看$\mathrm{QR}$算法的一个例子，对于如下矩阵</p>
<script type="math/tex; mode=display">
A=\left(\begin{array}{ccc}
-149 & -50 & -154 \\
537 & 180 & 546 \\
-27 & -9 & -25
\end{array}\right)</script><p>$Q R$算法第1次迭代的结果为</p>
<script type="math/tex; mode=display">
\boldsymbol{A}_{1}=\boldsymbol{R}_{0} \boldsymbol{Q}_{0}=\left(\begin{array}{ccc}
28.8263 & -259.8671 & 773.9292 \\
1.0353 & -8.6686 & 33.1759 \\
-0.5973 & 5.5786 & -14.1578
\end{array}\right)</script><p>再经过5次迭代后的结果为</p>
<script type="math/tex; mode=display">
\boldsymbol{A}_{6}=\boldsymbol{R}_{5} \boldsymbol{Q}_{5}=\left(\begin{array}{ccc}
3.0321 & -8.0851 & 804.6651 \\
0.0017 & 0.9931 & 145.5046 \\
-0.0001 & 0.0005 & 1.9749
\end{array}\right)</script><p>此时矩阵$A_{6}$已经接近于上三角矩阵，主对角线元素接近于$A$的特征值，事实上，矩阵$A$的特征值为$1,2,3$ </p>
<p>为了加速收敛，通常采用带位移的$QR$算法(Shifted QR Algorithm)，在第$k$次迭代时，对于设定的移位常数$s_{k}$，迭代公式为</p>
<script type="math/tex; mode=display">
\boldsymbol{A}_{k}-s_{k} I=\boldsymbol{Q}_{k} \boldsymbol{R}_{k} \qquad \boldsymbol{A}_{k+1}=\boldsymbol{R}_{k} \boldsymbol{Q}_{k}+s_{k} \boldsymbol{I}</script><p>即先将矩阵<script type="math/tex">\boldsymbol{A}_{k}</script>减掉<script type="math/tex">s_{k} \boldsymbol{I}</script>后再进行<script type="math/tex">\mathrm{QR}</script>分解，在构造<script type="math/tex">\boldsymbol{A}_{k+1}</script>时再将<script type="math/tex">s_{k} \boldsymbol{I}</script>加回来</p>
<p>按照这种迭代公式，<script type="math/tex">\boldsymbol{A}_{k}</script>与<script type="math/tex">\boldsymbol{A}_{k+1}</script>也是相似的，根据上式的1式有</p>
<script type="math/tex; mode=display">
\boldsymbol{R}_{k}=\boldsymbol{Q}_{k}^{-1}\left(\boldsymbol{A}_{k}-s_{k} \boldsymbol{I}\right)</script><p>将其代人上式的2式，可得</p>
<script type="math/tex; mode=display">
A_{k+1}=R_{k} Q_{k}+s_{k} I=Q_{k}^{-1}\left(A_{k}-s_{k} I\right) Q_{k}+s_{k} I=Q_{k}^{-1} A_{k} Q_{k}-Q_{k}^{-1} s_{k} I Q_{k}+s_{k} I=Q_{k}^{-1} A_{k} Q_{k}</script><p>因此<script type="math/tex">\boldsymbol{A}_{k}</script>与<script type="math/tex">\boldsymbol{A}_{k+1}</script>相似</p>
<blockquote>
<p>移位系数$s_{k}$的计算</p>
</blockquote>
<p>一种方案是选择<script type="math/tex">\boldsymbol{A}_{k}</script>右下角<script type="math/tex">2 \times 2</script>子矩阵的两个特征值中接近于<script type="math/tex">\boldsymbol{A}_{k}</script>元素<script type="math/tex">a_{n, n-1}</script>的那个特征值，以便于使得经过此次<script type="math/tex">\mathrm{QR}</script>迭代后<script type="math/tex">\boldsymbol{A}_{k+1}</script>的<script type="math/tex">a_{n, n-1}</script>变为0</p>
<p>计算此子矩阵的特征值可以通过求解特征方程实现</p>
<script type="math/tex; mode=display">
\left|\begin{array}{cc}
a_{n-1, n-1}-\lambda & a_{n-1, n} \\
a_{n, n-1} & a_{n, n}-\lambda
\end{array}\right|=0</script><p>这里<script type="math/tex">\boldsymbol{A}_{k+1}</script>的<script type="math/tex">a_{n n}</script>即为<script type="math/tex">\boldsymbol{A}</script>的一个特征值，对剩下的<script type="math/tex">(n-1) \times(n-1)</script>矩阵继续进行<script type="math/tex">\mathrm{QR}</script>算法迭代， 得到所有的特征值</p>
<p>对于一般的矩阵，QR算法的收敛速度可能很慢，如果将矩阵变换成接近于三角阵，则能加快收敛速度</p>
<p>如果是对称矩阵，可先用豪斯霍尔德变换将其化为对称三对角矩阵，然后用$Q R$算法进行达代，收敛到对角矩阵</p>
<p>求解特征值的整个流程为: 对称矩阵$\rightarrow$对称三对角矩阵$\rightarrow$对角矩阵</p>
<p>对于普通矩阵，可用豪斯霍尔德变换将其化为上海森堡矩阵，然后用QR算法进行迭代，收敛到上三角矩阵</p>
<p>整个流程为: 普通矩阵$\rightarrow$上海森堡矩阵$\rightarrow$三角矩阵</p>
<h2 id="广义特征值"><a href="#广义特征值" class="headerlink" title="广义特征值"></a>广义特征值</h2><p><code>广义特征值</code>(Generalized Eigenvalue)是特征值的推广，定义于两个矩阵之上</p>
<p>对于方阵$A$和$B$，如果存在一个数$\lambda$及非0向量$\boldsymbol{x}$，满足</p>
<script type="math/tex; mode=display">
\boldsymbol{A x}=\lambda \boldsymbol{B x}</script><p>则称$\lambda$为广义特征值，$x$为广义特征向量，类似的有特征方程</p>
<script type="math/tex; mode=display">
|A-\lambda B|=0</script><p>如果矩阵$B$可逆，对第一个式子左乘$B^{-1}$，则式1的问题等价于下面的特征值问题</p>
<script type="math/tex; mode=display">
B^{-1} \boldsymbol{A x}=\lambda \boldsymbol{x}</script><p>广义特征值在机器学习中被广泛使用，包括流形学习、谱聚类算法，以及线性判别分析等</p>
<h2 id="瑞利商"><a href="#瑞利商" class="headerlink" title="瑞利商"></a>瑞利商</h2><blockquote>
<p>瑞利商</p>
</blockquote>
<p>方阵$A$和非0向量$x$的<code>瑞利商</code>(Rayleigh Quotient)定义为如下比值</p>
<script type="math/tex; mode=display">
R(\boldsymbol{A}, \boldsymbol{x})=\frac{\boldsymbol{x}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{x}}{\boldsymbol{x}^{\mathrm{T}} \boldsymbol{x}}</script><p>根据式子的定义，对于任意的非0实数$k$，有</p>
<script type="math/tex; mode=display">
R(\boldsymbol{A}, k \boldsymbol{x})=R(\boldsymbol{A}, \boldsymbol{x})</script><p>即对向量缩放之后其瑞利商不变，瑞利商存在冗余，证明如下</p>
<script type="math/tex; mode=display">
R(\boldsymbol{A}, k \boldsymbol{x})=\frac{(k \boldsymbol{x})^{\mathrm{T}} \boldsymbol{A}(k \boldsymbol{x})}{(k \boldsymbol{x})^{\mathrm{T}}(k \boldsymbol{x})}=\frac{k^{2} \boldsymbol{x}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{x}}{k^{2} \boldsymbol{x}^{\mathrm{T}} \boldsymbol{x}}=\frac{\boldsymbol{x}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{x}}{\boldsymbol{x}^{\mathrm{T}} \boldsymbol{x}}</script><p>假设<script type="math/tex">\lambda_{\text {min }}</script>是矩阵<script type="math/tex">\boldsymbol{A}</script>的最小特征值，<script type="math/tex">\lambda_{\max }</script>是最大特征值，则有</p>
<script type="math/tex; mode=display">
\lambda_{\min } \leqslant R(\boldsymbol{A}, \boldsymbol{x}) \leqslant \lambda_{\max }</script><p>即瑞利商的最小值为矩阵的最小特征值，最大值为矩阵的最大特征值</p>
<p>并且当$x$分别为最小和最大的特征值对应的特征向量的时候取得这两个值，可以用<code>拉格朗日乘数法</code>证明</p>
<p>由于将向量乘以非0系数之后瑞利商不变，因此式1极值问题的解不唯一</p>
<p>为此增加一个约束条件以保证解的唯一性，同时简化问题的表述，限定$x$为单位向量，有下面的等式约束</p>
<script type="math/tex; mode=display">
\boldsymbol{x}^{\mathrm{T}} \boldsymbol{x}=1</script><p>增加此约束之后，瑞利商变为</p>
<script type="math/tex; mode=display">
R(\boldsymbol{A}, \boldsymbol{x})=\boldsymbol{x}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{x}</script><p>构造拉格朗日乘子函数</p>
<script type="math/tex; mode=display">
L(\boldsymbol{x}, \lambda)=\boldsymbol{x}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{x}+\lambda\left(\boldsymbol{x}^{\mathrm{T}} \boldsymbol{x}-1\right)</script><p>对$\boldsymbol{x}$求样度并令栖度为$\boldsymbol{0}$可以得到</p>
<script type="math/tex; mode=display">
2 A x+2 \lambda x=0</script><p>这里利用了矩阵与向量求导公式，上式等价于</p>
<script type="math/tex; mode=display">
A \boldsymbol{x}=\lambda \boldsymbol{x}</script><p>此结果意味着瑞利商的所有极值在矩阵的特征值与特征向量处取得</p>
<p>假设<script type="math/tex">\lambda_{i}</script>是<script type="math/tex">A</script>的第<script type="math/tex">i</script>个待征值、<script type="math/tex">x_{i}</script>是其对应的特征向量，将它们代人瑞利商的定义，可以得到</p>
<script type="math/tex; mode=display">
R\left(\boldsymbol{A}, \boldsymbol{x}_{i}\right)=\frac{\boldsymbol{x}_{i}^{\mathrm{T}}\left(\boldsymbol{A} \boldsymbol{x}_{i}\right)}{\boldsymbol{x}_{i}^{\mathrm{T}} \boldsymbol{x}_{i}}=\frac{\boldsymbol{x}_{i}^{\mathrm{T}}\left(\lambda_{i} \boldsymbol{x}_{i}\right)}{\boldsymbol{x}_{i}^{\mathrm{T}} \boldsymbol{x}_{i}}=\frac{\lambda_{i} \boldsymbol{x}_{i}^{\mathrm{T}} \boldsymbol{x}_{i}}{\boldsymbol{x}_{i}^{\mathrm{T}} \boldsymbol{x}_{i}}=\lambda_{i}</script><p>因此，在最大的特征值处，瑞利商有最大值；在最小的特征值处，瑞利商有最小值</p>
<p>瑞利商在机器学习领域的典型应用是<code>主成分分析</code></p>
<blockquote>
<p>广义瑞利商</p>
</blockquote>
<p>对瑞利商进行推广，得到<code>广义瑞利商</code>，定义为</p>
<script type="math/tex; mode=display">
R(\boldsymbol{A}, \boldsymbol{B}, \boldsymbol{x})=\frac{\boldsymbol{x}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{x}}{\boldsymbol{x}^{\mathrm{T}} \boldsymbol{B} \boldsymbol{x}}</script><p>同样，广义瑞利商存在余，将向量$x$缩放之后广义瑞利商不变</p>
<p>假设对任意的非0向量$x$，有$\boldsymbol{x}^{\mathrm{T}} B x&gt;0$</p>
<p>如果令$B=C C^{\mathrm{T}}$，这是对矩阵$B$的<code>楚列斯基</code>(Cholesky)分解，同时令$x=\left(C^{\mathrm{T}}\right)^{-1} y$，则可以将广义瑞利商转化成瑞利商的形式</p>
<script type="math/tex; mode=display">
\frac{\boldsymbol{x}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{x}}{\boldsymbol{x}^{\mathrm{T}} \boldsymbol{B} \boldsymbol{x}}=\frac{\left(\left(\boldsymbol{C}^{\mathrm{T}}\right)^{-1} \boldsymbol{y}\right)^{\mathrm{T}} \boldsymbol{A}\left(\left(\boldsymbol{C}^{\mathrm{T}}\right)^{-1} \boldsymbol{y}\right)}{\left(\left(\boldsymbol{C}^{\mathrm{T}}\right)^{-1} \boldsymbol{y}\right)^{\mathrm{T}} \boldsymbol{C} \boldsymbol{C}^{\mathrm{T}}\left(\left(\boldsymbol{C}^{\mathrm{T}}\right)^{-1} \boldsymbol{y}\right)}=\frac{\boldsymbol{y}^{\mathrm{T}} \boldsymbol{C}^{-1} \boldsymbol{A}\left(\boldsymbol{C}^{\mathrm{T}}\right)^{-1} \boldsymbol{y}}{\boldsymbol{y}^{\mathrm{T}} \boldsymbol{C}^{-1} \boldsymbol{C} \boldsymbol{C}^{\mathrm{T}}\left(\boldsymbol{C}^{\mathrm{T}}\right)^{-1} \boldsymbol{y}}=\frac{\boldsymbol{y}^{\mathrm{T}} \boldsymbol{C}^{-1} \boldsymbol{A}\left(\boldsymbol{C}^{\mathrm{T}}\right)^{-1} \boldsymbol{y}}{\boldsymbol{y}^{\mathrm{T}} \boldsymbol{y}}</script><p>根据瑞利商的结论，广义瑞利商的最大值和最小值由矩阵$C^{-1} A\left(C^{\mathrm{T}}\right)^{-1}$的最大和最小特佂值决定</p>
<p>也可以直接通过广义特征值得到广义瑞利商的极值，与瑞利商类似，加上等式约束消掉最优解的冗余</p>
<script type="math/tex; mode=display">
\boldsymbol{x}^{\mathrm{T}} \boldsymbol{B} \boldsymbol{x}=1</script><p>广义瑞利商变为</p>
<script type="math/tex; mode=display">
R(\boldsymbol{A}, \boldsymbol{B}, \boldsymbol{x})=\boldsymbol{x}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{x}</script><p>可以用<code>拉格朗日乘数法</code>求解，构造拉格朗日乘子函数</p>
<script type="math/tex; mode=display">
L(\boldsymbol{x}, \boldsymbol{\lambda})=\boldsymbol{x}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{x}+\boldsymbol{\lambda}\left(\boldsymbol{x}^{\mathrm{T}} \boldsymbol{B} \boldsymbol{x}-1\right)</script><p>对$\boldsymbol{x}$求梯度并令梯度为$\boldsymbol{0}$，可以得到</p>
<script type="math/tex; mode=display">
2 A x+2 \lambda B x=0</script><p>这等价于</p>
<script type="math/tex; mode=display">
\boldsymbol{A} \boldsymbol{x}=\lambda \boldsymbol{B x}</script><p>这是广义特征值问题，如果矩阵$\boldsymbol{B}$可逆，那么上式两边同乘以其逆矩阵可以得到</p>
<script type="math/tex; mode=display">
B^{-1} A x=\lambda x</script><p>因此广义瑞利商的所有极值在上面的广义特征值处取得，假设<script type="math/tex">\lambda_{i}</script>是第<script type="math/tex">i</script>个广义特征值，<script type="math/tex">\boldsymbol{x}_{i}</script>是其对应的特征向量，将它们代人广义瑞利商的定义，可以得到</p>
<script type="math/tex; mode=display">
R\left(\boldsymbol{A}, \boldsymbol{B}, \boldsymbol{x}_{i}\right)=\frac{\boldsymbol{x}_{i}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{x}_{i}}{\boldsymbol{x}_{i}^{\mathrm{T}} \boldsymbol{B} \boldsymbol{x}_{i}}=\frac{\boldsymbol{x}_{i}^{\mathrm{T}} \lambda_{i} B x_{i}}{\boldsymbol{x}_{i}^{\mathrm{T}} \boldsymbol{B} \boldsymbol{x}_{i}}=\lambda_{i}</script><p>因此广义瑞利商的极大值在最大广义特征值处取得，极小值在最小广义特征值处取得</p>
<p><strong>线性判別分析的优化目标函数即为广义瑞利商</strong></p>
<h2 id="谱范数与特征值的关系"><a href="#谱范数与特征值的关系" class="headerlink" title="谱范数与特征值的关系"></a>谱范数与特征值的关系</h2><p>前面定义了谱范数的概念，可以证明矩阵$\boldsymbol{W}$的谱范数等于$\boldsymbol{W}^{\mathrm{T}} \boldsymbol{W}$的最大特征值的平方根，即$\boldsymbol{W}$最大的奇异值</p>
<script type="math/tex; mode=display">
\|\boldsymbol{W}\|_{2}=\max \left\{\sigma_{1}，\cdots，\sigma_{n}\right\}</script><p>其中<script type="math/tex">\sigma_{1}，\cdots，\sigma_{n}</script>为<script type="math/tex">\boldsymbol{W}</script>的奇异值，是<script type="math/tex">\boldsymbol{W}^{\mathrm{T}} \boldsymbol{W}</script>的特征值的平方根，奇异值将在后面详细介绍，根据定义，谱范数的平方为</p>
<script type="math/tex; mode=display">
|\boldsymbol{W}\|_{2}^{2}=\max _{\boldsymbol{x} \neq 0} \frac{\boldsymbol{x}^{\mathrm{T}} \boldsymbol{W}^{\mathrm{T}} \boldsymbol{W} \boldsymbol{x}}{\boldsymbol{x}^{\mathrm{T}} \boldsymbol{x}}</script><p>它就是瑞利商的极大值，上一节已经证明了这一最优化问题的解是矩阵$\boldsymbol{W}^{\mathrm{T}} \boldsymbol{W}$的最大特征值，因此结论成立</p>
<p>Python中linalg的norm函数提供了计算矩阵范数的功能，函数的输人参数为要计算的矩阵，以及范数的类型，如果类型值为2，则计算谱范数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">A = np.array([[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>],[<span class="number">8</span>,<span class="number">9</span>,<span class="number">10</span>,<span class="number">11</span>]])</span><br><span class="line"><span class="built_in">print</span>(n)</span><br></pre></td></tr></table></figure>
<p>程序运行结果为22</p>
<h2 id="条件数"><a href="#条件数" class="headerlink" title="条件数"></a>条件数</h2><p>如果矩阵$W$可逆，条件数(Condition Number)定义为它的范数与它的逆矩阵范数的乘积</p>
<script type="math/tex; mode=display">
\operatorname{cond}(\boldsymbol{W})=\|\boldsymbol{W}\| \cdot\left\|\boldsymbol{W}^{-1}\right\|</script><p>这里的范数可以是任何一种范数</p>
<p>如果使用谱范数，则$|\boldsymbol{W}|$等于$\boldsymbol{W}$的最大奇异值，$\left|\boldsymbol{W}^{-1}\right|$等于$W$最小奇异值的逆，根据谱范数的定义有</p>
<script type="math/tex; mode=display">
\left\|\boldsymbol{W}^{-1}\right\|=\max _{\boldsymbol{y} \neq 0} \frac{\left\|\boldsymbol{W}^{-1} y\right\|}{\|\boldsymbol{y}\|}=\max _{\boldsymbol{x} \neq 0} \frac{\|\boldsymbol{x}\|}{\|\boldsymbol{W} \boldsymbol{x}\|}=\frac{1}{\min _{\boldsymbol{x} \neq 0} \frac{\|\boldsymbol{W} \boldsymbol{x}\|}{\|\boldsymbol{x}\|}}</script><p>上式第二步进行了换元，令$\boldsymbol{W}^{-1} y=x$，根据前二节的结论，$\frac{|\boldsymbol{W} \boldsymbol{x}|}{|\boldsymbol{x}|}$的最小奇异值</p>
<p>此时条件数等于矩阵的最大奇异值与最小奇异值的比值</p>
<script type="math/tex; mode=display">
\operatorname{cond}(\boldsymbol{W})=\frac{\max \left\{\sigma_{1},\cdots,\sigma_{n}\right\}}{\min \left\{\sigma_{1},\cdots,\sigma_{n}\right\}}</script><p>其中<script type="math/tex">\sigma_{1}, \cdots, \sigma_{n}</script>为<script type="math/tex">W</script>的奇异值，显然矩阵的条件数总是大于或等于1</p>
<p><strong>条件数决定了矩阵的稳定性</strong>，一个矩阵的条件数越大，则它越接近于不可逆矩阵，矩阵越”病态”</p>
<p>条件数在诸多算法的稳定性分析中有重要的作用，Python中linalg的cond函数实现了计算矩阵条件数的功能</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">A = np.array([[<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">0</span>,<span class="number">5</span>]])</span><br><span class="line">c = np.linalg.cond(A)</span><br><span class="line"><span class="built_in">print</span>(c)</span><br></pre></td></tr></table></figure>
<p>程序运行结果为$5.0$，是该矩阵最大特征值与最小特征值的比值，在这里奇异值等于特征值</p>
<h2 id="应用——谱归一化与谱正则化"><a href="#应用——谱归一化与谱正则化" class="headerlink" title="应用——谱归一化与谱正则化"></a>应用——谱归一化与谱正则化</h2><blockquote>
<p>正则化</p>
</blockquote>
<p>正则化是机器学习中减轻过拟合的一种技术，它迫使模型的参数值很小，使模型变得更简单，一般情况下，简单的模型有更好的泛化性能</p>
<p>正则化可以通过在目标函数中增加正则化项实现，正则化项通常为参数向量的L1范数，或L2范数的平方</p>
<p><code>谱正则化</code>(Spectral Regularization)用谱范数构造正则化项</p>
<p>另外一种技术是<code>谱归一化</code>(Spectral Normalization)，通过用谱范数对线性映射的矩阵进行谱归一化而确保映射有较小的李普希茨常数，从而保证机器学习模型对输人数据的扰动不敏感</p>
<p>神经网络中用权重矩阵$\boldsymbol{W}$与偏置向量$\boldsymbol{b}$对输人数据$\boldsymbol{x}$进行映射，得到输出结果$W x+b$，如果此映射满足李普希茨条件(这里将其推广到多元函数，将绝对值改为向量的范数)，则有</p>
<script type="math/tex; mode=display">
\left\|\boldsymbol{W} x_{1}+b-W x_{2}-b\right\|=\left\|\boldsymbol{W} x_{1}-\boldsymbol{W} x_{2}\right\| \leqslant K\left\|x_{1}-x_{2}\right\|</script><p>其中$K$为李普希茨常数，将式子变形后可以得到</p>
<script type="math/tex; mode=display">
\frac{\left\|\boldsymbol{W}\left(\boldsymbol{x}_{1}-\boldsymbol{x}_{2}\right)\right\|}{\left\|\boldsymbol{x}_{1}-\boldsymbol{x}_{2}\right\|} \leqslant K</script><p>上式左侧部分的极大值就是权重矩阵的谱范数</p>
<p>如果权重矩阵的谱范数存在一个较小的上界，则神经网络该层的映射有较小的李普希茨常数，从而保证输人值的较小改变不会导致输出值的突变，映射更为平滑</p>
<p>假设权重矩阵的谱范数为$\sigma(\boldsymbol{W})$，如果用它对矩阵进行归一化</p>
<script type="math/tex; mode=display">
\overline {W}_{\mathrm{SN}}(\boldsymbol{W})=\boldsymbol{W} / \sigma(\boldsymbol{W})</script><p>则能保证归一化之后的权重矩阵满足$\sigma(\boldsymbol{W})=1$，这由矩阵乘以常数之后的特征值的性质保证</p>
<p>前两节已经证明谱范数是矩阵$W$的最大奇异值，计算矩阵奇异值的代价太大，因此在实现时需要对谱范数$\sigma(\boldsymbol{W})$的值近似计算，可以采用幂迭代法</p>
<p>接下来考虑如何用谱范数为神经网络的目标函数构造正则化项(Spectral Norm Regularizer)</p>
<p>给定训练样本集<script type="math/tex">\left(\boldsymbol{x}_{i}, \boldsymbol{y}_{i}\right), i=1, \cdots, N, \boldsymbol{x}_{i}</script>为输人向量，<script type="math/tex">\boldsymbol{y}_{i}</script>为标签向量，加上谱正则化项后的目标函数为</p>
<script type="math/tex; mode=display">
\frac{1}{N} \sum_{i=1}^{N} L\left(\boldsymbol{x}_{i}, \boldsymbol{y}_{i}\right)+\frac{\lambda}{2} \sum_{i=1}^{l} \sigma\left(\boldsymbol{W}^{(i)}\right)^{2}</script><p>其中<script type="math/tex">L\left(\boldsymbol{x}_{i}, \boldsymbol{y}_{i}\right)</script>为对单个样本的损失函数，<script type="math/tex">l</script>为神经网络的层数，<script type="math/tex">\boldsymbol{W}^{(i)}</script>为第<script type="math/tex">i</script>层的权重矩阵</p>
<p>上式第2项为谱正则化项，$\lambda&gt;0$为正则化项的权重，谱正则化项由神经网络所有层权重矩阵的谱范数平方之和构成</p>
<p>可以防止权重矩阵出现大的谱范数，从而保证神经网络的映射有较小的李普希茨常数</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/narutohyc">narutohyc</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://study.hycbook.com/article/58496.html">https://study.hycbook.com/article/58496.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="external nofollow noreferrer" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://study.hycbook.com" target="_blank">兼一书虫</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B0%E5%AD%A6/">机器学习数学</a><a class="post-meta__tags" href="/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/">线性代数</a><a class="post-meta__tags" href="/tags/%E7%9F%A9%E9%98%B5%E8%AE%BA/">矩阵论</a></div><div class="post_share"><div class="social-share" data-image="https://pic.hycbook.com/i/hexo/post_cover/蕾姆5.webp" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><link rel="stylesheet" href="/" media="defer" onload="this.media='all'"/><div class="post-reward"><button class="tip-button reward-button"><span class="tip-button__text">打赏</span><div class="coin-wrapper"><div class="coin"><div class="coin__middle"></div><div class="coin__back"></div><div class="coin__front"></div></div></div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="https://pic.hycbook.com/i//hexo/qr_codes/hyc_wechat.webp" rel="external nofollow noreferrer" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i//hexo/qr_codes/hyc_wechat.webp" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="https://pic.hycbook.com/i//hexo/qr_codes/hyc_alipay.webp" rel="external nofollow noreferrer" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i//hexo/qr_codes/hyc_alipay.webp" alt="alipay"/></a><div class="post-qr-code-desc">alipay</div></li></ul></div></button></div><audio id="coinAudio" src="https://s1.vika.cn/space/2022/10/29/6db0ad2bccf949f09054b3b206dcc66f?attname=马里奥游戏投币叮当.mp3"></audio><script defer="defer" src="/"></script><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/article/47450.html"><img class="prev-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i/hexo/post_cover/蕾姆2.webp" onerror="onerror=null;src='https://pic.hycbook.com/i/hexo/config_imgs/404.svg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">图神经网络</div></div></a></div><div class="next-post pull-right"><a href="/article/29825.html"><img class="next-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i/hexo/post_cover/蕾姆6.webp" onerror="onerror=null;src='https://pic.hycbook.com/i/hexo/config_imgs/404.svg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">机器学习_线性代数与矩阵论(3)</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/article/29825.html" title="机器学习_线性代数与矩阵论(3)"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i/hexo/post_cover/蕾姆6.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-09-08</div><div class="title">机器学习_线性代数与矩阵论(3)</div></div></a></div><div><a href="/article/47032.html" title="机器学习_线性代数与矩阵论(1)"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i/hexo/post_cover/蕾姆1.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-10-11</div><div class="title">机器学习_线性代数与矩阵论(1)</div></div></a></div><div><a href="/article/8171.html" title="机器学习_一元函数微积分(2)"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i/hexo/post_cover/蕾姆4.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-09-08</div><div class="title">机器学习_一元函数微积分(2)</div></div></a></div><div><a href="/article/10706.html" title="机器学习_一元函数微积分(1)"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i/hexo/post_cover/蕾姆0.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-09-10</div><div class="title">机器学习_一元函数微积分(1)</div></div></a></div><div><a href="/article/58730.html" title="机器学习_最优化方法"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i/hexo/post_cover/蕾姆3.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-12-31</div><div class="title">机器学习_最优化方法</div></div></a></div><div><a href="/article/8271.html" title="机器学习_概率论"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i/hexo/post_cover/蕾姆4.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-27</div><div class="title">机器学习_概率论</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div><div id="comment-switch"><span class="first-comment">Twikoo</span><span class="switch-btn"></span><span class="second-comment">Valine</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84"><span class="toc-number">1.</span> <span class="toc-text">线性方程组</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%AB%98%E6%96%AF%E6%B6%88%E5%85%83%E6%B3%95"><span class="toc-number">1.1.</span> <span class="toc-text">高斯消元法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%BD%90%E6%AC%A1%E6%96%B9%E7%A8%8B%E7%BB%84"><span class="toc-number">1.2.</span> <span class="toc-text">齐次方程组</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9D%9E%E9%BD%90%E6%AC%A1%E6%96%B9%E7%A8%8B%E7%BB%84"><span class="toc-number">1.3.</span> <span class="toc-text">非齐次方程组</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E5%80%BC%E5%92%8C%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F"><span class="toc-number">2.</span> <span class="toc-text">特征值和特征向量</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E5%80%BC%E4%B8%8E%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F"><span class="toc-number">2.1.</span> <span class="toc-text">特征值与特征向量</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9B%B8%E4%BC%BC%E5%8F%98%E6%8D%A2"><span class="toc-number">2.2.</span> <span class="toc-text">相似变换</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%AD%A3%E4%BA%A4%E5%8F%98%E6%8D%A2"><span class="toc-number">2.3.</span> <span class="toc-text">正交变换</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#QR-%E7%AE%97%E6%B3%95"><span class="toc-number">2.4.</span> <span class="toc-text">QR 算法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B9%BF%E4%B9%89%E7%89%B9%E5%BE%81%E5%80%BC"><span class="toc-number">2.5.</span> <span class="toc-text">广义特征值</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%91%9E%E5%88%A9%E5%95%86"><span class="toc-number">2.6.</span> <span class="toc-text">瑞利商</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%B0%B1%E8%8C%83%E6%95%B0%E4%B8%8E%E7%89%B9%E5%BE%81%E5%80%BC%E7%9A%84%E5%85%B3%E7%B3%BB"><span class="toc-number">2.7.</span> <span class="toc-text">谱范数与特征值的关系</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9D%A1%E4%BB%B6%E6%95%B0"><span class="toc-number">2.8.</span> <span class="toc-text">条件数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BA%94%E7%94%A8%E2%80%94%E2%80%94%E8%B0%B1%E5%BD%92%E4%B8%80%E5%8C%96%E4%B8%8E%E8%B0%B1%E6%AD%A3%E5%88%99%E5%8C%96"><span class="toc-number">2.9.</span> <span class="toc-text">应用——谱归一化与谱正则化</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer" style="background-image: url('https://pic.hycbook.com/i/hexo/config_imgs/footer_bg.webp')"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2023 By narutohyc</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener external nofollow noreferrer" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text"><p><a target="_blank" href="https://hexo.io/" rel="external nofollow noreferrer"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&logo=hexo" title="博客框架为Hexo"></a>&nbsp;<a target="_blank" href="https://demo.jerryc.me/" rel="external nofollow noreferrer"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&logo=bitdefender" title="主题采用butterfly"></a>&nbsp;<a target="_blank" href="https://vercel.com/ " rel="external nofollow noreferrer"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Hosted-Vervel-brightgreen?style=flat&logo=Vercel" title="本站采用双线部署，默认线路托管于Vercel"></a>&nbsp;<a target="_blank" href="https://github.com/" rel="external nofollow noreferrer"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&logo=GitHub" title="本站项目由Gtihub托管"></a>&nbsp;<a target="_blank" href="https://zixiaoyun.com" rel="external nofollow noreferrer"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/图床-薄荷图床-green" title="薄荷图床"></a></p><a target="_blank" href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=35020502000647" rel="external nofollow noreferrer"><img style="position:relative;top:4px" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i//hexo/config_imgs//备案图标.webp" alt="ICP"/>闽公网安备35020502000647号  </a><a href="https://beian.miit.gov.cn/" rel="external nofollow noreferrer" target="_blank">闽ICP备2022013843号-1</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">简</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div id="rightMenu"><div class="rightMenu-group rightMenu-small"><div class="rightMenu-item" id="menu-backward"><i class="fa-solid fa-arrow-left"></i></div><div class="rightMenu-item" id="menu-forward"><i class="fa-solid fa-arrow-right"></i></div><div class="rightMenu-item" id="menu-refresh"><i class="fa-solid fa-arrow-rotate-right"></i></div><div class="rightMenu-item" id="menu-home"><i class="fa-solid fa-house"></i></div></div><div class="rightMenu-group rightMenu-line hide" id="menu-text"><a class="rightMenu-item" href="javascript:window.open(&quot;https://www.baidu.com/s?wd=&quot;+window.getSelection().toString());window.location.reload();" rel="external nofollow noreferrer"><i class="fas fa-comment"></i><span>百度搜索</span></a></div><div class="rightMenu-group rightMenu-line rightMenuOther"><a class="rightMenu-item menu-link" href="/archives/"><i class="fa-solid fa-archive"></i><span>文章归档</span></a><a class="rightMenu-item menu-link" href="/categories/"><i class="fa-solid fa-folder-open"></i><span>文章分类</span></a><a class="rightMenu-item menu-link" href="/tags/"><i class="fa-solid fa-tags"></i><span>文章标签</span></a></div><div class="rightMenu-group rightMenu-line rightMenuNormal"><a class="rightMenu-item menu-link" id="menu-radompage"><i class="fa-solid fa-shoe-prints"></i><span>随便逛逛</span></a><div class="rightMenu-item" id="menu-translate"><i class="fa-solid fa-earth-asia"></i><span>繁简切换</span></div><div class="rightMenu-item" id="menu-darkmode"><i class="fa-solid fa-moon"></i><span>切换模式</span></div></div></div><div id="rightmenu-mask"></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script>(() => {
  const $mermaidWrap = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaidWrap.length) {
    window.runMermaid = () => {
      window.loadMermaid = true
      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? '' : ''

      Array.from($mermaidWrap).forEach((item, index) => {
        const mermaidSrc = item.firstElementChild
        const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
        const mermaidID = 'mermaid-' + index
        const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent
        mermaid.mermaidAPI.render(mermaidID, mermaidDefinition, (svgCode) => {
          mermaidSrc.insertAdjacentHTML('afterend', svgCode)
        })
      })
    }

    const loadMermaid = () => {
      window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
    }

    window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
  }
})()</script><script>(()=>{
  const init = () => {
    twikoo.init(Object.assign({
      el: '#twikoo-wrap',
      envId: 'https://vercel.hycbook.com',
      region: '',
      onCommentLoaded: function () {
        btf.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.tk-owo-emotion)'))
      }
    }, null))
  }

  const getCount = () => {
    const countELement = document.getElementById('twikoo-count')
    if(!countELement) return
    twikoo.getCommentsCount({
      envId: 'https://vercel.hycbook.com',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      countELement.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const runFn = () => {
    init()
    GLOBAL_CONFIG_SITE.isPost && getCount()
  }

  const loadTwikoo = () => {
    if (typeof twikoo === 'object') {
      setTimeout(runFn,0)
      return
    } 
    getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(runFn)
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo()
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script><script>function loadValine () {
  function initValine () {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: 'ncn88uooQf0IO2rrGE7Vniwp-gzGzoHsz',
      appKey: 'Yghpzg1QfBMFJ0MxxHubVzKL',
      avatar: 'monsterid',
      serverURLs: '',
      emojiMaps: "",
      path: window.location.pathname,
      visitor: true
    }, null))
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
}

if ('Twikoo' === 'Valine' || !false) {
  if (false) btf.loadComment(document.getElementById('vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script></div><script>window.addEventListener('load', () => {
  const changeContent = (content) => {
    if (content === '') return content

    content = content.replace(/<img.*?src="(.*?)"?[^\>]+>/ig, '[图片]') // replace image link
    content = content.replace(/<a[^>]+?href=["']?([^"']+)["']?[^>]*>([^<]+)<\/a>/gi, '[链接]') // replace url
    content = content.replace(/<pre><code>.*?<\/pre>/gi, '[代码]') // replace code
    content = content.replace(/<[^>]+>/g,"") // remove html tag

    if (content.length > 150) {
      content = content.substring(0,150) + '...'
    }
    return content
  }

  const getComment = () => {
    const runTwikoo = () => {
      twikoo.getRecentComments({
        envId: 'https://vercel.hycbook.com',
        region: '',
        pageSize: 3,
        includeReply: true
      }).then(function (res) {
        const twikooArray = res.map(e => {
          return {
            'content': changeContent(e.comment),
            'avatar': e.avatar,
            'nick': e.nick,
            'url': e.url + '#' + e.id,
            'date': new Date(e.created).toISOString()
          }
        })

        saveToLocal.set('twikoo-newest-comments', JSON.stringify(twikooArray), 10/(60*24))
        generateHtml(twikooArray)
      }).catch(function (err) {
        const $dom = document.querySelector('#card-newest-comments .aside-list')
        $dom.innerHTML= "无法获取评论，请确认相关配置是否正确"
      })
    }

    if (typeof twikoo === 'object') {
      runTwikoo()
    } else {
      getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(runTwikoo)
    }
  }

  const generateHtml = array => {
    let result = ''

    if (array.length) {
      for (let i = 0; i < array.length; i++) {
        result += '<div class=\'aside-list-item\'>'

        if (true) {
          const name = 'data-lazy-src'
          result += `<a href='${array[i].url}' class='thumbnail'><img ${name}='${array[i].avatar}' alt='${array[i].nick}'></a>`
        }
        
        result += `<div class='content'>
        <a class='comment' href='${array[i].url}' title='${array[i].content}'>${array[i].content}</a>
        <div class='name'><span>${array[i].nick} / </span><time datetime="${array[i].date}">${btf.diffDate(array[i].date, true)}</time></div>
        </div></div>`
      }
    } else {
      result += '没有评论'
    }

    let $dom = document.querySelector('#card-newest-comments .aside-list')
    $dom.innerHTML= result
    window.lazyLoadInstance && window.lazyLoadInstance.update()
    window.pjax && window.pjax.refresh($dom)
  }

  const newestCommentInit = () => {
    if (document.querySelector('#card-newest-comments .aside-list')) {
      const data = saveToLocal.get('twikoo-newest-comments')
      if (data) {
        generateHtml(JSON.parse(data))
      } else {
        getComment()
      }
    }
  }

  newestCommentInit()
  document.addEventListener('pjax:complete', newestCommentInit)
})</script><script defer src="https://npm.elemecdn.com/jquery@latest/dist/jquery.min.js"></script><script defer data-pjax src="/js/rightMenu.js"></script><script defer data-pjax src="/js/udf_mouse.js"></script><script defer data-pjax src="/js/udf_js.js"></script><script defer data-pjax src="/zhheo/random.js"></script><script data-pjax src="/js/coin.js"></script><script defer src="https://npm.elemecdn.com/vue@2.6.11"></script><script async src="//at.alicdn.com/t/c/font_3670467_a0sijt8frxo.js"></script><script defer src="/live2d-widget/autoload.js"></script><script defer src="/js/udf_js.js"></script><script defer src="https://cdnjs.cloudflare.com/ajax/libs/toastr.js/latest/toastr.min.js"></script><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-fluttering-ribbon.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = false;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-heart.min.js" async="async" mobile="true"></script><script>window.$crisp = [];
window.CRISP_WEBSITE_ID = "561b80db-3f0f-45cb-b3b1-aae7355939e6";
(function () {
  d = document;
  s = d.createElement("script");
  s.src = "https://client.crisp.chat/l.js";
  s.async = 1;
  d.getElementsByTagName("head")[0].appendChild(s);
})();
$crisp.push(["safe", true])

if (false) {
  $crisp.push(["do", "chat:hide"])
  $crisp.push(["on", "chat:closed", function() {
    $crisp.push(["do", "chat:hide"])
  }])
  var chatBtnFn = () => {
    var chatBtn = document.getElementById("chat_btn")
    chatBtn.addEventListener("click", function(){
      $crisp.push(["do", "chat:show"])
      $crisp.push(["do", "chat:open"])

    });
  }
  chatBtnFn()
} else {
  if (false) {
    function chatBtnHide () {
      $crisp.push(["do", "chat:hide"])
    }
    function chatBtnShow () {
      $crisp.push(["do", "chat:show"])
    }
  }
}</script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener scroll 
  window.tocScrollFn && window.removeEventListener('scroll', window.tocScrollFn)
  window.scrollCollect && window.removeEventListener('scroll', scrollCollect)

  typeof preloader === 'object' && preloader.initLoading()
  document.getElementById('rightside').style.cssText = "opacity: ''; transform: ''"
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

  typeof disqusjs === 'object' && disqusjs.destroy()
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()

  typeof preloader === 'object' && preloader.endLoading()
})

document.addEventListener('pjax:error', (e) => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div class="app-refresh" id="app-refresh" style="position: fixed;top: -2.2rem;left: 0;right: 0;z-index: 99999;padding: 0 1rem;font-size: 15px;height: 2.2rem;transition: all 0.3s ease;"><div class="app-refresh-wrap" style=" display: flex;color: #fff;height: 100%;align-items: center;justify-content: center;"><label>✨ 兼一书虫上新啦！ 👉</label><a href="javascript:void(0)" rel="external nofollow noreferrer" onclick="location.reload()"><span style="color: #fff;text-decoration: underline;cursor: pointer;">🍭查看新品🍬</span></a></div></div><script>if ('serviceWorker' in navigator) {
  if (navigator.serviceWorker.controller) {
    navigator.serviceWorker.addEventListener('controllerchange', function() {
      showNotification()
    })
  }
  window.addEventListener('load', function() {
    navigator.serviceWorker.register('/sw.js')
  })
}

function showNotification() {
  if (GLOBAL_CONFIG.Snackbar) {
    var snackbarBg =
      document.documentElement.getAttribute('data-theme') === 'light' ?
      GLOBAL_CONFIG.Snackbar.bgLight :
      GLOBAL_CONFIG.Snackbar.bgDark
    var snackbarPos = GLOBAL_CONFIG.Snackbar.position
    Snackbar.show({
      text: '✨ 兼一书虫上新啦！ 👉',
      backgroundColor: snackbarBg,
      duration: 500000,
      pos: snackbarPos,
      actionText: '🍭查看新品🍬',
      actionTextColor: '#fff',
      onActionClick: function(e) {
        location.reload()
      },
    })
  } else {
    var showBg =
      document.documentElement.getAttribute('data-theme') === 'light' ?
      '#49b1f5' :
      '#1f1f1f'
    var cssText = `top: 0; background: ${showBg};`
    document.getElementById('app-refresh')
      .style.cssText = cssText
  }
}</script></div><!-- hexo injector body_end start --><script async src="//at.alicdn.com/t/font_2032782_8d5kxvn09md.js"></script><!-- hexo injector body_end end --></body></html>