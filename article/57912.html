<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>huggingfaceåŸºæœ¬ä½¿ç”¨æ•™ç¨‹ | å…¼ä¸€ä¹¦è™«</title><meta name="keywords" content="huggingface,transformers"><meta name="author" content="narutohyc"><meta name="copyright" content="narutohyc"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="huggingfaceåŸºæœ¬ä½¿ç”¨æ•™ç¨‹">
<meta property="og:type" content="article">
<meta property="og:title" content="huggingfaceåŸºæœ¬ä½¿ç”¨æ•™ç¨‹">
<meta property="og:url" content="https://study.hycbook.com/article/57912.html">
<meta property="og:site_name" content="å…¼ä¸€ä¹¦è™«">
<meta property="og:description" content="huggingfaceåŸºæœ¬ä½¿ç”¨æ•™ç¨‹">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://pic.hycbook.com/i/hexo/post_cover/%E8%95%BE%E5%A7%860.webp">
<meta property="article:published_time" content="2023-06-10T10:36:10.000Z">
<meta property="article:modified_time" content="2023-09-06T14:53:56.114Z">
<meta property="article:author" content="narutohyc">
<meta property="article:tag" content="huggingface">
<meta property="article:tag" content="transformers">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://pic.hycbook.com/i/hexo/post_cover/%E8%95%BE%E5%A7%860.webp"><link rel="shortcut icon" href="https://pic.hycbook.com/i//hexo/config_imgs/ç½‘ç«™å›¾æ ‡.webp"><link rel="canonical" href="https://study.hycbook.com/article/57912"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="manifest" href="/manifest.json"/><meta name="msapplication-TileColor" content="#c6ff7a"/><link rel="apple-touch-icon" sizes="180x180" href="https://pic.hycbook.com/i//hexo/source/img/siteicon/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="https://pic.hycbook.com/i//hexo/source/img/siteicon/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="https://pic.hycbook.com/i//hexo/source/img/siteicon/favicon-16x16.png"/><link rel="mask-icon" href="https://pic.hycbook.com/i//hexo/source/img/siteicon/safari-pinned-tab.svg" color="#5bbad5"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?68340394dfd808cea9826e8a57f87aa6";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"languages":{"hits_empty":"æ‰¾ä¸åˆ°æ‚¨æŸ¥è¯¢çš„å†…å®¹ï¼š${query}"}},
  translate: {"defaultEncoding":1,"translateDelay":0,"msgToTraditionalChinese":"ç¹","msgToSimplifiedChinese":"ç°¡"},
  noticeOutdate: {"limitDay":120,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":400},
  copy: {
    success: 'å¤åˆ¶æˆåŠŸ',
    error: 'å¤åˆ¶é”™è¯¯',
    noSupport: 'æµè§ˆå™¨ä¸æ”¯æŒ'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: 'å¤©',
  date_suffix: {
    just: 'åˆšåˆš',
    min: 'åˆ†é’Ÿå‰',
    hour: 'å°æ—¶å‰',
    day: 'å¤©å‰',
    month: 'ä¸ªæœˆå‰'
  },
  copyright: {"limitCount":200,"languages":{"author":"ä½œè€…: narutohyc","link":"é“¾æ¥: ","source":"æ¥æº: å…¼ä¸€ä¹¦è™«","info":"è‘—ä½œæƒå½’ä½œè€…æ‰€æœ‰ã€‚å•†ä¸šè½¬è½½è¯·è”ç³»ä½œè€…è·å¾—æˆæƒï¼Œéå•†ä¸šè½¬è½½è¯·æ³¨æ˜å‡ºå¤„ã€‚"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'huggingfaceåŸºæœ¬ä½¿ç”¨æ•™ç¨‹',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-09-06 22:53:56'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/hyc_udf.css"><link rel="stylesheet" href="/css/udf_css.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/js-heo@1.0.11/mainColor/heoMainColor.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/js-heo@1.0.11/404/404.css"><script src="https://npm.elemecdn.com/echarts@4.9.0/dist/echarts.min.js"></script><link href="https://cdn.bootcdn.net/ajax/libs/toastr.js/2.1.4/toastr.min.css" rel="stylesheet"><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.cbd.int/hexo-butterfly-tag-plugins-plus@latest/lib/assets/font-awesome-animation.min.css" media="defer" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.cbd.int/hexo-butterfly-tag-plugins-plus@latest/lib/tag_plugins.css" media="defer" onload="this.media='all'"><script src="https://cdn.cbd.int/hexo-butterfly-tag-plugins-plus@latest/lib/assets/carousel-touch.js"></script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i/hexo/person_img/å…¼ä¸€å¤´åƒ.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">æ–‡ç« </div><div class="length-num">115</div></a><a href="/tags/"><div class="headline">æ ‡ç­¾</div><div class="length-num">169</div></a><a href="/categories/"><div class="headline">åˆ†ç±»</div><div class="length-num">9</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-fangwu"></use></svg><span> é¦–é¡µ</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-wenzhang1">             </use></svg><span> æ–‡ç« </span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-guidang">                   </use></svg><span> å½’æ¡£</span></a></li><li><a class="site-page child" href="/categories"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-fenlei">                   </use></svg><span> åˆ†ç±»</span></a></li><li><a class="site-page child" href="/tags"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-biaoqian">                   </use></svg><span> æ ‡ç­¾</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-wenzhang1">             </use></svg><span> gitbookç‰ˆ</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://common.hycbook.com"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-guidang">                   </use></svg><span> common</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://python.hycbook.com"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-fenlei">                   </use></svg><span> python</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://dl.hycbook.com"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-biaoqian">                   </use></svg><span> æ·±åº¦å­¦ä¹ </span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-xuegao">             </use></svg><span> å¨±ä¹</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-yinle">                   </use></svg><span> éŸ³ä¹</span></a></li><li><a class="site-page child" href="/bangumis"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-wodezhuifan">                   </use></svg><span> è¿½ç•ª</span></a></li><li><a class="site-page child" href="/gallery"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-xiangce">                   </use></svg><span> ç›¸å†Œ</span></a></li><li><a class="site-page child" href="/video"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-shipin">                   </use></svg><span> è§†é¢‘</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/charts"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-xigua"></use></svg><span> ç»Ÿè®¡å›¾</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-suannai">             </use></svg><span> ç½‘ç›˜</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://pan.hycbook.com"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-guidang">                   </use></svg><span> ç§æœˆç›˜</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://share.hycbook.com"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-zhifengche">                   </use></svg><span> å…±äº«ç›˜</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-zhifeiji">             </use></svg><span> å¯¼èˆª</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/comments"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-TIFFANYSROOM_huaban">                   </use></svg><span> ç•™è¨€æ¿</span></a></li><li><a class="site-page child" href="/link"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-changyonglianjie">                   </use></svg><span> å‹é“¾</span></a></li><li><a class="site-page child" href="/about"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-aixin">                   </use></svg><span> å…³äº</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://pic.hycbook.com/i/hexo/post_imgs/è•¾å§†0.webp')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">å…¼ä¸€ä¹¦è™«</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> æœç´¢</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-fangwu"></use></svg><span> é¦–é¡µ</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-wenzhang1">             </use></svg><span> æ–‡ç« </span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-guidang">                   </use></svg><span> å½’æ¡£</span></a></li><li><a class="site-page child" href="/categories"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-fenlei">                   </use></svg><span> åˆ†ç±»</span></a></li><li><a class="site-page child" href="/tags"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-biaoqian">                   </use></svg><span> æ ‡ç­¾</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-wenzhang1">             </use></svg><span> gitbookç‰ˆ</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://common.hycbook.com"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-guidang">                   </use></svg><span> common</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://python.hycbook.com"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-fenlei">                   </use></svg><span> python</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://dl.hycbook.com"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-biaoqian">                   </use></svg><span> æ·±åº¦å­¦ä¹ </span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-xuegao">             </use></svg><span> å¨±ä¹</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-yinle">                   </use></svg><span> éŸ³ä¹</span></a></li><li><a class="site-page child" href="/bangumis"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-wodezhuifan">                   </use></svg><span> è¿½ç•ª</span></a></li><li><a class="site-page child" href="/gallery"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-xiangce">                   </use></svg><span> ç›¸å†Œ</span></a></li><li><a class="site-page child" href="/video"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-shipin">                   </use></svg><span> è§†é¢‘</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/charts"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-xigua"></use></svg><span> ç»Ÿè®¡å›¾</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-suannai">             </use></svg><span> ç½‘ç›˜</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://pan.hycbook.com"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-guidang">                   </use></svg><span> ç§æœˆç›˜</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://share.hycbook.com"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-zhifengche">                   </use></svg><span> å…±äº«ç›˜</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-zhifeiji">             </use></svg><span> å¯¼èˆª</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/comments"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-TIFFANYSROOM_huaban">                   </use></svg><span> ç•™è¨€æ¿</span></a></li><li><a class="site-page child" href="/link"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-changyonglianjie">                   </use></svg><span> å‹é“¾</span></a></li><li><a class="site-page child" href="/about"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-aixin">                   </use></svg><span> å…³äº</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">huggingfaceåŸºæœ¬ä½¿ç”¨æ•™ç¨‹</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">å‘è¡¨äº</span><time class="post-meta-date-created" datetime="2023-06-10T10:36:10.000Z" title="å‘è¡¨äº 2023-06-10 18:36:10">2023-06-10</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">æ›´æ–°äº</span><time class="post-meta-date-updated" datetime="2023-09-06T14:53:56.114Z" title="æ›´æ–°äº 2023-09-06 22:53:56">2023-09-06</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/deep-learning/">deep_learning</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">å­—æ•°æ€»è®¡:</span><span class="word-count">16.3k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">é˜…è¯»æ—¶é•¿:</span><span>68åˆ†é’Ÿ</span></span><span class="post-meta-separator">|</span><span id="" data-flag-title="huggingfaceåŸºæœ¬ä½¿ç”¨æ•™ç¨‹"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">é˜…è¯»é‡:</span><span id="twikoo_visitors"><i class="fa-solid fa-spinner fa-spin"></i></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">è¯„è®ºæ•°:</span><a href="/article/57912.html#post-comment"><span id="twikoo-count"><i class="fa-solid fa-spinner fa-spin"></i></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><hr>
<h1 id="huggingface"><a href="#huggingface" class="headerlink" title="huggingface"></a>huggingface</h1><h2 id="æ¦‚è¿°"><a href="#æ¦‚è¿°" class="headerlink" title="æ¦‚è¿°"></a>æ¦‚è¿°</h2><blockquote>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://huggingface.co/docs">Hugging Face</a></p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://huggingface.co/tasks">å®˜ç½‘ä»»åŠ¡åˆ†ç±»å’Œç¤ºä¾‹</a></p>
</blockquote>
<p><code>Hugging Face</code>æ˜¯ä¸€ä¸ªçŸ¥åçš„å¼€æºç¤¾åŒºå’Œå…¬å¸ï¼Œä¸“æ³¨äºè‡ªç„¶è¯­è¨€å¤„ç†(NLP)å’Œæœºå™¨å­¦ä¹ (ML)é¢†åŸŸã€‚ä»–ä»¬å¼€å‘äº†è®¸å¤šæµè¡Œçš„å¼€æºå·¥å…·å’Œåº“ï¼Œä½¿å¾—æ„å»ºå’Œåº”ç”¨NLPæ¨¡å‹æ›´åŠ ä¾¿æ·</p>
<p>Hugging faceèµ·åˆæ˜¯ä¸€å®¶æ€»éƒ¨ä½äºçº½çº¦çš„èŠå¤©æœºå™¨äººåˆåˆ›æœåŠ¡å•†ï¼Œä»–ä»¬æœ¬æ¥æ‰“ç®—åˆ›ä¸šåšèŠå¤©æœºå™¨äººï¼Œç„¶ååœ¨githubä¸Šå¼€æºäº†ä¸€ä¸ªTransformersåº“ï¼Œè™½ç„¶èŠå¤©æœºå™¨äººä¸šåŠ¡æ²¡æèµ·æ¥ï¼Œä½†æ˜¯ä»–ä»¬çš„è¿™ä¸ªåº“åœ¨æœºå™¨å­¦ä¹ ç¤¾åŒºè¿…é€Ÿå¤§ç«èµ·æ¥ã€‚ç›®å‰å·²ç»å…±äº«äº†è¶…100,000ä¸ªé¢„è®­ç»ƒæ¨¡å‹ï¼Œ10,000ä¸ªæ•°æ®é›†ï¼Œå˜æˆäº†æœºå™¨å­¦ä¹ ç•Œçš„github</p>
<blockquote>
<p>åœ¨è¿™é‡Œä¸»è¦æœ‰ä»¥ä¸‹å¤§å®¶éœ€è¦çš„èµ„æº</p>
</blockquote>
<ol>
<li><p><strong>Datasets</strong>ï¼šæ•°æ®é›†ï¼Œä»¥åŠæ•°æ®é›†çš„ä¸‹è½½åœ°å€</p>
</li>
<li><p><strong>Models</strong>ï¼šåŒ…æ‹¬å„ç§å¤„ç†CVå’ŒNLPç­‰ä»»åŠ¡çš„æ¨¡å‹ï¼Œä¸Šé¢æ¨¡å‹éƒ½æ˜¯å¯ä»¥å…è´¹è·å¾—</p>
<p>ä¸»è¦åŒ…æ‹¬è®¡ç®—æœºè§†è§‰ã€è‡ªç„¶è¯­è¨€å¤„ç†ã€è¯­éŸ³å¤„ç†ã€å¤šæ¨¡æ€ã€è¡¨æ ¼å¤„ç†ã€å¼ºåŒ–å­¦ä¹ </p>
</li>
<li><p><strong>course</strong>ï¼šå…è´¹çš„nlpè¯¾ç¨‹</p>
</li>
<li><p><strong>docs</strong>ï¼šæ–‡æ¡£</p>
</li>
</ol>
<blockquote>
<p>å±•å¼€ç»†èŠ‚</p>
</blockquote>
<ul>
<li><strong>Computer Vision(è®¡ç®—æœºè§†è§‰ä»»åŠ¡)</strong>ï¼šåŒ…æ‹¬lmage Classification(å›¾åƒåˆ†ç±»)ï¼Œlmage Segmentation(å›¾åƒåˆ†å‰²)ã€zero-Shot lmage Classification(é›¶æ ·æœ¬å›¾åƒåˆ†ç±»)ã€lmage-to-Image(å›¾åƒåˆ°å›¾åƒçš„ä»»åŠ¡)ã€Unconditional lmage Generation(æ— æ¡ä»¶å›¾åƒç”Ÿæˆ)ã€Object Detection(ç›®æ ‡æ£€æµ‹)ã€Video Classification(è§†é¢‘åˆ†ç±»)ã€Depth Estimation(æ·±åº¦ä¼°è®¡ï¼Œä¼°è®¡æ‹æ‘„è€…è·ç¦»å›¾åƒå„å¤„çš„è·ç¦»)</li>
<li><strong>Natural Language Processing(è‡ªç„¶è¯­è¨€å¤„ç†)</strong>ï¼šåŒ…æ‹¬Translation(æœºå™¨ç¿»è¯‘)ã€Fill-Mask(å¡«å……æ©ç ï¼Œé¢„æµ‹å¥å­ä¸­è¢«é®æ©çš„è¯)ã€Token Classification(è¯åˆ†ç±»)ã€Sentence Similarity(å¥å­ç›¸ä¼¼åº¦)ã€Question Answering(é—®ç­”ç³»ç»Ÿ)ï¼ŒSummarization(æ€»ç»“ï¼Œç¼©å¥)ã€Zero-Shot Classification (é›¶æ ·æœ¬åˆ†ç±»)ã€Text Classification(æ–‡æœ¬åˆ†ç±»)ã€Text2Text(æ–‡æœ¬åˆ°æ–‡æœ¬çš„ç”Ÿæˆ)ã€Text Generation(æ–‡æœ¬ç”Ÿæˆ)ã€Conversational(èŠå¤©)ã€Table Question Answer(è¡¨é—®ç­”ï¼Œ1.é¢„æµ‹è¡¨æ ¼ä¸­è¢«é®æ©å•è¯2.æ•°å­—æ¨ç†ï¼Œåˆ¤æ–­å¥å­æ˜¯å¦è¢«è¡¨æ ¼æ•°æ®æ”¯æŒ)</li>
<li><strong>Audio(è¯­éŸ³)</strong>ï¼šAutomatic Speech Recognition(è¯­éŸ³è¯†åˆ«)ã€Audio Classification(è¯­éŸ³åˆ†ç±»)ã€Text-to-Speech(æ–‡æœ¬åˆ°è¯­éŸ³çš„ç”Ÿæˆ)ã€Audio-to-Audio(è¯­éŸ³åˆ°è¯­éŸ³çš„ç”Ÿæˆ)ã€Voice Activity Detection(å£°éŸ³æ£€æµ‹ã€æ£€æµ‹è¯†åˆ«å‡ºéœ€è¦çš„å£°éŸ³éƒ¨åˆ†)</li>
<li><strong>Multimodal(å¤šæ¨¡æ€)</strong>ï¼šFeature Extraction(ç‰¹å¾æå–)ã€Text-to-Image(æ–‡æœ¬åˆ°å›¾åƒ)ã€Visual Question Answering(è§†è§‰é—®ç­”)ã€Image2Text(å›¾åƒåˆ°æ–‡æœ¬)ã€Document Question Answering(æ–‡æ¡£é—®ç­”)</li>
<li><strong>Tabular(è¡¨æ ¼)</strong>ï¼šTabular Classification(è¡¨åˆ†ç±»)ã€Tabular Regression(è¡¨å›å½’)</li>
<li><strong>Reinforcement Learning(å¼ºåŒ–å­¦ä¹ )</strong>ï¼šReinforcement Learning(å¼ºåŒ–å­¦ä¹ )ã€Robotics(æœºå™¨äºº)</li>
</ul>
<h2 id="å®‰è£…"><a href="#å®‰è£…" class="headerlink" title="å®‰è£…"></a>å®‰è£…</h2><blockquote>
<p>å®‰è£…transformersåº“</p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install transformers</span><br></pre></td></tr></table></figure>
<h1 id="datasets"><a href="#datasets" class="headerlink" title="datasets"></a>datasets</h1><blockquote>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://zhuanlan.zhihu.com/p/582687507">HuggingFace datasetsåº“æ€»ç»“</a></p>
</blockquote>
<h2 id="å®‰è£…-1"><a href="#å®‰è£…-1" class="headerlink" title="å®‰è£…"></a>å®‰è£…</h2><p>ä¸‹é¢ä¸‰ä¸ªå‘½ä»¤éƒ½ç”¨äºå®‰è£…Hugging Faceçš„<code>datasets</code>åº“çš„ä¸åŒé…ç½®</p>
<ol>
<li><code>pip install datasets</code>ï¼šè¿™ä¸ªå‘½ä»¤å®‰è£…çš„æ˜¯<code>datasets</code>åº“çš„åŸºæœ¬é…ç½®ï¼Œå®ƒæä¾›äº†å¯¹å¸¸è§çš„è‡ªç„¶è¯­è¨€å¤„ç†(NLP)ä»»åŠ¡å’Œæ•°æ®é›†çš„æ”¯æŒï¼Œä¾‹å¦‚æ–‡æœ¬åˆ†ç±»ã€å‘½åå®ä½“è¯†åˆ«ã€é—®ç­”ç³»ç»Ÿç­‰ã€‚å¦‚æœæ‚¨åªéœ€è¦å¤„ç†æ–‡æœ¬æ•°æ®æˆ–è¿›è¡Œå¸¸è§çš„NLPä»»åŠ¡ï¼Œè¿™ä¸ªåŸºæœ¬é…ç½®å°±è¶³å¤Ÿäº†</li>
<li><code>pip install datasets[audio]</code>ï¼šè¿™ä¸ªå‘½ä»¤å®‰è£…çš„æ˜¯<code>datasets</code>åº“çš„â€audioâ€é…ç½®ã€‚å®ƒåŒ…å«äº†å¯¹å£°éŸ³å’ŒéŸ³é¢‘æ•°æ®é›†çš„æ”¯æŒï¼Œä¾‹å¦‚è‡ªåŠ¨è¯­éŸ³è¯†åˆ«(ASR)å’ŒéŸ³é¢‘åˆ†ç±»ä»»åŠ¡ã€‚å¦‚æœæ‚¨éœ€è¦å¤„ç†å£°éŸ³å’ŒéŸ³é¢‘æ•°æ®ï¼Œæ¯”å¦‚è¿›è¡Œè¯­éŸ³è¯†åˆ«æˆ–éŸ³é¢‘åˆ†ç±»ï¼Œå®‰è£…è¿™ä¸ªé…ç½®ä¼šæä¾›ç›¸åº”çš„åŠŸèƒ½å’Œæ•°æ®é›†æ”¯æŒ</li>
<li><code>pip install datasets[vision]</code>ï¼šè¿™ä¸ªå‘½ä»¤å®‰è£…çš„æ˜¯<code>datasets</code>åº“çš„â€visionâ€é…ç½®ã€‚å®ƒåŒ…å«äº†å¯¹å›¾åƒå’Œè®¡ç®—æœºè§†è§‰ä»»åŠ¡çš„æ”¯æŒï¼Œä¾‹å¦‚å›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹å’Œåˆ†å‰²ç­‰ã€‚å¦‚æœæ‚¨éœ€è¦å¤„ç†å›¾åƒæ•°æ®æˆ–è¿›è¡Œè®¡ç®—æœºè§†è§‰ä»»åŠ¡ï¼Œå®‰è£…è¿™ä¸ªé…ç½®ä¼šæä¾›ç›¸åº”çš„åŠŸèƒ½å’Œæ•°æ®é›†æ”¯æŒ</li>
</ol>
<p>é€šè¿‡å®‰è£…ä¸åŒçš„é…ç½®ï¼Œæ‚¨å¯ä»¥é€‰æ‹©ä»…å®‰è£…æ‚¨éœ€è¦çš„åŠŸèƒ½å’Œæ”¯æŒçš„ä»»åŠ¡ç±»å‹ï¼Œä»¥å‡å°‘åº“çš„å®‰è£…å’Œå­˜å‚¨ç©ºé—´ã€‚æ ¹æ®æ‚¨çš„å…·ä½“éœ€æ±‚ï¼Œé€‰æ‹©é€‚åˆçš„é…ç½®è¿›è¡Œå®‰è£…å³å¯</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># å®‰è£…åŸºç¡€ç‰ˆ</span></span><br><span class="line">pip install datasets</span><br><span class="line"><span class="comment"># å®‰è£…forå£°éŸ³</span></span><br><span class="line">pip install datasets[audio]</span><br><span class="line"><span class="comment"># å®‰è£…forå›¾åƒ</span></span><br><span class="line">pip install datasets[vision]</span><br></pre></td></tr></table></figure>
<h2 id="å¿«é€Ÿå¼€å§‹"><a href="#å¿«é€Ÿå¼€å§‹" class="headerlink" title="å¿«é€Ÿå¼€å§‹"></a>å¿«é€Ÿå¼€å§‹</h2><h3 id="è§†è§‰"><a href="#è§†è§‰" class="headerlink" title="è§†è§‰"></a>è§†è§‰</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset, Image</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torchvision.transforms <span class="keyword">import</span> Compose, ColorJitter, ToTensor</span><br><span class="line"></span><br><span class="line"><span class="comment"># åŠ è½½æ•°æ®é›†</span></span><br><span class="line">dataset = load_dataset(<span class="string">&quot;beans&quot;</span>, split=<span class="string">&quot;train&quot;</span>)</span><br><span class="line"></span><br><span class="line">jitter = Compose(</span><br><span class="line">    [ColorJitter(brightness=<span class="number">0.5</span>, hue=<span class="number">0.5</span>), ToTensor()]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">transforms</span>(<span class="params">examples</span>):</span><br><span class="line">    examples[<span class="string">&quot;pixel_values&quot;</span>] = [jitter(image.convert(<span class="string">&quot;RGB&quot;</span>)) <span class="keyword">for</span> image <span class="keyword">in</span> examples[<span class="string">&quot;image&quot;</span>]]</span><br><span class="line">    <span class="keyword">return</span> examples</span><br><span class="line"></span><br><span class="line">dataset = dataset.with_transform(transforms)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">collate_fn</span>(<span class="params">examples</span>):</span><br><span class="line">    images = []</span><br><span class="line">    labels = []</span><br><span class="line">    <span class="keyword">for</span> example <span class="keyword">in</span> examples:</span><br><span class="line">        images.append((example[<span class="string">&quot;pixel_values&quot;</span>]))</span><br><span class="line">        labels.append(example[<span class="string">&quot;labels&quot;</span>])</span><br><span class="line">        </span><br><span class="line">    pixel_values = torch.stack(images)</span><br><span class="line">    labels = torch.tensor(labels)</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;pixel_values&quot;</span>: pixel_values, <span class="string">&quot;labels&quot;</span>: labels&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># å®šä¹‰DataLoader</span></span><br><span class="line">dataloader = DataLoader(dataset, collate_fn=collate_fn, batch_size=<span class="number">4</span>)</span><br></pre></td></tr></table></figure>
<h3 id="nlp"><a href="#nlp" class="headerlink" title="nlp"></a>nlp</h3><p>ä½¿ç”¨ Hugging Face æä¾›çš„<code>datasets</code>åº“åŠ è½½äº†<a target="_blank" rel="noopener external nofollow noreferrer" href="https://huggingface.co/datasets/glue/viewer/mrpc/test">GLUE</a>(General Language Understanding Evaluation)æ•°æ®é›†ä¸­çš„MRPC(Microsoft Research Paraphrase Corpus)éƒ¨åˆ†çš„è®­ç»ƒé›†ã€‚è¿™ä¸ªæ•°æ®é›†ç”¨äºå¥å­å¯¹çš„ç›¸ä¼¼æ€§åˆ¤æ–­ä»»åŠ¡</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForSequenceClassification, AutoTokenizer</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">dataset = load_dataset(<span class="string">&quot;glue&quot;</span>, <span class="string">&quot;mrpc&quot;</span>, split=<span class="string">&quot;test&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># load a pretrained BERT model and its corresponding tokenizer from the ğŸ¤— Transformers library.</span></span><br><span class="line">model = AutoModelForSequenceClassification.from_pretrained(<span class="string">&quot;bert-base-uncased&quot;</span>)</span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(<span class="string">&quot;bert-base-uncased&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">encode</span>(<span class="params">examples</span>):</span><br><span class="line">    <span class="keyword">return</span> tokenizer(examples[<span class="string">&quot;sentence1&quot;</span>], examples[<span class="string">&quot;sentence2&quot;</span>], truncation=<span class="literal">True</span>, padding=<span class="string">&quot;max_length&quot;</span>)</span><br><span class="line"></span><br><span class="line">dataset = dataset.<span class="built_in">map</span>(encode, batched=<span class="literal">True</span>)</span><br><span class="line">dataset[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">&#123;<span class="string">&#x27;sentence1&#x27;</span>: <span class="string">&#x27;Amrozi accused his brother , whom he called &quot; the witness &quot; , of deliberately distorting his evidence .&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;sentence2&#x27;</span>: <span class="string">&#x27;Referring to him as only &quot; the witness &quot; , Amrozi accused his brother of deliberately distorting his evidence .&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;label&#x27;</span>: <span class="number">1</span>,</span><br><span class="line"><span class="string">&#x27;idx&#x27;</span>: <span class="number">0</span>,</span><br><span class="line"><span class="string">&#x27;input_ids&#x27;</span>: array([  <span class="number">101</span>,  <span class="number">7277</span>,  <span class="number">2180</span>,  <span class="number">5303</span>,  <span class="number">4806</span>,  <span class="number">1117</span>,  <span class="number">1711</span>,   <span class="number">117</span>,  <span class="number">2292</span>, <span class="number">1119</span>,  <span class="number">1270</span>,   <span class="number">107</span>,  <span class="number">1103</span>,  <span class="number">7737</span>,   <span class="number">107</span>,   <span class="number">117</span>,  <span class="number">1104</span>,  <span class="number">9938</span>, <span class="number">4267</span>, <span class="number">12223</span>, <span class="number">21811</span>,  <span class="number">1117</span>,  <span class="number">2554</span>,   <span class="number">119</span>,   <span class="number">102</span>, <span class="number">11336</span>,  <span class="number">6732</span>, <span class="number">3384</span>,  <span class="number">1106</span>,  <span class="number">1140</span>,  <span class="number">1112</span>,  <span class="number">1178</span>,   <span class="number">107</span>,  <span class="number">1103</span>,  <span class="number">7737</span>,   <span class="number">107</span>, <span class="number">117</span>,  <span class="number">7277</span>,  <span class="number">2180</span>,  <span class="number">5303</span>,  <span class="number">4806</span>,  <span class="number">1117</span>,  <span class="number">1711</span>,  <span class="number">1104</span>,  <span class="number">9938</span>, <span class="number">4267</span>, <span class="number">12223</span>, <span class="number">21811</span>,  <span class="number">1117</span>,  <span class="number">2554</span>,   <span class="number">119</span>,   <span class="number">102</span>]),</span><br><span class="line"><span class="string">&#x27;token_type_ids&#x27;</span>: array([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]),</span><br><span class="line"><span class="string">&#x27;attention_mask&#x27;</span>: array([<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>])&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#  Rename the label column to labels, which is the expected input name in BertForSequenceClassification</span></span><br><span class="line">dataset = dataset.<span class="built_in">map</span>(<span class="keyword">lambda</span> examples: &#123;<span class="string">&quot;labels&quot;</span>: examples[<span class="string">&quot;label&quot;</span>]&#125;, batched=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">dataset.set_format(<span class="built_in">type</span>=<span class="string">&quot;torch&quot;</span>, columns=[<span class="string">&quot;input_ids&quot;</span>, <span class="string">&quot;token_type_ids&quot;</span>, <span class="string">&quot;attention_mask&quot;</span>, <span class="string">&quot;labels&quot;</span>])</span><br><span class="line">dataloader = torch.utils.data.DataLoader(dataset, batch_size=<span class="number">32</span>)</span><br></pre></td></tr></table></figure>
<h2 id="åŠ è½½æ•°æ®é›†"><a href="#åŠ è½½æ•°æ®é›†" class="headerlink" title="åŠ è½½æ•°æ®é›†"></a>åŠ è½½æ•°æ®é›†</h2><blockquote>
<p>æŸ¥çœ‹æ•°æ®é›†æè¿°</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset_builder</span><br><span class="line">ds_builder = load_dataset_builder(<span class="string">&quot;rotten_tomatoes&quot;</span>)</span><br><span class="line"></span><br><span class="line">ds_builder.info.description</span><br><span class="line">Movie Review Dataset. This <span class="keyword">is</span> a dataset of containing <span class="number">5</span>,<span class="number">331</span> positive <span class="keyword">and</span> <span class="number">5</span>,<span class="number">331</span> negative processed sentences <span class="keyword">from</span> Rotten Tomatoes movie reviews. This data was first used <span class="keyword">in</span> Bo Pang <span class="keyword">and</span> Lillian Lee, ``Seeing stars: Exploiting <span class="keyword">class</span> <span class="title class_">relationships</span> <span class="keyword">for</span> sentiment categorization <span class="keyword">with</span> respect to rating scales.<span class="string">&#x27;&#x27;</span>, Proceedings of the ACL, <span class="number">2005.</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ds_builder.info.features</span><br><span class="line">&#123;<span class="string">&#x27;label&#x27;</span>: ClassLabel(num_classes=<span class="number">2</span>, names=[<span class="string">&#x27;neg&#x27;</span>, <span class="string">&#x27;pos&#x27;</span>], <span class="built_in">id</span>=<span class="literal">None</span>),</span><br><span class="line"> <span class="string">&#x27;text&#x27;</span>: Value(dtype=<span class="string">&#x27;string&#x27;</span>, <span class="built_in">id</span>=<span class="literal">None</span>)&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>åŠ è½½æ•°æ®é›†</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"></span><br><span class="line">dataset = load_dataset(<span class="string">&quot;rotten_tomatoes&quot;</span>, split=<span class="string">&quot;train&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>å½“ä¸€ä¸ªæ•°æ®é›†ç”±å¤šä¸ªæ–‡ä»¶(æˆ‘ä»¬ç§°ä¹‹ä¸º<strong>åˆ†ç‰‡</strong>)ç»„æˆæ—¶ï¼Œå¯ä»¥æ˜¾è‘—åŠ å¿«æ•°æ®é›†çš„ä¸‹è½½å’Œå‡†å¤‡æ­¥éª¤</p>
<p>æ‚¨å¯ä»¥ä½¿ç”¨num_procå‚æ•°é€‰æ‹©å¹¶è¡Œå‡†å¤‡æ•°æ®é›†æ—¶è¦ä½¿ç”¨çš„è¿›ç¨‹æ•°ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ¯ä¸ªè¿›ç¨‹è¢«åˆ†é…äº†ä¸€éƒ¨åˆ†åˆ†ç‰‡æ¥è¿›è¡Œå‡†å¤‡</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"></span><br><span class="line">oscar_afrikaans = load_dataset(<span class="string">&quot;oscar-corpus/OSCAR-2201&quot;</span>, <span class="string">&quot;af&quot;</span>, num_proc=<span class="number">8</span>)</span><br><span class="line">imagenet = load_dataset(<span class="string">&quot;imagenet-1k&quot;</span>, num_proc=<span class="number">8</span>)</span><br><span class="line">ml_librispeech_spanish = load_dataset(<span class="string">&quot;facebook/multilingual_librispeech&quot;</span>, <span class="string">&quot;spanish&quot;</span>, num_proc=<span class="number">8</span>)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>æŸ¥çœ‹æ•°æ®é›†çš„åˆ†ç‰‡åç§°ï¼Œå¹¶åŠ è½½æŒ‡å®šçš„åˆ†ç‰‡åç§°</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> get_dataset_split_names</span><br><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"></span><br><span class="line">get_dataset_split_names(<span class="string">&quot;rotten_tomatoes&quot;</span>)</span><br><span class="line">[<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;validation&#x27;</span>, <span class="string">&#x27;test&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># åŠ è½½æŒ‡å®šåˆ†ç‰‡</span></span><br><span class="line">dataset = load_dataset(<span class="string">&quot;rotten_tomatoes&quot;</span>, split=<span class="string">&quot;train&quot;</span>)</span><br><span class="line"></span><br><span class="line">Dataset(&#123;</span><br><span class="line">    features: [<span class="string">&#x27;text&#x27;</span>, <span class="string">&#x27;label&#x27;</span>],</span><br><span class="line">    num_rows: <span class="number">8530</span></span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># è¿˜å¯ä»¥è¿™ä¹ˆå†™ï¼š</span></span><br><span class="line">train_test_ds = datasets.load_dataset(<span class="string">&quot;bookcorpus&quot;</span>, split=<span class="string">&quot;train+test&quot;</span>)</span><br><span class="line">train_10_20_ds = datasets.load_dataset(<span class="string">&quot;bookcorpus&quot;</span>, split=<span class="string">&quot;train[10:20]&quot;</span>)</span><br><span class="line">train_10pct_ds = datasets.load_dataset(<span class="string">&quot;bookcorpus&quot;</span>, split=<span class="string">&quot;train[:10%]&quot;</span>)</span><br><span class="line">train_10_80pct_ds = datasets.load_dataset(<span class="string">&quot;bookcorpus&quot;</span>, split=<span class="string">&quot;train[:10%]+train[-80%:]&quot;</span>)</span><br><span class="line">val_ds = datasets.load_dataset(<span class="string">&quot;bookcorpus&quot;</span>, split=[<span class="string">f&quot;train[<span class="subst">&#123;k&#125;</span>%:<span class="subst">&#123;k+<span class="number">10</span>&#125;</span>%]&quot;</span> <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">100</span>, <span class="number">10</span>)])</span><br><span class="line">train_ds = datasets.load_dataset(<span class="string">&quot;bookcorpus&quot;</span>, split=[<span class="string">f&quot;train[:<span class="subst">&#123;k&#125;</span>%]+train[<span class="subst">&#123;k+<span class="number">10</span>&#125;</span>%:]&quot;</span> <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">100</span>, <span class="number">10</span>)])</span><br><span class="line">train_50_52_ds = datasets.load_dataset(<span class="string">&quot;bookcorpus&quot;</span>, split=<span class="string">&quot;train[50%:52%]&quot;</span>)</span><br><span class="line">train_52_54_ds = datasets.load_dataset(<span class="string">&quot;bookcorpus&quot;</span>, split=<span class="string">&quot;train[52%:54%]&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 18 records, from 450 (included) to 468 (excluded).</span></span><br><span class="line">train_50_52pct1_ds = datasets.load_dataset(<span class="string">&quot;bookcorpus&quot;</span>, split=datasets.ReadInstruction(<span class="string">&quot;train&quot;</span>, from_=<span class="number">50</span>, to=<span class="number">52</span>, unit=<span class="string">&quot;%&quot;</span>, rounding=<span class="string">&quot;pct1_dropremainder&quot;</span>))</span><br><span class="line"><span class="comment"># 18 records, from 468 (included) to 486 (excluded).</span></span><br><span class="line">train_52_54pct1_ds = datasets.load_dataset(<span class="string">&quot;bookcorpus&quot;</span>, split=datasets.ReadInstruction(<span class="string">&quot;train&quot;</span>,from_=<span class="number">52</span>, to=<span class="number">54</span>, unit=<span class="string">&quot;%&quot;</span>, rounding=<span class="string">&quot;pct1_dropremainder&quot;</span>))</span><br><span class="line"><span class="comment"># Or equivalently:</span></span><br><span class="line">train_50_52pct1_ds = datasets.load_dataset(<span class="string">&quot;bookcorpus&quot;</span>, split=<span class="string">&quot;train[50%:52%](pct1_dropremainder)&quot;</span>)</span><br><span class="line">train_52_54pct1_ds = datasets.load_dataset(<span class="string">&quot;bookcorpus&quot;</span>, split=<span class="string">&quot;train[52%:54%](pct1_dropremainder)&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># åŠ è½½å…¨éƒ¨æ•°æ®</span></span><br><span class="line">dataset = load_dataset(<span class="string">&quot;rotten_tomatoes&quot;</span>)</span><br><span class="line">DatasetDict(&#123;</span><br><span class="line">    train: Dataset(&#123;</span><br><span class="line">        features: [<span class="string">&#x27;text&#x27;</span>, <span class="string">&#x27;label&#x27;</span>],</span><br><span class="line">        num_rows: <span class="number">8530</span></span><br><span class="line">    &#125;)</span><br><span class="line">    validation: Dataset(&#123;</span><br><span class="line">        features: [<span class="string">&#x27;text&#x27;</span>, <span class="string">&#x27;label&#x27;</span>],</span><br><span class="line">        num_rows: <span class="number">1066</span></span><br><span class="line">    &#125;)</span><br><span class="line">    test: Dataset(&#123;</span><br><span class="line">        features: [<span class="string">&#x27;text&#x27;</span>, <span class="string">&#x27;label&#x27;</span>],</span><br><span class="line">        num_rows: <span class="number">1066</span></span><br><span class="line">    &#125;)</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>æŸ¥çœ‹æ•°æ®é›†å­é›†ï¼Œä¸€ä¸ªæ•°æ®ä¸‹å¯èƒ½è¿˜æœ‰å¾ˆå¤šå­æ•°æ®é›†</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> get_dataset_config_names</span><br><span class="line"></span><br><span class="line">configs = get_dataset_config_names(<span class="string">&quot;PolyAI/minds14&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(configs)</span><br><span class="line"></span><br><span class="line">[<span class="string">&#x27;cs-CZ&#x27;</span>, <span class="string">&#x27;de-DE&#x27;</span>, <span class="string">&#x27;en-AU&#x27;</span>, <span class="string">&#x27;en-GB&#x27;</span>, <span class="string">&#x27;en-US&#x27;</span>, <span class="string">&#x27;es-ES&#x27;</span>, <span class="string">&#x27;fr-FR&#x27;</span>, <span class="string">&#x27;it-IT&#x27;</span>, <span class="string">&#x27;ko-KR&#x27;</span>, <span class="string">&#x27;nl-NL&#x27;</span>, <span class="string">&#x27;pl-PL&#x27;</span>, <span class="string">&#x27;pt-PT&#x27;</span>, <span class="string">&#x27;ru-RU&#x27;</span>, <span class="string">&#x27;zh-CN&#x27;</span>, <span class="string">&#x27;all&#x27;</span>]</span><br></pre></td></tr></table></figure>
<blockquote>
<p>åŠ è½½æŒ‡å®šå­æ•°æ®é›†</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"></span><br><span class="line">mindsFR = load_dataset(<span class="string">&quot;PolyAI/minds14&quot;</span>, <span class="string">&quot;fr-FR&quot;</span>, split=<span class="string">&quot;train&quot;</span>) <span class="comment"># æŒ‡å®šå­æ•°æ®é›†æ˜¯fr-FR</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>æŒ‡å®šæ•°æ®é›†çš„æ–‡ä»¶, é¿å…loadè¿‡å¤šçš„æ•°æ®</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data_files = &#123;<span class="string">&quot;validation&quot;</span>: <span class="string">&quot;en/c4-validation.*.json.gz&quot;</span>&#125;</span><br><span class="line">c4_validation = load_dataset(<span class="string">&quot;allenai/c4&quot;</span>, data_files=data_files, split=<span class="string">&quot;validation&quot;</span>)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>loadæœ¬åœ°çš„jsonã€csvæ–‡ä»¶ç­‰ï¼Œå¯ä»¥loadè¿œç¨‹æ–‡ä»¶ã€sqlç­‰</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#&#123;&quot;version&quot;: &quot;0.1.0&quot;,</span></span><br><span class="line"><span class="comment"># &quot;data&quot;: [&#123;&quot;a&quot;: 1, &quot;b&quot;: 2.0, &quot;c&quot;: &quot;foo&quot;, &quot;d&quot;: false&#125;,</span></span><br><span class="line"><span class="comment">#          &#123;&quot;a&quot;: 4, &quot;b&quot;: -5.5, &quot;c&quot;: null, &quot;d&quot;: true&#125;]</span></span><br><span class="line"><span class="comment">#&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line">dataset = load_dataset(<span class="string">&quot;json&quot;</span>, data_files=<span class="string">&quot;my_file.json&quot;</span>, field=<span class="string">&quot;data&quot;</span>)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>é€šè¿‡pythonå¯¹è±¡æ¥åˆ›å»ºdataset</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># å­—å…¸æ–¹å¼</span></span><br><span class="line">my_dict = &#123;<span class="string">&quot;a&quot;</span>: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]&#125;</span><br><span class="line">dataset = Dataset.from_dict(my_dict)</span><br><span class="line"></span><br><span class="line"><span class="comment"># listæ–¹å¼</span></span><br><span class="line">my_list = [&#123;<span class="string">&quot;a&quot;</span>: <span class="number">1</span>&#125;, &#123;<span class="string">&quot;a&quot;</span>: <span class="number">2</span>&#125;, &#123;<span class="string">&quot;a&quot;</span>: <span class="number">3</span>&#125;]</span><br><span class="line">dataset = Dataset.from_list(my_list)</span><br><span class="line"></span><br><span class="line"><span class="comment"># pandasæ–¹å¼</span></span><br><span class="line">df = pd.DataFrame(&#123;<span class="string">&quot;a&quot;</span>: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]&#125;)</span><br><span class="line">dataset = Dataset.from_pandas(df)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>loadå¤šä¸ªæ–‡æœ¬æ–‡ä»¶: æ–‡æœ¬å¿…é¡»ä¸€è¡Œå°±æ˜¯ä¸€æ¡æ ·æœ¬</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line">dataset = load_dataset(<span class="string">&quot;text&quot;</span>, data_files=&#123;<span class="string">&quot;train&quot;</span>: [<span class="string">&quot;my_text_1.txt&quot;</span>, <span class="string">&quot;my_text_2.txt&quot;</span>], <span class="string">&quot;test&quot;</span>: <span class="string">&quot;my_test_file.txt&quot;</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load from a directory</span></span><br><span class="line">dataset = load_dataset(<span class="string">&quot;text&quot;</span>, data_dir=<span class="string">&quot;path/to/text/dataset&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>ç¦»çº¿load: å°†ç¯å¢ƒå˜é‡<code>HF_DATASETS_OFFLINE</code>è®¾ç½®ä¸º1ä»¥å¯ç”¨å®Œå…¨ç¦»çº¿æ¨¡å¼</p>
<h2 id="è¿›é˜¶åŠ è½½æ•°æ®é›†"><a href="#è¿›é˜¶åŠ è½½æ•°æ®é›†" class="headerlink" title="è¿›é˜¶åŠ è½½æ•°æ®é›†"></a>è¿›é˜¶åŠ è½½æ•°æ®é›†</h2><blockquote>
<p>ä»è„šæœ¬åŠ è½½æ•°æ®é›†</p>
</blockquote>
<p>æ‚¨å¯èƒ½åœ¨æœ¬åœ°è®¡ç®—æœºä¸Šæœ‰ä¸€ä¸ªğŸ¤—Datasetsçš„åŠ è½½è„šæœ¬ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œé€šè¿‡å°†ä»¥ä¸‹è·¯å¾„ä¹‹ä¸€ä¼ é€’ç»™load_dataset()æ¥åŠ è½½æ•°æ®é›†ï¼š</p>
<p>åŠ è½½è„šæœ¬æ–‡ä»¶çš„æœ¬åœ°è·¯å¾„ã€‚ åŒ…å«åŠ è½½è„šæœ¬æ–‡ä»¶çš„ç›®å½•çš„æœ¬åœ°è·¯å¾„(ä»…å½“è„šæœ¬æ–‡ä»¶ä¸ç›®å½•å…·æœ‰ç›¸åŒçš„åç§°æ—¶)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dataset = load_dataset(<span class="string">&quot;path/to/local/loading_script/loading_script.py&quot;</span>, split=<span class="string">&quot;train&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># equivalent because the file has the same name as the directory</span></span><br><span class="line">dataset = load_dataset(<span class="string">&quot;path/to/local/loading_script&quot;</span>, split=<span class="string">&quot;train&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>å¯ä»¥ä»Hubä¸Šä¸‹è½½åŠ è½½è„šæœ¬ï¼Œå¹¶å¯¹å…¶è¿›è¡Œç¼–è¾‘ä»¥æ·»åŠ è‡ªå·±çš„ä¿®æ”¹ã€‚å°†æ•°æ®é›†ä»“åº“ä¸‹è½½åˆ°æœ¬åœ°ï¼Œä»¥ä¾¿åŠ è½½è„šæœ¬ä¸­ç›¸å¯¹è·¯å¾„å¼•ç”¨çš„ä»»ä½•æ•°æ®æ–‡ä»¶éƒ½å¯ä»¥è¢«åŠ è½½</p>
<figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://huggingface.co/datasets/eli5</span><br></pre></td></tr></table></figure>
<p>åœ¨åŠ è½½è„šæœ¬ä¸Šè¿›è¡Œç¼–è¾‘åï¼Œé€šè¿‡å°†å…¶æœ¬åœ°è·¯å¾„ä¼ é€’ç»™load_dataset()æ¥åŠ è½½å®ƒ</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"></span><br><span class="line">eli5 = load_dataset(<span class="string">&quot;path/to/local/eli5&quot;</span>)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>csv+jsonæ–¹å¼</p>
</blockquote>
<p>æ•°æ®é›†å¯ä»¥ä»å­˜å‚¨åœ¨è®¡ç®—æœºä¸Šçš„æœ¬åœ°æ–‡ä»¶å’Œè¿œç¨‹æ–‡ä»¶ä¸­åŠ è½½ã€‚è¿™äº›æ•°æ®é›†å¾ˆå¯èƒ½ä»¥csvã€jsonã€txtæˆ–parquetæ–‡ä»¶çš„å½¢å¼å­˜å‚¨ã€‚load_dataset()å‡½æ•°å¯ä»¥åŠ è½½è¿™äº›æ–‡ä»¶ç±»å‹çš„æ•°æ®é›†</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"></span><br><span class="line"><span class="comment"># csvæ–¹å¼</span></span><br><span class="line">dataset = load_dataset(<span class="string">&quot;csv&quot;</span>, data_files=<span class="string">&quot;my_file.csv&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># jsonæ–¹å¼</span></span><br><span class="line"><span class="comment"># &#123;&quot;a&quot;: 1, &quot;b&quot;: 2.0, &quot;c&quot;: &quot;foo&quot;, &quot;d&quot;: false&#125;</span></span><br><span class="line"><span class="comment"># &#123;&quot;a&quot;: 4, &quot;b&quot;: -5.5, &quot;c&quot;: null, &quot;d&quot;: true&#125;</span></span><br><span class="line">dataset = load_dataset(<span class="string">&quot;json&quot;</span>, data_files=<span class="string">&quot;my_file.json&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># &#123;&quot;version&quot;: &quot;0.1.0&quot;,</span></span><br><span class="line"><span class="comment">#  &quot;data&quot;: [&#123;&quot;a&quot;: 1, &quot;b&quot;: 2.0, &quot;c&quot;: &quot;foo&quot;, &quot;d&quot;: false&#125;,</span></span><br><span class="line"><span class="comment">#           &#123;&quot;a&quot;: 4, &quot;b&quot;: -5.5, &quot;c&quot;: null, &quot;d&quot;: true&#125;]</span></span><br><span class="line"><span class="comment"># &#125;</span></span><br><span class="line">dataset = load_dataset(<span class="string">&quot;json&quot;</span>, data_files=<span class="string">&quot;my_file.json&quot;</span>, field=<span class="string">&quot;data&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ä»httpæ–¹å¼åŠ è½½csv</span></span><br><span class="line">base_url = <span class="string">&quot;https://rajpurkar.github.io/SQuAD-explorer/dataset/&quot;</span></span><br><span class="line">dataset = load_dataset(<span class="string">&quot;json&quot;</span>, data_files=&#123;<span class="string">&quot;train&quot;</span>: base_url + <span class="string">&quot;train-v1.1.json&quot;</span>, <span class="string">&quot;validation&quot;</span>: base_url + <span class="string">&quot;dev-v1.1.json&quot;</span>&#125;, field=<span class="string">&quot;data&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Parquetæ–¹å¼</span></span><br><span class="line">dataset = load_dataset(<span class="string">&quot;parquet&quot;</span>, data_files=&#123;<span class="string">&#x27;train&#x27;</span>: <span class="string">&#x27;train.parquet&#x27;</span>, <span class="string">&#x27;test&#x27;</span>: <span class="string">&#x27;test.parquet&#x27;</span>&#125;)</span><br><span class="line"></span><br><span class="line">base_url = <span class="string">&quot;https://storage.googleapis.com/huggingface-nlp/cache/datasets/wikipedia/20200501.en/1.0.0/&quot;</span></span><br><span class="line">data_files = &#123;<span class="string">&quot;train&quot;</span>: base_url + <span class="string">&quot;wikipedia-train.parquet&quot;</span>&#125;</span><br><span class="line">wiki = load_dataset(<span class="string">&quot;parquet&quot;</span>, data_files=data_files, split=<span class="string">&quot;train&quot;</span>)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>sqlæ–¹å¼</p>
</blockquote>
<p>ä½¿ç”¨from_sql()æ–¹æ³•å¯ä»¥é€šè¿‡æŒ‡å®šè¿æ¥åˆ°æ•°æ®åº“çš„URIæ¥è¯»å–æ•°æ®åº“å†…å®¹ã€‚æ‚¨å¯ä»¥è¯»å–è¡¨åæˆ–æ‰§è¡ŒæŸ¥è¯¢æ“ä½œ</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> Dataset</span><br><span class="line"></span><br><span class="line">dataset = Dataset.from_sql(<span class="string">&quot;data_table_name&quot;</span>, con=<span class="string">&quot;sqlite:///sqlite_file.db&quot;</span>)</span><br><span class="line">dataset = Dataset.from_sql(<span class="string">&quot;SELECT text FROM table WHERE length(text) &gt; 100 LIMIT 10&quot;</span>, con=<span class="string">&quot;sqlite:///sqlite_file.db&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>For more details, check out the <a target="_blank" rel="noopener external nofollow noreferrer" href="https://huggingface.co/docs/datasets/tabular_load#databases">how to load tabular datasets from SQL databases</a> guide.</p>
<h2 id="æ¢ç´¢æ•°æ®é›†"><a href="#æ¢ç´¢æ•°æ®é›†" class="headerlink" title="æ¢ç´¢æ•°æ®é›†"></a>æ¢ç´¢æ•°æ®é›†</h2><blockquote>
<p>ä¸‹æ ‡</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ç¬¬ä¸€ä¸ªæ ·æœ¬</span></span><br><span class="line">dataset[<span class="number">0</span>]</span><br><span class="line"><span class="comment">#&#123;&#x27;label&#x27;: 1,</span></span><br><span class="line"><span class="comment"># &#x27;text&#x27;: &#x27;the rock is destined to be the 21st century\&#x27;s new &quot; conan &quot; and that he\&#x27;s going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .&#x27;&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># æœ€åä¸€ä¸ªæ ·æœ¬</span></span><br><span class="line">dataset[-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># åªå–textåˆ—</span></span><br><span class="line">dataset[<span class="string">&quot;text&quot;</span>] <span class="comment"># è¿”å›a list of æ ·æœ¬åˆ—</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ç¬¬ä¸€ä¸ªæ ·æœ¬textåˆ—</span></span><br><span class="line">dataset[<span class="number">0</span>][<span class="string">&quot;text&quot;</span>] <span class="comment"># æ€§èƒ½ï¼šdataset[0][&#x27;text&#x27;]æ¯”dataset[&#x27;text&#x27;][0]å¿«2å€ã€‚</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>æ•°æ®åˆ‡ç‰‡</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Get the first three rows</span></span><br><span class="line">dataset[:<span class="number">3</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get rows between three and six</span></span><br><span class="line">dataset[<span class="number">3</span>:<span class="number">6</span>]</span><br></pre></td></tr></table></figure>
<blockquote>
<p>è¿­ä»£æ–¹å¼ï¼Œstreaming=True</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"></span><br><span class="line">iterable_dataset = load_dataset(<span class="string">&quot;food101&quot;</span>, split=<span class="string">&quot;train&quot;</span>, streaming=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">for</span> example <span class="keyword">in</span> iterable_dataset:</span><br><span class="line">    <span class="built_in">print</span>(example)</span><br><span class="line">    <span class="keyword">break</span></span><br><span class="line">    </span><br><span class="line">&#123;<span class="string">&#x27;image&#x27;</span>: &lt;PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at <span class="number">0x7F0681F5C520</span>&gt;, <span class="string">&#x27;label&#x27;</span>: <span class="number">6</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get first three examples</span></span><br><span class="line"><span class="built_in">list</span>(iterable_dataset.take(<span class="number">3</span>))</span><br><span class="line">[&#123;<span class="string">&#x27;image&#x27;</span>: &lt;PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at <span class="number">0x7F7479DEE9D0</span>&gt;,</span><br><span class="line">  <span class="string">&#x27;label&#x27;</span>: <span class="number">6</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;image&#x27;</span>: &lt;PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=512x512 at <span class="number">0x7F7479DE8190</span>&gt;,</span><br><span class="line">  <span class="string">&#x27;label&#x27;</span>: <span class="number">6</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;image&#x27;</span>: &lt;PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=512x383 at <span class="number">0x7F7479DE8310</span>&gt;,</span><br><span class="line">  <span class="string">&#x27;label&#x27;</span>: <span class="number">6</span>&#125;]</span><br></pre></td></tr></table></figure>
<blockquote>
<p>æ’åº+shuffle+é€‰æ‹©+filter+åˆ‡åˆ†æ•°æ®é›†+åˆ†ç‰‡</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># sort: æŒ‰æŸä¸€åˆ—æ’åº</span></span><br><span class="line">dataset.sort(<span class="string">&quot;label&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># æ‰“ä¹±</span></span><br><span class="line">shuffled_dataset = sorted_dataset.shuffle(seed=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># é€‰æ‹©</span></span><br><span class="line">small_dataset = dataset.select([<span class="number">0</span>, <span class="number">10</span>, <span class="number">20</span>, <span class="number">30</span>, <span class="number">40</span>, <span class="number">50</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># åŒ¹é…æŸ¥æ‰¾</span></span><br><span class="line">start_with_ar = dataset.<span class="built_in">filter</span>(<span class="keyword">lambda</span> example: example[<span class="string">&quot;sentence1&quot;</span>].startswith(<span class="string">&quot;Ar&quot;</span>))</span><br><span class="line"><span class="built_in">len</span>(start_with_ar)</span><br><span class="line">start_with_ar[<span class="string">&quot;sentence1&quot;</span>]</span><br><span class="line"><span class="comment"># åŒ¹é…æŸ¥æ‰¾ï¼šæ ¹æ®ä¸‹æ ‡</span></span><br><span class="line">even_dataset = dataset.<span class="built_in">filter</span>(<span class="keyword">lambda</span> example, idx: idx % <span class="number">2</span> == <span class="number">0</span>, with_indices=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># åˆ‡åˆ†</span></span><br><span class="line">dataset.train_test_split(test_size=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># åˆ†ç‰‡</span></span><br><span class="line"><span class="comment"># æ•°æ®é›†æ”¯æŒåˆ†ç‰‡ï¼Œå°†éå¸¸å¤§çš„æ•°æ®é›†åˆ’åˆ†ä¸ºé¢„å®šä¹‰æ•°é‡çš„å—ã€‚ åœ¨ shard() ä¸­æŒ‡å®š num_shards å‚æ•°ä»¥ç¡®å®šè¦å°†æ•°æ®é›†æ‹†åˆ†æˆçš„åˆ†ç‰‡æ•°ã€‚ æ‚¨è¿˜éœ€è¦ä½¿ç”¨ index å‚æ•°æä¾›è¦è¿”å›çš„åˆ†ç‰‡ã€‚</span></span><br><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line">datasets = load_dataset(<span class="string">&quot;imdb&quot;</span>, split=<span class="string">&quot;train&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(dataset)</span><br><span class="line">dataset.shard(num_shards=<span class="number">4</span>, index=<span class="number">0</span>) <span class="comment"># å››åˆ†ä¹‹ä¸€</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>åˆ—é‡å‘½å+ç§»é™¤åˆ—+è½¬æ¢æ ¼å¼+flatten</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> ClassLabel, Value</span><br><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"></span><br><span class="line"><span class="comment"># åˆ—é‡å‘½å</span></span><br><span class="line">dataset = dataset.rename_column(<span class="string">&quot;sentence1&quot;</span>, <span class="string">&quot;sentenceA&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># å»æ‰æŸä¸€åˆ—</span></span><br><span class="line">dataset = dataset.remove_columns([<span class="string">&quot;sentence1&quot;</span>, <span class="string">&quot;sentence2&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># è½¬æ¢æ ¼å¼ï¼šä¸€åˆ—æˆ–è€…å¤šåˆ—</span></span><br><span class="line">new_features = dataset.features.copy()</span><br><span class="line">new_features[<span class="string">&quot;label&quot;</span>] = ClassLabel(names=[<span class="string">&quot;negative&quot;</span>, <span class="string">&quot;positive&quot;</span>])</span><br><span class="line">new_features[<span class="string">&quot;idx&quot;</span>] = Value(<span class="string">&quot;int64&quot;</span>)</span><br><span class="line">dataset = dataset.cast(new_features)</span><br><span class="line"></span><br><span class="line"><span class="comment"># è½¬æ¢æ ¼å¼ï¼šä¸€åˆ—</span></span><br><span class="line">dataset = dataset.cast_column(<span class="string">&quot;audio&quot;</span>, Audio(sampling_rate=<span class="number">16000</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># å°†æŸä¸€åˆ—çš„key\valueæ‹‰å¹³</span></span><br><span class="line">dataset = load_dataset(<span class="string">&quot;squad&quot;</span>, split=<span class="string">&quot;train&quot;</span>) <span class="comment"># ???</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>mapè½¬æ¢</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> multiprocess <span class="keyword">import</span> set_start_method</span><br><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">set_start_method(<span class="string">&quot;spawn&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># remove_columns è½¬æ¢çš„åŒæ—¶å»æ‰æŸä¸€åˆ—</span></span><br><span class="line">updated_dataset = dataset.<span class="built_in">map</span>(<span class="keyword">lambda</span> example: &#123;<span class="string">&quot;new_sentence&quot;</span>: example[<span class="string">&quot;sentence1&quot;</span>]&#125;, remove_columns=[<span class="string">&quot;sentence1&quot;</span>])</span><br><span class="line">updated_dataset.column_names</span><br><span class="line"></span><br><span class="line"><span class="comment"># with_indices: å¯¹ä¸‹æ ‡å¤„ç†</span></span><br><span class="line">updated_dataset = dataset.<span class="built_in">map</span>(<span class="keyword">lambda</span> example, idx: &#123;<span class="string">&quot;sentence2&quot;</span>: <span class="string">f&quot;<span class="subst">&#123;idx&#125;</span>: &quot;</span> + example[<span class="string">&quot;sentence2&quot;</span>]&#125;, with_indices=<span class="literal">True</span>)</span><br><span class="line">updated_dataset[<span class="string">&quot;sentence2&quot;</span>][:<span class="number">5</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#å¦‚æœæ‚¨è®¾ç½®with_rank=Trueï¼Œmap()ä¹Ÿé€‚ç”¨äºè¿›ç¨‹çš„ç­‰çº§ã€‚ è¿™ç±»ä¼¼äºwith_indiceså‚æ•°ã€‚ æ˜ å°„å‡½æ•°ä¸­çš„with_rankå‚æ•°ä½äºç´¢å¼•1ä¹‹å(å¦‚æœå®ƒå·²ç»å­˜åœ¨)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gpu_computation</span>(<span class="params">example, rank</span>):</span><br><span class="line">    os.environ[<span class="string">&quot;CUDA_VISIBLE_DEVICES&quot;</span>] = <span class="built_in">str</span>(rank % torch.cuda.device_count())</span><br><span class="line">    <span class="comment"># Your big GPU call goes here</span></span><br><span class="line">    <span class="keyword">return</span> examples</span><br><span class="line">updated_dataset = dataset.<span class="built_in">map</span>(gpu_computation, with_rank=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># å¤šçº¿ç¨‹</span></span><br><span class="line">updated_dataset = dataset.<span class="built_in">map</span>(<span class="keyword">lambda</span> example, idx: &#123;<span class="string">&quot;sentence2&quot;</span>: <span class="string">f&quot;<span class="subst">&#123;idx&#125;</span>: &quot;</span> + example[<span class="string">&quot;sentence2&quot;</span>]&#125;, num_proc=<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># batched</span></span><br><span class="line">chunked_dataset = dataset.<span class="built_in">map</span>(chunk_examples, batched=<span class="literal">True</span>, remove_columns=dataset.column_names)</span><br><span class="line"></span><br><span class="line"><span class="comment"># æ•°æ®å¢å¼º</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">augment_data</span>(<span class="params">examples</span>):</span><br><span class="line">    outputs = []</span><br><span class="line">    <span class="keyword">for</span> sentence <span class="keyword">in</span> examples[<span class="string">&quot;sentence1&quot;</span>]:</span><br><span class="line">        words = sentence.split(<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">        K = randint(<span class="number">1</span>, <span class="built_in">len</span>(words)-<span class="number">1</span>)</span><br><span class="line">        masked_sentence = <span class="string">&quot; &quot;</span>.join(words[:K]  + [mask_token] + words[K+<span class="number">1</span>:])</span><br><span class="line">        predictions = fillmask(masked_sentence)</span><br><span class="line">        augmented_sequences = [predictions[i][<span class="string">&quot;sequence&quot;</span>] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>)]</span><br><span class="line">        outputs += [sentence] + augmented_sequences</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;data&quot;</span>: outputs&#125;</span><br><span class="line">augmented_dataset = smaller_dataset.<span class="built_in">map</span>(augment_data, batched=<span class="literal">True</span>, remove_columns=dataset.column_names, batch_size=<span class="number">8</span>)</span><br><span class="line">augmented_dataset[:<span class="number">9</span>][<span class="string">&quot;data&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># å¤„ç†å¤šsplit</span></span><br><span class="line">dataset = load_dataset(<span class="string">&#x27;glue&#x27;</span>, <span class="string">&#x27;mrpc&#x27;</span>)</span><br><span class="line">encoded_dataset = dataset.<span class="built_in">map</span>(<span class="keyword">lambda</span> examples: tokenizer(examples[<span class="string">&quot;sentence1&quot;</span>]), batched=<span class="literal">True</span>)</span><br><span class="line">encoded_dataset[<span class="string">&quot;train&quot;</span>][<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<blockquote>
<p>åˆå¹¶+æ‹¼æ¥æ•°æ®é›†</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> concatenate_datasets, load_dataset</span><br><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> Dataset</span><br><span class="line"></span><br><span class="line"><span class="comment"># åŠ è½½æ•°æ®é›†</span></span><br><span class="line">bookcorpus = load_dataset(<span class="string">&quot;bookcorpus&quot;</span>, split=<span class="string">&quot;train&quot;</span>)</span><br><span class="line">wiki = load_dataset(<span class="string">&quot;wikipedia&quot;</span>, <span class="string">&quot;20220301.en&quot;</span>, split=<span class="string">&quot;train&quot;</span>)</span><br><span class="line">wiki = wiki.remove_columns([col <span class="keyword">for</span> col <span class="keyword">in</span> wiki.column_names <span class="keyword">if</span> col != <span class="string">&quot;text&quot;</span>])  <span class="comment"># only keep the &#x27;text&#x27; column</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">assert</span> bookcorpus.features.<span class="built_in">type</span> == wiki.features.<span class="built_in">type</span></span><br><span class="line">bert_dataset = concatenate_datasets([bookcorpus, wiki])</span><br><span class="line"></span><br><span class="line"><span class="comment"># å¯ä»¥æ¢concateçš„æ–¹å‘</span></span><br><span class="line">bookcorpus_ids = Dataset.from_dict(&#123;<span class="string">&quot;ids&quot;</span>: <span class="built_in">list</span>(<span class="built_in">range</span>(<span class="built_in">len</span>(bookcorpus)))&#125;)</span><br><span class="line">bookcorpus_with_ids = concatenate_datasets([bookcorpus, bookcorpus_ids], axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>ç›¸äº’ç©¿æ’</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="comment"># æŒ‰æ¦‚ç‡ç©¿æ’</span></span><br><span class="line">seed = <span class="number">42</span></span><br><span class="line">probabilities = [<span class="number">0.3</span>, <span class="number">0.5</span>, <span class="number">0.2</span>]</span><br><span class="line">d1 = Dataset.from_dict(&#123;<span class="string">&quot;a&quot;</span>: [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>]&#125;)</span><br><span class="line">d2 = Dataset.from_dict(&#123;<span class="string">&quot;a&quot;</span>: [<span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>, <span class="number">13</span>]&#125;)</span><br><span class="line">d3 = Dataset.from_dict(&#123;<span class="string">&quot;a&quot;</span>: [<span class="number">20</span>, <span class="number">21</span>, <span class="number">22</span>]&#125;)</span><br><span class="line">dataset = interleave_datasets([d1, d2, d3], probabilities=probabilities, seed=seed)</span><br><span class="line">dataset[<span class="string">&quot;a&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># æŒ‰æ‰€æœ‰çš„æ ·æœ¬éƒ½å‡ºç°è¿‡ä¸€æ¬¡åï¼Œé©¬ä¸Šåœæ­¢</span></span><br><span class="line">d1 = Dataset.from_dict(&#123;<span class="string">&quot;a&quot;</span>: [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>]&#125;)</span><br><span class="line">d2 = Dataset.from_dict(&#123;<span class="string">&quot;a&quot;</span>: [<span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>, <span class="number">13</span>]&#125;)</span><br><span class="line">d3 = Dataset.from_dict(&#123;<span class="string">&quot;a&quot;</span>: [<span class="number">20</span>, <span class="number">21</span>, <span class="number">22</span>]&#125;)</span><br><span class="line">dataset = interleave_datasets([d1, d2, d3], stopping_strategy=<span class="string">&quot;all_exhausted&quot;</span>)</span><br><span class="line">dataset[<span class="string">&quot;a&quot;</span>]</span><br></pre></td></tr></table></figure>
<blockquote>
<p>format</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">dataset.set_format(<span class="built_in">type</span>=<span class="string">&quot;torch&quot;</span>, columns=[<span class="string">&quot;input_ids&quot;</span>, <span class="string">&quot;token_type_ids&quot;</span>, <span class="string">&quot;attention_mask&quot;</span>, <span class="string">&quot;label&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># è¿”å›ä¸€ä¸ªæ–°dataset</span></span><br><span class="line">dataset = dataset.with_format(<span class="built_in">type</span>=<span class="string">&quot;torch&quot;</span>, columns=[<span class="string">&quot;input_ids&quot;</span>, <span class="string">&quot;token_type_ids&quot;</span>, <span class="string">&quot;attention_mask&quot;</span>, <span class="string">&quot;label&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># æŸ¥çœ‹</span></span><br><span class="line">dataset.<span class="built_in">format</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>ä¿å­˜</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_from_disk</span><br><span class="line"></span><br><span class="line">encoded_dataset.save_to_disk(<span class="string">&quot;path/of/my/dataset/directory&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ä»æœ¬åœ°loadä¸Šæ¥</span></span><br><span class="line">reloaded_dataset = load_from_disk(<span class="string">&quot;path/of/my/dataset/directory&quot;</span>)</span><br><span class="line">encoded_dataset.to_csv(<span class="string">&quot;path/of/my/dataset.csv&quot;</span>)</span><br><span class="line">Dataset.to_json()</span><br></pre></td></tr></table></figure>
<h2 id="Preprocesså¤„ç†"><a href="#Preprocesså¤„ç†" class="headerlink" title="Preprocesså¤„ç†"></a>Preprocesså¤„ç†</h2><blockquote>
<p>æ–‡æœ¬å¤„ç†ï¼šç”¨transformersçš„tokenizer</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer</span><br><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(<span class="string">&quot;bert-base-uncased&quot;</span>)</span><br><span class="line">dataset = load_dataset(<span class="string">&quot;rotten_tomatoes&quot;</span>, split=<span class="string">&quot;train&quot;</span>)</span><br><span class="line"></span><br><span class="line">tokenizer(dataset[<span class="number">0</span>][<span class="string">&quot;text&quot;</span>])</span><br><span class="line"></span><br><span class="line">&#123;<span class="string">&#x27;input_ids&#x27;</span>: [<span class="number">101</span>, <span class="number">1103</span>, <span class="number">2067</span>, <span class="number">1110</span>, <span class="number">17348</span>, <span class="number">1106</span>, <span class="number">1129</span>, <span class="number">1103</span>, <span class="number">6880</span>, <span class="number">1432</span>, <span class="number">112</span>, <span class="number">188</span>, <span class="number">1207</span>, <span class="number">107</span>, <span class="number">14255</span>, <span class="number">1389</span>, <span class="number">107</span>, <span class="number">1105</span>, <span class="number">1115</span>, <span class="number">1119</span>, <span class="number">112</span>, <span class="number">188</span>, <span class="number">1280</span>, <span class="number">1106</span>, <span class="number">1294</span>, <span class="number">170</span>, <span class="number">24194</span>, <span class="number">1256</span>, <span class="number">3407</span>, <span class="number">1190</span>, <span class="number">170</span>, <span class="number">11791</span>, <span class="number">5253</span>, <span class="number">188</span>, <span class="number">1732</span>, <span class="number">7200</span>, <span class="number">10947</span>, <span class="number">12606</span>, <span class="number">2895</span>, <span class="number">117</span>, <span class="number">179</span>, <span class="number">7766</span>, <span class="number">118</span>, <span class="number">172</span>, <span class="number">15554</span>, <span class="number">1181</span>, <span class="number">3498</span>, <span class="number">6961</span>, <span class="number">3263</span>, <span class="number">1137</span>, <span class="number">188</span>, <span class="number">1566</span>, <span class="number">7912</span>, <span class="number">14516</span>, <span class="number">6997</span>, <span class="number">119</span>, <span class="number">102</span>], </span><br><span class="line"> <span class="string">&#x27;token_type_ids&#x27;</span>: [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>], </span><br><span class="line"> <span class="string">&#x27;attention_mask&#x27;</span>: [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]&#125;</span><br></pre></td></tr></table></figure>
<p>åˆ†è¯å™¨è¿”å›ä¸€ä¸ªåŒ…å«ä¸‰ä¸ªé¡¹ç›®çš„å­—å…¸ï¼š</p>
<ul>
<li><strong>input_ids</strong>ï¼šè¡¨ç¤ºæ–‡æœ¬ä¸­å„ä¸ªæ ‡è®°çš„æ•°å­—</li>
<li><strong>token_type_ids</strong>ï¼šå¦‚æœæœ‰å¤šä¸ªåºåˆ—ï¼ŒæŒ‡ç¤ºä¸€ä¸ªæ ‡è®°å±äºå“ªä¸ªåºåˆ—</li>
<li><strong>attention_mask</strong>ï¼šæŒ‡ç¤ºä¸€ä¸ªæ ‡è®°æ˜¯å¦åº”è¯¥è¢«æ©ç›–(masked)</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataset.set_format(<span class="built_in">type</span>=<span class="string">&quot;torch&quot;</span>, columns=[<span class="string">&quot;input_ids&quot;</span>, <span class="string">&quot;token_type_ids&quot;</span>, <span class="string">&quot;attention_mask&quot;</span>, <span class="string">&quot;labels&quot;</span>])</span><br></pre></td></tr></table></figure>
<blockquote>
<p>éŸ³é¢‘ä¿¡å·ï¼šé‡æ–°é‡‡æ ·éŸ³é¢‘ä¿¡å·</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoFeatureExtractor</span><br><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset, Audio</span><br><span class="line"></span><br><span class="line">feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="string">&quot;facebook/wav2vec2-base-960h&quot;</span>)</span><br><span class="line">dataset = load_dataset(<span class="string">&quot;PolyAI/minds14&quot;</span>, <span class="string">&quot;en-US&quot;</span>, split=<span class="string">&quot;train&quot;</span>)</span><br><span class="line"></span><br><span class="line">dataset[<span class="number">0</span>][<span class="string">&quot;audio&quot;</span>]</span><br><span class="line"></span><br><span class="line">&#123;<span class="string">&#x27;array&#x27;</span>: array([ <span class="number">0.</span>        ,  <span class="number">0.00024414</span>, -<span class="number">0.00024414</span>, ..., -<span class="number">0.00024414</span>,</span><br><span class="line">         <span class="number">0.</span>        ,  <span class="number">0.</span>        ], dtype=float32),</span><br><span class="line"> <span class="string">&#x27;path&#x27;</span>: <span class="string">&#x27;/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~JOINT_ACCOUNT/602ba55abb1e6d0fbce92065.wav&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;sampling_rate&#x27;</span>: <span class="number">8000</span>&#125;</span><br></pre></td></tr></table></figure>
<p>MInDS-14æ•°æ®é›†å¡ä¼šå‘Šè¯‰æ‚¨é‡‡æ ·ç‡ä¸º8kHz</p>
<p>Wav2Vec2æ¨¡å‹å¡è¯´å®ƒæ˜¯åœ¨16kHzè¯­éŸ³éŸ³é¢‘ä¸Šé‡‡æ ·çš„ã€‚ è¿™æ„å‘³ç€æ‚¨éœ€è¦å¯¹MInDS-14æ•°æ®é›†è¿›è¡Œä¸Šé‡‡æ ·ä»¥åŒ¹é…æ¨¡å‹çš„é‡‡æ ·ç‡</p>
<p>ä½¿ç”¨cast_column()å‡½æ•°å¹¶åœ¨AudioåŠŸèƒ½ä¸­è®¾ç½®sampling_rateå‚æ•°ä»¥å¯¹éŸ³é¢‘ä¿¡å·è¿›è¡Œä¸Šé‡‡æ ·ã€‚ å½“æ‚¨ç°åœ¨è°ƒç”¨éŸ³é¢‘åˆ—æ—¶ï¼Œå®ƒä¼šè¢«è§£ç å¹¶é‡æ–°é‡‡æ ·åˆ°16kHzï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">dataset = dataset.cast_column(<span class="string">&quot;audio&quot;</span>, Audio(sampling_rate=<span class="number">16_000</span>))</span><br><span class="line">dataset[<span class="number">0</span>][<span class="string">&quot;audio&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># åŠ é€Ÿï¼šä½¿ç”¨ map() å‡½æ•°å°†æ•´ä¸ªæ•°æ®é›†é‡æ–°é‡‡æ ·åˆ°16kHz</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">preprocess_function</span>(<span class="params">examples</span>):</span><br><span class="line">    audio_arrays = [x[<span class="string">&quot;array&quot;</span>] <span class="keyword">for</span> x <span class="keyword">in</span> examples[<span class="string">&quot;audio&quot;</span>]]</span><br><span class="line">    inputs = feature_extractor(</span><br><span class="line">        audio_arrays, sampling_rate=feature_extractor.sampling_rate, max_length=<span class="number">16000</span>, truncation=<span class="literal">True</span></span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> inputs</span><br><span class="line"></span><br><span class="line">dataset = dataset.<span class="built_in">map</span>(preprocess_function, batched=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>å›¾åƒå¢å¼º</p>
</blockquote>
<p>åœ¨å›¾åƒæ•°æ®é›†ä¸­ï¼Œæœ€å¸¸è§çš„é¢„å¤„ç†æ“ä½œä¹‹ä¸€æ˜¯<code>æ•°æ®å¢å¼º</code>(data augmentation)ï¼Œè¿™æ˜¯ä¸€ç§åœ¨ä¸æ”¹å˜æ•°æ®å«ä¹‰çš„æƒ…å†µä¸‹å¯¹å›¾åƒå¼•å…¥éšæœºå˜åŒ–çš„è¿‡ç¨‹</p>
<p>è¿™å¯ä»¥åŒ…æ‹¬æ”¹å˜å›¾åƒçš„é¢œè‰²å±æ€§æˆ–éšæœºè£å‰ªå›¾åƒã€‚æ‚¨å¯ä»¥è‡ªç”±é€‰æ‹©ä»»ä½•æ•°æ®å¢å¼ºåº“ï¼Œå¹¶ä¸”ğŸ¤—Datasetså°†å¸®åŠ©æ‚¨å°†æ•°æ®å¢å¼ºåº”ç”¨åˆ°æ‚¨çš„æ•°æ®é›†ä¸­</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoFeatureExtractor</span><br><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset, Image</span><br><span class="line"><span class="keyword">from</span> torchvision.transforms <span class="keyword">import</span> RandomRotation</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="string">&quot;google/vit-base-patch16-224-in21k&quot;</span>)</span><br><span class="line">dataset = load_dataset(<span class="string">&quot;beans&quot;</span>, split=<span class="string">&quot;train&quot;</span>)</span><br><span class="line"></span><br><span class="line">rotate = RandomRotation(degrees=(<span class="number">0</span>, <span class="number">90</span>))</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">transforms</span>(<span class="params">examples</span>):</span><br><span class="line">    examples[<span class="string">&quot;pixel_values&quot;</span>] = [rotate(image.convert(<span class="string">&quot;RGB&quot;</span>)) <span class="keyword">for</span> image <span class="keyword">in</span> examples[<span class="string">&quot;image&quot;</span>]]</span><br><span class="line">    <span class="keyword">return</span> examples</span><br><span class="line"></span><br><span class="line"><span class="comment"># åº”ç”¨å›¾åƒè½¬æ¢</span></span><br><span class="line">dataset.set_transform(transforms)</span><br><span class="line">dataset[<span class="number">0</span>][<span class="string">&quot;pixel_values&quot;</span>]</span><br></pre></td></tr></table></figure>
<blockquote>
<p>label idå¯¹é½</p>
</blockquote>
<p>åœ¨Transformersåº“ä¸­ï¼Œ<strong>label idå¯¹é½</strong>(label ID alignment)é€šå¸¸æŒ‡çš„æ˜¯å°†æ ‡ç­¾ä¸æ¨¡å‹è¾“å‡ºçš„é¢„æµ‹ç»“æœå¯¹é½ã€‚å½“ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œåˆ†ç±»æˆ–å›å½’ç­‰ä»»åŠ¡æ—¶ï¼Œé€šå¸¸éœ€è¦å°†æ ‡ç­¾æ˜ å°„ä¸ºæ¨¡å‹æœŸæœ›çš„æ ‡ç­¾ID</p>
<p>å…·ä½“æ¥è¯´ï¼Œå¯¹äºåˆ†ç±»ä»»åŠ¡ï¼Œå¸¸è§çš„åšæ³•æ˜¯å°†æ ‡ç­¾æ˜ å°„ä¸ºæ•´æ•°æ ‡ç­¾IDã€‚ä¾‹å¦‚ï¼Œå¦‚æœæœ‰ä¸‰ä¸ªç±»åˆ«[â€œcatâ€, â€œdogâ€, â€œbirdâ€]ï¼Œå¯ä»¥å°†å®ƒä»¬æ˜ å°„ä¸º[0, 1, 2]ï¼Œå¹¶å°†æ¨¡å‹çš„è¾“å‡ºæ ‡ç­¾é¢„æµ‹ç»“æœä¸è¿™äº›æ ‡ç­¾IDè¿›è¡Œå¯¹é½</p>
<p>å¯¹äºå›å½’ä»»åŠ¡ï¼Œå¯èƒ½éœ€è¦å°†è¿ç»­å€¼çš„æ ‡ç­¾è¿›è¡Œç¦»æ•£åŒ–æˆ–å½’ä¸€åŒ–ï¼Œå¹¶å°†å…¶æ˜ å°„ä¸ºæ ‡ç­¾IDã€‚ä¾‹å¦‚ï¼Œå°†ä¸€ä¸ªè¿ç»­çš„ç›®æ ‡å€¼èŒƒå›´æ˜ å°„ä¸ºä¸€ç»„ç¦»æ•£çš„æ ‡ç­¾ID</p>
<p>åœ¨ä½¿ç”¨Transformersåº“è¿›è¡Œè®­ç»ƒæˆ–è¯„ä¼°æ—¶ï¼Œæ‚¨éœ€è¦ç¡®ä¿æ ‡ç­¾ä¸æ¨¡å‹çš„è¾“å‡ºç»“æœå…·æœ‰ç›¸åŒçš„æ ‡ç­¾IDå¯¹é½ï¼Œä»¥ä¾¿æ­£ç¡®è®¡ç®—æŸå¤±ã€è¯„ä¼°æŒ‡æ ‡å’Œè§£ç é¢„æµ‹ç»“æœ</p>
<p>éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œæ ‡ç­¾IDå¯¹é½çš„å…·ä½“å®ç°æ–¹å¼å¯èƒ½å› ä»»åŠ¡å’Œåº“çš„ä½¿ç”¨è€Œæœ‰æ‰€ä¸åŒã€‚åœ¨å…·ä½“çš„ä»£ç å®ç°ä¸­ï¼Œæ‚¨å¯èƒ½éœ€è¦æ ¹æ®æ‚¨çš„æ•°æ®é›†å’Œæ¨¡å‹è®¾ç½®è¿›è¡Œç›¸åº”çš„æ ‡ç­¾IDå¯¹é½æ“ä½œ</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">label2id = &#123;<span class="string">&quot;contradiction&quot;</span>: <span class="number">0</span>, <span class="string">&quot;neutral&quot;</span>: <span class="number">1</span>, <span class="string">&quot;entailment&quot;</span>: <span class="number">2</span>&#125;</span><br><span class="line">mnli = load_dataset(<span class="string">&quot;glue&quot;</span>, <span class="string">&quot;mnli&quot;</span>, split=<span class="string">&quot;train&quot;</span>)</span><br><span class="line">mnli_aligned = mnli.align_labels_with_mapping(label2id, <span class="string">&quot;label&quot;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="æ„å»ºæ•°æ®é›†"><a href="#æ„å»ºæ•°æ®é›†" class="headerlink" title="æ„å»ºæ•°æ®é›†"></a>æ„å»ºæ•°æ®é›†</h2><p>å¦‚æœæ‚¨ä½¿ç”¨è‡ªå·±çš„æ•°æ®ï¼Œå¯èƒ½éœ€è¦åˆ›å»ºä¸€ä¸ªæ•°æ®é›†ã€‚ä½¿ç”¨ğŸ¤—Datasetsåˆ›å»ºæ•°æ®é›†å¯ä»¥äº«å—åˆ°è¯¥åº“çš„æ‰€æœ‰ä¼˜åŠ¿ï¼šå¿«é€ŸåŠ è½½å’Œå¤„ç†æ•°æ®ã€æµå¼å¤„ç†å¤§å‹æ•°æ®é›†ã€å†…å­˜æ˜ å°„ç­‰ç­‰ã€‚æ‚¨å¯ä»¥ä½¿ç”¨ğŸ¤—Datasetsçš„ä½ä»£ç æ–¹æ³•è½»æ¾å¿«é€Ÿåœ°åˆ›å»ºæ•°æ®é›†ï¼Œå‡å°‘å¯åŠ¨è®­ç»ƒæ¨¡å‹æ‰€éœ€çš„æ—¶é—´ã€‚åœ¨è®¸å¤šæƒ…å†µä¸‹ï¼Œåªéœ€å°†æ•°æ®æ–‡ä»¶æ‹–æ”¾åˆ°Hubä¸Šçš„æ•°æ®é›†ä»“åº“ä¸­ï¼Œå°±å¯ä»¥è½»æ¾å®Œæˆ</p>
<p>åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæ‚¨å°†å­¦ä¹ å¦‚ä½•ä½¿ç”¨ğŸ¤—Datasetsçš„ä½ä»£ç æ–¹æ³•åˆ›å»ºå„ç§ç±»å‹çš„æ•°æ®é›†ï¼š</p>
<ul>
<li>åŸºäºæ–‡ä»¶å¤¹çš„æ„å»ºå™¨(Folder-based builders)ï¼Œç”¨äºå¿«é€Ÿåˆ›å»º<strong>å›¾åƒæˆ–éŸ³é¢‘æ•°æ®é›†</strong></li>
<li>ä½¿ç”¨from_æ–¹æ³•ä»æœ¬åœ°æ–‡ä»¶åˆ›å»ºæ•°æ®é›†</li>
</ul>
<blockquote>
<p>åŸºäºæ–‡ä»¶å¤¹çš„æ„å»ºå™¨</p>
</blockquote>
<p>æœ‰ä¸¤ä¸ªåŸºäºæ–‡ä»¶å¤¹çš„æ„å»ºå™¨ï¼š<code>ImageFolder(å›¾åƒæ–‡ä»¶å¤¹æ„å»ºå™¨)</code>å’Œ<code>AudioFolder(éŸ³é¢‘æ–‡ä»¶å¤¹æ„å»ºå™¨)</code></p>
<p>å®ƒä»¬æ˜¯ä½ä»£ç æ–¹æ³•ï¼Œå¯ä»¥å¿«é€Ÿåˆ›å»ºåŒ…å«æ•°åƒä¸ªç¤ºä¾‹çš„å›¾åƒã€è¯­éŸ³å’ŒéŸ³é¢‘æ•°æ®é›†ã€‚å®ƒä»¬éå¸¸é€‚ç”¨äºåœ¨æ‰©å±•åˆ°æ›´å¤§çš„æ•°æ®é›†ä¹‹å‰ï¼Œå¿«é€ŸåŸå‹åŒ–è®¡ç®—æœºè§†è§‰å’Œè¯­éŸ³æ¨¡å‹</p>
<p>åŸºäºæ–‡ä»¶å¤¹çš„æ„å»ºå™¨ä¼šä½¿ç”¨æ‚¨çš„æ•°æ®ï¼Œå¹¶è‡ªåŠ¨ç”Ÿæˆæ•°æ®é›†çš„ç‰¹å¾ã€åˆ’åˆ†å’Œæ ‡ç­¾ã€‚å…·ä½“æ¥è¯´ï¼š</p>
<ul>
<li>ImageFolderä½¿ç”¨Imageç‰¹å¾æ¥è§£ç å›¾åƒæ–‡ä»¶ã€‚å®ƒæ”¯æŒè®¸å¤šå›¾åƒæ‰©å±•æ ¼å¼ï¼Œä¾‹å¦‚jpgå’Œpngï¼Œè¿˜æ”¯æŒå…¶ä»–æ ¼å¼ã€‚æ‚¨å¯ä»¥æŸ¥çœ‹æ”¯æŒçš„å›¾åƒæ‰©å±•æ ¼å¼çš„å®Œæ•´åˆ—è¡¨</li>
<li>AudioFolderä½¿ç”¨Audioç‰¹å¾æ¥è§£ç éŸ³é¢‘æ–‡ä»¶ã€‚å®ƒæ”¯æŒéŸ³é¢‘æ‰©å±•æ ¼å¼ï¼Œå¦‚wavå’Œmp3ï¼Œæ‚¨å¯ä»¥æŸ¥çœ‹æ”¯æŒçš„éŸ³é¢‘æ‰©å±•æ ¼å¼çš„å®Œæ•´åˆ—è¡¨</li>
</ul>
<p>ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨çš„å›¾åƒæ•°æ®é›†(å¯¹äºéŸ³é¢‘æ•°æ®é›†ä¹Ÿæ˜¯ä¸€æ ·)å­˜å‚¨å¦‚ä¸‹æ‰€ç¤ºï¼š</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">pokemon/train/grass/bulbasaur.png</span><br><span class="line">pokemon/train/fire/charmander.png</span><br><span class="line">pokemon/train/water/squirtle.png</span><br><span class="line"></span><br><span class="line">pokemon/test/grass/ivysaur.png</span><br><span class="line">pokemon/test/fire/charmeleon.png</span><br><span class="line">pokemon/test/water/wartortle.png</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> ImageFolder</span><br><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> AudioFolder</span><br><span class="line"></span><br><span class="line">dataset = load_dataset(<span class="string">&quot;imagefolder&quot;</span>, data_dir=<span class="string">&quot;/path/to/pokemon&quot;</span>)</span><br><span class="line">dataset = load_dataset(<span class="string">&quot;audiofolder&quot;</span>, data_dir=<span class="string">&quot;/path/to/folder&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>æ•°æ®é›†ä¸­å¯ä»¥åŒ…å«æœ‰å…³æ•°æ®é›†çš„å…¶ä»–ä¿¡æ¯ï¼Œä¾‹å¦‚æ–‡æœ¬æ ‡é¢˜æˆ–è½¬å½•ï¼Œå¯ä»¥ä½¿ç”¨åŒ…å«åœ¨æ•°æ®é›†æ–‡ä»¶å¤¹ä¸­çš„metadata.csvæ–‡ä»¶æ¥è¿›è¡Œå­˜å‚¨</p>
<p>metadataæ–‡ä»¶éœ€è¦æœ‰ä¸€ä¸ªfile_nameåˆ—ï¼Œå°†å›¾åƒæˆ–éŸ³é¢‘æ–‡ä»¶ä¸å…¶ç›¸åº”çš„å…ƒæ•°æ®è¿›è¡Œå…³è”</p>
<figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">file_name, text</span><br><span class="line">bulbasaur.png, There is a plant seed on its back right from the day this PokÃ©mon is born.</span><br><span class="line">charmander.png, It has a preference for hot things.</span><br><span class="line">squirtle.png, When it retracts its long neck into its shell, it squirts out water with vigorous force.</span><br></pre></td></tr></table></figure>
<p>To learn more about each of these folder-based builders, check out the and <a target="_blank" rel="noopener external nofollow noreferrer" href="https://huggingface.co/docs/datasets/image_dataset#imagefolder">ImageFolder</a> or <a target="_blank" rel="noopener external nofollow noreferrer" href="https://huggingface.co/docs/datasets/audio_dataset#audiofolder">AudioFolder</a> guides.</p>
<blockquote>
<p>åŸºäºæ–‡ä»¶çš„æ„å»ºå™¨</p>
</blockquote>
<p>ä½¿ç”¨ from_generator() æ–¹æ³•æ˜¯ä»ç”Ÿæˆå™¨åˆ›å»ºæ•°æ®é›†çš„æœ€èŠ‚çœå†…å­˜çš„æ–¹å¼ï¼Œè¿™æ˜¯ç”±äºç”Ÿæˆå™¨çš„è¿­ä»£è¡Œä¸ºã€‚è¿™åœ¨å¤„ç†éå¸¸å¤§çš„æ•°æ®é›†æ—¶ç‰¹åˆ«æœ‰ç”¨ï¼Œå› ä¸ºæ•°æ®é›†æ˜¯é€æ­¥åœ¨ç£ç›˜ä¸Šç”Ÿæˆçš„ï¼Œç„¶åè¿›è¡Œå†…å­˜æ˜ å°„ï¼Œè¿™æ ·å¯ä»¥é¿å…å°†æ•´ä¸ªæ•°æ®é›†åŠ è½½åˆ°å†…å­˜ä¸­</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gen</span>():</span><br><span class="line">    <span class="keyword">yield</span> &#123;<span class="string">&quot;pokemon&quot;</span>: <span class="string">&quot;bulbasaur&quot;</span>, <span class="string">&quot;type&quot;</span>: <span class="string">&quot;grass&quot;</span>&#125;</span><br><span class="line">    <span class="keyword">yield</span> &#123;<span class="string">&quot;pokemon&quot;</span>: <span class="string">&quot;squirtle&quot;</span>, <span class="string">&quot;type&quot;</span>: <span class="string">&quot;water&quot;</span>&#125;</span><br><span class="line">ds = Dataset.from_generator(gen)</span><br><span class="line">ds[<span class="number">0</span>]</span><br><span class="line">&#123;<span class="string">&quot;pokemon&quot;</span>: <span class="string">&quot;bulbasaur&quot;</span>, <span class="string">&quot;type&quot;</span>: <span class="string">&quot;grass&quot;</span>&#125;</span><br></pre></td></tr></table></figure>
<p>åŸºäºç”Ÿæˆå™¨çš„IterableDatasetéœ€è¦ä½¿ç”¨forå¾ªç¯è¿›è¡Œè¿­ä»£ï¼Œä¾‹å¦‚ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> IterableDataset</span><br><span class="line">ds = IterableDataset.from_generator(gen)</span><br><span class="line"><span class="keyword">for</span> example <span class="keyword">in</span> ds:</span><br><span class="line">    <span class="built_in">print</span>(example)</span><br><span class="line">    </span><br><span class="line">&#123;<span class="string">&quot;pokemon&quot;</span>: <span class="string">&quot;bulbasaur&quot;</span>, <span class="string">&quot;type&quot;</span>: <span class="string">&quot;grass&quot;</span>&#125;</span><br><span class="line">&#123;<span class="string">&quot;pokemon&quot;</span>: <span class="string">&quot;squirtle&quot;</span>, <span class="string">&quot;type&quot;</span>: <span class="string">&quot;water&quot;</span>&#125;</span><br></pre></td></tr></table></figure>
<p>ä½¿ç”¨from_dict()æ–¹æ³•æ˜¯ä»å­—å…¸åˆ›å»ºæ•°æ®é›†çš„ç®€å•ç›´æ¥çš„æ–¹å¼ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> Dataset</span><br><span class="line">ds = Dataset.from_dict(&#123;<span class="string">&quot;pokemon&quot;</span>: [<span class="string">&quot;bulbasaur&quot;</span>, <span class="string">&quot;squirtle&quot;</span>], <span class="string">&quot;type&quot;</span>: [<span class="string">&quot;grass&quot;</span>, <span class="string">&quot;water&quot;</span>]&#125;)</span><br><span class="line">ds[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">&#123;<span class="string">&quot;pokemon&quot;</span>: <span class="string">&quot;bulbasaur&quot;</span>, <span class="string">&quot;type&quot;</span>: <span class="string">&quot;grass&quot;</span>&#125;</span><br></pre></td></tr></table></figure>
<h2 id="åˆ†äº«æ•°æ®é›†"><a href="#åˆ†äº«æ•°æ®é›†" class="headerlink" title="åˆ†äº«æ•°æ®é›†"></a>åˆ†äº«æ•°æ®é›†</h2><p>ç‚¹å‡»æ‚¨çš„ä¸ªäººèµ„æ–™å¹¶é€‰æ‹©æ–°çš„æ•°æ®é›†ä»¥åˆ›å»ºä¸€ä¸ªæ–°çš„æ•°æ®é›†ä»“åº“ã€‚ ä¸ºæ‚¨çš„æ•°æ®é›†é€‰æ‹©ä¸€ä¸ªåç§°ï¼Œå¹¶é€‰æ‹©å®ƒæ˜¯ä¸€ä¸ªå…¬å…±æ•°æ®é›†è¿˜æ˜¯ç§æœ‰æ•°æ®é›†ã€‚å…¬å…±æ•°æ®é›†å¯¹ä»»ä½•äººå¯è§ï¼Œè€Œç§æœ‰æ•°æ®é›†åªèƒ½ç”±æ‚¨æˆ–æ‚¨ç»„ç»‡çš„æˆå‘˜æŸ¥çœ‹</p>
<p>ä¸€æ—¦æ‚¨çš„æ•°æ®é›†å­˜å‚¨åœ¨Hubä¸Šï¼Œä»»ä½•äººéƒ½å¯ä»¥ä½¿ç”¨load_dataset()å‡½æ•°åŠ è½½å®ƒï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"></span><br><span class="line">dataset = load_dataset(<span class="string">&quot;stevhliu/demo&quot;</span>)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>ä½¿ç”¨Pythonè¿›è¡Œä¸Šä¼ </p>
</blockquote>
<p>å–œæ¬¢ä»¥ç¼–ç¨‹æ–¹å¼ä¸Šä¼ æ•°æ®é›†çš„ç”¨æˆ·å¯ä»¥ä½¿ç”¨huggingface_hubåº“ã€‚è¯¥åº“å…è®¸ç”¨æˆ·ä»Pythonä¸­ä¸Hubè¿›è¡Œäº¤äº’</p>
<p>é¦–å…ˆå®‰è£…è¯¥åº“ï¼š</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install huggingface_hub</span><br></pre></td></tr></table></figure>
<p>è¦åœ¨Hubä¸Šä½¿ç”¨Pythonä¸Šä¼ æ•°æ®é›†ï¼Œæ‚¨éœ€è¦ç™»å½•åˆ°æ‚¨çš„Hugging Faceè´¦æˆ·ï¼š</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">huggingface-cli login</span><br></pre></td></tr></table></figure>
<p>ä½¿ç”¨push_to_hub()å‡½æ•°å¸®åŠ©æ‚¨å°†æ–‡ä»¶æ·»åŠ ã€æäº¤å’Œæ¨é€åˆ°æ‚¨çš„ä»“åº“ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"></span><br><span class="line">dataset = load_dataset(<span class="string">&quot;stevhliu/demo&quot;</span>)</span><br><span class="line"><span class="comment"># dataset = dataset.map(...)  # åœ¨è¿™é‡Œè¿›è¡Œæ‰€æœ‰çš„æ•°æ®å¤„ç†</span></span><br><span class="line">dataset.push_to_hub(<span class="string">&quot;stevhliu/processed_demo&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>å¦‚æœè¦å°†æ•°æ®é›†è®¾ç½®ä¸ºç§æœ‰ï¼Œè¯·å°†privateå‚æ•°è®¾ç½®ä¸ºTrueã€‚è¯¥å‚æ•°ä»…åœ¨é¦–æ¬¡åˆ›å»ºä»“åº“æ—¶æœ‰æ•ˆ</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataset.push_to_hub(<span class="string">&quot;stevhliu/private_processed_demo&quot;</span>, private=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<h1 id="è¯„ä¼°æŒ‡æ ‡"><a href="#è¯„ä¼°æŒ‡æ ‡" class="headerlink" title="è¯„ä¼°æŒ‡æ ‡"></a>è¯„ä¼°æŒ‡æ ‡</h1><h2 id="å®‰è£…-2"><a href="#å®‰è£…-2" class="headerlink" title="å®‰è£…"></a>å®‰è£…</h2><p>ä¸€ç§ç”¨äºè½»æ¾è¯„ä¼°æœºå™¨å­¦ä¹ æ¨¡å‹å’Œæ•°æ®é›†çš„åº“</p>
<p>åªéœ€ä¸€è¡Œä»£ç ï¼Œæ‚¨å°±å¯ä»¥è®¿é—®æ•°åç§ä¸åŒé¢†åŸŸ(è‡ªç„¶è¯­è¨€å¤„ç†ã€è®¡ç®—æœºè§†è§‰ã€å¼ºåŒ–å­¦ä¹ ç­‰)çš„è¯„ä¼°æ–¹æ³•</p>
<p>æ— è®ºæ˜¯åœ¨æœ¬åœ°æœºå™¨ä¸Šè¿˜æ˜¯åœ¨åˆ†å¸ƒå¼è®­ç»ƒç¯å¢ƒä¸­ï¼Œæ‚¨éƒ½å¯ä»¥ä»¥ä¸€ç§ä¸€è‡´ä¸”å¯é‡å¤çš„æ–¹å¼è¯„ä¼°æ‚¨çš„æ¨¡å‹</p>
<blockquote>
<p>å®‰è£…</p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install evaluate</span><br></pre></td></tr></table></figure>
<blockquote>
<p>æµ‹è¯•</p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">python -c <span class="string">&quot;import evaluate; print(evaluate.load(&#x27;exact_match&#x27;).compute(references=[&#x27;hello&#x27;], predictions=[&#x27;hello&#x27;]))&quot;</span></span><br><span class="line"></span><br><span class="line">&#123;<span class="string">&#x27;exact_match&#x27;</span>: 1.0&#125;</span><br></pre></td></tr></table></figure>
<h2 id="å¿«é€Ÿå¼€å§‹-1"><a href="#å¿«é€Ÿå¼€å§‹-1" class="headerlink" title="å¿«é€Ÿå¼€å§‹"></a>å¿«é€Ÿå¼€å§‹</h2><h3 id="æŒ‡æ ‡ç§ç±»"><a href="#æŒ‡æ ‡ç§ç±»" class="headerlink" title="æŒ‡æ ‡ç§ç±»"></a>æŒ‡æ ‡ç§ç±»</h3><blockquote>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://huggingface.co/evaluate-metric">Evaluate Metricå¡ç‰‡å®ä¾‹</a></p>
</blockquote>
<p>ğŸ¤—Evaluateæä¾›äº†å¹¿æ³›çš„è¯„ä¼°å·¥å…·ã€‚å®ƒæ¶µç›–äº†æ–‡æœ¬ã€è®¡ç®—æœºè§†è§‰ã€éŸ³é¢‘ç­‰å¤šç§å½¢å¼ï¼Œå¹¶æä¾›äº†ç”¨äºè¯„ä¼°æ¨¡å‹æˆ–æ•°æ®é›†çš„å·¥å…·ã€‚è¿™äº›å·¥å…·åˆ†ä¸ºä¸‰ä¸ªç±»åˆ«</p>
<p>è¯„ä¼°ç±»å‹ å…¸å‹çš„æœºå™¨å­¦ä¹ æµç¨‹æ¶‰åŠåˆ°ä¸åŒæ–¹é¢çš„è¯„ä¼°ï¼Œå¯¹äºæ¯ä¸ªæ–¹é¢ï¼ŒğŸ¤— Evaluateéƒ½æä¾›äº†ç›¸åº”çš„å·¥å…·ï¼š</p>
<ul>
<li><strong>æŒ‡æ ‡(Metric)</strong>ï¼šç”¨äºè¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ï¼Œé€šå¸¸æ¶‰åŠæ¨¡å‹çš„é¢„æµ‹ç»“æœå’Œä¸€äº›çœŸå®æ ‡ç­¾ã€‚æ‚¨å¯ä»¥åœ¨evaluate-metricä¸­æ‰¾åˆ°æ‰€æœ‰é›†æˆçš„æŒ‡æ ‡</li>
<li><strong>æ¯”è¾ƒ(Comparison)</strong>ï¼šç”¨äºæ¯”è¾ƒä¸¤ä¸ªæ¨¡å‹ã€‚å¯ä»¥é€šè¿‡å°†å®ƒä»¬çš„é¢„æµ‹ç»“æœä¸çœŸå®æ ‡ç­¾è¿›è¡Œæ¯”è¾ƒå¹¶è®¡ç®—å®ƒä»¬çš„ä¸€è‡´æ€§æ¥è¿›è¡Œæ¯”è¾ƒã€‚æ‚¨å¯ä»¥åœ¨evaluate-comparisonä¸­æ‰¾åˆ°æ‰€æœ‰é›†æˆçš„æ¯”è¾ƒæ–¹æ³•</li>
<li><strong>æµ‹é‡(Measurement)</strong>ï¼šæ•°æ®é›†å’Œè®­ç»ƒåœ¨å…¶ä¸Šçš„æ¨¡å‹åŒæ ·é‡è¦ã€‚é€šè¿‡æµ‹é‡å¯ä»¥ç ”ç©¶æ•°æ®é›†çš„ç‰¹æ€§ã€‚æ‚¨å¯ä»¥åœ¨evaluate-measurementä¸­æ‰¾åˆ°æ‰€æœ‰é›†æˆçš„æµ‹é‡æ–¹æ³•</li>
</ul>
<p>æ¯ä¸ªè¯„ä¼°æ¨¡å—éƒ½ä½œä¸ºä¸€ä¸ªSpaceå­˜å‚¨åœ¨Hugging Face Hubä¸Šã€‚å®ƒä»¬æä¾›äº†ä¸€ä¸ªäº¤äº’å¼å°éƒ¨ä»¶å’Œä¸€ä¸ªæ–‡æ¡£å¡ç‰‡ï¼Œç”¨äºè®°å½•å…¶ä½¿ç”¨æ–¹æ³•å’Œé™åˆ¶</p>
<blockquote>
<p>è¯„ä¼°å·¥å…·ä¹‹é—´çš„å…³ç³»å’ŒåŒºåˆ«</p>
</blockquote>
<p>Evaluateåº“ä¸­çš„<code>Metric(æŒ‡æ ‡)</code>ã€<code>Comparison(æ¯”è¾ƒ)</code>å’Œ<code>Measurement(æµ‹é‡)</code>æ˜¯ä¸‰ç§ä¸åŒçš„è¯„ä¼°å·¥å…·ï¼Œç”¨äºè¯„ä¼°æœºå™¨å­¦ä¹ æ¨¡å‹å’Œæ•°æ®é›†ã€‚å®ƒä»¬ä¹‹é—´çš„å…³ç³»å’ŒåŒºåˆ«å¦‚ä¸‹ï¼š</p>
<ol>
<li>Metric(æŒ‡æ ‡)ï¼š<ul>
<li>ç”¨é€”ï¼š<strong>ç”¨äºè¯„ä¼°æ¨¡å‹çš„æ€§èƒ½</strong></li>
<li>å…·ä½“å«ä¹‰ï¼šæŒ‡æ ‡é€šè¿‡å°†æ¨¡å‹çš„é¢„æµ‹ç»“æœä¸çœŸå®æ ‡ç­¾è¿›è¡Œæ¯”è¾ƒæ¥è¡¡é‡æ¨¡å‹çš„è¡¨ç°</li>
<li>ç¤ºä¾‹ï¼šå‡†ç¡®ç‡ã€ç²¾ç¡®ç‡ã€å¬å›ç‡ã€F1åˆ†æ•°ç­‰</li>
<li>ç›®çš„ï¼šæä¾›äº†å¯¹æ¨¡å‹æ€§èƒ½çš„å®šé‡è¯„ä¼°ï¼Œå¸®åŠ©è¡¡é‡æ¨¡å‹åœ¨ç‰¹å®šä»»åŠ¡ä¸Šçš„è¡¨ç°</li>
</ul>
</li>
<li>Comparison(æ¯”è¾ƒ)ï¼š<ul>
<li>ç”¨é€”ï¼šç”¨äº<strong>æ¯”è¾ƒä¸¤ä¸ªæ¨¡å‹ä¹‹é—´çš„å·®å¼‚</strong></li>
<li>å…·ä½“å«ä¹‰ï¼šæ¯”è¾ƒå·¥å…·å°†ä¸¤ä¸ªæ¨¡å‹çš„é¢„æµ‹ç»“æœä¸çœŸå®æ ‡ç­¾è¿›è¡Œå¯¹æ¯”ï¼Œè®¡ç®—å®ƒä»¬ä¹‹é—´çš„ä¸€è‡´æ€§æˆ–å·®å¼‚ç¨‹åº¦</li>
<li>ç¤ºä¾‹ï¼šä¸€è‡´æ€§æŒ‡æ ‡ã€ç›¸å¯¹è¯¯å·®ç­‰</li>
<li>ç›®çš„ï¼šå¸®åŠ©è¯„ä¼°ä¸åŒæ¨¡å‹ä¹‹é—´çš„æ€§èƒ½å·®å¼‚ï¼Œæ‰¾åˆ°æ›´å¥½çš„æ¨¡å‹æˆ–è¿›è¡Œæ¨¡å‹é€‰æ‹©</li>
</ul>
</li>
<li>Measurement(æµ‹é‡)ï¼š<ul>
<li>ç”¨é€”ï¼šç”¨äº<strong>ç ”ç©¶æ•°æ®é›†çš„å±æ€§å’Œç‰¹æ€§</strong></li>
<li>å…·ä½“å«ä¹‰ï¼šæµ‹é‡å·¥å…·ç”¨äºå¯¹æ•°æ®é›†è¿›è¡Œåˆ†æï¼Œæ¢ç´¢æ•°æ®é›†çš„ç»“æ„ã€åˆ†å¸ƒã€åå·®ç­‰æ–¹é¢çš„ä¿¡æ¯</li>
<li>ç¤ºä¾‹ï¼šæ•°æ®é›†å¤§å°ã€æ ·æœ¬åˆ†å¸ƒã€ç±»åˆ«ä¸å¹³è¡¡åº¦ç­‰</li>
<li>ç›®çš„ï¼šæä¾›å¯¹æ•°æ®é›†çš„è¯¦ç»†äº†è§£ï¼Œå¸®åŠ©äº†è§£æ•°æ®é›†çš„ç‰¹ç‚¹å’Œæ½œåœ¨é—®é¢˜</li>
</ul>
</li>
</ol>
<p>è¿™ä¸‰ç§è¯„ä¼°å·¥å…·åœ¨Evaluateåº“ä¸­å„è‡ªç‹¬ç«‹ï¼Œç”¨äºä¸åŒçš„è¯„ä¼°ç›®çš„ã€‚Metricç”¨äºè¡¡é‡æ¨¡å‹æ€§èƒ½ï¼ŒComparisonç”¨äºæ¯”è¾ƒä¸åŒæ¨¡å‹ä¹‹é—´çš„æ€§èƒ½å·®å¼‚ï¼ŒMeasurementç”¨äºç ”ç©¶å’Œäº†è§£æ•°æ®é›†çš„ç‰¹æ€§ã€‚é€šè¿‡ä½¿ç”¨è¿™äº›å·¥å…·ï¼Œå¯ä»¥å…¨é¢è¯„ä¼°å’Œç†è§£æœºå™¨å­¦ä¹ æ¨¡å‹å’Œæ•°æ®é›†çš„è¡¨ç°å’Œç‰¹ç‚¹</p>
<h3 id="æŒ‡æ ‡åŠ è½½"><a href="#æŒ‡æ ‡åŠ è½½" class="headerlink" title="æŒ‡æ ‡åŠ è½½"></a>æŒ‡æ ‡åŠ è½½</h3><blockquote>
<p>å®˜æ–¹+ç¤¾åŒº æŒ‡æ ‡</p>
</blockquote>
<p>åœ¨ä½¿ç”¨Hugging Faceçš„Evaluateåº“åŠ è½½è¯„ä¼°å·¥å…·æ—¶ï¼Œå¯ä»¥é€šè¿‡æ˜¾å¼æŒ‡å®šè¯„ä¼°çš„ç±»å‹æ¥ç¡®ä¿åŠ è½½æ­£ç¡®çš„å·¥å…·ã€‚è¿™å¯ä»¥é˜²æ­¢åç§°å†²çªæˆ–æ··æ·†ï¼Œç¡®ä¿æ‚¨ä½¿ç”¨çš„æ˜¯æœŸæœ›çš„è¯„ä¼°å·¥å…·</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> evaluate</span><br><span class="line"></span><br><span class="line">accuracy = evaluate.load(<span class="string">&quot;accuracy&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># æ˜¾å¼æŒ‡å®šè¯„ä¼°çš„ç±»å‹</span></span><br><span class="line">word_length = evaluate.load(<span class="string">&quot;word_length&quot;</span>, module_type=<span class="string">&quot;measurement&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ç¤¾åŒºæŒ‡æ ‡</span></span><br><span class="line">element_count = evaluate.load(<span class="string">&quot;lvwerra/element_count&quot;</span>, module_type=<span class="string">&quot;measurement&quot;</span>)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>æŸ¥çœ‹å¯ç”¨çš„æ¨¡å—æ–¹æ³•</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">evaluate.list_evaluation_modules(</span><br><span class="line">  module_type=<span class="string">&quot;comparison&quot;</span>,</span><br><span class="line">  include_community=<span class="literal">False</span>,</span><br><span class="line">  with_details=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">[&#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;mcnemar&#x27;</span>, <span class="string">&#x27;type&#x27;</span>: <span class="string">&#x27;comparison&#x27;</span>, <span class="string">&#x27;community&#x27;</span>: <span class="literal">False</span>, <span class="string">&#x27;likes&#x27;</span>: <span class="number">1</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;exact_match&#x27;</span>, <span class="string">&#x27;type&#x27;</span>: <span class="string">&#x27;comparison&#x27;</span>, <span class="string">&#x27;community&#x27;</span>: <span class="literal">False</span>, <span class="string">&#x27;likes&#x27;</span>: <span class="number">0</span>&#125;]</span><br></pre></td></tr></table></figure>
<h3 id="æŒ‡æ ‡è®¡ç®—"><a href="#æŒ‡æ ‡è®¡ç®—" class="headerlink" title="æŒ‡æ ‡è®¡ç®—"></a>æŒ‡æ ‡è®¡ç®—</h3><blockquote>
<p>è®¡ç®—æŒ‡æ ‡</p>
</blockquote>
<p>å½“æ¶‰åŠåˆ°è®¡ç®—å®é™…å¾—åˆ†æ—¶ï¼Œæœ‰ä¸¤ç§ä¸»è¦çš„æ–¹æ³•ï¼š</p>
<ul>
<li><p><strong>ä¸€ä½“å¼è®¡ç®—(All-in-one)</strong>ï¼šé€šè¿‡ä¸€æ¬¡æ€§å°†æ‰€æœ‰å¿…è¦çš„è¾“å…¥ä¼ é€’ç»™compute()æ–¹æ³•æ¥è®¡ç®—å¾—åˆ†</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">accuracy.compute(references=[<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>], predictions=[<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">&#123;<span class="string">&#x27;accuracy&#x27;</span>: <span class="number">0.5</span>&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>é€æ­¥è®¡ç®—(Incremental)</strong>ï¼šé€šè¿‡ä½¿ç”¨EvaluationModule.add()æˆ–EvaluationModule.add_batch()å°†å¿…è¦çš„è¾“å…¥é€æ­¥æ·»åŠ åˆ°æ¨¡å—ä¸­ï¼Œç„¶ååœ¨æœ€åä½¿ç”¨ EvaluationModule.compute()è®¡ç®—å¾—åˆ†</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># addçš„æ–¹å¼</span></span><br><span class="line"><span class="keyword">for</span> ref, pred <span class="keyword">in</span> <span class="built_in">zip</span>([<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>], [<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>]):</span><br><span class="line">    accuracy.add(references=ref, predictions=pred)</span><br><span class="line">accuracy.compute()</span><br><span class="line">&#123;<span class="string">&#x27;accuracy&#x27;</span>: <span class="number">0.5</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># add_batchçš„æ–¹å¼</span></span><br><span class="line"><span class="keyword">for</span> refs, preds <span class="keyword">in</span> <span class="built_in">zip</span>([[<span class="number">0</span>,<span class="number">1</span>],[<span class="number">0</span>,<span class="number">1</span>]], [[<span class="number">1</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">1</span>]]):</span><br><span class="line">    accuracy.add_batch(references=refs, predictions=preds)</span><br><span class="line">accuracy.compute()</span><br><span class="line">&#123;<span class="string">&#x27;accuracy&#x27;</span>: <span class="number">0.5</span>&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>åœ¨ä½ éœ€è¦ä»¥æ‰¹é‡æ–¹å¼ä»æ¨¡å‹ä¸­è·å–é¢„æµ‹ç»“æœæ—¶ç‰¹åˆ«æœ‰ç”¨ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> model_inputs, gold_standards <span class="keyword">in</span> evaluation_dataset:</span><br><span class="line">    predictions = model(model_inputs)</span><br><span class="line">    metric.add_batch(references=gold_standards, predictions=predictions)</span><br><span class="line">metric.compute()</span><br></pre></td></tr></table></figure>
<blockquote>
<p>åˆ†å¸ƒå¼æŒ‡æ ‡</p>
</blockquote>
<p>åœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸­è®¡ç®—æŒ‡æ ‡å¯èƒ½ä¼šæœ‰äº›æ£˜æ‰‹ã€‚æŒ‡æ ‡è¯„ä¼°æ˜¯åœ¨ä¸åŒçš„æ•°æ®å­é›†ä¸Šçš„å•ç‹¬Pythonè¿›ç¨‹æˆ–èŠ‚ç‚¹ä¸­æ‰§è¡Œçš„</p>
<p>é€šå¸¸æƒ…å†µä¸‹ï¼Œå½“ä¸€ä¸ªæŒ‡æ ‡å¾—åˆ†æ˜¯å¯åŠ çš„(<script type="math/tex">f(A \cup B) = f(A) + f(B)</script>)æ—¶ï¼Œä½ å¯ä»¥ä½¿ç”¨åˆ†å¸ƒå¼çš„reduceæ“ä½œæ¥æ”¶é›†æ¯ä¸ªæ•°æ®å­é›†çš„å¾—åˆ†ã€‚ä½†æ˜¯å½“æŒ‡æ ‡æ˜¯éå¯åŠ çš„(<script type="math/tex">f(A \cup B) \neq f(A) + f(B)</script>)æ—¶ï¼Œæƒ…å†µå°±ä¸é‚£ä¹ˆç®€å•äº†ã€‚ä¾‹å¦‚ï¼Œä½ ä¸èƒ½å°†æ¯ä¸ªæ•°æ®å­é›†çš„F1åˆ†æ•°ç›¸åŠ ä½œä¸ºæœ€ç»ˆçš„æŒ‡æ ‡</p>
<p><strong>å…‹æœè¿™ä¸ªé—®é¢˜çš„å¸¸è§æ–¹æ³•æ˜¯å›é€€åˆ°å•è¿›ç¨‹è¯„ä¼°ï¼Œä½†æŒ‡æ ‡åœ¨å•ä¸ªGPUä¸Šè¿›è¡Œè¯„ä¼°ï¼Œè¿™ä¼šå¯¼è‡´æ•ˆç‡é™ä½</strong></p>
<ol>
<li>ğŸ¤—Evaluateé€šè¿‡ä»…åœ¨ç¬¬ä¸€ä¸ªèŠ‚ç‚¹ä¸Šè®¡ç®—æœ€ç»ˆçš„æŒ‡æ ‡æ¥è§£å†³äº†è¿™ä¸ªé—®é¢˜</li>
<li><strong>é¢„æµ‹ç»“æœå’Œå‚è€ƒç»“æœè¢«åˆ†åˆ«è®¡ç®—å¹¶æä¾›ç»™æ¯ä¸ªèŠ‚ç‚¹çš„æŒ‡æ ‡</strong>ï¼Œè¿™äº›ç»“æœæš‚æ—¶å­˜å‚¨åœ¨Apache Arrowè¡¨ä¸­ï¼Œé¿å…äº†GPUæˆ–CPUå†…å­˜çš„æ··ä¹±</li>
<li>å½“ä½ å‡†å¤‡ä½¿ç”¨compute()è®¡ç®—æœ€ç»ˆæŒ‡æ ‡æ—¶ï¼Œç¬¬ä¸€ä¸ªèŠ‚ç‚¹èƒ½å¤Ÿè®¿é—®æ‰€æœ‰å…¶ä»–èŠ‚ç‚¹ä¸Šå­˜å‚¨çš„é¢„æµ‹ç»“æœå’Œå‚è€ƒç»“æœã€‚ä¸€æ—¦å®ƒæ”¶é›†åˆ°æ‰€æœ‰çš„é¢„æµ‹ç»“æœå’Œå‚è€ƒç»“æœï¼Œcompute()å°†è¿›è¡Œæœ€ç»ˆçš„æŒ‡æ ‡è¯„ä¼°</li>
</ol>
<p>è¿™ä¸ªè§£å†³æ–¹æ¡ˆä½¿å¾—ğŸ¤—Evaluateèƒ½å¤Ÿåœ¨åˆ†å¸ƒå¼è®¾ç½®ä¸­æ‰§è¡Œåˆ†å¸ƒå¼é¢„æµ‹ï¼Œè¿™å¯¹äºæé«˜è¯„ä¼°é€Ÿåº¦éå¸¸é‡è¦ã€‚åŒæ—¶ï¼Œä½ è¿˜å¯ä»¥ä½¿ç”¨å¤æ‚çš„éå¯åŠ æŒ‡æ ‡ï¼Œè€Œä¸æµªè´¹å®è´µçš„GPUæˆ–CPUå†…å­˜</p>
<blockquote>
<p>ç»„åˆè¯„ä¼°</p>
</blockquote>
<p>é€šå¸¸æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ä¸ä»…æƒ³è¯„ä¼°å•ä¸ªæŒ‡æ ‡ï¼Œè€Œæ˜¯æƒ³è¯„ä¼°ä¸€ç³»åˆ—ä¸åŒçš„æŒ‡æ ‡ï¼Œä»¥æ•æ‰æ¨¡å‹æ€§èƒ½çš„ä¸åŒæ–¹é¢</p>
<p>ä¾‹å¦‚ï¼Œå¯¹äºåˆ†ç±»é—®é¢˜ï¼Œé™¤äº†å‡†ç¡®åº¦å¤–ï¼Œé€šå¸¸è¿˜ä¼šè®¡ç®—F1åˆ†æ•°ã€å¬å›ç‡å’Œç²¾ç¡®åº¦ï¼Œä»¥ä¾¿æ›´å¥½åœ°äº†è§£æ¨¡å‹çš„æ€§èƒ½ã€‚å½“ç„¶ï¼Œä½ å¯ä»¥åŠ è½½ä¸€ç³»åˆ—æŒ‡æ ‡å¹¶ä¾æ¬¡è°ƒç”¨å®ƒä»¬ã€‚ç„¶è€Œï¼Œä¸€ç§æ›´æ–¹ä¾¿çš„æ–¹æ³•æ˜¯ä½¿ç”¨combine()å‡½æ•°å°†å®ƒä»¬æ†ç»‘åœ¨ä¸€èµ·ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">clf_metrics = evaluate.combine([<span class="string">&quot;accuracy&quot;</span>, <span class="string">&quot;f1&quot;</span>, <span class="string">&quot;precision&quot;</span>, <span class="string">&quot;recall&quot;</span>])</span><br><span class="line">clf_metrics.compute(predictions=[<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>], references=[<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">&#x27;accuracy&#x27;</span>: <span class="number">0.667</span>,</span><br><span class="line">  <span class="string">&#x27;f1&#x27;</span>: <span class="number">0.667</span>,</span><br><span class="line">  <span class="string">&#x27;precision&#x27;</span>: <span class="number">1.0</span>,</span><br><span class="line">  <span class="string">&#x27;recall&#x27;</span>: <span class="number">0.5</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>è‡ªåŠ¨åŒ–è¯„ä¼°</p>
</blockquote>
<p><strong>ä½¿ç”¨evaluate.evaluator()æä¾›äº†è‡ªåŠ¨åŒ–çš„è¯„ä¼°åŠŸèƒ½</strong>ï¼Œåªéœ€è¦ä¸€ä¸ªæ¨¡å‹ã€æ•°æ®é›†å’Œåº¦é‡æŒ‡æ ‡ï¼Œä¸EvaluationModulesä¸­çš„åº¦é‡æŒ‡æ ‡ç›¸æ¯”ï¼Œå®ƒä¸éœ€è¦æ¨¡å‹çš„é¢„æµ‹ç»“æœã€‚å› æ­¤ï¼Œä½¿ç”¨ç»™å®šçš„åº¦é‡æŒ‡æ ‡åœ¨æ•°æ®é›†ä¸Šè¯„ä¼°æ¨¡å‹æ›´å®¹æ˜“ï¼Œå› ä¸ºæ¨ç†è¿‡ç¨‹æ˜¯åœ¨å†…éƒ¨å¤„ç†çš„</p>
<p>ä¸ºäº†å®ç°è¿™ä¸€ç‚¹ï¼Œå®ƒä½¿ç”¨äº†transformersåº“ä¸­çš„pipelineæŠ½è±¡ã€‚ç„¶è€Œï¼Œåªè¦ç¬¦åˆpipelineæ¥å£ï¼Œä½ ä¹Ÿå¯ä»¥ä½¿ç”¨è‡ªå·±çš„æ¡†æ¶</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> pipeline</span><br><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"><span class="keyword">from</span> evaluate <span class="keyword">import</span> evaluator</span><br><span class="line"><span class="keyword">import</span> evaluate</span><br></pre></td></tr></table></figure>
<p>ä¸ºäº†ä½¿ç”¨evaluatorè¿›è¡Œè¯„ä¼°ï¼Œè®©æˆ‘ä»¬åŠ è½½ä¸€ä¸ªåŸºäºIMDbè®­ç»ƒçš„transformers pipelineï¼ˆä½†ä½ ä¹Ÿå¯ä»¥ä¼ é€’è‡ªå·±çš„è‡ªå®šä¹‰æ¨ç†ç±»æ¥é€‚åº”ä»»ä½•éµå¾ªpipelineè°ƒç”¨APIçš„æ¡†æ¶ï¼‰ï¼Œå¹¶ä½¿ç”¨IMDbçš„æµ‹è¯•é›†å’Œå‡†ç¡®åº¦åº¦é‡æŒ‡æ ‡è¿›è¡Œè¯„ä¼°</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">pipe = pipeline(<span class="string">&quot;text-classification&quot;</span>, model=<span class="string">&quot;lvwerra/distilbert-imdb&quot;</span>, device=<span class="number">0</span>)</span><br><span class="line">data = load_dataset(<span class="string">&quot;imdb&quot;</span>, split=<span class="string">&quot;test&quot;</span>).shuffle().select(<span class="built_in">range</span>(<span class="number">1000</span>))</span><br><span class="line">metric = evaluate.load(<span class="string">&quot;accuracy&quot;</span>)</span><br><span class="line"></span><br><span class="line">task_evaluator = evaluator(<span class="string">&quot;text-classification&quot;</span>)</span><br><span class="line">results = task_evaluator.compute(model_or_pipeline=pipe, data=data, metric=metric,</span><br><span class="line">                       label_mapping=&#123;<span class="string">&quot;NEGATIVE&quot;</span>: <span class="number">0</span>, <span class="string">&quot;POSITIVE&quot;</span>: <span class="number">1</span>&#125;,)</span><br><span class="line"></span><br><span class="line">&#123;<span class="string">&#x27;accuracy&#x27;</span>: <span class="number">0.934</span>&#125;</span><br></pre></td></tr></table></figure>
<p>ä»…ä»…è®¡ç®—åº¦é‡æŒ‡æ ‡çš„å€¼é€šå¸¸è¿˜ä¸è¶³ä»¥çŸ¥é“ä¸€ä¸ªæ¨¡å‹æ˜¯å¦æ˜¾è‘—ä¼˜äºå¦ä¸€ä¸ªæ¨¡å‹ã€‚é€šè¿‡ä½¿ç”¨<code>è‡ªåŠ©æ³•(bootstrapping)</code>ï¼Œevaluateè®¡ç®—ç½®ä¿¡åŒºé—´å’Œæ ‡å‡†è¯¯å·®ï¼Œè¿™æœ‰åŠ©äºä¼°è®¡åˆ†æ•°çš„ç¨³å®šæ€§</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">results = <span class="built_in">eval</span>.compute(model_or_pipeline=pipe, data=data, metric=metric,</span><br><span class="line">                       label_mapping=&#123;<span class="string">&quot;NEGATIVE&quot;</span>: <span class="number">0</span>, <span class="string">&quot;POSITIVE&quot;</span>: <span class="number">1</span>&#125;,</span><br><span class="line">                       strategy=<span class="string">&quot;bootstrap&quot;</span>, n_resamples=<span class="number">200</span>)</span><br><span class="line"></span><br><span class="line">&#123;<span class="string">&#x27;accuracy&#x27;</span>:</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="string">&#x27;confidence_interval&#x27;</span>: (<span class="number">0.906</span>, <span class="number">0.9406749892841922</span>),</span><br><span class="line">      <span class="string">&#x27;standard_error&#x27;</span>: <span class="number">0.00865213251082787</span>,</span><br><span class="line">      <span class="string">&#x27;score&#x27;</span>: <span class="number">0.923</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>è¯„ä¼°å™¨æœŸæœ›æ•°æ®è¾“å…¥å…·æœ‰â€textâ€å’Œâ€labelâ€åˆ—ã€‚å¦‚æœæ‚¨çš„æ•°æ®é›†ä¸åŒï¼Œå¯ä»¥ä½¿ç”¨å…³é”®å­—å‚æ•°input_column=â€textâ€å’Œlabel_column=â€labelâ€æ¥æä¾›åˆ—å</p>
<p>ç›®å‰åªæ”¯æŒâ€text-classificationâ€ä»»åŠ¡ï¼Œå°†æ¥å¯èƒ½ä¼šæ·»åŠ æ›´å¤šçš„ä»»åŠ¡ç±»å‹</p>
<h3 id="ç»“æœå­˜å‚¨"><a href="#ç»“æœå­˜å‚¨" class="headerlink" title="ç»“æœå­˜å‚¨"></a>ç»“æœå­˜å‚¨</h3><blockquote>
<p>è¯„ä¼°ç»“æœsaveå’Œpush</p>
</blockquote>
<p>ä¿å­˜å’Œåˆ†äº«è¯„ä¼°ç»“æœæ˜¯ä¸€ä¸ªé‡è¦çš„æ­¥éª¤ã€‚æˆ‘ä»¬æä¾›evaluate.save()å‡½æ•°æ¥æ–¹ä¾¿åœ°ä¿å­˜æŒ‡æ ‡ç»“æœã€‚ä½ å¯ä»¥ä¼ é€’ä¸€ä¸ªç‰¹å®šçš„æ–‡ä»¶åæˆ–ç›®å½•ã€‚åœ¨åä¸€ç§æƒ…å†µä¸‹ï¼Œç»“æœå°†ä¿å­˜åœ¨ä¸€ä¸ªå¸¦æœ‰è‡ªåŠ¨åˆ›å»ºçš„æ–‡ä»¶åçš„æ–‡ä»¶ä¸­</p>
<p>é™¤äº†ç›®å½•æˆ–æ–‡ä»¶åï¼Œè¯¥å‡½æ•°è¿˜æ¥å—ä»»æ„çš„é”®å€¼å¯¹ä½œä¸ºè¾“å…¥ï¼Œå¹¶å°†å®ƒä»¬å­˜å‚¨åœ¨ä¸€ä¸ªJSONæ–‡ä»¶ä¸­</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">result = accuracy.compute(references=[<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>], predictions=[<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">hyperparams = &#123;<span class="string">&quot;model&quot;</span>: <span class="string">&quot;bert-base-uncased&quot;</span>&#125;</span><br><span class="line">evaluate.save(<span class="string">&quot;./results/&quot;</span>, experiment=<span class="string">&quot;run 42&quot;</span>, **result, **hyperparams)</span><br><span class="line"></span><br><span class="line">PosixPath(<span class="string">&#x27;results/result-2022_05_30-22_09_11.json&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># result-2022_05_30-22_09_11.json</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">&quot;experiment&quot;</span>: <span class="string">&quot;run 42&quot;</span>,</span><br><span class="line">    <span class="string">&quot;accuracy&quot;</span>: <span class="number">0.5</span>,</span><br><span class="line">    <span class="string">&quot;model&quot;</span>: <span class="string">&quot;bert-base-uncased&quot;</span>,</span><br><span class="line">    <span class="string">&quot;_timestamp&quot;</span>: <span class="string">&quot;2022-05-30T22:09:11.959469&quot;</span>,</span><br><span class="line">    <span class="string">&quot;_git_commit_hash&quot;</span>: <span class="string">&quot;123456789abcdefghijkl&quot;</span>,</span><br><span class="line">    <span class="string">&quot;_evaluate_version&quot;</span>: <span class="string">&quot;0.1.0&quot;</span>,</span><br><span class="line">    <span class="string">&quot;_python_version&quot;</span>: <span class="string">&quot;3.9.12 (main, Mar 26 2022, 15:51:15) \n[Clang 13.1.6 (clang-1316.0.21.2)]&quot;</span>,</span><br><span class="line">    <span class="string">&quot;_interpreter_path&quot;</span>: <span class="string">&quot;/Users/leandro/git/evaluate/env/bin/python&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>é™¤äº†æŒ‡å®šçš„å­—æ®µï¼Œå®ƒè¿˜åŒ…å«æœ‰ç”¨çš„ç³»ç»Ÿä¿¡æ¯ï¼Œç”¨äºé‡ç°ç»“æœï¼Œä½ è¿˜åº”è¯¥å°†å®ƒä»¬æŠ¥å‘Šåˆ°æ¨¡å‹åœ¨Hubä¸Šçš„å­˜å‚¨åº“ä¸­</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">evaluate.push_to_hub(</span><br><span class="line">  model_id=<span class="string">&quot;huggingface/gpt2-wikitext2&quot;</span>,  <span class="comment"># model repository on hub</span></span><br><span class="line">  metric_value=<span class="number">0.5</span>,                       <span class="comment"># metric value</span></span><br><span class="line">  metric_type=<span class="string">&quot;bleu&quot;</span>,                     <span class="comment"># metric name, e.g. accuracy.name</span></span><br><span class="line">  metric_name=<span class="string">&quot;BLEU&quot;</span>,                     <span class="comment"># pretty name which is displayed</span></span><br><span class="line">  dataset_type=<span class="string">&quot;wikitext&quot;</span>,                <span class="comment"># dataset name on the hub</span></span><br><span class="line">  dataset_name=<span class="string">&quot;WikiText&quot;</span>,                <span class="comment"># pretty name</span></span><br><span class="line">  dataset_split=<span class="string">&quot;test&quot;</span>,                   <span class="comment"># dataset split used</span></span><br><span class="line">  task_type=<span class="string">&quot;text-generation&quot;</span>,            <span class="comment"># task id, see https://github.com/huggingface/datasets/blob/master/src/datasets/utils/resources/tasks.json</span></span><br><span class="line">  task_name=<span class="string">&quot;Text Generation&quot;</span>             <span class="comment"># pretty name for task</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>ä¸Šä¼ è‡ªå·±çš„æŒ‡æ ‡<a target="_blank" rel="noopener external nofollow noreferrer" href="https://huggingface.co/docs/evaluate/main/en/creating_and_sharing">Creating and sharing a new evaluation</a></p>
</blockquote>
<h3 id="å¯è§†åŒ–"><a href="#å¯è§†åŒ–" class="headerlink" title="å¯è§†åŒ–"></a>å¯è§†åŒ–</h3><p>å½“æ¯”è¾ƒå¤šä¸ªæ¨¡å‹æ—¶ï¼Œä»…é€šè¿‡æŸ¥çœ‹å®ƒä»¬çš„å¾—åˆ†å¾€å¾€å¾ˆéš¾å‘ç°å®ƒä»¬ä¹‹é—´çš„å·®å¼‚ã€‚è€Œä¸”é€šå¸¸æƒ…å†µä¸‹ï¼Œå¹¶æ²¡æœ‰ä¸€ä¸ªå•ä¸€çš„æœ€ä½³æ¨¡å‹ï¼Œè€Œæ˜¯åœ¨å‡†ç¡®æ€§å’Œå»¶è¿Ÿç­‰æ–¹é¢å­˜åœ¨ç€æƒè¡¡ï¼Œå› ä¸ºè¾ƒå¤§çš„æ¨¡å‹å¯èƒ½å…·æœ‰æ›´å¥½çš„æ€§èƒ½ä½†ä¹Ÿæ›´æ…¢ã€‚æˆ‘ä»¬æ­£åœ¨é€æ­¥æ·»åŠ ä¸åŒçš„å¯è§†åŒ–æ–¹æ³•ï¼Œä¾‹å¦‚ç»˜å›¾ï¼Œä»¥ä¾¿æ›´è½»æ¾åœ°é€‰æ‹©é€‚åˆç‰¹å®šç”¨ä¾‹çš„æœ€ä½³æ¨¡å‹ã€‚</p>
<p>ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨æœ‰å¤šä¸ªæ¨¡å‹çš„ç»“æœåˆ—è¡¨ï¼ˆä»¥å­—å…¸å½¢å¼ï¼‰ï¼Œæ‚¨å¯ä»¥å°†å®ƒä»¬ä¼ é€’ç»™radar_plot()å‡½æ•°è¿›è¡Œå¯è§†åŒ–ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> evaluate</span><br><span class="line"><span class="keyword">from</span> evaluate.visualization <span class="keyword">import</span> radar_plot</span><br><span class="line"></span><br><span class="line">data = [</span><br><span class="line">   &#123;<span class="string">&quot;accuracy&quot;</span>: <span class="number">0.99</span>, <span class="string">&quot;precision&quot;</span>: <span class="number">0.8</span>, <span class="string">&quot;f1&quot;</span>: <span class="number">0.95</span>, <span class="string">&quot;latency_in_seconds&quot;</span>: <span class="number">33.6</span>&#125;,</span><br><span class="line">   &#123;<span class="string">&quot;accuracy&quot;</span>: <span class="number">0.98</span>, <span class="string">&quot;precision&quot;</span>: <span class="number">0.87</span>, <span class="string">&quot;f1&quot;</span>: <span class="number">0.91</span>, <span class="string">&quot;latency_in_seconds&quot;</span>: <span class="number">11.2</span>&#125;,</span><br><span class="line">   &#123;<span class="string">&quot;accuracy&quot;</span>: <span class="number">0.98</span>, <span class="string">&quot;precision&quot;</span>: <span class="number">0.78</span>, <span class="string">&quot;f1&quot;</span>: <span class="number">0.88</span>, <span class="string">&quot;latency_in_seconds&quot;</span>: <span class="number">87.6</span>&#125;, </span><br><span class="line">   &#123;<span class="string">&quot;accuracy&quot;</span>: <span class="number">0.88</span>, <span class="string">&quot;precision&quot;</span>: <span class="number">0.78</span>, <span class="string">&quot;f1&quot;</span>: <span class="number">0.81</span>, <span class="string">&quot;latency_in_seconds&quot;</span>: <span class="number">101.6</span>&#125;</span><br><span class="line">   ]</span><br><span class="line">model_names = [<span class="string">&quot;Model 1&quot;</span>, <span class="string">&quot;Model 2&quot;</span>, <span class="string">&quot;Model 3&quot;</span>, <span class="string">&quot;Model 4&quot;</span>]</span><br><span class="line">plot = radar_plot(data=data, model_names=model_names)</span><br><span class="line">plot.show()</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i/hexo/bk_resources/deep_learning/huggingfaceåŸºæœ¬ä½¿ç”¨æ•™ç¨‹/æ¨¡å‹æ¯”è¾ƒæŒ‡æ ‡å›¾.webp" alt="æ¨¡å‹æ¯”è¾ƒæŒ‡æ ‡å›¾"></p>
<h3 id="é€‰æ‹©åˆé€‚æŒ‡æ ‡"><a href="#é€‰æ‹©åˆé€‚æŒ‡æ ‡" class="headerlink" title="é€‰æ‹©åˆé€‚æŒ‡æ ‡"></a>é€‰æ‹©åˆé€‚æŒ‡æ ‡</h3><p>è¯„ä¼°æŒ‡æ ‡å¯ä»¥åˆ†ä¸ºä¸‰ä¸ªé«˜çº§ç±»åˆ«ï¼š</p>
<ul>
<li><p><strong>é€šç”¨æŒ‡æ ‡</strong>ï¼šé€‚ç”¨äºå„ç§æƒ…å†µå’Œæ•°æ®é›†çš„æŒ‡æ ‡ï¼Œä¾‹å¦‚ç²¾ç¡®åº¦å’Œå‡†ç¡®åº¦</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">precision_metric = evaluate.load(<span class="string">&quot;precision&quot;</span>)</span><br><span class="line">results = precision_metric.compute(references=[<span class="number">0</span>, <span class="number">1</span>], predictions=[<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line"><span class="built_in">print</span>(results)</span><br><span class="line"></span><br><span class="line">&#123;<span class="string">&#x27;precision&#x27;</span>: <span class="number">1.0</span>&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>ä»»åŠ¡ç‰¹å®šæŒ‡æ ‡</strong>ï¼šä»…é€‚ç”¨äºç‰¹å®šä»»åŠ¡çš„æŒ‡æ ‡ï¼Œä¾‹å¦‚æœºå™¨ç¿»è¯‘(é€šå¸¸ä½¿ç”¨BLEUæˆ–ROUGEæŒ‡æ ‡è¿›è¡Œè¯„ä¼°)æˆ–å‘½åå®ä½“è¯†åˆ«(é€šå¸¸ä½¿ç”¨seqevalè¿›è¡Œè¯„ä¼°)</p>
</li>
<li><p><strong>æ•°æ®é›†ç‰¹å®šæŒ‡æ ‡</strong>ï¼šæ—¨åœ¨è¡¡é‡æ¨¡å‹åœ¨ç‰¹å®šåŸºå‡†æ•°æ®é›†ä¸Šçš„æ€§èƒ½ï¼Œä¾‹å¦‚GLUEåŸºå‡†æµ‹è¯•å…·æœ‰ä¸“é—¨çš„è¯„ä¼°æŒ‡æ ‡</p>
</li>
</ul>
<h1 id="transformers"><a href="#transformers" class="headerlink" title="transformers"></a>transformers</h1><h2 id="æ¦‚è¿°-1"><a href="#æ¦‚è¿°-1" class="headerlink" title="æ¦‚è¿°"></a>æ¦‚è¿°</h2><blockquote>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://huggingface.co/docs/transformers/v4.30.0/en/task_summary">What ğŸ¤— Transformers can do</a></p>
</blockquote>
<p>ğŸ¤— Transformersæä¾›äº†APIå’Œå·¥å…·ï¼Œå¯è½»æ¾ä¸‹è½½å’Œè®­ç»ƒæœ€å…ˆè¿›çš„é¢„è®­ç»ƒæ¨¡å‹ã€‚ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹å¯ä»¥å‡å°‘è®¡ç®—æˆæœ¬ã€ç¢³è¶³è¿¹ï¼Œå¹¶èŠ‚çœä»å¤´å¼€å§‹è®­ç»ƒæ¨¡å‹æ‰€éœ€çš„æ—¶é—´å’Œèµ„æºã€‚è¿™äº›æ¨¡å‹æ”¯æŒä¸åŒé¢†åŸŸçš„å¸¸è§ä»»åŠ¡ï¼ŒåŒ…æ‹¬ï¼š</p>
<ul>
<li>ğŸ“ è‡ªç„¶è¯­è¨€å¤„ç†ï¼šæ–‡æœ¬åˆ†ç±»ã€å‘½åå®ä½“è¯†åˆ«ã€é—®ç­”ç³»ç»Ÿã€è¯­è¨€å»ºæ¨¡ã€æ‘˜è¦ç”Ÿæˆã€ç¿»è¯‘ã€å¤šé¡¹é€‰æ‹©å’Œæ–‡æœ¬ç”Ÿæˆ</li>
<li>ğŸ–¼ï¸ è®¡ç®—æœºè§†è§‰ï¼šå›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹å’Œåˆ†å‰²</li>
<li>ğŸ—£ï¸ éŸ³é¢‘ï¼šè‡ªåŠ¨è¯­éŸ³è¯†åˆ«å’ŒéŸ³é¢‘åˆ†ç±»</li>
<li>ğŸ™ å¤šæ¨¡æ€ï¼šè¡¨æ ¼é—®ç­”ã€å…‰å­¦å­—ç¬¦è¯†åˆ«ã€ä»æ‰«ææ–‡æ¡£ä¸­æå–ä¿¡æ¯ã€è§†é¢‘åˆ†ç±»å’Œè§†è§‰é—®ç­”</li>
</ul>
<p>ğŸ¤— Transformersæ”¯æŒåœ¨PyTorchã€TensorFlowå’ŒJAXä¹‹é—´è¿›è¡Œæ¡†æ¶äº’æ“ä½œã€‚è¿™æä¾›äº†åœ¨æ¨¡å‹çš„ä¸åŒé˜¶æ®µä½¿ç”¨ä¸åŒæ¡†æ¶çš„çµæ´»æ€§ï¼›å¯ä»¥åœ¨ä¸€ä¸ªæ¡†æ¶ä¸­ç”¨ä¸‰è¡Œä»£ç è®­ç»ƒæ¨¡å‹ï¼Œç„¶ååœ¨å¦ä¸€ä¸ªæ¡†æ¶ä¸­åŠ è½½æ¨¡å‹è¿›è¡Œæ¨ç†ã€‚æ¨¡å‹è¿˜å¯ä»¥å¯¼å‡ºä¸ºONNXå’ŒTorchScriptç­‰æ ¼å¼ï¼Œä»¥ä¾¿åœ¨ç”Ÿäº§ç¯å¢ƒä¸­è¿›è¡Œéƒ¨ç½²</p>
<h2 id="å®‰è£…-3"><a href="#å®‰è£…-3" class="headerlink" title="å®‰è£…"></a>å®‰è£…</h2><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install transformers datasets</span><br></pre></td></tr></table></figure>
<h2 id="å¿«é€Ÿå¼€å§‹-2"><a href="#å¿«é€Ÿå¼€å§‹-2" class="headerlink" title="å¿«é€Ÿå¼€å§‹"></a>å¿«é€Ÿå¼€å§‹</h2><h3 id="Pipeline"><a href="#Pipeline" class="headerlink" title="Pipeline"></a>Pipeline</h3><p>pipeline()æ˜¯ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œæ¨ç†çš„æœ€ç®€å•å’Œæœ€å¿«æ·çš„æ–¹æ³•ã€‚æ‚¨å¯ä»¥ç›´æ¥ä½¿ç”¨pipeline()è¿›è¡Œè®¸å¤šä»»åŠ¡çš„æ¨ç†ï¼Œæ¶µç›–äº†ä¸åŒçš„æ¨¡æ€ï¼Œä¸‹è¡¨åˆ—å‡ºäº†å…¶ä¸­ä¸€äº›ä»»åŠ¡</p>
<div class="table-container">
<table>
<thead>
<tr>
<th><strong>Task</strong></th>
<th><strong>Description</strong></th>
<th><strong>Modality</strong></th>
<th><strong>Pipeline identifier</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>Text classification</td>
<td>assign a label to a given sequence of text</td>
<td>NLP</td>
<td>pipeline(task=â€œsentiment-analysisâ€)</td>
</tr>
<tr>
<td>Text generation</td>
<td>generate text given a prompt</td>
<td>NLP</td>
<td>pipeline(task=â€œtext-generationâ€)</td>
</tr>
<tr>
<td>Summarization</td>
<td>generate a summary of a sequence of text or document</td>
<td>NLP</td>
<td>pipeline(task=â€œsummarizationâ€)</td>
</tr>
<tr>
<td>Image classification</td>
<td>assign a label to an image</td>
<td>CV</td>
<td>pipeline(task=â€œimage-classificationâ€)</td>
</tr>
<tr>
<td>Image segmentation</td>
<td>assign a label to each individual pixel of an image (supports semantic, panoptic, and instance segmentation)</td>
<td>CV</td>
<td>pipeline(task=â€œimage-segmentationâ€)</td>
</tr>
<tr>
<td>Object detection</td>
<td>predict the bounding boxes and classes of objects in an image</td>
<td>CV</td>
<td>pipeline(task=â€œobject-detectionâ€)</td>
</tr>
<tr>
<td>Audio classification</td>
<td>assign a label to some audio data</td>
<td>Audio</td>
<td>pipeline(task=â€œaudio-classificationâ€)</td>
</tr>
<tr>
<td>Automatic speech recognition</td>
<td>transcribe speech into text</td>
<td>Audio</td>
<td>pipeline(task=â€œautomatic-speech-recognitionâ€)</td>
</tr>
<tr>
<td>Visual question answering</td>
<td>answer a question about the image, given an image and a question</td>
<td>Multimodal</td>
<td>pipeline(task=â€œvqaâ€)</td>
</tr>
<tr>
<td>Document question answering</td>
<td>answer a question about a document, given an image and a question</td>
<td>Multimodal</td>
<td>pipeline(task=â€œdocument-question-answeringâ€)</td>
</tr>
<tr>
<td>Image captioning</td>
<td>generate a caption for a given image</td>
<td>Multimodal</td>
<td>pipeline(task=â€œimage-to-textâ€)</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p>åŸºæœ¬ä½¿ç”¨</p>
</blockquote>
<p>é¦–å…ˆï¼Œé€šè¿‡åˆ›å»ºpipeline()çš„å®ä¾‹å¹¶æŒ‡å®šè¦ä½¿ç”¨çš„ä»»åŠ¡ï¼Œå¼€å§‹ä½¿ç”¨å®ƒã€‚åœ¨æœ¬æŒ‡å—ä¸­ï¼Œæˆ‘ä»¬ä»¥æƒ…æ„Ÿåˆ†æçš„pipeline()ä¸ºä¾‹ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> pipeline</span><br><span class="line"></span><br><span class="line">classifier = pipeline(<span class="string">&quot;sentiment-analysis&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>pipeline()ä¼šä¸‹è½½å¹¶ç¼“å­˜ç”¨äºæƒ…æ„Ÿåˆ†æçš„é»˜è®¤é¢„è®­ç»ƒæ¨¡å‹å’Œåˆ†è¯å™¨ã€‚ç°åœ¨ï¼Œæ‚¨å¯ä»¥åœ¨ç›®æ ‡æ–‡æœ¬ä¸Šä½¿ç”¨åˆ†ç±»å™¨äº†ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">classifier(<span class="string">&quot;We are very happy to show you the ğŸ¤— Transformers library.&quot;</span>)</span><br><span class="line"></span><br><span class="line">[&#123;<span class="string">&#x27;label&#x27;</span>: <span class="string">&#x27;POSITIVE&#x27;</span>, <span class="string">&#x27;score&#x27;</span>: <span class="number">0.9998</span>&#125;]</span><br></pre></td></tr></table></figure>
<p>å¦‚æœæ‚¨æœ‰å¤šä¸ªè¾“å…¥ï¼Œè¯·å°†è¾“å…¥ä½œä¸ºåˆ—è¡¨ä¼ é€’ç»™pipeline()ï¼Œä»¥è¿”å›ä¸€ä¸ªå­—å…¸åˆ—è¡¨</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">results = classifier([<span class="string">&quot;We are very happy to show you the ğŸ¤— Transformers library.&quot;</span>, <span class="string">&quot;We hope you don&#x27;t hate it.&quot;</span>])</span><br><span class="line"><span class="keyword">for</span> result <span class="keyword">in</span> results:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;label: <span class="subst">&#123;result[<span class="string">&#x27;label&#x27;</span>]&#125;</span>, with score: <span class="subst">&#123;<span class="built_in">round</span>(result[<span class="string">&#x27;score&#x27;</span>], <span class="number">4</span>)&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">label: POSITIVE, <span class="keyword">with</span> score: <span class="number">0.9998</span></span><br><span class="line">label: NEGATIVE, <span class="keyword">with</span> score: <span class="number">0.5309</span></span><br></pre></td></tr></table></figure>
<p>pipeline()è¿˜å¯ä»¥å¯¹ä»»ä½•æ‚¨å–œæ¬¢çš„ä»»åŠ¡è¿­ä»£æ•´ä¸ªæ•°æ®é›†ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œè®©æˆ‘ä»¬é€‰æ‹©è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ä½œä¸ºæˆ‘ä»¬çš„ä»»åŠ¡</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> pipeline</span><br><span class="line"></span><br><span class="line">speech_recognizer = pipeline(<span class="string">&quot;automatic-speech-recognition&quot;</span>, model=<span class="string">&quot;facebook/wav2vec2-base-960h&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>åŠ è½½æ‚¨æƒ³è¦è¿­ä»£çš„éŸ³é¢‘æ•°æ®é›†(æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…ğŸ¤— Datasetså¿«é€Ÿå…¥é—¨)ã€‚ä¾‹å¦‚ï¼ŒåŠ è½½MInDS-14æ•°æ®é›†ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset, Audio</span><br><span class="line"></span><br><span class="line">dataset = load_dataset(<span class="string">&quot;PolyAI/minds14&quot;</span>, name=<span class="string">&quot;en-US&quot;</span>, split=<span class="string">&quot;train&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>æ‚¨éœ€è¦ç¡®ä¿æ•°æ®é›†çš„é‡‡æ ·ç‡ä¸facebook/wav2vec2-base-960h è®­ç»ƒæ—¶ä½¿ç”¨çš„é‡‡æ ·ç‡ç›¸åŒ¹é…</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataset = dataset.cast_column(<span class="string">&quot;audio&quot;</span>, Audio(sampling_rate=speech_recognizer.feature_extractor.sampling_rate))</span><br></pre></td></tr></table></figure>
<p>è°ƒç”¨â€audioâ€åˆ—æ—¶ï¼ŒéŸ³é¢‘æ–‡ä»¶ä¼šè‡ªåŠ¨åŠ è½½å’Œé‡æ–°é‡‡æ ·ã€‚ä»å‰å››ä¸ªæ ·æœ¬ä¸­æå–åŸå§‹æ³¢å½¢æ•°ç»„ï¼Œå¹¶å°†å…¶ä½œä¸ºåˆ—è¡¨ä¼ é€’ç»™pipelineï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">result = speech_recognizer(dataset[:<span class="number">4</span>][<span class="string">&quot;audio&quot;</span>])</span><br><span class="line"><span class="built_in">print</span>([d[<span class="string">&quot;text&quot;</span>] <span class="keyword">for</span> d <span class="keyword">in</span> result])</span><br><span class="line"></span><br><span class="line">[<span class="string">&#x27;I WOULD LIKE TO SET UP A JOINT ACCOUNT WITH MY PARTNER HOW DO I PROCEED WITH DOING THAT&#x27;</span>, <span class="string">&quot;FONDERING HOW I&#x27;D SET UP A JOIN TO HELL T WITH MY WIFE AND WHERE THE AP MIGHT BE&quot;</span>, <span class="string">&quot;I I&#x27;D LIKE TOY SET UP A JOINT ACCOUNT WITH MY PARTNER I&#x27;M NOT SEEING THE OPTION TO DO IT ON THE APSO I CALLED IN TO GET SOME HELP CAN I JUST DO IT OVER THE PHONE WITH YOU AND GIVE YOU THE INFORMATION OR SHOULD I DO IT IN THE AP AN I&#x27;M MISSING SOMETHING UQUETTE HAD PREFERRED TO JUST DO IT OVER THE PHONE OF POSSIBLE THINGS&quot;</span>, <span class="string">&#x27;HOW DO I FURN A JOINA COUT&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p>å¯¹äºè¾“å…¥è¾ƒå¤§çš„æ›´å¤§æ•°æ®é›†(å¦‚è¯­éŸ³æˆ–è§†è§‰æ•°æ®)ï¼Œæ‚¨å¯ä»¥å°†ç”Ÿæˆå™¨ä¼ é€’ç»™pipelineï¼Œè€Œä¸æ˜¯å°†å…¶ä½œä¸ºåˆ—è¡¨åŠ è½½åˆ°å†…å­˜ä¸­</p>
<p>åœ¨pipelineä¸­ä½¿ç”¨å…¶ä»–æ¨¡å‹å’Œåˆ†è¯å™¨pipeline()å¯ä»¥é€‚åº”Hubä¸­çš„ä»»ä½•æ¨¡å‹ï¼Œè¿™ä½¿å¾—å¯¹pipeline()è¿›è¡Œå…¶ä»–ç”¨é€”çš„è°ƒæ•´å˜å¾—å®¹æ˜“</p>
<p>ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨æƒ³è¦ä¸€ä¸ªèƒ½å¤Ÿå¤„ç†æ³•è¯­æ–‡æœ¬çš„æ¨¡å‹ï¼Œè¯·ä½¿ç”¨Hubä¸Šçš„æ ‡ç­¾æ¥è¿‡æ»¤åˆé€‚çš„æ¨¡å‹ã€‚é€šè¿‡å¯¹è¿‡æ»¤ç»“æœè¿›è¡Œæ’åºï¼Œæ‚¨å¯ä»¥è·å¾—ä¸€ä¸ªé’ˆå¯¹æ³•è¯­æ–‡æœ¬è¿›è¡Œæƒ…æ„Ÿåˆ†æçš„å¤šè¯­è¨€BERTæ¨¡å‹</p>
<blockquote>
<p>åœ¨pipelineä¸­ä½¿ç”¨å¦ä¸€ä¸ªæ¨¡å‹å’Œåˆ†è¯å™¨</p>
</blockquote>
<p>pipeline()å¯ä»¥é€‚åº”Hubä¸­çš„ä»»ä½•æ¨¡å‹ï¼Œè¿™ä½¿å¾—å°†pipeline()é€‚åº”å…¶ä»–ç”¨ä¾‹å˜å¾—å®¹æ˜“</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer, AutoModelForSequenceClassification</span><br><span class="line"></span><br><span class="line">model_name = <span class="string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span></span><br><span class="line">model = AutoModelForSequenceClassification.from_pretrained(model_name)</span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(model_name)</span><br><span class="line"></span><br><span class="line">classifier = pipeline(<span class="string">&quot;sentiment-analysis&quot;</span>, model=model, tokenizer=tokenizer)</span><br><span class="line">classifier(<span class="string">&quot;Nous sommes trÃ¨s heureux de vous prÃ©senter la bibliothÃ¨que ğŸ¤— Transformers.&quot;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="AutoClass"><a href="#AutoClass" class="headerlink" title="AutoClass"></a>AutoClass</h3><p>AutoClassæ˜¯ä¸€ç§å¿«æ·æ–¹å¼ï¼Œå®ƒå¯ä»¥æ ¹æ®æ¨¡å‹çš„åç§°æˆ–è·¯å¾„è‡ªåŠ¨è·å–é¢„è®­ç»ƒæ¨¡å‹çš„æ¶æ„ã€‚æ‚¨åªéœ€è¦é€‰æ‹©ä¸æ‚¨çš„ä»»åŠ¡ç›¸åŒ¹é…çš„AutoClasså’Œç›¸åº”çš„é¢„å¤„ç†ç±»</p>
<h4 id="AutoTokenizer"><a href="#AutoTokenizer" class="headerlink" title="AutoTokenizer"></a>AutoTokenizer</h4><p>AutoTokenizeråˆ†è¯å™¨è´Ÿè´£å°†æ–‡æœ¬é¢„å¤„ç†ä¸ºæ¨¡å‹è¾“å…¥çš„æ•°å­—æ•°ç»„ã€‚æœ‰å¤šä¸ªè§„åˆ™æ¥è§„å®šåˆ†è¯çš„è¿‡ç¨‹ï¼ŒåŒ…æ‹¬å¦‚ä½•æ‹†åˆ†ä¸€ä¸ªå•è¯ä»¥åŠä»¥ä½•ç§çº§åˆ«æ‹†åˆ†å•è¯</p>
<p>æœ€é‡è¦çš„æ˜¯ï¼Œæ‚¨<strong>éœ€è¦ä½¿ç”¨ç›¸åŒçš„æ¨¡å‹åç§°æ¥å®ä¾‹åŒ–ä¸€ä¸ªåˆ†è¯å™¨ï¼Œä»¥ç¡®ä¿æ‚¨ä½¿ç”¨äº†ä¸é¢„è®­ç»ƒæ¨¡å‹ç›¸åŒçš„åˆ†è¯è§„åˆ™</strong></p>
<blockquote>
<p>ä½¿ç”¨AutoTokenizeråŠ è½½ä¸€ä¸ªåˆ†è¯å™¨</p>
</blockquote>
<p>å°†<code>return_tensors</code>å‚æ•°è®¾ç½®ä¸º<code>pt</code>ä»¥è¿”å›é€‚ç”¨äºPyTorchçš„å¼ é‡ï¼Œæˆ–è€…è®¾ç½®ä¸º<code>tf</code>ä»¥è¿”å›é€‚ç”¨äºTensorFlowçš„å¼ é‡</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer</span><br><span class="line"></span><br><span class="line">model_name = <span class="string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(model_name)</span><br><span class="line">encoding = tokenizer(<span class="string">&quot;We are very happy to show you the ğŸ¤— Transformers library.&quot;</span>, return_tensors=<span class="string">&quot;pt&quot;</span>)</span><br><span class="line"></span><br><span class="line">&#123;<span class="string">&#x27;input_ids&#x27;</span>: [<span class="number">101</span>, <span class="number">11312</span>, <span class="number">10320</span>, <span class="number">12495</span>, <span class="number">19308</span>, <span class="number">10114</span>, <span class="number">11391</span>, <span class="number">10855</span>, <span class="number">10103</span>, <span class="number">100</span>, <span class="number">58263</span>, <span class="number">13299</span>, <span class="number">119</span>, <span class="number">102</span>],</span><br><span class="line"> <span class="string">&#x27;token_type_ids&#x27;</span>: [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line"> <span class="string">&#x27;attention_mask&#x27;</span>: [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]&#125;</span><br><span class="line"></span><br><span class="line">tokenizer.decode(encoding[<span class="string">&quot;input_ids&quot;</span>])</span><br><span class="line"><span class="string">&quot;We are very happy to show you the ğŸ¤— Transformers library.&quot;</span></span><br></pre></td></tr></table></figure>
<p>åˆ†è¯å™¨è¿”å›ä¸€ä¸ªåŒ…å«ä¸‰ä¸ªé¡¹ç›®çš„å­—å…¸ï¼š</p>
<ul>
<li><strong>input_ids</strong>ï¼šè¡¨ç¤ºæ–‡æœ¬ä¸­å„ä¸ªæ ‡è®°çš„æ•°å­—</li>
<li><strong>token_type_ids</strong>ï¼šå¦‚æœæœ‰å¤šä¸ªåºåˆ—ï¼ŒæŒ‡ç¤ºä¸€ä¸ªæ ‡è®°å±äºå“ªä¸ªåºåˆ—</li>
<li><strong>attention_mask</strong>ï¼šæŒ‡ç¤ºä¸€ä¸ªæ ‡è®°æ˜¯å¦åº”è¯¥è¢«æ©ç›–(masked)</li>
</ul>
<p>åˆ†è¯å™¨è¿˜å¯ä»¥æ¥å—ä¸€ä¸ªè¾“å…¥åˆ—è¡¨ï¼Œå¹¶å¯¹æ–‡æœ¬è¿›è¡Œå¡«å……å’Œæˆªæ–­ï¼Œä»¥è¿”å›å…·æœ‰ç»Ÿä¸€é•¿åº¦çš„æ‰¹å¤„ç†æ•°æ®</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">pt_batch = tokenizer(</span><br><span class="line">    [<span class="string">&quot;We are very happy to show you the ğŸ¤— Transformers library.&quot;</span>, <span class="string">&quot;We hope you don&#x27;t hate it.&quot;</span>],</span><br><span class="line">    padding=<span class="literal">True</span>,</span><br><span class="line">    truncation=<span class="literal">True</span>,</span><br><span class="line">    max_length=<span class="number">512</span>,</span><br><span class="line">    return_tensors=<span class="string">&quot;pt&quot;</span>)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>pad + truncation</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># padding</span></span><br><span class="line">batch_sentences = [</span><br><span class="line">    <span class="string">&quot;But what about second breakfast?&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Don&#x27;t think he knows about second breakfast, Pip.&quot;</span>,</span><br><span class="line">    <span class="string">&quot;What about elevensies?&quot;</span>,</span><br><span class="line">]</span><br><span class="line">encoded_input = tokenizer(batch_sentences, padding=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">&#123;<span class="string">&#x27;input_ids&#x27;</span>: [[<span class="number">101</span>, <span class="number">1252</span>, <span class="number">1184</span>, <span class="number">1164</span>, <span class="number">1248</span>, <span class="number">6462</span>, <span class="number">136</span>, <span class="number">102</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>], </span><br><span class="line">               [<span class="number">101</span>, <span class="number">1790</span>, <span class="number">112</span>, <span class="number">189</span>, <span class="number">1341</span>, <span class="number">1119</span>, <span class="number">3520</span>, <span class="number">1164</span>, <span class="number">1248</span>, <span class="number">6462</span>, <span class="number">117</span>, <span class="number">21902</span>, <span class="number">1643</span>, <span class="number">119</span>, <span class="number">102</span>], </span><br><span class="line">               [<span class="number">101</span>, <span class="number">1327</span>, <span class="number">1164</span>, <span class="number">5450</span>, <span class="number">23434</span>, <span class="number">136</span>, <span class="number">102</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]], </span><br><span class="line"> <span class="string">&#x27;token_type_ids&#x27;</span>: [[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>], </span><br><span class="line">                    [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>], </span><br><span class="line">                    [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]], </span><br><span class="line"> <span class="string">&#x27;attention_mask&#x27;</span>: [[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>], </span><br><span class="line">                    [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], </span><br><span class="line">                    [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]]&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># truncation  å°†truncationå‚æ•°è®¾ç½®ä¸ºTrueï¼Œå¯ä»¥å°†åºåˆ—æˆªæ–­ä¸ºæ¨¡å‹æ‰€èƒ½æ¥å—çš„æœ€å¤§é•¿åº¦</span></span><br><span class="line">batch_sentences = [</span><br><span class="line">    <span class="string">&quot;But what about second breakfast?&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Don&#x27;t think he knows about second breakfast, Pip.&quot;</span>,</span><br><span class="line">    <span class="string">&quot;What about elevensies?&quot;</span>,</span><br><span class="line">]</span><br><span class="line">encoded_input = tokenizer(batch_sentences, padding=<span class="literal">True</span>, truncation=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">&#123;<span class="string">&#x27;input_ids&#x27;</span>: [[<span class="number">101</span>, <span class="number">1252</span>, <span class="number">1184</span>, <span class="number">1164</span>, <span class="number">1248</span>, <span class="number">6462</span>, <span class="number">136</span>, <span class="number">102</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>], </span><br><span class="line">               [<span class="number">101</span>, <span class="number">1790</span>, <span class="number">112</span>, <span class="number">189</span>, <span class="number">1341</span>, <span class="number">1119</span>, <span class="number">3520</span>, <span class="number">1164</span>, <span class="number">1248</span>, <span class="number">6462</span>, <span class="number">117</span>, <span class="number">21902</span>, <span class="number">1643</span>, <span class="number">119</span>, <span class="number">102</span>], </span><br><span class="line">               [<span class="number">101</span>, <span class="number">1327</span>, <span class="number">1164</span>, <span class="number">5450</span>, <span class="number">23434</span>, <span class="number">136</span>, <span class="number">102</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]], </span><br><span class="line"> <span class="string">&#x27;token_type_ids&#x27;</span>: [[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>], </span><br><span class="line">                    [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>], </span><br><span class="line">                    [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]], </span><br><span class="line"> <span class="string">&#x27;attention_mask&#x27;</span>: [[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>], </span><br><span class="line">                    [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], </span><br><span class="line">                    [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]]&#125;</span><br></pre></td></tr></table></figure>
<h4 id="AutoModel"><a href="#AutoModel" class="headerlink" title="AutoModel"></a>AutoModel</h4><p>ğŸ¤—Transformersæä¾›äº†ä¸€ç§ç®€å•è€Œç»Ÿä¸€çš„æ–¹æ³•æ¥åŠ è½½é¢„è®­ç»ƒæ¨¡å‹å®ä¾‹ã€‚è¿™æ„å‘³ç€æ‚¨å¯ä»¥åƒåŠ è½½AutoTokenizerä¸€æ ·åŠ è½½AutoModel</p>
<p>å”¯ä¸€çš„åŒºåˆ«æ˜¯<strong>é€‰æ‹©æ­£ç¡®çš„AutoModelæ¥é€‚åº”ä»»åŠ¡</strong>ã€‚å¯¹äºæ–‡æœ¬(æˆ–åºåˆ—)åˆ†ç±»ï¼Œæ‚¨åº”è¯¥åŠ è½½AutoModelForSequenceClassification</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForSequenceClassification</span><br><span class="line"></span><br><span class="line">model_name = <span class="string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span></span><br><span class="line">pt_model = AutoModelForSequenceClassification.from_pretrained(model_name)</span><br><span class="line"></span><br><span class="line">pt_outputs = pt_model(**pt_batch)</span><br></pre></td></tr></table></figure>
<p>æ¨¡å‹å°†æœ€ç»ˆçš„æ¿€æ´»å€¼å­˜å‚¨åœ¨logitså±æ€§ä¸­ã€‚åº”ç”¨softmaxå‡½æ•°åˆ°logitsä¸Šä»¥è·å–æ¦‚ç‡å€¼</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line">pt_predictions = nn.functional.softmax(pt_outputs.logits, dim=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">tensor([[<span class="number">0.0021</span>, <span class="number">0.0018</span>, <span class="number">0.0115</span>, <span class="number">0.2121</span>, <span class="number">0.7725</span>],</span><br><span class="line">        [<span class="number">0.2084</span>, <span class="number">0.1826</span>, <span class="number">0.1969</span>, <span class="number">0.1755</span>, <span class="number">0.2365</span>]], grad_fn=&lt;SoftmaxBackward0&gt;)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>åœ¨huggingfaceåº“ä¸­ï¼ŒAutoModelç±»å¯ä»¥æ ¹æ®ç»™å®šçš„checkpointè‡ªåŠ¨é€‰æ‹©å¹¶åŠ è½½é€‚åˆçš„æ¨¡å‹ã€‚å®ƒæ”¯æŒå„ç§ä¸åŒçš„æ¨¡å‹æ¶æ„ï¼ŒåŒ…æ‹¬ï¼š</p>
</blockquote>
<ul>
<li>AutoModel: ç”¨äºé€šç”¨çš„æ¨¡å‹åŠ è½½ï¼Œæ ¹æ®checkpointè‡ªåŠ¨é€‰æ‹©é€‚åˆçš„æ¨¡å‹æ¶æ„</li>
<li>AutoModelForSequenceClassification: ç”¨äºåºåˆ—åˆ†ç±»ä»»åŠ¡çš„æ¨¡å‹ï¼Œå¦‚æ–‡æœ¬åˆ†ç±»</li>
<li>AutoModelForQuestionAnswering: ç”¨äºé—®ç­”ä»»åŠ¡çš„æ¨¡å‹ï¼Œå¦‚é˜…è¯»ç†è§£</li>
<li>AutoModelForTokenClassification: ç”¨äºæ ‡è®°åˆ†ç±»ä»»åŠ¡çš„æ¨¡å‹ï¼Œå¦‚å‘½åå®ä½“è¯†åˆ«</li>
<li>AutoModelForMaskedLM: ç”¨äºé®è”½è¯­è¨€å»ºæ¨¡ä»»åŠ¡çš„æ¨¡å‹ï¼Œå¦‚BERT</li>
<li>AutoModelForCausalLM: ç”¨äºæœ‰å› æœå…³ç³»çš„è¯­è¨€å»ºæ¨¡ä»»åŠ¡çš„æ¨¡å‹ï¼Œå¦‚GPT</li>
<li>AutoModelForImageClassification: ç”¨äºå›¾åƒåˆ†ç±»ä»»åŠ¡çš„æ¨¡å‹ï¼Œå¦‚ResNet</li>
<li>AutoModelForImageSegmentation: ç”¨äºå›¾åƒåˆ†å‰²ä»»åŠ¡çš„æ¨¡å‹ï¼Œå¦‚Mask R-CNN</li>
</ul>
<p>è¿™äº›ä»…æ˜¯AutoModelç±»çš„ä¸€äº›ç¤ºä¾‹ï¼Œå®é™…ä¸Šè¿˜æœ‰æ›´å¤šå¯ç”¨çš„æ¨¡å‹æ¶æ„ã€‚æ‚¨å¯ä»¥æ ¹æ®å…·ä½“çš„ä»»åŠ¡éœ€æ±‚é€‰æ‹©é€‚åˆçš„AutoModelç±»è¿›è¡ŒåŠ è½½å’Œä½¿ç”¨</p>
<h4 id="å…¶ä»–çš„Autoç±»"><a href="#å…¶ä»–çš„Autoç±»" class="headerlink" title="å…¶ä»–çš„Autoç±»"></a>å…¶ä»–çš„Autoç±»</h4><blockquote>
<p>AutoImageProcessor</p>
</blockquote>
<p>å¯¹äºè§†è§‰ä»»åŠ¡ï¼Œå›¾åƒå¤„ç†å™¨å°†å›¾åƒå¤„ç†ä¸ºæ­£ç¡®çš„è¾“å…¥æ ¼å¼</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoImageProcessor</span><br><span class="line"></span><br><span class="line">image_processor = AutoImageProcessor.from_pretrained(<span class="string">&quot;google/vit-base-patch16-224&quot;</span>)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>AutoFeatureExtractor</p>
</blockquote>
<p>å¯¹äºéŸ³é¢‘ä»»åŠ¡ï¼Œç‰¹å¾æå–å™¨å°†éŸ³é¢‘ä¿¡å·å¤„ç†ä¸ºæ­£ç¡®çš„è¾“å…¥æ ¼å¼</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoFeatureExtractor</span><br><span class="line"></span><br><span class="line">feature_extractor = AutoFeatureExtractor.from_pretrained(</span><br><span class="line">    <span class="string">&quot;ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition&quot;</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>AutoProcessor</p>
</blockquote>
<p>å¤šæ¨¡æ€ä»»åŠ¡éœ€è¦ä¸€ä¸ªå¤„ç†å™¨æ¥ç»“åˆä¸¤ç§ç±»å‹çš„é¢„å¤„ç†å·¥å…·ã€‚ä¾‹å¦‚ï¼ŒLayoutLMV2æ¨¡å‹éœ€è¦ä¸€ä¸ªå›¾åƒå¤„ç†å™¨æ¥å¤„ç†å›¾åƒï¼Œè¿˜éœ€è¦ä¸€ä¸ªåˆ†è¯å™¨æ¥å¤„ç†æ–‡æœ¬ï¼›å¤„ç†å™¨å°†ä¸¤è€…ç»“åˆèµ·æ¥</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoProcessor</span><br><span class="line"></span><br><span class="line">processor = AutoProcessor.from_pretrained(<span class="string">&quot;microsoft/layoutlmv2-base-uncased&quot;</span>)</span><br></pre></td></tr></table></figure>
<h4 id="æ¨¡å‹ä¿å­˜"><a href="#æ¨¡å‹ä¿å­˜" class="headerlink" title="æ¨¡å‹ä¿å­˜"></a>æ¨¡å‹ä¿å­˜</h4><p>ä¸€æ—¦æ‚¨çš„æ¨¡å‹ç»è¿‡å¾®è°ƒï¼Œæ‚¨å¯ä»¥ä½¿ç”¨PreTrainedModel.save_pretrained()å°†å…¶ä¸å…¶æ ‡è®°å™¨ä¸€èµ·ä¿å­˜èµ·æ¥ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># æ¨¡å‹+åˆ†è¯å™¨ ä¿å­˜</span></span><br><span class="line">pt_save_directory = <span class="string">&quot;./pt_save_pretrained&quot;</span></span><br><span class="line">tokenizer.save_pretrained(pt_save_directory)</span><br><span class="line">pt_model.save_pretrained(pt_save_directory)</span><br><span class="line"></span><br><span class="line"><span class="comment"># åŠ è½½</span></span><br><span class="line">pt_model = AutoModelForSequenceClassification.from_pretrained(pt_save_directory)</span><br></pre></td></tr></table></figure>
<h3 id="AutoConfig"><a href="#AutoConfig" class="headerlink" title="AutoConfig"></a>AutoConfig</h3><p>æ‚¨å¯ä»¥ä¿®æ”¹æ¨¡å‹çš„<strong>é…ç½®ç±»</strong>æ¥æ›´æ”¹æ¨¡å‹çš„æ„å»ºæ–¹å¼ã€‚é…ç½®ç±»æŒ‡å®šäº†æ¨¡å‹çš„å±æ€§ï¼Œä¾‹å¦‚éšè—å±‚çš„æ•°é‡æˆ–æ³¨æ„åŠ›å¤´æ•°</p>
<p>å½“æ‚¨ä»è‡ªå®šä¹‰é…ç½®ç±»åˆå§‹åŒ–æ¨¡å‹æ—¶ï¼Œæ‚¨å°†ä»å¤´å¼€å§‹ã€‚æ¨¡å‹çš„å±æ€§å°†è¢«éšæœºåˆå§‹åŒ–ï¼Œæ‚¨éœ€è¦åœ¨ä½¿ç”¨æ¨¡å‹ä¹‹å‰å¯¹å…¶è¿›è¡Œè®­ç»ƒä»¥è·å¾—æœ‰æ„ä¹‰çš„ç»“æœ</p>
<p>é¦–å…ˆå¯¼å…¥AutoConfigï¼Œç„¶ååŠ è½½è¦ä¿®æ”¹çš„é¢„è®­ç»ƒæ¨¡å‹ã€‚åœ¨AutoConfig.from_pretrained()ä¸­ï¼Œæ‚¨å¯ä»¥æŒ‡å®šè¦æ›´æ”¹çš„å±æ€§ï¼Œä¾‹å¦‚æ³¨æ„åŠ›å¤´çš„æ•°é‡ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoConfig</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModel</span><br><span class="line"></span><br><span class="line">my_config = AutoConfig.from_pretrained(<span class="string">&quot;distilbert-base-uncased&quot;</span>, n_heads=<span class="number">12</span>)</span><br><span class="line">my_model = AutoModel.from_config(my_config)</span><br></pre></td></tr></table></figure>
<h3 id="Trainer"><a href="#Trainer" class="headerlink" title="Trainer"></a>Trainer</h3><p>å¯¹äºPyTorchï¼Œæ‰€æœ‰æ¨¡å‹éƒ½æ˜¯æ ‡å‡†çš„torch.nn.Moduleï¼Œå› æ­¤æ‚¨å¯ä»¥åœ¨ä»»ä½•å…¸å‹çš„è®­ç»ƒå¾ªç¯ä¸­ä½¿ç”¨å®ƒä»¬ã€‚è™½ç„¶æ‚¨å¯ä»¥ç¼–å†™è‡ªå·±çš„è®­ç»ƒå¾ªç¯ï¼Œä½†ğŸ¤—Transformersæä¾›äº†<code>Trainer</code>ç±»ï¼Œå…¶ä¸­åŒ…å«åŸºæœ¬çš„è®­ç»ƒå¾ªç¯ï¼Œå¹¶æ·»åŠ äº†å…¶ä»–åŠŸèƒ½ï¼Œå¦‚åˆ†å¸ƒå¼è®­ç»ƒã€æ··åˆç²¾åº¦ç­‰</p>
<p>æ ¹æ®æ‚¨çš„ä»»åŠ¡ï¼Œé€šå¸¸ä¼šå‘Trainerä¼ é€’ä»¥ä¸‹å‚æ•°ï¼š</p>
<ol>
<li><p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://huggingface.co/docs/transformers/v4.30.0/en/main_classes/model#transformers.PreTrainedModel">PreTrainedModel</a>æˆ–<a target="_blank" rel="noopener external nofollow noreferrer" href="https://pytorch.org/docs/stable/nn.html#torch.nn.Module"><code>torch.nn.Module</code></a>å¯¹è±¡</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForSequenceClassification</span><br><span class="line"></span><br><span class="line">model = AutoModelForSequenceClassification.from_pretrained(<span class="string">&quot;distilbert-base-uncased&quot;</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>TrainingArguments</strong>åŒ…å«äº†å¯ä»¥ä¿®æ”¹çš„æ¨¡å‹è¶…å‚æ•°ï¼Œæ¯”å¦‚å­¦ä¹ ç‡ã€æ‰¹å¤§å°å’Œè®­ç»ƒçš„è½®æ•°ã€‚å¦‚æœä½ ä¸æŒ‡å®šä»»ä½•è®­ç»ƒå‚æ•°ï¼Œå°†ä½¿ç”¨é»˜è®¤å€¼</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> TrainingArguments</span><br><span class="line"></span><br><span class="line">training_args = TrainingArguments(</span><br><span class="line">    output_dir=<span class="string">&quot;path/to/save/folder/&quot;</span>,</span><br><span class="line">    learning_rate=<span class="number">2e-5</span>,</span><br><span class="line">    per_device_train_batch_size=<span class="number">8</span>,</span><br><span class="line">    per_device_eval_batch_size=<span class="number">8</span>,</span><br><span class="line">    num_train_epochs=<span class="number">2</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>Preprocessing</strong>ç±»ï¼Œä¾‹å¦‚tokenizer(æ ‡è®°å™¨)ã€image processor(å›¾åƒå¤„ç†å™¨)ã€feature extractor(ç‰¹å¾æå–å™¨)æˆ–processor(å¤„ç†å™¨)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer</span><br><span class="line"></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(<span class="string">&quot;distilbert-base-uncased&quot;</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>åŠ è½½æ•°æ®é›†</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"></span><br><span class="line">dataset = load_dataset(<span class="string">&quot;rotten_tomatoes&quot;</span>)  <span class="comment"># doctest: +IGNORE_RESULT</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>åˆ›å»ºä¸€ä¸ªå‡½æ•°æ¥å¯¹æ•°æ®é›†è¿›è¡Œ<strong>æ ‡è®°åŒ–</strong>å¤„ç†ï¼Œç„¶åä½¿ç”¨<code>map</code>å‡½æ•°å°†å…¶åº”ç”¨äºæ•´ä¸ªæ•°æ®é›†</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">tokenize_dataset</span>(<span class="params">dataset</span>):</span><br><span class="line">    <span class="keyword">return</span> tokenizer(dataset[<span class="string">&quot;text&quot;</span>])</span><br><span class="line"></span><br><span class="line">dataset = dataset.<span class="built_in">map</span>(tokenize_dataset, batched=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>ä½¿ç”¨<code>DataCollatorWithPadding</code>æ¥ä»æ•°æ®é›†ä¸­åˆ›å»ºä¸€ä¸ªæ‰¹æ¬¡çš„ç¤ºä¾‹</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> DataCollatorWithPadding</span><br><span class="line"></span><br><span class="line">data_collator = DataCollatorWithPadding(tokenizer=tokenizer)</span><br></pre></td></tr></table></figure>
<p><code>DataCollatorWithPadding</code>æ˜¯Hugging Faceçš„<code>transformers</code>åº“ä¸­çš„ä¸€ä¸ªç±»ï¼Œç”¨äºåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åˆ›å»ºæ‰¹æ¬¡æ•°æ®ã€‚å®ƒçš„ä½œç”¨æ˜¯å°†ä¸åŒé•¿åº¦çš„æ ·æœ¬å¡«å……åˆ°ç›¸åŒé•¿åº¦ï¼Œä»¥ä¾¿èƒ½å¤ŸåŒæ—¶è¿›è¡Œæ‰¹å¤„ç†</p>
<p>å…·ä½“æ¥è¯´ï¼Œ<code>DataCollatorWithPadding</code>ä¼šæ ¹æ®ç»™å®šçš„æ•°æ®é›†ï¼Œæ‰¾åˆ°å…¶ä¸­æœ€é•¿çš„æ ·æœ¬ï¼Œå¹¶å°†å…¶ä»–æ ·æœ¬å¡«å……åˆ°ç›¸åŒçš„é•¿åº¦ã€‚å¡«å……é€šå¸¸ä½¿ç”¨ç‰¹å®šçš„å¡«å……ä»¤ç‰Œ(token)æ¥å®Œæˆï¼Œè¿™æ ·æ¨¡å‹åœ¨å¤„ç†æ—¶å¯ä»¥è¯†åˆ«å‡ºå¡«å……éƒ¨åˆ†ï¼Œå¹¶è¿›è¡Œç›¸åº”çš„å¤„ç†</p>
<p>ä½¿ç”¨<code>DataCollatorWithPadding</code>å¯ä»¥ç¡®ä¿æ‰¹æ¬¡æ•°æ®çš„é•¿åº¦ä¸€è‡´ï¼Œä»è€Œæé«˜è®­ç»ƒæ•ˆç‡ï¼Œå¹¶é¿å…ç”±äºä¸åŒé•¿åº¦æ ·æœ¬å¯¼è‡´çš„é”™è¯¯</p>
</li>
</ol>
<p>ç°åœ¨å°†æ‰€æœ‰è¿™äº›ç±»ç»„åˆåœ¨Trainerä¸­</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> Trainer</span><br><span class="line"></span><br><span class="line">trainer = Trainer(</span><br><span class="line">    model=model,</span><br><span class="line">    args=training_args,</span><br><span class="line">    train_dataset=dataset[<span class="string">&quot;train&quot;</span>],</span><br><span class="line">    eval_dataset=dataset[<span class="string">&quot;test&quot;</span>],</span><br><span class="line">    tokenizer=tokenizer,</span><br><span class="line">    data_collator=data_collator,</span><br><span class="line">)  <span class="comment"># doctest: +SKIP</span></span><br><span class="line"></span><br><span class="line">trainer.train()</span><br></pre></td></tr></table></figure>
<p>Trainerç±»æä¾›äº†è‡ªå®šä¹‰è®­ç»ƒå¾ªç¯è¡Œä¸ºçš„æ–¹æ³•ï¼Œä½ å¯ä»¥é€šè¿‡ç»§æ‰¿Trainerç±»å¹¶é‡å†™å…¶ä¸­çš„æ–¹æ³•æ¥å®ç°è‡ªå®šä¹‰è¡Œä¸ºã€‚è¿™æ ·ä½ å°±å¯ä»¥å®šåˆ¶è¯¸å¦‚æŸå¤±å‡½æ•°ã€ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡è°ƒåº¦å™¨ç­‰åŠŸèƒ½ã€‚ä½ å¯ä»¥å‚è€ƒTrainerç±»çš„æ–‡æ¡£äº†è§£å¯ä»¥é‡å†™çš„æ–¹æ³•</p>
<p>å¦ä¸€ç§å®šåˆ¶è®­ç»ƒå¾ªç¯çš„æ–¹å¼æ˜¯ä½¿ç”¨å›è°ƒå‡½æ•°(Callbacks)ã€‚ä½ å¯ä»¥ä½¿ç”¨å›è°ƒå‡½æ•°ä¸å…¶ä»–åº“è¿›è¡Œé›†æˆï¼Œç›‘è§†è®­ç»ƒè¿‡ç¨‹å¹¶æŠ¥å‘Šè¿›å±•ï¼Œæˆ–åœ¨å¿…è¦æ—¶æå‰åœæ­¢è®­ç»ƒã€‚å›è°ƒå‡½æ•°ä¸ä¼šä¿®æ”¹è®­ç»ƒå¾ªç¯æœ¬èº«çš„è¡Œä¸ºã€‚å¦‚æœä½ éœ€è¦å®šåˆ¶æŸå¤±å‡½æ•°ç­‰å†…å®¹ï¼Œä½ éœ€è¦ç»§æ‰¿Trainerç±»æ¥å®ç°</p>
<h1 id="æ•™ç¨‹"><a href="#æ•™ç¨‹" class="headerlink" title="æ•™ç¨‹"></a>æ•™ç¨‹</h1><h2 id="æ¨¡å‹è®­ç»ƒ"><a href="#æ¨¡å‹è®­ç»ƒ" class="headerlink" title="æ¨¡å‹è®­ç»ƒ"></a>æ¨¡å‹è®­ç»ƒ</h2><p>ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹æœ‰å¾ˆå¤šå¥½å¤„ã€‚å®ƒå¯ä»¥å‡å°‘è®¡ç®—æˆæœ¬å’Œç¢³è¶³è¿¹ï¼Œå¹¶ä¸”å¯ä»¥è®©æ‚¨ä½¿ç”¨æœ€å…ˆè¿›çš„æ¨¡å‹ï¼Œè€Œæ— éœ€ä»å¤´å¼€å§‹è®­ç»ƒ</p>
<p>ğŸ¤—Transformersæä¾›äº†å¯¹å„ç§ä»»åŠ¡çš„æ•°åƒä¸ªé¢„è®­ç»ƒæ¨¡å‹çš„è®¿é—®ã€‚å½“æ‚¨ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹æ—¶ï¼Œæ‚¨å¯ä»¥åœ¨ç‰¹å®šäºæ‚¨ä»»åŠ¡çš„æ•°æ®é›†ä¸Šè¿›è¡Œå¾®è°ƒè®­ç»ƒã€‚è¿™è¢«ç§°ä¸º<code>å¾®è°ƒ</code>ï¼Œæ˜¯ä¸€ç§éå¸¸å¼ºå¤§çš„è®­ç»ƒæŠ€æœ¯</p>
<blockquote>
<p>æ•°æ®å‡†å¤‡</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. åŠ è½½æ•°æ®é›†</span></span><br><span class="line">dataset = load_dataset(<span class="string">&quot;yelp_review_full&quot;</span>)</span><br><span class="line">dataset[<span class="string">&quot;train&quot;</span>][<span class="number">100</span>]</span><br><span class="line">&#123;<span class="string">&#x27;label&#x27;</span>: <span class="number">0</span>,</span><br><span class="line"> <span class="string">&#x27;text&#x27;</span>: <span class="string">&#x27;My expectations for McDonalds are t rarely high. But for one to still fail so spectacularly...that takes something special!\\nThe cashier took my friends\&#x27;s order, then promptly ignored me. I had to force myself in front of a cashier who opened his register to wait on the person BEHIND me. I waited over five minutes for a gigantic order that included precisely one kid\&#x27;s meal. After watching two people who ordered after me be handed their food, I asked where mine was. The manager started yelling at the cashiers for \\&quot;serving off their orders\\&quot; when they didn\&#x27;t have their food. But neither cashier was anywhere near those controls, and the manager was the one serving food to customers and clearing the boards.\\nThe manager was rude when giving me my order. She didn\&#x27;t make sure that I had everything ON MY RECEIPT, and never even had the decency to apologize that I felt I was getting poor service.\\nI\&#x27;ve eaten at various McDonalds restaurants for over 30 years. I\&#x27;ve worked at more than one location. I expect bad days, bad moods, and the occasional mistake. But I have yet to have a decent experience at this store. It will remain a place I avoid unless someone in my party needs to avoid illness from low blood sugar. Perhaps I should go back to the racially biased service of Steak n Shake instead!&#x27;</span>&#125;</span><br><span class="line"><span class="comment"># å¯ä»¥åˆ›å»ºä¸€ä¸ªè¾ƒå°çš„æ•°æ®é›†å­é›†ï¼Œç”¨äºå¾®è°ƒï¼Œä»¥å‡å°‘æ‰€éœ€çš„æ—¶é—´</span></span><br><span class="line">small_train_dataset = tokenized_datasets[<span class="string">&quot;train&quot;</span>].shuffle(seed=<span class="number">42</span>).select(<span class="built_in">range</span>(<span class="number">1000</span>))</span><br><span class="line">small_eval_dataset = tokenized_datasets[<span class="string">&quot;test&quot;</span>].shuffle(seed=<span class="number">42</span>).select(<span class="built_in">range</span>(<span class="number">1000</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. åˆ†è¯å™¨</span></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(<span class="string">&quot;bert-base-cased&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">tokenize_function</span>(<span class="params">examples</span>):</span><br><span class="line">    <span class="keyword">return</span> tokenizer(examples[<span class="string">&quot;text&quot;</span>], padding=<span class="string">&quot;max_length&quot;</span>, truncation=<span class="literal">True</span>)</span><br><span class="line">tokenized_datasets = dataset.<span class="built_in">map</span>(tokenize_function, batched=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Train with PyTorch Trainer</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForSequenceClassification</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> TrainingArguments</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> evaluate</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. åŠ è½½æ¨¡å‹</span></span><br><span class="line">model = AutoModelForSequenceClassification.from_pretrained(<span class="string">&quot;bert-base-cased&quot;</span>, num_labels=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. å®šä¹‰è®­ç»ƒå‚æ•°  åœ¨è®­ç»ƒå‚æ•°ä¸­æŒ‡å®ševaluation_strategyå‚æ•°ï¼Œä»¥åœ¨æ¯ä¸ªepochç»“æŸæ—¶æŠ¥å‘Šè¯„ä¼°æŒ‡æ ‡</span></span><br><span class="line">training_args = TrainingArguments(output_dir=<span class="string">&quot;test_trainer&quot;</span>, evaluation_strategy=<span class="string">&quot;epoch&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. åŠ è½½è¯„ä¼°å™¨</span></span><br><span class="line">metric = evaluate.load(<span class="string">&quot;accuracy&quot;</span>)</span><br><span class="line"><span class="comment"># åœ¨è®¡ç®—åº¦é‡æ ‡å‡†çš„æ—¶å€™è°ƒç”¨computeï¼Œä»¥è®¡ç®—æ‚¨çš„é¢„æµ‹çš„å‡†ç¡®ç‡ã€‚åœ¨å°†é¢„æµ‹ç»“æœä¼ é€’ç»™computeä¹‹å‰ï¼Œæ‚¨éœ€è¦å°†é¢„æµ‹ç»“æœè½¬æ¢ä¸ºlogits</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">compute_metrics</span>(<span class="params">eval_pred</span>):</span><br><span class="line">    logits, labels = eval_pred</span><br><span class="line">    predictions = np.argmax(logits, axis=-<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> metric.compute(predictions=predictions, references=labels)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. å®šä¹‰Trainer</span></span><br><span class="line">trainer = Trainer(</span><br><span class="line">    model=model,</span><br><span class="line">    args=training_args,</span><br><span class="line">    train_dataset=small_train_dataset,</span><br><span class="line">    eval_dataset=small_eval_dataset,</span><br><span class="line">    compute_metrics=compute_metrics,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5. å¼€å§‹è®­ç»ƒ</span></span><br><span class="line">trainer.train()</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Train in native PyTorch</p>
</blockquote>
<p>Trainerè´Ÿè´£è®­ç»ƒå¾ªç¯ï¼Œå¹¶å…è®¸æ‚¨é€šè¿‡ä¸€è¡Œä»£ç å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒã€‚å¯¹äºå–œæ¬¢ç¼–å†™è‡ªå·±çš„è®­ç»ƒå¾ªç¯çš„ç”¨æˆ·ï¼Œæ‚¨ä¹Ÿå¯ä»¥åœ¨åŸç”ŸPyTorchä¸­å¯¹ğŸ¤—Transformersæ¨¡å‹è¿›è¡Œå¾®è°ƒ</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForSequenceClassification</span><br><span class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> AdamW</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> get_scheduler</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> tqdm.auto <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">import</span> evaluate</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. æ•°æ®é›†é¢„å¤„ç†</span></span><br><span class="line">tokenized_datasets = tokenized_datasets.remove_columns([<span class="string">&quot;text&quot;</span>])</span><br><span class="line">tokenized_datasets = tokenized_datasets.rename_column(<span class="string">&quot;label&quot;</span>, <span class="string">&quot;labels&quot;</span>)</span><br><span class="line">tokenized_datasets.set_format(<span class="string">&quot;torch&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. å®šä¹‰DataLoader</span></span><br><span class="line">train_dataloader = DataLoader(small_train_dataset, shuffle=<span class="literal">True</span>, batch_size=<span class="number">8</span>)</span><br><span class="line">eval_dataloader = DataLoader(small_eval_dataset, batch_size=<span class="number">8</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. åŠ è½½æ¨¡å‹</span></span><br><span class="line">model = AutoModelForSequenceClassification.from_pretrained(<span class="string">&quot;bert-base-cased&quot;</span>, num_labels=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. å®šä¹‰ä¼˜åŒ–å™¨</span></span><br><span class="line">optimizer = AdamW(model.parameters(), lr=<span class="number">5e-5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5. å®šä¹‰scheduler</span></span><br><span class="line">num_epochs = <span class="number">3</span></span><br><span class="line">num_training_steps = num_epochs * <span class="built_in">len</span>(train_dataloader)</span><br><span class="line">lr_scheduler = get_scheduler(</span><br><span class="line">    name=<span class="string">&quot;linear&quot;</span>, optimizer=optimizer, num_warmup_steps=<span class="number">0</span>, num_training_steps=num_training_steps</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 6. ç§»åŠ¨æ¨¡å‹åˆ°æŒ‡å®šè®¾å¤‡ </span></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span>) <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> torch.device(<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">model.to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 7. å¼€å§‹è®­ç»ƒ</span></span><br><span class="line">progress_bar = tqdm(<span class="built_in">range</span>(num_training_steps))</span><br><span class="line">model.train()</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> batch <span class="keyword">in</span> train_dataloader:</span><br><span class="line">        batch = &#123;k: v.to(device) <span class="keyword">for</span> k, v <span class="keyword">in</span> batch.items()&#125;</span><br><span class="line">        outputs = model(**batch)</span><br><span class="line">        loss = outputs.loss</span><br><span class="line">        loss.backward()</span><br><span class="line"></span><br><span class="line">        optimizer.step()</span><br><span class="line">        lr_scheduler.step()</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        progress_bar.update(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 8. éªŒè¯é›†è¯„ä¼°</span></span><br><span class="line">metric = evaluate.load(<span class="string">&quot;accuracy&quot;</span>)</span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line"><span class="keyword">for</span> batch <span class="keyword">in</span> eval_dataloader:</span><br><span class="line">    batch = &#123;k: v.to(device) <span class="keyword">for</span> k, v <span class="keyword">in</span> batch.items()&#125;</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        outputs = model(**batch)</span><br><span class="line"></span><br><span class="line">    logits = outputs.logits</span><br><span class="line">    predictions = torch.argmax(logits, dim=-<span class="number">1</span>)</span><br><span class="line">    metric.add_batch(predictions=predictions, references=batch[<span class="string">&quot;labels&quot;</span>])</span><br><span class="line"></span><br><span class="line">metric.compute()</span><br></pre></td></tr></table></figure>
<h2 id="åˆ†å¸ƒå¼åŠ é€Ÿ"><a href="#åˆ†å¸ƒå¼åŠ é€Ÿ" class="headerlink" title="åˆ†å¸ƒå¼åŠ é€Ÿ"></a>åˆ†å¸ƒå¼åŠ é€Ÿ</h2><blockquote>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://huggingface.co/docs/accelerate/quicktour">huggingfaceçš„accelerateæ¨¡å—</a></p>
</blockquote>
<p>ğŸ¤—Accelerateæ˜¯Hugging Faceæä¾›çš„ç”¨äºç®€åŒ–åˆ†å¸ƒå¼è®­ç»ƒçš„åº“ã€‚å®ƒæ—¨åœ¨ä½¿åˆ†å¸ƒå¼è®­ç»ƒæ›´åŠ å®¹æ˜“å’Œé«˜æ•ˆï¼Œæ”¯æŒå¤šç§æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼ŒåŒ…æ‹¬PyTorchå’ŒTensorFlow</p>
<p>Accelerateæä¾›äº†ä»¥ä¸‹åŠŸèƒ½ï¼š</p>
<ol>
<li><strong>æ•°æ®å¹¶è¡Œ</strong>ï¼šAccelerateä½¿ç”¨<code>accelerator.DataParallel</code>ç±»æ¥å®ç°æ•°æ®å¹¶è¡Œï¼Œå¯ä»¥åœ¨å¤šä¸ªGPUä¸ŠåŒæ—¶è®­ç»ƒæ¨¡å‹</li>
<li><strong>æ··åˆç²¾åº¦è®­ç»ƒ</strong>ï¼šAccelerateæ”¯æŒè‡ªåŠ¨æ··åˆç²¾åº¦è®­ç»ƒï¼Œé€šè¿‡å°†æ¨¡å‹å‚æ•°å’Œæ¢¯åº¦è½¬æ¢ä¸ºåŠç²¾åº¦æµ®ç‚¹æ•°æ¥å‡å°‘å†…å­˜å ç”¨å’Œè®¡ç®—é‡</li>
<li><strong>åˆ†å¸ƒå¼è®­ç»ƒ</strong>ï¼šAccelerateä½¿ç”¨<code>accelerator.DistributedDataParallel</code>ç±»æ¥å®ç°åˆ†å¸ƒå¼è®­ç»ƒï¼Œå¯ä»¥åœ¨å¤šä¸ªæœºå™¨ä¸Šå¹¶è¡Œè®­ç»ƒæ¨¡å‹</li>
<li>è®­ç»ƒå¾ªç¯çš„è‡ªåŠ¨ç®¡ç†ï¼šAccelerateæä¾›äº†ä¸€ä¸ª<code>accelerator.Trainer</code>ç±»ï¼Œå®ƒå°è£…äº†è®­ç»ƒå¾ªç¯ï¼Œè‡ªåŠ¨å¤„ç†æ•°æ®åŠ è½½ã€å‰å‘ä¼ æ’­ã€åå‘ä¼ æ’­ã€ä¼˜åŒ–å™¨æ›´æ–°ç­‰è¿‡ç¨‹</li>
</ol>
<p>ä½¿ç”¨Accelerateå¯ä»¥ç®€åŒ–åˆ†å¸ƒå¼è®­ç»ƒçš„é…ç½®å’Œç®¡ç†ï¼Œä½¿ç”¨æˆ·èƒ½å¤Ÿæ›´è½»æ¾åœ°åˆ©ç”¨å¤šä¸ªGPUæˆ–å¤šå°æœºå™¨è¿›è¡Œè®­ç»ƒï¼Œå¹¶è·å¾—æ›´é«˜çš„è®­ç»ƒæ•ˆç‡</p>
<blockquote>
<p>å®‰è£…</p>
</blockquote>
<figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install accelerate</span><br></pre></td></tr></table></figure>
<blockquote>
<p>ç¤ºä¾‹ä»£ç ï¼Œä»¥ä¸‹ä»£ç åªåˆ—å‡ºæ”¹å˜çš„éƒ¨åˆ†ä»£ç </p>
</blockquote>
<p>åªéœ€è¦åœ¨è®­ç»ƒå¾ªç¯ä¸­æ·»åŠ å››è¡Œé¢å¤–çš„ä»£ç å³å¯å¯ç”¨åˆ†å¸ƒå¼è®­ç»ƒ</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> accelerate <span class="keyword">import</span> Accelerator</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. å®šä¹‰åŠ é€Ÿå™¨</span></span><br><span class="line">accelerator = Accelerator()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. dataloaderåŒ…è£…</span></span><br><span class="line">train_dataloader, eval_dataloader, model, optimizer = accelerator.prepare(</span><br><span class="line">    train_dataloader, eval_dataloader, model, optimizer</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. åå‘ä¼ æ’­</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> batch <span class="keyword">in</span> train_dataloader:</span><br><span class="line">        outputs = model(**batch)</span><br><span class="line">        loss = outputs.loss</span><br><span class="line">        accelerator.backward(loss)</span><br><span class="line"></span><br><span class="line">        optimizer.step()</span><br><span class="line">        lr_scheduler.step()</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        progress_bar.update(<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>å®Œæ•´ä»£ç å¦‚ä¸‹</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">+ <span class="keyword">from</span> accelerate <span class="keyword">import</span> Accelerator</span><br><span class="line">  <span class="keyword">from</span> transformers <span class="keyword">import</span> AdamW, AutoModelForSequenceClassification, get_scheduler</span><br><span class="line"></span><br><span class="line">+ accelerator = Accelerator()</span><br><span class="line"></span><br><span class="line">  model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=<span class="number">2</span>)</span><br><span class="line">  optimizer = AdamW(model.parameters(), lr=<span class="number">3e-5</span>)</span><br><span class="line"></span><br><span class="line">- device = torch.device(<span class="string">&quot;cuda&quot;</span>) <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> torch.device(<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">- model.to(device)</span><br><span class="line"></span><br><span class="line">+ train_dataloader, eval_dataloader, model, optimizer = accelerator.prepare(</span><br><span class="line">+     train_dataloader, eval_dataloader, model, optimizer</span><br><span class="line">+ )</span><br><span class="line"></span><br><span class="line">  num_epochs = <span class="number">3</span></span><br><span class="line">  num_training_steps = num_epochs * <span class="built_in">len</span>(train_dataloader)</span><br><span class="line">  lr_scheduler = get_scheduler(</span><br><span class="line">      <span class="string">&quot;linear&quot;</span>,</span><br><span class="line">      optimizer=optimizer,</span><br><span class="line">      num_warmup_steps=<span class="number">0</span>,</span><br><span class="line">      num_training_steps=num_training_steps</span><br><span class="line">  )</span><br><span class="line"></span><br><span class="line">  progress_bar = tqdm(<span class="built_in">range</span>(num_training_steps))</span><br><span class="line"></span><br><span class="line">  model.train()</span><br><span class="line">  <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">      <span class="keyword">for</span> batch <span class="keyword">in</span> train_dataloader:</span><br><span class="line">-         batch = &#123;k: v.to(device) <span class="keyword">for</span> k, v <span class="keyword">in</span> batch.items()&#125;</span><br><span class="line">          outputs = model(**batch)</span><br><span class="line">          loss = outputs.loss</span><br><span class="line">-         loss.backward()</span><br><span class="line">+         accelerator.backward(loss)</span><br><span class="line"></span><br><span class="line">          optimizer.step()</span><br><span class="line">          lr_scheduler.step()</span><br><span class="line">          optimizer.zero_grad()</span><br><span class="line">          progress_bar.update(<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h2 id="ç¤ºä¾‹ä»£ç "><a href="#ç¤ºä¾‹ä»£ç " class="headerlink" title="ç¤ºä¾‹ä»£ç "></a>ç¤ºä¾‹ä»£ç </h2><p>åŒ…æ‹¬<a target="_blank" rel="noopener external nofollow noreferrer" href="https://huggingface.co/docs/transformers/v4.30.0/en/tasks/sequence_classification">è‡ªç„¶è¯­è¨€å¤„ç†</a>ã€<a target="_blank" rel="noopener external nofollow noreferrer" href="https://huggingface.co/docs/transformers/v4.30.0/en/tasks/audio_classification">è¯­éŸ³</a>ã€<a target="_blank" rel="noopener external nofollow noreferrer" href="https://huggingface.co/docs/transformers/v4.30.0/en/tasks/image_classification">è®¡ç®—æœºè§†è§‰</a>å’Œ<a target="_blank" rel="noopener external nofollow noreferrer" href="https://huggingface.co/docs/transformers/v4.30.0/en/tasks/image_captioning">å¤šæ¨¡æ€</a></p>
<h1 id="PEFTæ¨¡å—"><a href="#PEFTæ¨¡å—" class="headerlink" title="PEFTæ¨¡å—"></a>PEFTæ¨¡å—</h1><blockquote>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://huggingface.co/docs/peft/index#supported-models">huggingface PEFTæ¨¡å—</a></p>
</blockquote>
<p>ğŸ¤—<code>PEFT</code>ï¼Œå³<strong>Parameter-Efficient Fine-Tuning(å‚æ•°é«˜æ•ˆå¾®è°ƒ)</strong>ï¼Œæ˜¯ä¸€ä¸ªç”¨äºé«˜æ•ˆåœ°å°†é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹(PLM)é€‚åº”äºå„ç§ä¸‹æ¸¸åº”ç”¨çš„åº“ï¼Œè€Œæ— éœ€å¯¹æ‰€æœ‰æ¨¡å‹å‚æ•°è¿›è¡Œå¾®è°ƒ</p>
<p>PEFTæ–¹æ³•åªå¾®è°ƒå°‘é‡çš„(é¢å¤–çš„)æ¨¡å‹å‚æ•°ï¼Œæ˜¾è‘—é™ä½äº†è®¡ç®—å’Œå­˜å‚¨æˆæœ¬ï¼Œå› ä¸ºå¯¹å¤§è§„æ¨¡PLMè¿›è¡Œå®Œæ•´å¾®è°ƒä»£ä»·è¿‡é«˜ã€‚æœ€è¿‘çš„æœ€å…ˆè¿›çš„PEFTæŠ€æœ¯è¾¾åˆ°äº†ä¸å®Œæ•´å¾®è°ƒç›¸å½“çš„æ€§èƒ½</p>
<p>PEFTä¸ğŸ¤—Accelerateåº“æ— ç¼é›†æˆï¼Œç”¨äºåˆ©ç”¨DeepSpeedå’ŒBig Model Inferenceè¿›è¡Œå¤§è§„æ¨¡æ¨¡å‹å¾®è°ƒ</p>
<blockquote>
<p>Supported methods (æˆªè‡³23-06-15)</p>
</blockquote>
<ol>
<li>LoRA: <a target="_blank" rel="noopener external nofollow noreferrer" href="https://arxiv.org/pdf/2106.09685.pdf">LORA: LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS</a></li>
<li>Prefix Tuning: <a target="_blank" rel="noopener external nofollow noreferrer" href="https://aclanthology.org/2021.acl-long.353/">Prefix-Tuning: Optimizing Continuous Prompts for Generation</a>, <a target="_blank" rel="noopener external nofollow noreferrer" href="https://arxiv.org/pdf/2110.07602.pdf">P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks</a></li>
<li>P-Tuning: <a target="_blank" rel="noopener external nofollow noreferrer" href="https://arxiv.org/pdf/2103.10385.pdf">GPT Understands, Too</a></li>
<li>Prompt Tuning: <a target="_blank" rel="noopener external nofollow noreferrer" href="https://arxiv.org/pdf/2104.08691.pdf">The Power of Scale for Parameter-Efficient Prompt Tuning</a></li>
<li>AdaLoRA: <a target="_blank" rel="noopener external nofollow noreferrer" href="https://arxiv.org/abs/2303.10512">Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning</a></li>
<li><a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/ZrrSkywalker/LLaMA-Adapter">LLaMA-Adapter: Efficient Fine-tuning of Language Models with Zero-init Attention</a></li>
</ol>
<h1 id="å…¶ä»–æ¨¡å—"><a href="#å…¶ä»–æ¨¡å—" class="headerlink" title="å…¶ä»–æ¨¡å—"></a>å…¶ä»–æ¨¡å—</h1><h2 id="AutoTrain"><a href="#AutoTrain" class="headerlink" title="AutoTrain"></a>AutoTrain</h2><p><code>AutoTrain</code>æ˜¯ä¸€ä¸ªç”¨äºè‡ªåŠ¨åŒ–è®­ç»ƒçš„åº“ï¼Œæ—¨åœ¨ç®€åŒ–æ¨¡å‹è®­ç»ƒçš„è¿‡ç¨‹ã€‚å®ƒæä¾›äº†ä¸€ç§ç®€å•çš„æ–¹æ³•æ¥å®šä¹‰å’Œè®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œè‡ªåŠ¨å¤„ç†æ•°æ®åŠ è½½ã€æ‰¹å¤„ç†ã€ä¼˜åŒ–å™¨ã€æŸå¤±å‡½æ•°ç­‰è®­ç»ƒè¿‡ç¨‹ä¸­çš„ç»†èŠ‚ã€‚é€šè¿‡ä½¿ç”¨AutoTrainï¼Œä½ å¯ä»¥æ›´å¿«é€Ÿåœ°æ­å»ºå’Œè®­ç»ƒæ¨¡å‹ï¼Œå‡å°‘æ ·æ¿ä»£ç çš„ç¼–å†™ï¼Œå¹¶ä¸”èƒ½å¤Ÿè½»æ¾åœ°è¿›è¡Œè¶…å‚æ•°æœç´¢å’Œæ¨¡å‹é€‰æ‹©</p>
<h2 id="Gradio"><a href="#Gradio" class="headerlink" title="Gradio"></a>Gradio</h2><p><code>Gradio</code>æ˜¯ä¸€ä¸ªç”¨äºæ„å»ºäº¤äº’å¼ç•Œé¢çš„åº“ï¼Œä½¿ä½ èƒ½å¤Ÿè½»æ¾åœ°ä¸ºä½ çš„æ·±åº¦å­¦ä¹ æ¨¡å‹åˆ›å»ºWebåº”ç”¨ç¨‹åºã€‚Gradioæä¾›äº†ä¸€ä¸ªç®€å•è€Œå¼ºå¤§çš„APIï¼Œå¯ä»¥å°†æ¨¡å‹ä¸ç”¨æˆ·ç•Œé¢ç»„ä»¶(å¦‚æ–‡æœ¬æ¡†ã€æ»‘å—ã€å›¾åƒä¸Šä¼ å™¨ç­‰)ç›¸è¿æ¥ï¼Œä»è€Œå®ç°æ¨¡å‹çš„å®æ—¶æ¨ç†å’Œå¯è§†åŒ–ã€‚é€šè¿‡Gradioï¼Œä½ å¯ä»¥å¿«é€Ÿæ„å»ºä¸€ä¸ªäº¤äº’å¼çš„æ¼”ç¤ºæˆ–éƒ¨ç½²ä½ çš„æ¨¡å‹åˆ°Webä¸Šï¼Œæ— éœ€ç¼–å†™å¤æ‚çš„å‰ç«¯ä»£ç </p>
<h2 id="Diffusers"><a href="#Diffusers" class="headerlink" title="Diffusers"></a>Diffusers</h2><p><code>Diffusers</code>æ˜¯ä¸€ä¸ªç”¨äºç”Ÿæˆå›¾åƒã€éŸ³é¢‘ç”šè‡³åˆ†å­çš„ä¸‰ç»´ç»“æ„çš„æœ€æ–°é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹çš„åº“ã€‚æ— è®ºæ‚¨æ˜¯å¯»æ‰¾ä¸€ä¸ªç®€å•çš„æ¨ç†è§£å†³æ–¹æ¡ˆï¼Œè¿˜æ˜¯æƒ³è¦è®­ç»ƒè‡ªå·±çš„æ‰©æ•£æ¨¡å‹ï¼ŒğŸ¤—Diffuserséƒ½æ˜¯ä¸€ä¸ªæ”¯æŒä¸¤è€…çš„æ¨¡å—åŒ–å·¥å…·ç®±ã€‚æˆ‘ä»¬çš„åº“ç€é‡äºæ˜“ç”¨æ€§è€Œéæ€§èƒ½ï¼Œç®€æ´è€Œéå¤æ‚ï¼Œå¯å®šåˆ¶æ€§è€ŒéæŠ½è±¡æ€§ï¼Œè¯¥åº“ä¸»è¦åŒ…å«ä»¥ä¸‹ä¸‰ä¸ªç»„ä»¶ï¼š</p>
<ol>
<li>æœ€æ–°çš„æ‰©æ•£æ¨ç†æµç¨‹ï¼Œåªéœ€å‡ è¡Œä»£ç å³å¯å®ç°</li>
<li>å¯äº’æ¢çš„å™ªå£°è°ƒåº¦å™¨ï¼Œç”¨äºåœ¨ç”Ÿæˆé€Ÿåº¦å’Œè´¨é‡ä¹‹é—´å¹³è¡¡æƒè¡¡</li>
<li>å¯ç”¨ä½œæ„å»ºå—çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œå¯ä»¥ä¸è°ƒåº¦å™¨ç»“åˆä½¿ç”¨ï¼Œåˆ›å»ºæ‚¨è‡ªå·±çš„ç«¯åˆ°ç«¯æ‰©æ•£ç³»ç»Ÿ</li>
</ol>
<h2 id="Accelerate"><a href="#Accelerate" class="headerlink" title="Accelerate"></a>Accelerate</h2><p>Hugging Faceçš„<code>Accelerate</code>æ˜¯ä¸€ä¸ªæ—¨åœ¨ç®€åŒ–å’ŒåŠ é€Ÿæ·±åº¦å­¦ä¹ æ¨¡å‹è®­ç»ƒå’Œæ¨ç†è¿‡ç¨‹çš„åº“</p>
<p>å®ƒæä¾›äº†ä¸€ä¸ªé«˜çº§APIï¼ŒæŠ½è±¡äº†åˆ†å¸ƒå¼è®­ç»ƒã€æ··åˆç²¾åº¦å’Œæ¢¯åº¦ç´¯ç§¯ç­‰å¤æ‚æ€§ï¼Œä½¿ç”¨æˆ·èƒ½å¤Ÿè½»æ¾åœ°å……åˆ†åˆ©ç”¨ç¡¬ä»¶èµ„æºçš„æ½œåŠ›</p>
<p>Accelerateå…¼å®¹PyTorchå’ŒTensorFlowï¼Œå¹¶æä¾›äº†ä¸€å¥—å·¥å…·å’Œå®ç”¨ç¨‹åºï¼Œä»¥å®ç°è·¨å¤šä¸ªGPUæˆ–å¤šå°æœºå™¨çš„é«˜æ•ˆåˆ†å¸ƒå¼è®­ç»ƒã€‚å®ƒåŒ…æ‹¬ä»¥ä¸‹åŠŸèƒ½ï¼š</p>
<ol>
<li><strong>åˆ†å¸ƒå¼è®­ç»ƒ</strong>ï¼šAccelerateæä¾›äº†ç®€å•æ˜“ç”¨çš„æ¥å£ï¼Œä½¿ç”¨æˆ·èƒ½å¤Ÿå°†è®­ç»ƒè¿‡ç¨‹åˆ†å¸ƒåˆ°å¤šä¸ªGPUæˆ–å¤šå°æœºå™¨ä¸Šã€‚å®ƒæ”¯æŒå¸¸è§çš„åˆ†å¸ƒå¼è®­ç»ƒç­–ç•¥ï¼Œå¦‚æ•°æ®å¹¶è¡Œå’Œæ¨¡å‹å¹¶è¡Œï¼Œå¹¶è‡ªåŠ¨å¤„ç†æ•°æ®çš„åˆ†å‘å’Œæ¢¯åº¦çš„èšåˆï¼Œä½¿ç”¨æˆ·æ— éœ€æ‰‹åŠ¨ç¼–å†™å¤æ‚çš„åˆ†å¸ƒå¼è®­ç»ƒä»£ç </li>
<li><strong>æ··åˆç²¾åº¦è®­ç»ƒ</strong>ï¼šAccelerateæ”¯æŒæ··åˆç²¾åº¦è®­ç»ƒï¼Œé€šè¿‡åŒæ—¶ä½¿ç”¨æµ®ç‚¹16ä½å’Œæµ®ç‚¹32ä½ç²¾åº¦æ¥åŠ å¿«æ¨¡å‹çš„è®­ç»ƒé€Ÿåº¦ã€‚å®ƒè‡ªåŠ¨å¤„ç†æ•°æ®ç±»å‹è½¬æ¢å’Œæ¢¯åº¦ç¼©æ”¾ï¼Œç”¨æˆ·åªéœ€ç®€å•åœ°æŒ‡å®šä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒå³å¯</li>
<li><strong>æ¢¯åº¦ç´¯ç§¯</strong>ï¼šAccelerateæ”¯æŒæ¢¯åº¦ç´¯ç§¯ï¼Œè¿™åœ¨GPUæ˜¾å­˜æœ‰é™çš„æƒ…å†µä¸‹ç‰¹åˆ«æœ‰ç”¨ã€‚æ¢¯åº¦ç´¯ç§¯å…è®¸åœ¨å¤šä¸ªå°æ‰¹æ¬¡ä¸Šç´¯ç§¯æ¢¯åº¦ï¼Œç„¶åè¿›è¡Œä¸€æ¬¡å¤§æ‰¹æ¬¡çš„å‚æ•°æ›´æ–°ï¼Œä»è€Œå‡å°‘æ˜¾å­˜å ç”¨å¹¶æé«˜è®­ç»ƒæ•ˆç‡</li>
<li><strong>è‡ªåŠ¨è°ƒèŠ‚æ‰¹æ¬¡å¤§å°</strong>ï¼šAccelerateå¯ä»¥è‡ªåŠ¨è°ƒæ•´æ‰¹æ¬¡å¤§å°ä»¥é€‚åº”å¯ç”¨çš„GPUå†…å­˜ã€‚å®ƒä¼šåŠ¨æ€è°ƒæ•´æ‰¹æ¬¡å¤§å°ï¼Œä»¥è¾¾åˆ°æœ€ä½³çš„GPUåˆ©ç”¨ç‡å’Œè®­ç»ƒæ€§èƒ½</li>
</ol>
<p>æ€»ä¹‹ï¼ŒHugging Faceçš„Accelerateæ˜¯ä¸€ä¸ªåŠŸèƒ½å¼ºå¤§çš„åº“ï¼Œæ—¨åœ¨ç®€åŒ–å’ŒåŠ é€Ÿæ·±åº¦å­¦ä¹ æ¨¡å‹çš„è®­ç»ƒå’Œæ¨ç†è¿‡ç¨‹ã€‚å®ƒæä¾›äº†é«˜çº§APIå’Œä¸€ç³»åˆ—å·¥å…·ï¼Œä½¿ç”¨æˆ·èƒ½å¤Ÿè½»æ¾åœ°å®ç°åˆ†å¸ƒå¼è®­ç»ƒã€æ··åˆç²¾åº¦è®­ç»ƒå’Œæ¢¯åº¦ç´¯ç§¯ç­‰é«˜æ•ˆè®­ç»ƒç­–ç•¥</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">æ–‡ç« ä½œè€…: </span><span class="post-copyright-info"><a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/narutohyc">narutohyc</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">æ–‡ç« é“¾æ¥: </span><span class="post-copyright-info"><a href="https://study.hycbook.com/article/57912.html">https://study.hycbook.com/article/57912.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">ç‰ˆæƒå£°æ˜: </span><span class="post-copyright-info">æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ«å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨ <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="external nofollow noreferrer" target="_blank">CC BY-NC-SA 4.0</a> è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥è‡ª <a href="https://study.hycbook.com" target="_blank">å…¼ä¸€ä¹¦è™«</a>ï¼</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/huggingface/">huggingface</a><a class="post-meta__tags" href="/tags/transformers/">transformers</a></div><div class="post_share"><div class="social-share" data-image="https://pic.hycbook.com/i/hexo/post_cover/è•¾å§†0.webp" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><link rel="stylesheet" href="/" media="defer" onload="this.media='all'"/><div class="post-reward"><button class="tip-button reward-button"><span class="tip-button__text">æ‰“èµ</span><div class="coin-wrapper"><div class="coin"><div class="coin__middle"></div><div class="coin__back"></div><div class="coin__front"></div></div></div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="https://pic.hycbook.com/i//hexo/qr_codes/hyc_wechat.webp" rel="external nofollow noreferrer" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i//hexo/qr_codes/hyc_wechat.webp" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="https://pic.hycbook.com/i//hexo/qr_codes/hyc_alipay.webp" rel="external nofollow noreferrer" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i//hexo/qr_codes/hyc_alipay.webp" alt="alipay"/></a><div class="post-qr-code-desc">alipay</div></li></ul></div></button></div><audio id="coinAudio" src="https://s1.vika.cn/space/2022/10/29/6db0ad2bccf949f09054b3b206dcc66f?attname=é©¬é‡Œå¥¥æ¸¸æˆæŠ•å¸å®å½“.mp3"></audio><script defer="defer" src="/"></script><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/article/53377.html"><img class="prev-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i/hexo/post_cover/è•¾å§†11.webp" onerror="onerror=null;src='https://pic.hycbook.com/i/hexo/config_imgs/404.svg'" alt="cover of previous post"><div class="pagination-info"><div class="label">ä¸Šä¸€ç¯‡</div><div class="prev_info">æ·±åº¦å­¦ä¹ æ¨¡å‹å‹ç¼©æŠ€æœ¯</div></div></a></div><div class="next-post pull-right"><a href="/article/24897.html"><img class="next-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i/hexo/post_cover/è•¾å§†12.webp" onerror="onerror=null;src='https://pic.hycbook.com/i/hexo/config_imgs/404.svg'" alt="cover of next post"><div class="pagination-info"><div class="label">ä¸‹ä¸€ç¯‡</div><div class="next_info">LLMæ¨¡å‹éƒ¨ç½²è°ƒè¯•æ¨ç†</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> è¯„è®º</span></div><div id="comment-switch"><span class="first-comment">Twikoo</span><span class="switch-btn"></span><span class="second-comment">Valine</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>ç›®å½•</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#huggingface"><span class="toc-number">1.</span> <span class="toc-text">huggingface</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A6%82%E8%BF%B0"><span class="toc-number">1.1.</span> <span class="toc-text">æ¦‚è¿°</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%89%E8%A3%85"><span class="toc-number">1.2.</span> <span class="toc-text">å®‰è£…</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#datasets"><span class="toc-number">2.</span> <span class="toc-text">datasets</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%89%E8%A3%85-1"><span class="toc-number">2.1.</span> <span class="toc-text">å®‰è£…</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B"><span class="toc-number">2.2.</span> <span class="toc-text">å¿«é€Ÿå¼€å§‹</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%86%E8%A7%89"><span class="toc-number">2.2.1.</span> <span class="toc-text">è§†è§‰</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#nlp"><span class="toc-number">2.2.2.</span> <span class="toc-text">nlp</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">2.3.</span> <span class="toc-text">åŠ è½½æ•°æ®é›†</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BF%9B%E9%98%B6%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">2.4.</span> <span class="toc-text">è¿›é˜¶åŠ è½½æ•°æ®é›†</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8E%A2%E7%B4%A2%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">2.5.</span> <span class="toc-text">æ¢ç´¢æ•°æ®é›†</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Preprocess%E5%A4%84%E7%90%86"><span class="toc-number">2.6.</span> <span class="toc-text">Preprocesså¤„ç†</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9E%84%E5%BB%BA%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">2.7.</span> <span class="toc-text">æ„å»ºæ•°æ®é›†</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%86%E4%BA%AB%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">2.8.</span> <span class="toc-text">åˆ†äº«æ•°æ®é›†</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87"><span class="toc-number">3.</span> <span class="toc-text">è¯„ä¼°æŒ‡æ ‡</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%89%E8%A3%85-2"><span class="toc-number">3.1.</span> <span class="toc-text">å®‰è£…</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B-1"><span class="toc-number">3.2.</span> <span class="toc-text">å¿«é€Ÿå¼€å§‹</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8C%87%E6%A0%87%E7%A7%8D%E7%B1%BB"><span class="toc-number">3.2.1.</span> <span class="toc-text">æŒ‡æ ‡ç§ç±»</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8C%87%E6%A0%87%E5%8A%A0%E8%BD%BD"><span class="toc-number">3.2.2.</span> <span class="toc-text">æŒ‡æ ‡åŠ è½½</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8C%87%E6%A0%87%E8%AE%A1%E7%AE%97"><span class="toc-number">3.2.3.</span> <span class="toc-text">æŒ‡æ ‡è®¡ç®—</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%93%E6%9E%9C%E5%AD%98%E5%82%A8"><span class="toc-number">3.2.4.</span> <span class="toc-text">ç»“æœå­˜å‚¨</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%AF%E8%A7%86%E5%8C%96"><span class="toc-number">3.2.5.</span> <span class="toc-text">å¯è§†åŒ–</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%80%89%E6%8B%A9%E5%90%88%E9%80%82%E6%8C%87%E6%A0%87"><span class="toc-number">3.2.6.</span> <span class="toc-text">é€‰æ‹©åˆé€‚æŒ‡æ ‡</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#transformers"><span class="toc-number">4.</span> <span class="toc-text">transformers</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A6%82%E8%BF%B0-1"><span class="toc-number">4.1.</span> <span class="toc-text">æ¦‚è¿°</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%89%E8%A3%85-3"><span class="toc-number">4.2.</span> <span class="toc-text">å®‰è£…</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B-2"><span class="toc-number">4.3.</span> <span class="toc-text">å¿«é€Ÿå¼€å§‹</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Pipeline"><span class="toc-number">4.3.1.</span> <span class="toc-text">Pipeline</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#AutoClass"><span class="toc-number">4.3.2.</span> <span class="toc-text">AutoClass</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#AutoTokenizer"><span class="toc-number">4.3.2.1.</span> <span class="toc-text">AutoTokenizer</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#AutoModel"><span class="toc-number">4.3.2.2.</span> <span class="toc-text">AutoModel</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B6%E4%BB%96%E7%9A%84Auto%E7%B1%BB"><span class="toc-number">4.3.2.3.</span> <span class="toc-text">å…¶ä»–çš„Autoç±»</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E4%BF%9D%E5%AD%98"><span class="toc-number">4.3.2.4.</span> <span class="toc-text">æ¨¡å‹ä¿å­˜</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#AutoConfig"><span class="toc-number">4.3.3.</span> <span class="toc-text">AutoConfig</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Trainer"><span class="toc-number">4.3.4.</span> <span class="toc-text">Trainer</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%95%99%E7%A8%8B"><span class="toc-number">5.</span> <span class="toc-text">æ•™ç¨‹</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83"><span class="toc-number">5.1.</span> <span class="toc-text">æ¨¡å‹è®­ç»ƒ</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%86%E5%B8%83%E5%BC%8F%E5%8A%A0%E9%80%9F"><span class="toc-number">5.2.</span> <span class="toc-text">åˆ†å¸ƒå¼åŠ é€Ÿ</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%A4%BA%E4%BE%8B%E4%BB%A3%E7%A0%81"><span class="toc-number">5.3.</span> <span class="toc-text">ç¤ºä¾‹ä»£ç </span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#PEFT%E6%A8%A1%E5%9D%97"><span class="toc-number">6.</span> <span class="toc-text">PEFTæ¨¡å—</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%85%B6%E4%BB%96%E6%A8%A1%E5%9D%97"><span class="toc-number">7.</span> <span class="toc-text">å…¶ä»–æ¨¡å—</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#AutoTrain"><span class="toc-number">7.1.</span> <span class="toc-text">AutoTrain</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Gradio"><span class="toc-number">7.2.</span> <span class="toc-text">Gradio</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Diffusers"><span class="toc-number">7.3.</span> <span class="toc-text">Diffusers</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Accelerate"><span class="toc-number">7.4.</span> <span class="toc-text">Accelerate</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer" style="background-image: url('https://pic.hycbook.com/i/hexo/config_imgs/footer_bg.webp')"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2023 By narutohyc</div><div class="framework-info"><span>æ¡†æ¶ </span><a target="_blank" rel="noopener external nofollow noreferrer" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>ä¸»é¢˜ </span><a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text"><p><a target="_blank" href="https://hexo.io/" rel="external nofollow noreferrer"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&logo=hexo" title="åšå®¢æ¡†æ¶ä¸ºHexo"></a>&nbsp;<a target="_blank" href="https://demo.jerryc.me/" rel="external nofollow noreferrer"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&logo=bitdefender" title="ä¸»é¢˜é‡‡ç”¨butterfly"></a>&nbsp;<a target="_blank" href="https://vercel.com/ " rel="external nofollow noreferrer"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Hosted-Vervel-brightgreen?style=flat&logo=Vercel" title="æœ¬ç«™é‡‡ç”¨åŒçº¿éƒ¨ç½²ï¼Œé»˜è®¤çº¿è·¯æ‰˜ç®¡äºVercel"></a>&nbsp;<a target="_blank" href="https://github.com/" rel="external nofollow noreferrer"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&logo=GitHub" title="æœ¬ç«™é¡¹ç›®ç”±Gtihubæ‰˜ç®¡"></a>&nbsp;<a target="_blank" href="https://zixiaoyun.com" rel="external nofollow noreferrer"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/å›¾åºŠ-è–„è·å›¾åºŠ-green" title="è–„è·å›¾åºŠ"></a></p><a target="_blank" href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=35020502000647" rel="external nofollow noreferrer"><img style="position:relative;top:4px" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i//hexo/config_imgs//å¤‡æ¡ˆå›¾æ ‡.webp" alt="ICP"/>é—½å…¬ç½‘å®‰å¤‡35020502000647å·  </a><a href="https://beian.miit.gov.cn/" rel="external nofollow noreferrer" target="_blank">é—½ICPå¤‡2022013843å·-1</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="é˜…è¯»æ¨¡å¼"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="ç®€ç¹è½¬æ¢">ç®€</button><button id="darkmode" type="button" title="æµ…è‰²å’Œæ·±è‰²æ¨¡å¼è½¬æ¢"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="å•æ å’ŒåŒæ åˆ‡æ¢"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="è®¾ç½®"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="ç›®å½•"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="ç›´è¾¾è¯„è®º"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="å›åˆ°é¡¶éƒ¨"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">æœç´¢</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  æ•°æ®åº“åŠ è½½ä¸­</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="æœç´¢æ–‡ç« " type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div id="rightMenu"><div class="rightMenu-group rightMenu-small"><div class="rightMenu-item" id="menu-backward"><i class="fa-solid fa-arrow-left"></i></div><div class="rightMenu-item" id="menu-forward"><i class="fa-solid fa-arrow-right"></i></div><div class="rightMenu-item" id="menu-refresh"><i class="fa-solid fa-arrow-rotate-right"></i></div><div class="rightMenu-item" id="menu-home"><i class="fa-solid fa-house"></i></div></div><div class="rightMenu-group rightMenu-line hide" id="menu-text"><a class="rightMenu-item" href="javascript:window.open(&quot;https://www.baidu.com/s?wd=&quot;+window.getSelection().toString());window.location.reload();" rel="external nofollow noreferrer"><i class="fas fa-comment"></i><span>ç™¾åº¦æœç´¢</span></a></div><div class="rightMenu-group rightMenu-line rightMenuOther"><a class="rightMenu-item menu-link" href="/archives/"><i class="fa-solid fa-archive"></i><span>æ–‡ç« å½’æ¡£</span></a><a class="rightMenu-item menu-link" href="/categories/"><i class="fa-solid fa-folder-open"></i><span>æ–‡ç« åˆ†ç±»</span></a><a class="rightMenu-item menu-link" href="/tags/"><i class="fa-solid fa-tags"></i><span>æ–‡ç« æ ‡ç­¾</span></a></div><div class="rightMenu-group rightMenu-line rightMenuNormal"><a class="rightMenu-item menu-link" id="menu-radompage"><i class="fa-solid fa-shoe-prints"></i><span>éšä¾¿é€›é€›</span></a><div class="rightMenu-item" id="menu-translate"><i class="fa-solid fa-earth-asia"></i><span>ç¹ç®€åˆ‡æ¢</span></div><div class="rightMenu-item" id="menu-darkmode"><i class="fa-solid fa-moon"></i><span>åˆ‡æ¢æ¨¡å¼</span></div></div></div><div id="rightmenu-mask"></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script>(() => {
  const $mermaidWrap = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaidWrap.length) {
    window.runMermaid = () => {
      window.loadMermaid = true
      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? '' : ''

      Array.from($mermaidWrap).forEach((item, index) => {
        const mermaidSrc = item.firstElementChild
        const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
        const mermaidID = 'mermaid-' + index
        const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent
        mermaid.mermaidAPI.render(mermaidID, mermaidDefinition, (svgCode) => {
          mermaidSrc.insertAdjacentHTML('afterend', svgCode)
        })
      })
    }

    const loadMermaid = () => {
      window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
    }

    window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
  }
})()</script><script>(()=>{
  const init = () => {
    twikoo.init(Object.assign({
      el: '#twikoo-wrap',
      envId: 'https://vercel.hycbook.com',
      region: '',
      onCommentLoaded: function () {
        btf.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.tk-owo-emotion)'))
      }
    }, null))
  }

  const getCount = () => {
    const countELement = document.getElementById('twikoo-count')
    if(!countELement) return
    twikoo.getCommentsCount({
      envId: 'https://vercel.hycbook.com',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      countELement.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const runFn = () => {
    init()
    GLOBAL_CONFIG_SITE.isPost && getCount()
  }

  const loadTwikoo = () => {
    if (typeof twikoo === 'object') {
      setTimeout(runFn,0)
      return
    } 
    getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(runFn)
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo()
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script><script>function loadValine () {
  function initValine () {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: 'ncn88uooQf0IO2rrGE7Vniwp-gzGzoHsz',
      appKey: 'Yghpzg1QfBMFJ0MxxHubVzKL',
      avatar: 'monsterid',
      serverURLs: '',
      emojiMaps: "",
      path: window.location.pathname,
      visitor: true
    }, null))
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
}

if ('Twikoo' === 'Valine' || !false) {
  if (false) btf.loadComment(document.getElementById('vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script></div><script>window.addEventListener('load', () => {
  const changeContent = (content) => {
    if (content === '') return content

    content = content.replace(/<img.*?src="(.*?)"?[^\>]+>/ig, '[å›¾ç‰‡]') // replace image link
    content = content.replace(/<a[^>]+?href=["']?([^"']+)["']?[^>]*>([^<]+)<\/a>/gi, '[é“¾æ¥]') // replace url
    content = content.replace(/<pre><code>.*?<\/pre>/gi, '[ä»£ç ]') // replace code
    content = content.replace(/<[^>]+>/g,"") // remove html tag

    if (content.length > 150) {
      content = content.substring(0,150) + '...'
    }
    return content
  }

  const getComment = () => {
    const runTwikoo = () => {
      twikoo.getRecentComments({
        envId: 'https://vercel.hycbook.com',
        region: '',
        pageSize: 3,
        includeReply: true
      }).then(function (res) {
        const twikooArray = res.map(e => {
          return {
            'content': changeContent(e.comment),
            'avatar': e.avatar,
            'nick': e.nick,
            'url': e.url + '#' + e.id,
            'date': new Date(e.created).toISOString()
          }
        })

        saveToLocal.set('twikoo-newest-comments', JSON.stringify(twikooArray), 10/(60*24))
        generateHtml(twikooArray)
      }).catch(function (err) {
        const $dom = document.querySelector('#card-newest-comments .aside-list')
        $dom.innerHTML= "æ— æ³•è·å–è¯„è®ºï¼Œè¯·ç¡®è®¤ç›¸å…³é…ç½®æ˜¯å¦æ­£ç¡®"
      })
    }

    if (typeof twikoo === 'object') {
      runTwikoo()
    } else {
      getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(runTwikoo)
    }
  }

  const generateHtml = array => {
    let result = ''

    if (array.length) {
      for (let i = 0; i < array.length; i++) {
        result += '<div class=\'aside-list-item\'>'

        if (true) {
          const name = 'data-lazy-src'
          result += `<a href='${array[i].url}' class='thumbnail'><img ${name}='${array[i].avatar}' alt='${array[i].nick}'></a>`
        }
        
        result += `<div class='content'>
        <a class='comment' href='${array[i].url}' title='${array[i].content}'>${array[i].content}</a>
        <div class='name'><span>${array[i].nick} / </span><time datetime="${array[i].date}">${btf.diffDate(array[i].date, true)}</time></div>
        </div></div>`
      }
    } else {
      result += 'æ²¡æœ‰è¯„è®º'
    }

    let $dom = document.querySelector('#card-newest-comments .aside-list')
    $dom.innerHTML= result
    window.lazyLoadInstance && window.lazyLoadInstance.update()
    window.pjax && window.pjax.refresh($dom)
  }

  const newestCommentInit = () => {
    if (document.querySelector('#card-newest-comments .aside-list')) {
      const data = saveToLocal.get('twikoo-newest-comments')
      if (data) {
        generateHtml(JSON.parse(data))
      } else {
        getComment()
      }
    }
  }

  newestCommentInit()
  document.addEventListener('pjax:complete', newestCommentInit)
})</script><script defer src="https://npm.elemecdn.com/jquery@latest/dist/jquery.min.js"></script><script defer data-pjax src="/js/rightMenu.js"></script><script defer data-pjax src="/js/udf_mouse.js"></script><script defer data-pjax src="/js/udf_js.js"></script><script defer data-pjax src="/zhheo/random.js"></script><script data-pjax src="/js/coin.js"></script><script defer src="https://npm.elemecdn.com/vue@2.6.11"></script><script async src="//at.alicdn.com/t/c/font_3670467_a0sijt8frxo.js"></script><script defer src="/live2d-widget/autoload.js"></script><script defer src="/js/udf_js.js"></script><script defer src="https://cdnjs.cloudflare.com/ajax/libs/toastr.js/latest/toastr.min.js"></script><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-fluttering-ribbon.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = false;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-heart.min.js" async="async" mobile="true"></script><script>window.$crisp = [];
window.CRISP_WEBSITE_ID = "561b80db-3f0f-45cb-b3b1-aae7355939e6";
(function () {
  d = document;
  s = d.createElement("script");
  s.src = "https://client.crisp.chat/l.js";
  s.async = 1;
  d.getElementsByTagName("head")[0].appendChild(s);
})();
$crisp.push(["safe", true])

if (false) {
  $crisp.push(["do", "chat:hide"])
  $crisp.push(["on", "chat:closed", function() {
    $crisp.push(["do", "chat:hide"])
  }])
  var chatBtnFn = () => {
    var chatBtn = document.getElementById("chat_btn")
    chatBtn.addEventListener("click", function(){
      $crisp.push(["do", "chat:show"])
      $crisp.push(["do", "chat:open"])

    });
  }
  chatBtnFn()
} else {
  if (false) {
    function chatBtnHide () {
      $crisp.push(["do", "chat:hide"])
    }
    function chatBtnShow () {
      $crisp.push(["do", "chat:show"])
    }
  }
}</script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener scroll 
  window.tocScrollFn && window.removeEventListener('scroll', window.tocScrollFn)
  window.scrollCollect && window.removeEventListener('scroll', scrollCollect)

  typeof preloader === 'object' && preloader.initLoading()
  document.getElementById('rightside').style.cssText = "opacity: ''; transform: ''"
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

  typeof disqusjs === 'object' && disqusjs.destroy()
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()

  typeof preloader === 'object' && preloader.endLoading()
})

document.addEventListener('pjax:error', (e) => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div class="app-refresh" id="app-refresh" style="position: fixed;top: -2.2rem;left: 0;right: 0;z-index: 99999;padding: 0 1rem;font-size: 15px;height: 2.2rem;transition: all 0.3s ease;"><div class="app-refresh-wrap" style=" display: flex;color: #fff;height: 100%;align-items: center;justify-content: center;"><label>âœ¨ å…¼ä¸€ä¹¦è™«ä¸Šæ–°å•¦ï¼ ğŸ‘‰</label><a href="javascript:void(0)" rel="external nofollow noreferrer" onclick="location.reload()"><span style="color: #fff;text-decoration: underline;cursor: pointer;">ğŸ­æŸ¥çœ‹æ–°å“ğŸ¬</span></a></div></div><script>if ('serviceWorker' in navigator) {
  if (navigator.serviceWorker.controller) {
    navigator.serviceWorker.addEventListener('controllerchange', function() {
      showNotification()
    })
  }
  window.addEventListener('load', function() {
    navigator.serviceWorker.register('/sw.js')
  })
}

function showNotification() {
  if (GLOBAL_CONFIG.Snackbar) {
    var snackbarBg =
      document.documentElement.getAttribute('data-theme') === 'light' ?
      GLOBAL_CONFIG.Snackbar.bgLight :
      GLOBAL_CONFIG.Snackbar.bgDark
    var snackbarPos = GLOBAL_CONFIG.Snackbar.position
    Snackbar.show({
      text: 'âœ¨ å…¼ä¸€ä¹¦è™«ä¸Šæ–°å•¦ï¼ ğŸ‘‰',
      backgroundColor: snackbarBg,
      duration: 500000,
      pos: snackbarPos,
      actionText: 'ğŸ­æŸ¥çœ‹æ–°å“ğŸ¬',
      actionTextColor: '#fff',
      onActionClick: function(e) {
        location.reload()
      },
    })
  } else {
    var showBg =
      document.documentElement.getAttribute('data-theme') === 'light' ?
      '#49b1f5' :
      '#1f1f1f'
    var cssText = `top: 0; background: ${showBg};`
    document.getElementById('app-refresh')
      .style.cssText = cssText
  }
}</script></div><!-- hexo injector body_end start --><script async src="//at.alicdn.com/t/font_2032782_8d5kxvn09md.js"></script><!-- hexo injector body_end end --></body></html>