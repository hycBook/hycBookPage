<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>机器学习_线性代数与矩阵论 | 兼一书虫</title><meta name="keywords" content="python,机器学习数学,线性代数,矩阵论"><meta name="author" content="narutohyc"><meta name="copyright" content="narutohyc"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="机器学习的数学基础入门知识">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习_线性代数与矩阵论">
<meta property="og:url" content="https://study.hycbook.com/article/47032.html">
<meta property="og:site_name" content="兼一书虫">
<meta property="og:description" content="机器学习的数学基础入门知识">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://pic.hycbook.com/i/hexo/post_cover/%E8%95%BE%E5%A7%861.webp">
<meta property="article:published_time" content="2022-10-11T12:38:22.000Z">
<meta property="article:modified_time" content="2023-08-19T12:02:40.884Z">
<meta property="article:author" content="narutohyc">
<meta property="article:tag" content="python">
<meta property="article:tag" content="机器学习数学">
<meta property="article:tag" content="线性代数">
<meta property="article:tag" content="矩阵论">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://pic.hycbook.com/i/hexo/post_cover/%E8%95%BE%E5%A7%861.webp"><link rel="shortcut icon" href="https://pic.hycbook.com/i//hexo/config_imgs/网站图标.webp"><link rel="canonical" href="https://study.hycbook.com/article/47032"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="manifest" href="/manifest.json"/><meta name="msapplication-TileColor" content="#c6ff7a"/><link rel="apple-touch-icon" sizes="180x180" href="https://pic.hycbook.com/i//hexo/source/img/siteicon/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="https://pic.hycbook.com/i//hexo/source/img/siteicon/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="https://pic.hycbook.com/i//hexo/source/img/siteicon/favicon-16x16.png"/><link rel="mask-icon" href="https://pic.hycbook.com/i//hexo/source/img/siteicon/safari-pinned-tab.svg" color="#5bbad5"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?68340394dfd808cea9826e8a57f87aa6";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: {"defaultEncoding":1,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: {"limitDay":120,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":400},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":200,"languages":{"author":"作者: narutohyc","link":"链接: ","source":"来源: 兼一书虫","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '机器学习_线性代数与矩阵论',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-08-19 20:02:40'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/hyc_udf.css"><link rel="stylesheet" href="/css/udf_css.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/js-heo@1.0.11/mainColor/heoMainColor.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/js-heo@1.0.11/404/404.css"><script src="https://npm.elemecdn.com/echarts@4.9.0/dist/echarts.min.js"></script><link href="https://cdn.bootcdn.net/ajax/libs/toastr.js/2.1.4/toastr.min.css" rel="stylesheet"><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.cbd.int/hexo-butterfly-tag-plugins-plus@latest/lib/assets/font-awesome-animation.min.css" media="defer" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.cbd.int/hexo-butterfly-tag-plugins-plus@latest/lib/tag_plugins.css" media="defer" onload="this.media='all'"><script src="https://cdn.cbd.int/hexo-butterfly-tag-plugins-plus@latest/lib/assets/carousel-touch.js"></script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="兼一书虫" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i/hexo/person_img/兼一头像.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">115</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">169</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">9</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-fangwu"></use></svg><span> 首页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-wenzhang1">             </use></svg><span> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-guidang">                   </use></svg><span> 归档</span></a></li><li><a class="site-page child" href="/categories"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-fenlei">                   </use></svg><span> 分类</span></a></li><li><a class="site-page child" href="/tags"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-biaoqian">                   </use></svg><span> 标签</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-wenzhang1">             </use></svg><span> gitbook版</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://common.hycbook.com"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-guidang">                   </use></svg><span> common</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://python.hycbook.com"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-fenlei">                   </use></svg><span> python</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://dl.hycbook.com"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-biaoqian">                   </use></svg><span> 深度学习</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-xuegao">             </use></svg><span> 娱乐</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-yinle">                   </use></svg><span> 音乐</span></a></li><li><a class="site-page child" href="/bangumis"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-wodezhuifan">                   </use></svg><span> 追番</span></a></li><li><a class="site-page child" href="/gallery"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-xiangce">                   </use></svg><span> 相册</span></a></li><li><a class="site-page child" href="/video"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-shipin">                   </use></svg><span> 视频</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/charts"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-xigua"></use></svg><span> 统计图</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-suannai">             </use></svg><span> 网盘</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://pan.hycbook.com"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-guidang">                   </use></svg><span> 私月盘</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://share.hycbook.com"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-zhifengche">                   </use></svg><span> 共享盘</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-zhifeiji">             </use></svg><span> 导航</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/comments"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-TIFFANYSROOM_huaban">                   </use></svg><span> 留言板</span></a></li><li><a class="site-page child" href="/link"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-changyonglianjie">                   </use></svg><span> 友链</span></a></li><li><a class="site-page child" href="/about"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-aixin">                   </use></svg><span> 关于</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://pic.hycbook.com/i/hexo/post_imgs/蕾姆1.webp')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">兼一书虫</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-fangwu"></use></svg><span> 首页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-wenzhang1">             </use></svg><span> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-guidang">                   </use></svg><span> 归档</span></a></li><li><a class="site-page child" href="/categories"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-fenlei">                   </use></svg><span> 分类</span></a></li><li><a class="site-page child" href="/tags"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-biaoqian">                   </use></svg><span> 标签</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-wenzhang1">             </use></svg><span> gitbook版</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://common.hycbook.com"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-guidang">                   </use></svg><span> common</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://python.hycbook.com"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-fenlei">                   </use></svg><span> python</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://dl.hycbook.com"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-biaoqian">                   </use></svg><span> 深度学习</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-xuegao">             </use></svg><span> 娱乐</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-yinle">                   </use></svg><span> 音乐</span></a></li><li><a class="site-page child" href="/bangumis"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-wodezhuifan">                   </use></svg><span> 追番</span></a></li><li><a class="site-page child" href="/gallery"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-xiangce">                   </use></svg><span> 相册</span></a></li><li><a class="site-page child" href="/video"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-shipin">                   </use></svg><span> 视频</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/charts"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-xigua"></use></svg><span> 统计图</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-suannai">             </use></svg><span> 网盘</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://pan.hycbook.com"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-guidang">                   </use></svg><span> 私月盘</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://share.hycbook.com"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-zhifengche">                   </use></svg><span> 共享盘</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-zhifeiji">             </use></svg><span> 导航</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/comments"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-TIFFANYSROOM_huaban">                   </use></svg><span> 留言板</span></a></li><li><a class="site-page child" href="/link"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-changyonglianjie">                   </use></svg><span> 友链</span></a></li><li><a class="site-page child" href="/about"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-aixin">                   </use></svg><span> 关于</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">机器学习_线性代数与矩阵论</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-10-11T12:38:22.000Z" title="发表于 2022-10-11 20:38:22">2022-10-11</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-08-19T12:02:40.884Z" title="更新于 2023-08-19 20:02:40">2023-08-19</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/math/">math</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">18.2k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>81分钟</span></span><span class="post-meta-separator">|</span><span id="" data-flag-title="机器学习_线性代数与矩阵论"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="twikoo_visitors"><i class="fa-solid fa-spinner fa-spin"></i></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/article/47032.html#post-comment"><span id="twikoo-count"><i class="fa-solid fa-spinner fa-spin"></i></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><hr>
<h1 id="向量及其运算"><a href="#向量及其运算" class="headerlink" title="向量及其运算"></a>向量及其运算</h1><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><div class="note success modern"><p>线性代数是多元函数微积分的基础</p>
</div>
<blockquote>
<p>定义</p>
</blockquote>
<p><code>向量(Vector)</code>是具有大小和方向的量，是由多个数构成的一维数组，每个数称为向量的分量，向量分量的数量称为向量的<code>维数</code></p>
<blockquote>
<p>向量的表示</p>
</blockquote>
<p>物理中的力、速度以及加速度是典型的向量，$n$维向量$x$有$n$个分量，可以写成行向量的形式$(x_1 \cdots x_n)$</p>
<p>通常将向量写成<strong>小写黑体斜体</strong>字符，如果写成列的形式则称为列向量，这些分量在列方向排列</p>
<script type="math/tex; mode=display">
\begin{bmatrix}
x_1 \\
\vdots \\
x_n
\end{bmatrix}</script><p>这些向量的分量是实数，则成为实向量，如果是复数，则成为复向量，$n$维实向量的集合记为$\mathbb{R}^n$</p>
<p>与向量相对的是<code>标量(Scalar)</code>，标量只有大小而无方向，物理中的时间、质量以及电流是典型的标量</p>
<p>在数学中通常把向量表示成列向量，而计算机中通常按行存储</p>
<p>二维平面内的一个向量，其在$x$轴方向和$y$轴方向的分量分别为$3$和$1$，写成行向量形式为$\left[ \begin{matrix} 3 &amp; 1 \end{matrix} \right]$</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i//hexo/bk_resources/math/机器学习_线性代数与矩阵论/二维平面内的向量.webp" alt="二维平面内的向量"></p>
<p>图中的向量以虚线箭头表示，起点为原点，终点是以向量的分量为坐标的点，三维空间中的力是三维向量，写成向量形式为</p>
<script type="math/tex; mode=display">
\left[ \begin{matrix} F_x & F_y & F_z \end{matrix} \right]</script><p>力的加法遵守<code>平行四边形法则</code></p>
<blockquote>
<p>零向量</p>
</blockquote>
<p>所有分量全为$0$的向量称为<code>零向量</code>，即为$0$，它的方向是不确定的</p>
<p>向量与空间的点是一一对应的，向量$x$是以原点为起点，以$x$点为终点</p>
<p>在机器学习中，样本数据通常用向量的形式表达，称为<code>特征向量(Feature Vectos)</code>，用于描述样本的特征</p>
<p>但是这里的特征向量和矩阵的特征向量是不同的概念，不要混淆</p>
<h2 id="基本运算"><a href="#基本运算" class="headerlink" title="基本运算"></a>基本运算</h2><p><code>转置运算</code>(Transpose)将列向量变成行向量，将列向量转行向量，向量$x$的转置记为$x^T$</p>
<script type="math/tex; mode=display">
\left[  
  \begin{matrix}
   1 & 0 & 0
  \end{matrix}
\right]^T = 
\left[  
  \begin{matrix}
   1 \\
   0 \\
   1
  \end{matrix} 
\right]</script><blockquote>
<p>加法</p>
</blockquote>
<p>两个向量的加法定义为对应分量相加，要求参与运算的两个向量<code>维数相等</code></p>
<p>向量$x$和$y$相加记为$x+y$，比如$\left[ \begin{matrix} 1 &amp; 0 &amp; 0 \end{matrix} \right] + \left[ \begin{matrix} 4 &amp; 0 &amp; 1 \end{matrix} \right] = \left[ \begin{matrix} 5 &amp; 2 &amp; 4 \end{matrix} \right]$</p>
<p>这与力的加法的平行四边形法则一致，是其在高维空间的推广</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i//hexo/bk_resources/math/机器学习_线性代数与矩阵论/向量的加法.webp" alt="向量的加法"></p>
<p>向量满足<code>交换律</code>和<code>结合律</code></p>
<script type="math/tex; mode=display">
x+y=y+x \qquad x+y+z=x+(y+z)</script><blockquote>
<p>减法</p>
</blockquote>
<p>两个向量的减法为它们对应分量相减，同样要求参与运算的两个向量<code>维数相等</code></p>
<p>与向量加法的平行四边形法则相对应，向量减法符合三角形法则，$x-y$的结果是以$y$为起点，以$x$为终点的向量</p>
<blockquote>
<p>乘积</p>
</blockquote>
<p>向量$x$与标量$k$的乘积$kx$定义为标量与向量的每个分量相乘，比如</p>
<script type="math/tex; mode=display">
5 \times \left[ \begin{matrix} 1 & 0 & 0 \end{matrix} \right] = \left[ \begin{matrix} 5 \times 2 & 5 \times 3 & 5 \times 1 \end{matrix} \right] = \left[ \begin{matrix} 10 & 15 & 5 \end{matrix} \right]</script><p>乘积运算可以改变向量的大小和方向</p>
<p>加法和数乘满足分配律</p>
<script type="math/tex; mode=display">
k(x+y) = kx + ky</script><blockquote>
<p>内积</p>
</blockquote>
<p>两个向量$x$和$y$<code>内积(Inner Product)</code>定义为它们对应分量乘积之和</p>
<script type="math/tex; mode=display">
x^{T}y = \sum _{i=1}^{n}{x_iy_i}</script><p>内积可以记为$x \cdot y$</p>
<script type="math/tex; mode=display">
\left[  
  \begin{matrix}
   1 \\
   2 \\
   3
  \end{matrix}
\right]^T
\left[  
  \begin{matrix}
   1 \\
   0 \\
   1
  \end{matrix}
\right] = 1 \times 1 + 2 \times 0 + 3 \times 1 = 4</script><p>两个$n$维向量的内积运算需要执行$n$次乘法运算和$n-1$次加法运算</p>
<p>内积运算满足下面的规律</p>
<script type="math/tex; mode=display">
x^Ty = y^Tx \qquad (kx)^Ty=kx^Ty \\ \qquad
(x+y)^Tz=x^T+y^Tz \qquad z^T(x+y)=z^Tx+z^Ty</script><p>利用内积可以简化线性函数(一次函数)的表述</p>
<p>对于机器学习中广泛使用的线性模型的预测函数$\omega _1x_1 + \cdots \omega _nx_n + b$</p>
<p>定义系数(权重)向量$\omega = (\omega _1 \cdots \omega _n)^T$，输入向量$x = (x_1 \cdots x_n)^T$，$b$为偏置项，预测函数写成向量内积的话为</p>
<script type="math/tex; mode=display">
\omega ^Tx + b</script><p>向量与自身内积的结果为其所有分量的平方和，即$x^Tx=\sum _{i=1}^{n}{x_i^2}$</p>
<div class="note primary modern"><p>两个向量的内积为$0$，则称它们<code>正交</code></p>
</div>
<p>正交是<strong>几何垂直</strong>这一概念在高维空间的推广</p>
<script type="math/tex; mode=display">
\left[  
  \begin{matrix}
   1 \\
   0 \\
   0
  \end{matrix}
\right]^T
\left[  
  \begin{matrix}
   0 \\
   1 \\
   0
  \end{matrix}
\right] = 0</script><blockquote>
<p>阿达玛积</p>
</blockquote>
<p>两个向量的<code>阿达玛(Hadamard)</code>积定义为它们对应分量相乘，结果为相同维数的向量，记为$x \odot y$</p>
<p>对于两个向量</p>
<script type="math/tex; mode=display">
x = (x_1 \cdots x_n)^T \qquad y = (y_1 \cdots y_n)^T</script><p>它们的阿达玛积为</p>
<script type="math/tex; mode=display">
x \odot y = ({x_1}{y_1} \cdots {x_n}{y_n})^T</script><p>阿达玛积可以简化问题的表述，在反向传播算法、各种梯度下降法中被使用</p>
<h2 id="向量的范数"><a href="#向量的范数" class="headerlink" title="向量的范数"></a>向量的范数</h2><blockquote>
<p>定义</p>
</blockquote>
<p>向量的<code>范数(Norm)</code>是向量的模(长度)这一概念的推广，向量的$L-p$<code>范数是一个标量</code>，定义为</p>
<script type="math/tex; mode=display">
||x||_p = (\sum _{i=1}^{n}{|x_i|^p})^{\frac {1}{p}}</script><p>$p$为整数，常用的是$L1$和$L2$范数，$p$的取值分别为$1$和$2$</p>
<div class="tabs" id="范数"><ul class="nav-tabs"><li class="tab active"><button type="button" data-href="#范数-1">L1范数</button></li><li class="tab"><button type="button" data-href="#范数-2">L2范数</button></li><li class="tab"><button type="button" data-href="#范数-3">无穷范数</button></li></ul><div class="tab-contents"><div class="tab-item-content active" id="范数-1"><p>$L1$范数是所有分量的绝对值之和</p>
<script type="math/tex; mode=display">
||x||_1 = \sum _{i=1}^{n}{|x|_i}</script><p>对于向量$x = \left[ \begin{matrix} 1 &amp; -1 &amp; 2 \end{matrix} \right]$的$L1$范数为$||x||_1 = |1|+|-1|+|2| = 4$</p><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="范数-2"><p>$L2$范数也称为向量的模。即向量的长度，定义为</p>
<script type="math/tex; mode=display">
||x||_p = \sqrt {\sum _{i=1}^{n}{|x_i|^2}}</script><p>长度为$1$的向量称为单位向量，向量$x = \left[ \begin{matrix} 1 &amp; -1 &amp; 2 \end{matrix} \right]$的$L1$范数为$||x||_2 = \sqrt {1^2+(-1)^2+2^2} = \sqrt {6}$</p>
<p>$L1$范数和$L2$范数被用于构造机器学习的正则化项</p>
<p>向量范数默认指$L2$范数</p><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="范数-3"><p>当$p=\infty$时，称为$L - \infty$范数，其定义为</p>
<script type="math/tex; mode=display">
||x||_{\infty} = max|x_i|</script><p>即向量分量绝对值的最大值，向量$x = \left[ \begin{matrix} 1 &amp; -1 &amp; 2 \end{matrix} \right]$的$L1$范数为$||x||_1 = 2$</p>
<p>$L - \infty$范数是$L-p$范数的极限</p>
<script type="math/tex; mode=display">
||x||_{\infty} = \lim _{p \rightarrow + \infty}{(\sum _{i=1}^{n}{|x_i|^p})^{\frac {1}{p}}}</script><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div></div></div>
<blockquote>
<p>性质</p>
</blockquote>
<p>向量数乘之后的范数为$||kx|| = |k| \cdot ||x||$，显然有$x^Tx = ||x||_2^2$</p>
<p>对于非$0$向量，通过数乘向量模的倒数，可以将向量单位化(标准化)，使其长度为$1$</p>
<p>对于上面的$L2$范数，归一化之后为$\left[ \begin{matrix} \frac {1}{\sqrt 6} &amp; \frac {-1}{\sqrt 6} &amp; \frac {2}{\sqrt 6} \end{matrix} \right]$</p>
<blockquote>
<p>向量内积和$L2$范数满足著名的<code>柯西-施瓦茨(Cauchy-Schwarz)</code>不等式</p>
</blockquote>
<script type="math/tex; mode=display">
x^Ty \leq ||x|| \cdot ||y||</script><p>可以通过构造一元二次方程证明</p>
<p>由于$(x+ty)^T (x+ty) = y^Tyt^2 + 2x^Tyt + x^Tx \geq 0$</p>
<p>对于$t$的一元二次方程$y^Tyt^2+2x^Tyt+x^Tx = 0$，只有$x+ty=0$时才有实数解，根据二次方程的判别法则有</p>
<script type="math/tex; mode=display">
\Delta = (2x^Ty - 4y^Tyx^Tx \leq 0)</script><p>即$(x^Ty)^2 \leq ||x||^2 ||y||^2$，当且仅当$x+ty=0$即两个向量成比例时不等式取等号</p>
<blockquote>
<div class="note primary modern"><p>向量内积、向量模与向量夹角之间的关系</p>
</div>
</blockquote>
<p>可以表示为$x^Ty = ||x|| \cdot ||y|| \cdot cos \theta$</p>
<p>其中$\theta$为两个向量之间的夹角，其取值范围为$[0, \pi]$，变形后得到向量夹角计算公式</p>
<script type="math/tex; mode=display">
cos \theta = \frac {x^Ty}{||x|| \cdot ||y||}</script><p>当向量之间的夹角超过$\frac {\pi}{2}$时，它们的内积为负</p>
<p>对于两个长度确定的向量，当夹角为$0$时它们的内积最大，此时$cos \theta=1$；夹角为$\pi$时它们的内积最小，此时$cos \theta=-1$</p>
<p>这一结论常在<code>梯度下降法</code>和<code>最速下降法</code>的推导中被使用</p>
<p>对于向量$x = \left[ \begin{matrix} 1 &amp; 1 &amp; 0 \end{matrix} \right]$、$y=\left[ \begin{matrix} 0 &amp; 1 &amp; 1 \end{matrix} \right]$，它们夹角的余弦为</p>
<script type="math/tex; mode=display">
cos \theta = \frac {x^Ty}{||x|| \cdot ||y||} = \frac {1 \times 0 + 1 \times 1 + 0 \times 1}{\sqrt {1^2+1^2+0^2} \times \sqrt {0^2+1^2+1^2} } = \frac {1}{2}</script><p>因此它们的夹角为$\frac {\pi}{3}$</p>
<p>对于向量$x = \left[ \begin{matrix} 1 &amp; 0 &amp; 0 \end{matrix} \right]$、$y=\left[ \begin{matrix} 0 &amp; 1 &amp; 0 \end{matrix} \right]$，它们夹角的余弦为</p>
<script type="math/tex; mode=display">
cos \theta = \frac {x^Ty}{||x|| \cdot ||y||} = \frac {1 \times 0 + 0 \times 1 + 0 \times 0}{\sqrt {1^2+0^2+0^2} \times \sqrt {0^2+1^2+0^2} } = 0</script><p>因此它们的夹角为$\frac {\pi}{2}$，两个向量正交，正好是$x$轴和$y$轴</p>
<blockquote>
<p>范数满足三角不等式，是平面几何中三角不等式的抽象</p>
</blockquote>
<script type="math/tex; mode=display">
||x+y|| \leq ||x|| + ||y||</script><p>将三角不等式两边同时平方，有</p>
<script type="math/tex; mode=display">
||x+y||^2 = (x+y)^T(x+y) = x^Tx + 2x^Ty + y^Ty</script><p>以及</p>
<script type="math/tex; mode=display">
(||x||+||y||)^2 = ||x||^2 + 2||x||||u|| + ||y||^2 = x^Tx + 2 ||x|| ||y|| + y^Ty</script><blockquote>
<p>欧氏距离</p>
</blockquote>
<p>两个向量相减之后的$L2$范数是它们对应的点之间的距离，称为<code>欧氏距离</code>，即$||x-y||$</p>
<p>对于三维空间中的两个点$x_1 = \left[ \begin{matrix} 1 &amp; 2 &amp; 1 \end{matrix} \right]$与$x_2 = \left[ \begin{matrix} 1 &amp; 2 &amp; 3 \end{matrix} \right]$，它们之间的距离为</p>
<script type="math/tex; mode=display">
d = ||x_1 - x_2|| = \sqrt {(1-1)^2+(2-2)^2+(1-3)^2} = 2</script><p>除了欧氏距离还可以定义其他的距离</p>
<div class="note primary modern"><p>一个将两个向量映射为实数的函数$d(x_1,x_2)$只要满足下面的性质，均可以作为距离函数</p>
</div>
<ul>
<li><strong>非负性</strong>: 距离必须是非负的，对于$ \forall x_1,x_2 \in \mathbb {R}^n$，均有$d(x_1,x_2) \geq 0$</li>
<li><strong>对称性</strong>: 距离是对称的，对于$ \forall x_1,x_2 \in \mathbb {R}^n$，均有$d(x_1,x_2) = d(x_2, x_1)$</li>
<li><strong>三角不等式</strong>: 对于$ \forall x_1,x_2,x_3 \in \mathbb {R}^n$，均有$d(x_1,x_2) + d(x_2,x_3) \geq d(x_1, x_2)$</li>
</ul>
<p>这些性质是欧式几何中距离特性的抽象</p>
<h2 id="解析几何"><a href="#解析几何" class="headerlink" title="解析几何"></a>解析几何</h2><blockquote>
<p>定义</p>
</blockquote>
<p>介绍下线性代数在解析几何中的应用，结论可以从二维平面和三维空间</p>
<p>平面解析几何中直线方程为$ax+by+x=0$，空间解析几何中平面方程为$ax+by+cz+d = 0$</p>
<p>将其推广到$n$维空间，得到<code>超平面(Hyperplane)</code>方程$\omega ^Tx+b = 0$</p>
<blockquote>
<p>法向量</p>
</blockquote>
<p>超平面中的$\omega$称为法向量，它与超平面内任意两个不同点之间连成的直线垂直</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i//hexo/bk_resources/math/机器学习_线性代数与矩阵论/平面的法向量.webp" alt="平面的法向量"></p>
<p>图中黑色虚线为平面的法向量，它与平面垂直，对于平面内任意两点$x_1$和$x_2$，它们的连线(平面上虚线)均与法向量垂直</p>
<p>事实上，如果这两个点在平面内，则它们满足平面方程，有$\omega ^Tx_1 + b = 0$和$\omega ^Tx_2 + b = 0$</p>
<p>两式相减可以得到$\omega ^T(x_1-x_2) = 0$，因此法向量$\omega$与平面内任意两点之间的连线$x_1x_2$正交</p>
<p>将线性方程式的两侧同时乘以一个非$0$的系数，表示的还是同一个超平面</p>
<blockquote>
<p>点到超平面的距离</p>
</blockquote>
<div class="tabs" id="点到超平面的距离"><ul class="nav-tabs"><li class="tab active"><button type="button" data-href="#点到超平面的距离-1">平面解析</button></li><li class="tab"><button type="button" data-href="#点到超平面的距离-2">空间解析</button></li><li class="tab"><button type="button" data-href="#点到超平面的距离-3">超平面</button></li></ul><div class="tab-contents"><div class="tab-item-content active" id="点到超平面的距离-1"><p>在平面解析几何中，点$(x,y)$到直接的距离为</p>
<script type="math/tex; mode=display">
d = \frac {|ax+by+c|}{\sqrt {a^2+b^2}}</script><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="点到超平面的距离-2"><p>在空间解析几何中，点到平面的距离为</p>
<script type="math/tex; mode=display">
d = \frac {|ax+by+cz+d|}{\sqrt {a^2+b^2+c^2}}</script><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="点到超平面的距离-3"><p>将其推广到$n$维空间，根据向量内积和范数可以计算出点到超平面的距离，对于上面定义的超平面，点$x$到它的距离为</p>
<script type="math/tex; mode=display">
d = \frac {|\omega ^Tx+b|}{||\omega||^2}</script><p>这与二维平面、三维空间中点到直线和平面的距离公式在形式上是统一的，在支持向量机的推导过程中会用到</p><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div></div></div>
<p>计算点$\left[ \begin{matrix} 1 &amp; 1 &amp; 1 &amp; 1 \end{matrix} \right]$到超平面$x_1-2x_2+x_3-3x_4+1=0$的距离</p>
<script type="math/tex; mode=display">
d = \frac {|1-2 \times 1 + 1 - 3 \times 1 +1|}{\sqrt {1^2+(-2)^2+1^2+(-3)^2}} = \frac {2}{\sqrt {15}}</script><h2 id="线性相关性"><a href="#线性相关性" class="headerlink" title="线性相关性"></a>线性相关性</h2><blockquote>
<p>线性相关</p>
</blockquote>
<p>根据数乘和加法运算定义<code>线性组合</code>的概念，有向量组$x_1, \cdots ,x_l$，如果存在一组实数$k_1, \cdots ,k_l$使得</p>
<script type="math/tex; mode=display">
x = k_1x_1 + \cdots k_lx_l</script><p>则称向量$x$可由向量组$x_1, \cdots ,x_l$线性表达</p>
<p>右侧称为向量组$x_1, \cdots ,x_l$的<code>线性组合</code>，$k_1, \cdots ,k_l$为<code>组合系数</code></p>
<p>对于向量组</p>
<p>$x_1 = \left[ \begin{matrix} 1 &amp; 2 &amp; 3 \end{matrix} \right] \qquad x_2 = \left[ \begin{matrix} 1 &amp; 0 &amp; 2 \end{matrix} \right] \qquad x_3 = \left[ \begin{matrix} 0 &amp; 0 &amp; 1 \end{matrix} \right] $</p>
<p>向量$x= x_1+2_x2+x_3 = \left[ \begin{matrix} 3 &amp; 2 &amp; 8 \end{matrix} \right] $，可由该向量组线性表达，组合系数为$\left[ \begin{matrix} 1 &amp; 2 &amp; 1 \end{matrix} \right]$</p>
<p>对于向量组$x_1, \cdots ,x_l$，如果存在一组不全为$0$的数$kx_1, \cdots ,k_l$，使得</p>
<script type="math/tex; mode=display">
k_1x_1+k_2x_2+ \cdots +k_lx_l = 0</script><p>则称这组向量<code>线性相关</code>，如果不存在一组不全为$0$的数使得上式成立，则称为这组向量<code>线性无关</code>，也称为<code>线性独立</code></p>
<blockquote>
<p>线性无关</p>
</blockquote>
<p>线性相关意味着这组向量存在冗余，至少有一个向量可以由其他向量线性表达，如果$x_1 \neq 0$，则有</p>
<script type="math/tex; mode=display">
x_i = -\frac {\alpha _1}{\alpha _i}{x_1} - \cdots \frac {\alpha _{i-1}}{\alpha _i}{x_{i-1}} - \frac {\alpha _{i+1}}{\alpha _i}{x_{i+1}} - \frac {\alpha _{l}}{\alpha _i}{x_{l}}</script><p>比如下面的行向量线性无关</p>
<p>$x_1 = \left[ \begin{matrix} 1 &amp; 0 &amp; 0 \end{matrix} \right] \qquad x_2 = \left[ \begin{matrix} 0 &amp; 1 &amp; 0 \end{matrix} \right] \qquad x_3 = \left[ \begin{matrix} 0 &amp; 0 &amp; 1 \end{matrix} \right] $</p>
<p>给定组合系数$k_1$、$k_2$、$k_3$，有</p>
<p>$k_1 \left[ \begin{matrix} 1 &amp; 0 &amp; 0 \end{matrix} \right] + k_2 \left[ \begin{matrix} 0 &amp; 1 &amp; 0 \end{matrix} \right] + k_3 \left[ \begin{matrix} 0 &amp; 0 &amp; 1 \end{matrix} \right] = \left[ \begin{matrix} k_1 &amp; k_2 &amp; k_3 \end{matrix} \right]$</p>
<p>欲使该向量为$0$，则有$k_1=k_2=k_3=0$，因此这组向量线性无关</p>
<p>下面的行向量线性相关，因为存在系数$\left[ \begin{matrix} 1 &amp; 1 &amp; -1 \end{matrix} \right]$是的向量为$0$</p>
<p>$x_1 = \left[ \begin{matrix} 1 &amp; 1 &amp; 0 \end{matrix} \right] \qquad x_2 = \left[ \begin{matrix} 2 &amp; 2 &amp; 0 \end{matrix} \right] \qquad x_3 = \left[ \begin{matrix} 3 &amp; 3 &amp; 0 \end{matrix} \right] $</p>
<blockquote>
<p>极大线性无关组</p>
</blockquote>
<p>一个向量组数量最大的线性无关向量子集称为<code>极大线性无关组</code></p>
<p>给定向量组<script type="math/tex">x_1, \cdots, x_l</script>，如果<script type="math/tex">x_{i_1},x_{i_2}, \cdots, x_{i_m}</script>线性无关，但任意加入一个向量<script type="math/tex">x_{i_{m+1}}</script>之后线性相关</p>
<p>则<script type="math/tex">x_{i_1},x_{i_2}, \cdots, x_{i_m}</script>是极大线性无关组，<code>极大线性无关组不唯一</code></p>
<p>$n$维向量的极大线性无关组最多有$n$个向量，这意味着任意一个向量均可以由$n$个线性无关的$n$维向量线性表达</p>
<h2 id="向量空间"><a href="#向量空间" class="headerlink" title="向量空间"></a>向量空间</h2><blockquote>
<p>定义</p>
</blockquote>
<p>有$n$维向量的集合$X$，如果在其上定义了加法和数乘运算，且对两种计算封闭，即运算结果仍属于此集合，则称$X$为<code>向量空间(Vector Sapce)</code>，也称为线性空间，对于任意的向量$x,y \in X$都有$x+y \in X \qquad kx \in X$，则集合$X$为向量空间</p>
<p>根据线性组合的定义，向量空间中任意向量的线性组合仍属于此空间</p>
<p>设$S$是向量空间$X$的子集，如果$S$对加法和数乘运算都封闭，则称$S$为$X$的<code>子空间</code></p>
<p>例如，由三维实向量构成的集合$\mathbb {R}^3$是一个线性空间，显然对于任意$x,y \in \mathbb {R}^3$以及$k \in \mathbb {R}^3$，都有</p>
<script type="math/tex; mode=display">
x+y \in \mathbb {R}^3 \qquad kx \in \mathbb {R}^3</script><p>集合$S = { x \in \mathbb {R}^3, x_i &gt; 0 }$，即分量全为正的三维向量的集合不是线性空间，因为它对数乘不封闭</p>
<p>$S$中的向量$x$数乘一个负数，结果向量的分量为负，不再属于该集合</p>
<blockquote>
<p>基(维数)</p>
</blockquote>
<p>向量空间的极大线性无关组称为空间的<code>基</code>，基所包含的向量数称为空间的维数</p>
<p>如果$u_1, \cdots ,u_n$是空间的一组基，空间中的任意向量$x$均可由这组基线性表达$x = k_1u_1 + cdots + k_nu_n$</p>
<p>则$k_1, \cdots k_n$称为向量$x$在这组基下的坐标</p>
<blockquote>
<p>正交基</p>
</blockquote>
<p>如果基向量$u_1, \cdots ,u_n$相互正交</p>
<script type="math/tex; mode=display">
u_i^Tu_j = 0, i \neq j</script><p>则称为<code>正交基</code>，如果基向量相互正交且长度均为$1$</p>
<script type="math/tex; mode=display">
u_i^Tu_j = 0, i \neq j \qquad  u_i^Tu_i = 0</script><p>则称为<code>标准正交基</code></p>
<p>向量组$\left[ \begin{matrix} 1 &amp; 0 &amp; 0 \end{matrix} \right] \qquad \left[ \begin{matrix} 0 &amp; 1 &amp; 0 \end{matrix} \right] \qquad \left[ \begin{matrix} 0 &amp; 0 &amp; 1 \end{matrix} \right]$为$\mathbb {R}^3$的一组标准正交基，其方向对应三维空间的$3$个坐标轴方向</p>
<p>需要强调的是，空间的基和标准正交基不唯一</p>
<blockquote>
<p>格拉姆-施密特(Gram-Schmidt)正交化</p>
</blockquote>
<p>给定一组线性无关的向量，可以根据它们构造出标准正交基，用的是<code>格拉姆-施密特(Gram-Schmidt)正交化</code></p>
<p>具体方法: 给定一组非$0$且线性无关的向量$x_1, \cdots ,x_l$，格拉姆-施密特正交化先构造出一组正交基$u_1, \cdots ,u_l$</p>
<p>然后将这组正交基进行标准化得到标准正交基$e_1, \cdots ,e_l$</p>
<p>首先选择向量$x_1$作为一个正交基方向，令$u_1=x_1$</p>
<p>然后加入<script type="math/tex">x_2</script>，构造<script type="math/tex">u_1</script>和<script type="math/tex">x_2</script>的线性组合，使得它与<script type="math/tex">u_1</script>正交，即<script type="math/tex">u_2 = x_2 - \alpha_{21}u_1</script></p>
<p>由于<script type="math/tex">u_2</script>与<script type="math/tex">u_1</script>正交，因此有<script type="math/tex">(x_2- \alpha _{21}u_1)^T u_1 = 0</script></p>
<p>解得$\alpha _{21} = \frac {x_2^Tu_1}{u_1^Tu_1}$</p>
<p>解释下这种做法的几何意义，由于$x_2^Tu_1 = ||x_2||||u_1|| cos \theta$</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i//hexo/bk_resources/math/机器学习_线性代数与矩阵论/通过向量投影构造垂直向量.webp" alt="通过向量投影构造垂直向量"></p>
<p>因此$\frac {x_2^Tu_1}{||u_1||} = ||x_2|| cos \theta$就是$x_2$在$u_1$方向上投影向量的长度，是图中直角三角形$ABC$的直角边$AB$的长度，这里$x_2$是三角形的斜边$AC$</p>
<p>由于$\frac {u_1}{||u_1||}$是$u_1$方向的单位向量，$\frac {x_2^Tu_1}{||u_1||} \frac {u_1}{||u_1||} = \frac {x_2^Tu_1}{u_1^Tu_1} u_1$就是$x_2$在$u_1$方向上的投影向量，是图中的向量$AB$</p>
<p>根据向量减法的三角形法则，$x_2- \frac {x_2^Tu_1}{u_1^Tu_1} u_1$就是图中的向量$BC$，与$u_1$垂直</p>
<p>加下来加入$x_3$，构造出$u_3$，是$u_1$、$u_2$和$x_3$的线性组合，使得它与$u_1$及$u_2$均正交</p>
<script type="math/tex; mode=display">
u_3 = x_3 - \alpha _{31} u_1 - \alpha _{31} u_2</script><p>由于$u_3$与$u_1$正交，因此有</p>
<script type="math/tex; mode=display">
(x_3- \alpha _{31} u_1 - \alpha _{32} u_2)^T_1 = 0</script><p>而<script type="math/tex">u_1</script>与<script type="math/tex">u_2</script>正交，<script type="math/tex">(\alpha _{32} u_2)^T u_1 = 0</script>，因此可以解得<script type="math/tex">\alpha _{31} = \frac {x_3^T u_1}{u_1^T u_1}</script></p>
<p>由于$u_3$与$u_2$正交，因此有</p>
<script type="math/tex; mode=display">
(x_3 - \alpha _{31}u_1 - \alpha _{32}u_2 )^Tu_2 = 0</script><p>而<script type="math/tex">u_1</script>与<script type="math/tex">u_2</script>正交，<script type="math/tex">(\alpha _{31} u_1)^T u_2 = 0</script>，因此可以解得<script type="math/tex">\alpha _{32} = \frac {x_3^T u_2}{u_2^T u_2}</script></p>
<p>以此类推，在加入$x_k$时构造下面的线性组合</p>
<script type="math/tex; mode=display">
u_k = x_k - \sum _{i=1}^{k-1}{\alpha _{ki}u_i}</script><p>由于它与<script type="math/tex">u_1, \cdots, u_{k-1}</script>均正交，因此</p>
<script type="math/tex; mode=display">
(x_k - \sum _{i=1}^{k-1}{\alpha _{ki} u_i})^Tu_j = 0, j=0, \cdots ,k-1</script><p>而$u_j$与$u_i,i=1, \cdots, k-1 ,i \neq j$均正交，从而解得</p>
<script type="math/tex; mode=display">
\alpha _{ki} = \frac {x_k^T u_i}{u_i^T u_i}</script><p>反复执行上述步骤，可以得到一组正交基$u_1, \cdots , u_l$</p>
<p>将它们分别标准化，得到标准正交基$ \frac {u_1}{||u_1||} , \cdots , \frac {u_l}{||u_l||}$</p>
<blockquote>
<p>格拉姆-施密特正交化的几何意义</p>
</blockquote>
<p>首先考虑二维的情况</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i//hexo/bk_resources/math/机器学习_线性代数与矩阵论/二维平面的格拉姆-施密特正交化.webp" alt="二维平面的格拉姆-施密特正交化"></p>
<p>图中向量$\frac {x_2^Tu_1}{u_1^Tu_1}u_1$与$u_1$同向，是向量$x_2$在$x_1$方向的投影，显然$x_2$减掉该投影之后的向量，即向量$u_2$，与$u_1$垂直</p>
<p>下面考虑三维的情况</p>
<p>首先构造出$u_2$，与二维平面的方法相同，保证$u_2$与$u_1$垂直，然后处理$x_3$，首先减掉其在$u_1$方向的投影，保证相减之后与$u_1$垂直，然后减掉在$u_2$方向的投影，保证与$u_2$垂直</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i//hexo/bk_resources/math/机器学习_线性代数与矩阵论/三维空间的格拉姆-施密特正交化.webp" alt="三维空间的格拉姆-施密特正交化"></p>
<p>下面举例说明，有如下的向量组</p>
<script type="math/tex; mode=display">
x_1 = \left[ \begin{matrix} 1 \\ 0 \\ 1 \end{matrix} \right] \qquad x_2 = \left[ \begin{matrix} 1 \\ 1 \\ 0 \end{matrix} \right] \qquad x_3 = \left[ \begin{matrix} 0 \\ 1 \\ 1 \end{matrix} \right]</script><p>首先生成$u_1=x_2= \left[ \begin{matrix} 1 \ 0 \ 1 \end{matrix} \right]$</p>
<p>然后生成$u_2$，组合系数为</p>
<script type="math/tex; mode=display">
\alpha _{21} = \frac {x_2^T u_1}{x_1^T u_1} = \frac {1 \times 1 + 0 \times 1 + 1 \times 0}{1^2+0^2+1^2} = \frac {1}{2}</script><p>因此</p>
<script type="math/tex; mode=display">
u_2 = x_2 - \alpha _{21}u_1 = \left[ \begin{matrix} 1 \\ 1 \\ 0 \end{matrix} \right] - \frac {1}{2} \left[ \begin{matrix} 1 \\ 0 \\ 1 \end{matrix} \right] = \frac {1}{2}\left[ \begin{matrix} 1 \\ 2 \\ -1 \end{matrix} \right]</script><p>最后生成$u_3$，组合系数为</p>
<script type="math/tex; mode=display">
\alpha _{31} = \frac {x_3^Tu_1}{u_1^Tu_1} = \frac {1 \times 0 + 0 \times 1 + 1 \times 1}{1^2+0^2+1^2} = \frac {1}{2}</script><p>以及</p>
<script type="math/tex; mode=display">
\alpha _{32} = \frac {x_3^Tu_2}{u_2^Tu_2} = \frac {\frac {1}{2} ( 1 \times 0 + 2 \times 1 + (-1) \times 1)}{ \frac {1}{4} (1^2+2^2+(-1)^2)} = \frac {1}{3}</script><p>因此</p>
<script type="math/tex; mode=display">
u_3= x_3- \alpha_{31} u_1 - \alpha _{32}u_2 = \left[ \begin{matrix} 0 \\ 1 \\ 1 \end{matrix} \right] - \frac {1}{2} \left[ \begin{matrix} 1 \\ 0 \\ 1 \end{matrix} \right] - \frac {1}{3} \times \frac {1}{2} \left[ \begin{matrix} 1 \\ 2 \\ -1 \end{matrix} \right] = \frac {2}{3} \left[ \begin{matrix} -1 \\ 1 \\ 1 \end{matrix} \right]</script><p>最后对$u_1$、$u_2$和$u_3$进行单位化</p>
<script type="math/tex; mode=display">
e_1 = \frac {u_1}{||u_1||}=\frac {1}{\sqrt {2}} \left[ \begin{matrix} 1 \\ 0 \\ 1 \end{matrix} \right] \qquad 
e_1 = \frac {u_2}{||u_2||}=\frac {1}{\sqrt {6}} \left[ \begin{matrix} 1 \\ 2 \\ -1 \end{matrix} \right] \qquad 
e_1 = \frac {u_3}{||u_3||}=\frac {1}{\sqrt {3}} \left[ \begin{matrix} -1 \\ 1 \\ 1 \end{matrix} \right]</script><p>即为一组标准正交基</p>
<h2 id="应用之线性回归"><a href="#应用之线性回归" class="headerlink" title="应用之线性回归"></a>应用之线性回归</h2><h2 id="应用之线性分类器与支持向量机"><a href="#应用之线性分类器与支持向量机" class="headerlink" title="应用之线性分类器与支持向量机"></a>应用之线性分类器与支持向量机</h2><h1 id="矩阵及其运算"><a href="#矩阵及其运算" class="headerlink" title="矩阵及其运算"></a>矩阵及其运算</h1><h2 id="基本概念-1"><a href="#基本概念-1" class="headerlink" title="基本概念"></a>基本概念</h2><blockquote>
<p>定义</p>
</blockquote>
<p><code>矩阵</code>$A$是二维数组，一个$m \times n$的矩阵有$m$行和$n$列，每个位置$(i,j)$处的元素$a_{i,j}$是一个数，记为</p>
<script type="math/tex; mode=display">
\left[ 
\begin{matrix} 
a_{11} & \cdots & a_{an} \\ 
\vdots & \ddots & \vdots \\ 
a_{m1} & \cdots & a_{mn} 
\end{matrix} 
\right]</script><p>矩阵通常用大写的黑体、斜体字母表示</p>
<p>矩阵的元素可以是实数，称为<code>实矩阵</code>，元素为复数，称为<code>复矩阵</code>，全体$m \times n$实矩阵的集合记为$\mathbb R ^{m \times n}$</p>
<blockquote>
<p>方阵</p>
</blockquote>
<p>如果矩阵行数和列数相等，则称为<code>方阵</code>，$n \times n$的方阵称为$n$阶方阵</p>
<blockquote>
<p>对称矩阵</p>
</blockquote>
<p>如果一个方阵的元素满足<script type="math/tex">a_{ij} = a_{ji}</script>，则称为<code>对称矩阵</code>，比如</p>
<script type="math/tex; mode=display">
\left[ 
\begin{matrix} 
1 & 2 & 3 \\ 
2 & 2 & 0 \\ 
3 & 0 & 4
\end{matrix} 
\right]</script><blockquote>
<p>对角矩阵</p>
</blockquote>
<p>矩阵所有行号和列号相等的元素$a_{ii}$的全体称为<code>主对角线</code>，如果一个矩阵出主对角线之外所有的元素均为$0$，则称为<code>对角矩阵</code></p>
<script type="math/tex; mode=display">
\left[ 
\begin{matrix} 
1 & 0 & 0 \\ 
0 & 2 & 0 \\ 
0 & 0 & 4
\end{matrix} 
\right]</script><p>该对角矩阵可以简记为$diag(1,2,3)$，通常将对角矩阵记为$A$</p>
<blockquote>
<p>单位矩阵</p>
</blockquote>
<p>如果矩阵的主对角线的元素为$1$，其他元素为$0$，则称为<code>单位矩阵</code>，记为$I$</p>
<script type="math/tex; mode=display">
\left[ 
\begin{matrix} 
1 & 0 & 0 \\ 
0 & 1 & 0 \\ 
0 & 0 & 1
\end{matrix} 
\right]</script><p>单位矩阵的作用类似于实数中的$1$，在矩阵乘法中会说明，$n$阶单位矩阵记为$I_n$</p>
<blockquote>
<p>零矩阵</p>
</blockquote>
<p>如果矩阵的所有元素都为$0$，则称为<code>零矩阵</code>，记为<strong>$0$</strong>，其作用类似于实数中的$0$</p>
<blockquote>
<p>上三角矩阵</p>
</blockquote>
<p>如果矩阵的主对角线下方的元素全为$0$，则称为<code>上三角矩阵</code></p>
<script type="math/tex; mode=display">
\left[ 
\begin{matrix} 
1 & 1 & 0 \\ 
0 & 2 & 1 \\ 
0 & 0 & 3
\end{matrix} 
\right]</script><blockquote>
<p>下三角矩阵</p>
</blockquote>
<p>如果矩阵的主对角线上方的元素全为$0$，则称为<code>下三角矩阵</code></p>
<script type="math/tex; mode=display">
\left[ 
\begin{matrix} 
1 & 1 & 0 \\ 
4 & 2 & 0 \\ 
6 & 5 & 3
\end{matrix} 
\right]</script><blockquote>
<p>格拉姆(Gram)矩阵</p>
</blockquote>
<p>一个向量组<script type="math/tex">x_1, \cdots , x_n</script>的<code>格拉姆(Gram)矩阵</code>是一个$n \times  n$的矩阵，其每一个矩阵元素<script type="math/tex">G_{ij}</script>为向量<script type="math/tex">x_i</script>与<script type="math/tex">x_j</script>的内积，即</p>
<script type="math/tex; mode=display">
G = \left[ 
\begin{matrix} 
x_1^Tx_1 & x_1^Tx_2 & \cdots & x_1^Tx_n \\ 
x_2^Tx_1 & x_2^Tx_2 & \cdots & x_2^Tx_n \\ 
\vdots & \vdots & \ddots & \vdots \\ 
x_n^Tx_1 & x_n^Tx_3 & \cdots & x_n^Tx_n
\end{matrix} 
\right]</script><p>由于$x_i^Tx_j = x_j^Tx_i$，因此格拉姆矩阵是一个对称矩阵</p>
<p>对于向量<script type="math/tex">x_1 = \left[ \begin{matrix} 1 & 2 & 3 \end{matrix} \right] \qquad x_2 = \left[ \begin{matrix} 1 & 0 & 1 \end{matrix} \right]</script>，其格拉姆矩阵为</p>
<script type="math/tex; mode=display">
 G = \left[ \begin{matrix} x_1^Tx_1 & x_1^Tx_2 \\ x_2^Tx_1 & x_2^Tx_2 \end{matrix} \right] = \left[ \begin{matrix} 14 & 4 \\ 4 & 2 \end{matrix} \right]</script><p>在机器学习中该矩阵常被使用，比如主成分分析、核主成分分析、线性判别分析、线性回归、logisitic回归以及支持向量机的推导和证明</p>
<h2 id="基本运算-1"><a href="#基本运算-1" class="headerlink" title="基本运算"></a>基本运算</h2><blockquote>
<p>转置</p>
</blockquote>
<p>矩阵的<code>转置(Transpose)</code>定义为行和列下标相互交换，一个$m \times n$的矩阵转置之后为$n \times m$的矩阵，矩阵$A$的转置记为$A^T$</p>
<script type="math/tex; mode=display">
\left[ \begin{matrix} 1 & 2 & 3 \\ 4 & 5 & 6 \end{matrix} \right]^T = \left[ \begin{matrix} 1 & 4 \\ 2 & 5 \\ 3 & 6 \end{matrix} \right]</script><blockquote>
<p>加法</p>
</blockquote>
<p>矩阵的加法为对应位置的元素相加，需要保证两个矩阵有相同的尺寸，矩阵$A$和$B$相加记为$A+B$</p>
<script type="math/tex; mode=display">
\left[ \begin{matrix} 1 & 2 & 3 \\ 4 & 5 & 6 \end{matrix} \right] + 
\left[ \begin{matrix} 7 & 8 & 9 \\ 10 & 11 & 12 \end{matrix} \right] = 
\left[ \begin{matrix} 8 & 10 & 12 \\ 14 & 16 & 18 \end{matrix} \right]</script><p>加法和转置满足$(A+B)^T = A^T+B^T$</p>
<p>加法满足交换律和结合律$A+B=B+A \qquad A+B+C = A+(B+C)$</p>
<blockquote>
<p>数乘</p>
</blockquote>
<p>矩阵和标量的乘法即<code>数乘</code>，定义为标量和矩阵每个元素相乘，矩阵$A$和$k$数乘记为$kA$</p>
<script type="math/tex; mode=display">
5 \times \left[ \begin{matrix} 1 & 2 & 3 \\ 4 & 5 & 6 \end{matrix} \right] = \left[ \begin{matrix} 5 & 10 & 15 \\ 20 & 25 & 30 \end{matrix} \right]</script><p>数乘和加法满足分配律$k(A+B) = kA + kB$</p>
<blockquote>
<p>乘法</p>
</blockquote>
<p>矩阵<code>乘法</code>定义为第一个矩阵的每个行向量和第二个矩阵的每个列向量做<strong>内积</strong>，形成结果矩阵的每个元素，矩阵相乘记为$AB$</p>
<p>要求第一个矩阵的列数要等于第二个矩阵的行数</p>
<p>结果矩阵第$i$行第$j$列位置处的元素为$A$的第$i$行与$B$的第$j$列的内积<script type="math/tex">\sum _{k=1}^{p}{a_{ip}b_{pj}}</script></p>
<script type="math/tex; mode=display">
\left[ \begin{matrix} 1 & 1 & 0 \\ 0 & 0 & 1 \end{matrix} \right] \times
\left[ \begin{matrix} 0 & 1 \\ 0 & 0 \\ 1 & 0 \end{matrix} \right] = 
\left[ \begin{matrix} 1 \times 0 + 1 \times 0 + 0 \times 1 & 1 \times 1 + 1 \times 0 + 0 \times 0 \\ 0 \times 0 + 0 \times 0 + 1 \times 1  & 0 \times 1 + 0 \times 0 + 1 \times 0 \end{matrix} \right] =
\left[ \begin{matrix} 0 & 1 \\ 1 & 0 \end{matrix} \right]</script><p>结果矩阵的每个元素需要$p$次乘法运算、$p-1$次加法运算得到，结果矩阵有$m \times n$个元素</p>
<p>因此，矩阵乘法需要$m \times n \times p$次乘法和$m \times n \times (p-1)$次加法</p>
<p>使用矩阵乘法可以简化线性方程组的表述，对于如下的线性方程组</p>
<script type="math/tex; mode=display">
\begin{cases} a_{11}x_1 + a_{12}x_2 +\cdots + a_{1n}x_n = b_1 \\
\vdots \\
a_{n11}x_1 + a_{n2}x_2 +\cdots + a_{nn}x_n = b_n
\end{cases}</script><p>定义系数矩阵为</p>
<script type="math/tex; mode=display">
A = \left[ 
\begin{matrix} 
a_{11} & \cdots & x_{1n} \\ 
\vdots & \ddots & \vdots \\ 
x_{n1} & \cdots & x_{nn}
\end{matrix} 
\right]</script><p>定义解向量和常数向量为</p>
<script type="math/tex; mode=display">
x = \left[ 
\begin{matrix} 
x_{1} \\ 
\vdots \\ 
x_{n}
\end{matrix} 
\right]

\qquad

b = \left[ 
\begin{matrix} 
b_{1} \\ 
\vdots \\ 
b_{n}
\end{matrix} 
\right]</script><p>既可以将方程组写成矩阵的形式$Ax=b$</p>
<p>这种表示可以与一元一次方程$ax=b$达成形式上的统一，系数矩阵和常数向量合并之后称为<code>增广矩阵</code>，比如以上的增广矩阵为</p>
<script type="math/tex; mode=display">
A = \left[ 
\begin{matrix} 
a_{11} & \cdots & x_{1n} & b_1 \\ 
\vdots & \ddots & \vdots & \vdots \\ 
x_{n1} & \cdots & x_{nn} & b_n
\end{matrix} 
\right]</script><blockquote>
<p>阿达玛积</p>
</blockquote>
<p>矩阵的阿达玛积定义为对应位置元素乘积形成的矩阵，记为$A \odot B$</p>
<blockquote>
<p>矩阵分块表示</p>
</blockquote>
<p>对于下面的矩阵</p>
<script type="math/tex; mode=display">
A =
\left[ 
\begin{matrix} 
1 & 1 & 3 & 4 & 0 & 0 & 0 \\ 
5 & 6 & 7 & 8 & 0 & 0 & 0 \\ 
9 & 10 & 11 & 12 & 0 & 0 & 0 \\ 
0 & 0 & 0 & 0 & 1 & 0 & 0 \\ 
0 & 0 & 0 & 0 & 0 & 1 & 0 \\ 
0 & 0 & 0 & 0 & 0 & 0 & 1 \\ 
0 & 0 & 0 & 0 & 1 & 1 & 1
\end{matrix} 
\right]</script><p>可以将其分块为</p>
<script type="math/tex; mode=display">
A =
\left[ 
\begin{matrix} 
A_{11} & A_{12} \\ 
A_{21} & A_{22}
\end{matrix} 
\right]</script><p>其中</p>
<script type="math/tex; mode=display">
A_{11} =
\left[ 
\begin{matrix} 
1 & 1 & 3 & 4\\ 
5 & 6 & 7 & 8\\ 
9 & 10 & 11 & 12
\end{matrix} 
\right]

\qquad

A_{12} =
\left[ 
\begin{matrix} 
0 & 0 & 0 \\ 
0 & 0 & 0 \\ 
0 & 0 & 0 
\end{matrix} 
\right]</script><script type="math/tex; mode=display">
A_{11} =
\left[ 
\begin{matrix} 
0 & 0 & 0 & 0 \\ 
0 & 0 & 0 & 0 \\ 
0 & 0 & 0 & 0 \\ 
0 & 0 & 0 & 0
\end{matrix} 
\right]

\qquad

A_{12} =
\left[ 
\begin{matrix} 
1 & 0 & 0 \\ 
0 & 1 & 0 \\ 
0 & 0 & 1 \\ 
1 & 1 & 1
\end{matrix} 
\right]</script><p>如果矩阵的<code>子矩阵</code>为$0$矩阵，或者单位矩阵等特殊类型的矩阵，这边表示会非常有效</p>
<p>如果矩阵$A,B$分块后各块的尺寸以及水平、垂直方向的块数量相容，那可以将块当做标量来计算乘积$AB$</p>
<script type="math/tex; mode=display">
\left[ 
\begin{matrix} 
A_{11} & \cdots & A_{1s} \\ 
\vdots & \ddots & \vdots \\ 
A_{r1} & \cdots & A_{ns}
\end{matrix} 
\right]

\qquad

\left[ 
\begin{matrix} 
B_{11} & \cdots & B_{1t} \\ 
\vdots & \ddots & \vdots \\ 
B_{s1} & \cdots & B_{st}
\end{matrix} 
\right]</script><p>如果各个位置处对应的两个字块尺寸相容，那么可以进行矩阵乘积运算</p>
<script type="math/tex; mode=display">
AB = 
\left[ 
\begin{matrix} 
\sum_{i=1}^{s}{A_{1i}B_{i1}} & \cdots & \sum_{i=1}^{s}{A_{1i}B_{it}} \\ 
\vdots & \ddots & \vdots \\ 
\sum_{i=1}^{s}{A_{ri}B_{i1}} & \cdots & \sum_{i=1}^{s}{A_{ri}B_{it}}
\end{matrix} 
\right]</script><p>🌰举个分块乘法的例子</p>
<script type="math/tex; mode=display">
A =
\left[ 
\begin{matrix} 
1 & 0 & 0 & 0 & 0 \\ 
0 & 1 & 0 & 0 & 0 \\ 
-1 & 2 & 1 & 0 & 0 \\ 
1 & 1 & 0 & 1 & 0 \\ 
-2 & 0 & 0 & 0 & -1
\end{matrix} 
\right]

\qquad

B =
\left[ 
\begin{matrix} 
3 & 2 & 0 & 1 & 0 \\ 
1 & 3 & 0 & 0 & 1 \\ 
-1 & 0 & 0 & 0 & 0 \\ 
0 & -1 & 0 & 0 & 0 \\ 
0 & 0 & -1 & 0 & 0
\end{matrix} 
\right]</script><p>将$A$分为4块</p>
<script type="math/tex; mode=display">
A = 
\left[ 
\begin{matrix} 
I_{2} & 0_{2 \times 3} \\ 
A_{1} & I_{3}
\end{matrix} 
\right]

\qquad

A1 = 
\left[ 
\begin{matrix} 
-1 & 2 \\ 
1 & 1 \\ 
-2 & 0
\end{matrix} 
\right]</script><p>将$B$分块为</p>
<script type="math/tex; mode=display">
B = 
\left[ 
\begin{matrix} 
B_{1} & I_{2} \\ 
-I_{3} & 0_{3 \times 2}
\end{matrix} 
\right]

\qquad

B1 = 
\left[ 
\begin{matrix} 
3 & 2 & 0 \\ 
1 & 3 & 0
\end{matrix} 
\right]</script><p>因此它们的乘积为</p>
<script type="math/tex; mode=display">
AB =

\left[ 
\begin{matrix} 
I_{2} & 0_{2 \times 3} \\ 
A_{1} & I_{3}
\end{matrix} 
\right]

\left[ 
\begin{matrix} 
B_{1} & I_{2} \\ 
-I_{3} & 0_{3 \times 2}
\end{matrix} 
\right]
= 

\left[ 
\begin{matrix} 
B_{1} & I_{2} \\ 
A_{1}B_{1}-I_3 & A_{1}
\end{matrix} 
\right]</script><p>其中</p>
<script type="math/tex; mode=display">
A_{1}B_{1}-I_3 = 

\left[ 
\begin{matrix} 
-1 & 2 \\ 
1 & 1 \\ 
-2 & 0
\end{matrix} 
\right]

\left[ 
\begin{matrix} 
3 & 2 & 0 \\ 
1 & 3 & 0
\end{matrix} 
\right]

-

\left[ 
\begin{matrix} 
1 & 0 & 0 \\ 
0 & 1 & 0 \\
0 & 0 & 1
\end{matrix} 
\right]</script><p>因此</p>
<script type="math/tex; mode=display">
AB =

\left[ 
\begin{matrix} 
3 & 2 & 0 & 1 & 0 \\ 
1 & 3 & 0 & 0 & 1 \\ 
-2 & 4 & 0 & -1 & -2 \\ 
4 & 4 & 0 & 1 & 0 \\ 
-6 & -4 & -1 & -2 & 0
\end{matrix} 
\right]</script><p>在多态正态分布中，将会对协方差矩阵进行分块</p>
<blockquote>
<p>特性</p>
</blockquote>
<p>1️⃣单位矩阵与任意矩阵的左乘和右乘都等于该矩阵本身，即</p>
<script type="math/tex; mode=display">
IA = A = AI</script><p>2️⃣矩阵$A$左乘对角矩阵$\Lambda = diag(k_1, \cdots, k_n)$相当于将$A$的第$i$行的所有元素都乘以$k_i$</p>
<script type="math/tex; mode=display">
\left[ 
\begin{matrix} 
k_{1} & 0 & \cdots & 0 \\ 
0 & k_{2} & \cdots & 0 \\ 
\cdots & \cdots & \cdots & \cdots \\ 
0 & 0 & \cdots & k_{n}
\end{matrix} 
\right]

\left[ 
\begin{matrix} 
a_{11} & a_{12} & \cdots & a_{1n} \\ 
a_{21} & a_{22} & \cdots & a_{2n} \\ 
\cdots & \cdots & \cdots & \cdots \\ 
a_{n1} & a_{n2} & \cdots & a_{nn}
\end{matrix} 
\right]

=

\left[ 
\begin{matrix} 
k_1a_{11} & k_1a_{12} & \cdots & k_1a_{1n} \\ 
k_2a_{21} & k_2a_{22} & \cdots & k_2a_{2n} \\ 
\cdots & \cdots & \cdots & \cdots \\ 
k_na_{n1} & k_na_{n2} & \cdots & k_na_{nn}
\end{matrix} 
\right]</script><p>3️⃣矩阵$A$右乘对角矩阵$\Lambda = diag(k_1, \cdots, k_n)$相当于将$A$的第$i$列的所有元素都乘以$k_i$</p>
<script type="math/tex; mode=display">
\left[ 
\begin{matrix} 
a_{11} & a_{12} & \cdots & a_{1n} \\ 
a_{21} & a_{22} & \cdots & a_{2n} \\ 
\cdots & \cdots & \cdots & \cdots \\ 
a_{n1} & a_{n2} & \cdots & a_{nn}
\end{matrix} 
\right]

\left[ 
\begin{matrix} 
k_{1} & 0 & \cdots & 0 \\ 
0 & k_{2} & \cdots & 0 \\ 
\cdots & \cdots & \cdots & \cdots \\ 
0 & 0 & \cdots & k_{n}
\end{matrix} 
\right]

=

\left[ 
\begin{matrix} 
k_1a_{11} & k_2a_{12} & \cdots & k_na_{1n} \\ 
k_1a_{21} & k_2a_{22} & \cdots & k_na_{2n} \\ 
\cdots & \cdots & \cdots & \cdots \\ 
k_1a_{n1} & k_2a_{n2} & \cdots & k_na_{nn}
\end{matrix} 
\right]</script><p>4️⃣向量组<script type="math/tex">x_1, x_2, \cdots, x_n</script>的格拉姆矩阵可以写成一个矩阵与其转置的乘积</p>
<script type="math/tex; mode=display">
G = \left[ 
\begin{matrix} 
x_{1}^T \\ 
\vdots \\ 
x_{n}^T
\end{matrix} 
\right]

\left[ 
\begin{matrix} 
x_{1} & \cdots & x_{n}
\end{matrix} 
\right]

= X^TX</script><p>其中<script type="math/tex">X=\left[ \begin{matrix} x_{1} & \cdots & x_{n} \end{matrix} \right]</script>是所有向量按列形成的矩阵</p>
<p>5️⃣矩阵的乘法满足结合律</p>
<script type="math/tex; mode=display">
(AB)C = A(BC)</script><p>这些由标量乘法的结合律可推得</p>
<p>6️⃣矩阵乘法和加法满足左分配律和右分配律</p>
<script type="math/tex; mode=display">
A(B+C) = AB+AC \qquad (A+B)C=AC+BC</script><p>注意矩阵的乘法不满足交换律，即一般情况下$AB \neq BA$</p>
<p>7️⃣矩阵乘法和转置满足<code>穿脱原则</code></p>
<script type="math/tex; mode=display">
(AB)^T = B^TA^T</script><h2 id="逆矩阵"><a href="#逆矩阵" class="headerlink" title="逆矩阵"></a>逆矩阵</h2><blockquote>
<p>定义</p>
</blockquote>
<p><code>逆矩阵</code>对应标量的倒数运算，对于$n$阶矩阵$A$，如果存在另一个$n$阶矩阵$B$，使得它们的乘积为单位矩阵</p>
<script type="math/tex; mode=display">
AB=I \qquad BAI</script><p>对于$AB=I$，$B$称为$A$的右逆矩阵，对于$BA=I$，$B$称为$A$的左逆矩阵</p>
<blockquote>
<p>如果矩阵的左逆矩阵和右逆矩阵存在，则它们相等，统称为矩阵的逆，记为$A^{-1}$</p>
</blockquote>
<p>假设$B_1$是$A$的左逆，$B_2$是$A$的右逆，则有</p>
<script type="math/tex; mode=display">
B_1AB_2 = (B_1A)B_2=IB_2=B_2 \qquad B_1AB_2=B_1(AB_2)=B_1I=B_1</script><p>因此$B_1=B_2$</p>
<blockquote>
<p>非奇异矩阵和奇异矩阵</p>
</blockquote>
<p>如果矩阵的逆矩阵存在，则称其<code>可逆(Invertable)</code>。可逆矩阵也称为<code>非奇异矩阵</code>，不可逆矩阵也称为<code>奇异矩阵</code></p>
<blockquote>
<p>如果矩阵可逆，则其逆矩阵唯一</p>
</blockquote>
<p>假设$B$和$C$都是$A$的逆矩阵，则有$AB=BA=I$和$AC=CA-I$</p>
<p>从而有$CAB=(CA)B=IB=B$和$CAB=C(AB)=CI=C$，因此B=C</p>
<p>对于线性方程组，如果能得到系数矩阵的逆矩阵，方程两边同乘以该逆矩阵，可以得到方程的解</p>
<script type="math/tex; mode=display">
A^{-1}Ax = A^{-1}b \Rightarrow x=A^{-1}b</script><p>这与一元一次方程的求解形式上是统一的$ax=b \Rightarrow x=a^{-1b}$</p>
<blockquote>
<p>如果对角矩阵$A$的主对角线非$0$，则其逆矩阵存在，且逆矩阵为对角矩阵，主对角线元素为矩阵$A$的主对角线元素的逆</p>
</blockquote>
<script type="math/tex; mode=display">
\left[ 
\begin{matrix} 
a_{11} & \cdots & 0 \\ 
\vdots & \ddots & \vdots \\ 
0 & \cdots & a_{nn}
\end{matrix} 
\right] ^{-1}

= 
\left[ 
\begin{matrix} 
a_{11}^{-1} & \cdots & 0 \\ 
\vdots & \ddots & \vdots \\ 
0 & \cdots & a_{nn}^{-1}
\end{matrix} 
\right]</script><p>可以推出，上三角矩阵的逆矩阵仍然是上三角矩阵</p>
<script type="math/tex; mode=display">
(AB)^{-1} = B^{-1}A^{-1} \qquad (A^{-1})^{-1} = A</script><script type="math/tex; mode=display">
(A^T)^{-1} = (A^{-1})^T  \qquad (\lambda A)^{-1} = \lambda ^{-1} A^{-1}</script><p>第1个等式与矩阵乘法的转置类似</p>
<script type="math/tex; mode=display">
(AB)(B^{-1}A^{-1}) = ABB^{-1}A^{-1} = A(BB^{-1})A^{-1} = AIA^{-1} = AA^{-1} = I</script><p>因此第1个等式成立，这里利用了矩阵乘法的结合律</p>
<p>由于$AA^{-1}=I$根据逆矩阵的定义，第2个等式成立</p>
<p>由于$(A^{-1})^TA^T = (AA^{-1})^T = I^T = I$根据逆矩阵的定义，第3个等式成立</p>
<p>该等式可以证明对称矩阵的逆矩阵也是对称矩阵，用类似的方法可以证明第4个等式成立</p>
<blockquote>
<p>矩阵的秩</p>
</blockquote>
<p>矩阵的<code>秩</code>定义为矩阵线性无关的行向量或列向量的最大数量，记为$r(A)$</p>
<script type="math/tex; mode=display">
\left[ 
\begin{matrix} 
1 & 2 & 0 & 0 \\ 
1 & 0 & 0 & 0 \\ 
0 & 0 & 0 & 0 \\ 
0 & 0 & 0 & 0
\end{matrix} 
\right]</script><p>该矩阵秩为$2$，该矩阵的极大线性无关组为矩阵的前两个行向量或列向量</p>
<p>如果$n$阶方阵的秩为$n$，则称其<code>满秩</code>，矩阵可逆的充分必零条件是满秩</p>
<p>对于$m \times n$的矩阵$A$，其秩满足$r(A) \leq min(m,n)$，即矩阵的秩不超过其行数和列数的较小值</p>
<blockquote>
<p>矩阵的秩相关结论</p>
</blockquote>
<script type="math/tex; mode=display">
r(A) = r(A^T) \qquad r(A+B) \leq r(A)+r(B) \qquad r(AB) \leq min(r(A),r(B))</script><blockquote>
<p>初等行变换</p>
</blockquote>
<p>所谓矩阵的初等行变换是指以下3种变换</p>
<ol>
<li><p>用一个非零的数$k$乘矩阵的某一行</p>
<script type="math/tex; mode=display">
\left[ 
\begin{matrix} 
1 & 2 & 3 \\ 
4 & 5 & 6 \\ 
7 & 8 & 9
\end{matrix} 
\right]

\overset {r_1 \times 2}{\longrightarrow}

\left[ 
\begin{matrix} 
2 & 4 & 6 \\ 
4 & 5 & 6 \\ 
7 & 8 & 9
\end{matrix} 
\right]</script></li>
<li><p>把矩阵的某一行的$k$倍加到另一行，这里的$k$是任意实数</p>
<script type="math/tex; mode=display">
\left[ 
\begin{matrix} 
1 & 2 & 3 \\ 
4 & 5 & 6 \\ 
7 & 8 & 9
\end{matrix} 
\right]

\overset {r_2 + r_1 \times 2}{\longrightarrow}

\left[ 
\begin{matrix} 
1 & 2 & 3 \\ 
6 & 9 & 12 \\ 
7 & 8 & 9
\end{matrix} 
\right]</script></li>
<li><p>互换矩阵的两行</p>
<script type="math/tex; mode=display">
\left[ 
\begin{matrix} 
1 & 2 & 3 \\ 
4 & 5 & 6 \\ 
7 & 8 & 9
\end{matrix} 
\right]

\overset {r_2 \leftrightarrow r_3 }{\longrightarrow}

\left[ 
\begin{matrix} 
1 & 2 & 3 \\ 
7 & 8 & 9 \\
4 & 5 & 6
\end{matrix} 
\right]</script></li>
</ol>
<p>🌴<code>初等变换</code>是单位矩阵$I$经过一次初等变换之后得到的矩阵</p>
<ol>
<li><p>对于第一种初等行变化，对应的初等矩阵和逆矩阵分别如下，这意味着将单位矩阵的第$i$行乘以$k$，然后再乘以$\frac{1}{k}$，将变为单位矩阵</p>
<script type="math/tex; mode=display">
\left[ 
\begin{matrix} 
1 &   &   &   &   &   &   \\ 
 & \ddots  &   &   &   &   &   \\ 
 &   & 1 &   &   &   &   \\ 
 &   &   & k &   &   &   \\ 
 &   &   &   & 1 &   &   \\ 
 &   &   &   &   & \ddots &   \\ 
 &   &   &   &   &   & 1 
\end{matrix} 
\right]

\qquad

\left[ 
\begin{matrix} 
1 &   &   &   &   &   &   \\ 
 & \ddots  &   &   &   &   &   \\ 
 &   & 1 &   &   &   &   \\ 
 &   &   & \frac{1}{k} &   &   &   \\ 
 &   &   &   & 1 &   &   \\ 
 &   &   &   &   & \ddots &   \\ 
 &   &   &   &   &   & 1 
\end{matrix} 
\right]</script></li>
<li><p>对于第二种初等行变化，对应的初等矩阵和逆矩阵分别如下，意味着将单位矩阵的第$i$行乘以$k$之后加到第$j$行，然后再将第$i$行乘以$-k$之后加到第$j$行，将变为单位矩阵</p>
<script type="math/tex; mode=display">
\left[ 
\begin{matrix} 
1 &   &   &   &   &   &   \\ 
 & \ddots  &   &   &   &   &   \\ 
 &   & 1 &   &   &   &   \\ 
 &   & \vdots & k &   &   &   \\ 
 &   & k & \cdots & 1 &   &   \\ 
 &   &   &   &   & \ddots &   \\ 
 &   &   &   &   &   & 1 
\end{matrix} 
\right]

\qquad

\left[ 
\begin{matrix} 
1 &   &   &   &   &   &   \\ 
 & \ddots  &   &   &   &   &   \\ 
 &   & 1 &   &   &   &   \\ 
 &   & \vdots & k &   &   &   \\ 
 &   & -k & \cdots & 1 &   &   \\ 
 &   &   &   &   & \ddots &   \\ 
 &   &   &   &   &   & 1 
\end{matrix} 
\right]</script></li>
<li><p>对于第三种初等行变化，对应的初等矩阵和逆矩阵相等，这意味着，将单位矩阵的第$i$行和$j$行互换，然后再互换一次，将变为单位矩阵</p>
<script type="math/tex; mode=display">
\left[ 
\begin{matrix} 
1 &   &   &   &   &   &   \\ 
 & \ddots  &   &   &   &   &   \\ 
 &   & 0 & \cdots & 1 &   &   \\ 
 &   & \vdots & \ddots & \vdots &   &   \\ 
 &   & 1 & \cdots & 0 &   &   \\ 
 &   &   &   &   & \ddots &   \\ 
 &   &   &   &   &   & 1 
\end{matrix} 
\right]</script></li>
<li></li>
</ol>
<p>🍒对矩阵做初等变换，等价于左乘对应的初等矩阵</p>
<ol>
<li><p>对于第一种行变换</p>
<script type="math/tex; mode=display">
\left[ 
\begin{matrix} 
1 & 0 & 0 \\ 
0 & k & 0 \\
0 & 0 & 1
\end{matrix} 
\right]

\left[ 
\begin{matrix} 
a_{11} & a_{12} & a_{13} \\ 
a_{21} & a_{22} & a_{23} \\
a_{31} & a_{32} & a_{33}
\end{matrix} 
\right]

=

\left[ 
\begin{matrix} 
a_{11} & a_{12} & a_{13} \\ 
ka_{21} & ka_{22} & ka_{23} \\
a_{31} & a_{32} & a_{33}
\end{matrix} 
\right]</script></li>
<li><p>对于第二种行变换</p>
<script type="math/tex; mode=display">
\left[ 
\begin{matrix} 
1 & 0 & 0 \\ 
0 & 1 & 0 \\
0 & k & 1
\end{matrix} 
\right]

\left[ 
\begin{matrix} 
a_{11} & a_{12} & a_{13} \\ 
a_{21} & a_{22} & a_{23} \\
a_{31} & a_{32} & a_{33}
\end{matrix} 
\right]

=

\left[ 
\begin{matrix} 
a_{11} & a_{12} & a_{13} \\ 
a{21} & a_{22} & a_{23} \\
a_{31}+ka_{21} & a_{32}+ka_{22} & a_{33}+ka_{23}
\end{matrix} 
\right]</script></li>
<li><p>对于第三种行变换</p>
<script type="math/tex; mode=display">
\left[ 
\begin{matrix} 
0 & 1 & 0 \\ 
1 & 0 & 0 \\
0 & 0 & 1
\end{matrix} 
\right]

\left[ 
\begin{matrix} 
a_{11} & a_{12} & a_{13} \\ 
a_{21} & a_{22} & a_{23} \\
a_{31} & a_{32} & a_{33}
\end{matrix} 
\right]

=

\left[ 
\begin{matrix} 
a_{21} & a_{22} & a_{23} \\
a_{11} & a_{12} & a_{13} \\ 
a_{31} & a_{32} & a_{33}
\end{matrix} 
\right]</script></li>
<li></li>
</ol>
<blockquote>
<p>初等行变换计算逆矩阵</p>
</blockquote>
<p>如果矩阵$A$可逆，则可以利用初等行变换将其变换为单位矩阵，对应于一次左乘初等矩阵$P1,P2,\cdots,P_s$</p>
<script type="math/tex; mode=display">
P_s \cdots P_2P_! A = I</script><p>两侧同时右乘$A^{-1}$可以得到<script type="math/tex">P_s \cdots P_2P_! I = A^{-1}</script></p>
<p>这意味着同样的初等行变换序列，在将矩阵$A$化为单位矩阵的同时，可将矩阵$I$化为$A^{-1}$，这就是逆矩阵</p>
<p>🌰用初等行变换求解$A$的逆矩阵</p>
<script type="math/tex; mode=display">
A =

\left[ 
\begin{matrix} 
2 & 3 & 1 \\ 
0 & 1 & 3 \\
1 & 2 & 5
\end{matrix} 
\right]</script><p>求解过程如下</p>
<script type="math/tex; mode=display">
\left[ \begin{matrix} A & I\end{matrix} \right]
=

\left[ 
\begin{matrix} 
2 & 3 & 1 & 1 & 0 & 0 \\ 
0 & 1 & 3 & 0 & 1 & 0 \\
1 & 2 & 5 & 0 & 0 & 1
\end{matrix} 
\right]

\overset {r_1与r_3互换 }{\longrightarrow}

\left[ 
\begin{matrix} 
1 & 2 & 5 & 0 & 0 & 1 \\ 
0 & 1 & 3 & 0 & 1 & 0 \\
2 & 3 & 1 & 1 & 0 & 0
\end{matrix} 
\right]

\overset {r_3-2 \times r_1 }{\longrightarrow}

\left[ 
\begin{matrix} 
1 & 2 & 5 & 0 & 0 & 1 \\ 
0 & 1 & 3 & 0 & 1 & 0 \\
0 & -1 & -9 & 1 & 0 & -2
\end{matrix} 
\right]</script><script type="math/tex; mode=display">
\overset {r_3+r_2}{\longrightarrow}

\left[ 
\begin{matrix} 
1 & 2 & 5 & 0 & 0 & 1 \\ 
0 & 1 & 3 & 0 & 1 & 0 \\
0 & 0 & -6 & 1 & 1 & -2
\end{matrix} 
\right]

\overset {r_3 \times (-\frac{1}{6})}{\longrightarrow}

\left[ 
\begin{matrix} 
1 & 2 & 5 & 0 & 0 & 1 \\ 
0 & 1 & 3 & 0 & 1 & 0 \\
0 & 0 & 1 & -\frac{1}{6} & -\frac{1}{6} & \frac{1}{3}
\end{matrix} 
\right]


\overset {r_2 - r_3 \times 3}{\longrightarrow}

\left[ 
\begin{matrix} 
1 & 2 & 5 & 0 & 0 & 1 \\ 
0 & 1 & 0 & \frac{1}{2} & \frac{2}{3} & -1 \\
0 & 0 & 1 & -\frac{1}{6} & -\frac{1}{6} & \frac{1}{3}
\end{matrix} 
\right]</script><script type="math/tex; mode=display">
\overset {r_1 - r_3 \times 5}{\longrightarrow}

\left[ 
\begin{matrix} 
1 & 2 & 0 & \frac{5}{6} & \frac{5}{6} & -\frac{2}{3} \\ 
0 & 1 & 0 & \frac{1}{2} & \frac{2}{3} & -1 \\
0 & 0 & 1 & -\frac{1}{6} & -\frac{1}{6} & \frac{1}{3}
\end{matrix} 
\right]

\overset {r_1 - r_2 \times 2}{\longrightarrow}

\left[ 
\begin{matrix} 
1 & 1 & 0 & -\frac{1}{6} & -\frac{13}{6} & \frac{4}{3} \\ 
0 & 1 & 0 & \frac{1}{2} & \frac{2}{3} & -1 \\
0 & 0 & 1 & -\frac{1}{6} & -\frac{1}{6} & \frac{1}{3}
\end{matrix} 
\right]</script><blockquote>
<p>python的linalg库中的inv函数实现了逆矩阵的计算</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">A = np.array([[<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>], [<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>], [<span class="number">0</span>,<span class="number">0</span>,<span class="number">5</span>]])</span><br><span class="line">B = np.linalg.inv(A)</span><br></pre></td></tr></table></figure>
<script type="math/tex; mode=display">
A^{-1} =

\left[ 
\begin{matrix} 
1 & 0 & 0 \\ 
0 & 1 & 0 \\
0 & 0 & 5
\end{matrix} 
\right]^{-1}

=

\left[ 
\begin{matrix} 
1 & 0 & 0 \\ 
0 & 1 & 0 \\
0 & 0 & 0.2
\end{matrix} 
\right]</script><blockquote>
<p>正交矩阵</p>
</blockquote>
<p>如果一个方阵满足</p>
<script type="math/tex; mode=display">
AA^T=A^TA=I</script><p>则称为正交矩阵，正交矩阵的行向量均为单位向量且<code>相互正交</code>，构成<code>标准正交基</code>，对于矩阵按行分块，有</p>
<script type="math/tex; mode=display">
A A^{\mathrm{T}}=\left(\begin{array}{c}
a_{1} \\
a_{2} \\
\vdots \\
a_{n}
\end{array}\right)\left(\begin{array}{llll}
a_{1}^{\mathrm{T}} & a_{2}^{\mathrm{T}} & \cdots & \boldsymbol{a}_{n}^{\mathrm{T}}
\end{array}\right)=\left(\begin{array}{cccc}
\boldsymbol{a}_{1} a_{1}^{\mathrm{T}} & \boldsymbol{a}_{1} \boldsymbol{a}_{2}^{\mathrm{T}} & \cdots & \boldsymbol{a}_{1} a_{n}^{\mathrm{T}} \\
\boldsymbol{a}_{2} a_{1}^{\mathrm{T}} & a_{2} a_{2}^{\mathrm{T}} & \cdots & a_{2} a_{n}^{\mathrm{T}} \\
\vdots & \vdots & & \vdots \\
a_{n} a_{1}^{\mathrm{T}} & \boldsymbol{a}_{n} \boldsymbol{a}_{2}^{\mathrm{T}} & \cdots & \boldsymbol{a}_{n} a_{n}^{\mathrm{T}}
\end{array}\right)=\left(\begin{array}{cccc}
1 & 0 & \cdots & 0 \\
0 & 1 & \cdots & 0 \\
\vdots & \vdots & & \vdots \\
0 & 0 & \cdots & 1
\end{array}\right)</script><p>因此有</p>
<script type="math/tex; mode=display">
\begin{array}{l}
a_{i} a_{i}^{\mathrm{T}}=1 \\
a_{i} a_{j}^{\mathrm{T}}=0, i \neq j
\end{array}</script><ul>
<li>如果一个矩阵是正交矩阵，根据逆矩阵的定义，有</li>
</ul>
<script type="math/tex; mode=display">
\boldsymbol{A}^{-1}=\boldsymbol{A}^{\mathrm{T}}</script><p>下面是一个正交矩阵的例子</p>
<script type="math/tex; mode=display">
\left(\begin{array}{cc}
\frac{1}{\sqrt{2}} & -\frac{1}{\sqrt{2}} \\
\frac{1}{\sqrt{2}} & \frac{1}{\sqrt{2}}
\end{array}\right)</script><p>可以验证其行向量和列向量均为单位向量，且相互正交</p>
<ul>
<li>正交矩阵的乘积仍然是正交矩阵，如果</li>
</ul>
<script type="math/tex; mode=display">
\begin{array}{l}
\boldsymbol{A}^{-1}=\boldsymbol{A}^{\mathrm{T}} \\
\boldsymbol{B}^{-1}=\boldsymbol{B}^{\mathrm{T}}
\end{array}</script><p>则</p>
<script type="math/tex; mode=display">
(\boldsymbol{A B})^{-1}=\boldsymbol{B}^{-1} \boldsymbol{A}^{-1}=\boldsymbol{B}^{\mathrm{T}} \boldsymbol{A}^{\mathrm{T}}=(\boldsymbol{A B})^{\mathrm{T}}</script><ul>
<li>正交矩阵的逆矩阵仍然是正交矩阵。如果有</li>
</ul>
<script type="math/tex; mode=display">
\boldsymbol{A}^{-1}=\boldsymbol{A}^{\mathrm{T}}</script><p>则</p>
<script type="math/tex; mode=display">
\left(\boldsymbol{A}^{-1}\right)^{-1}=\left(\boldsymbol{A}^{\mathrm{T}}\right)^{-1}=\left(\boldsymbol{A}^{-1}\right)^{\mathrm{T}}</script><ul>
<li>正交矩阵的转置仍然是正交矩阵，因为</li>
</ul>
<script type="math/tex; mode=display">
A^{-1}=A^{\mathrm{T}}</script><p>而$A^{-1}$是正交矩阵，因此$A^{\mathrm{T}}$也是正交矩阵</p>
<h2 id="矩阵的范数"><a href="#矩阵的范数" class="headerlink" title="矩阵的范数"></a>矩阵的范数</h2><blockquote>
<p>诱导范数</p>
</blockquote>
<p>矩阵$\boldsymbol{W}$的范数定义为</p>
<script type="math/tex; mode=display">
\|\boldsymbol{W}\|_{p}=\max _{\boldsymbol{x} \neq 0} \frac{\|\boldsymbol{W} \boldsymbol{x}\|_{p}}{\|\boldsymbol{x}\|_{p}}</script><p>该范数通过向量的L-p范数定义，因此也称为<code>诱导范数</code>(Induced Norm)</p>
<p>式中右侧分母为向量$x$的L-p范数，分子是经过矩阵对应的线性映射作用之后的向量的L-p范数</p>
<p>因此诱导范数的几何意义是矩阵所代表的线性变换对向量进行变换后，向量长度的最大拉伸倍数</p>
<blockquote>
<p>谱范数</p>
</blockquote>
<p>如果$p=2$，此时诱导范数你为<code>谱范数</code>(Spectral Norm)</p>
<script type="math/tex; mode=display">
\|\boldsymbol{W}\|=\max _{\boldsymbol{x} \neq 0} \frac{\|\boldsymbol{W} \boldsymbol{x}\|}{\|\boldsymbol{x}\|}</script><blockquote>
<p>F范数</p>
</blockquote>
<p>矩阵的<code>Frobenius范数</code>(F范数)定义为</p>
<script type="math/tex; mode=display">
\|\boldsymbol{W}\|_{F}=\sqrt{\sum_{i=1}^{m} \sum_{j=1}^{n} w_{i j}^{2}}</script><p>这等价于向量的L2范数，将矩阵按行或列展开之后形成向量，然后计算L2范数</p>
<p>对于下面的矩阵</p>
<script type="math/tex; mode=display">
\boldsymbol{A}=\left(\begin{array}{lll}
1 & 2 & 3 \\
4 & 5 & 6
\end{array}\right)</script><p>其$\mathrm{F}$范数为</p>
<script type="math/tex; mode=display">
\|\boldsymbol{A}\|_{F}=\sqrt{1^{2}+2^{2}+3^{2}+4^{2}+5^{2}+6^{2}}=\sqrt{91}</script><p>根据<code>柯西不等式</code>，对于任意的$\boldsymbol{x}$，下面不等式成立</p>
<script type="math/tex; mode=display">
\|\boldsymbol{W} \boldsymbol{x}\| \leqslant\|\boldsymbol{W}\|_{F} \cdot\|\boldsymbol{x}\|</script><p>如果$x \neq 0$，上式两边同时除以$|x|$可以得到</p>
<script type="math/tex; mode=display">
\frac{\|\boldsymbol{W} \boldsymbol{x}\|}{\|\boldsymbol{x}\|} \leqslant\|\boldsymbol{W}\|_{F}</script><p>因此$(\mathrm{F}$范数)是谱范数的一个上界</p>
<p>矩阵的范数对于分析线性映射函数的特性有重要的作用，典型的应用是深度神经网络稳定性与泛化性能的分析</p>
<h2 id="线性变换"><a href="#线性变换" class="headerlink" title="线性变换"></a>线性变换</h2><blockquote>
<p>定义</p>
</blockquote>
<p>矩阵与向量的乘法可以解释为<code>线性变换</code>(Linear Transformation)，它将一个向量变成另外一个向量</p>
<p>对于线性空间$X$，如果在其上定义了一种变换(即映射)$A$，对任意$\boldsymbol{x} 、 y \in X$以及数域中的数$k$均满足</p>
<script type="math/tex; mode=display">
A(x+y)=A(x)+A(y)</script><p>以及</p>
<script type="math/tex; mode=display">
A(k x)=k A(x)</script><p>即对加法和数乘具有线性关系，则称这种映射为线性变换</p>
<blockquote>
<p>线性变换对向量的加法与数乘运算具有线性</p>
</blockquote>
<p>矩阵乘法是一种线性变换，它满足线性变换的定义要求，对任意的向量$x, y \in \mathbb{R}^{n}$以及实数$k$有</p>
<script type="math/tex; mode=display">
\boldsymbol{A}(\boldsymbol{x}+\boldsymbol{y})=\boldsymbol{A} \boldsymbol{x}+\boldsymbol{A} y \qquad \boldsymbol{A}(k \boldsymbol{x})=k \boldsymbol{A} \boldsymbol{x}</script><p>几何中的旋转变换是一种线性变换，下面以二维平面的旋转为例进行说明</p>
<p>对于二维平面内的向量<script type="math/tex">\boldsymbol{x}=\left(x_{1} x_{2}\right)^{\mathrm{T}}</script>，其在极坐标系下的坐标为<script type="math/tex">(r \theta)^{\mathrm{T}}</script>，从极坐标系到直角坐标系的转换公式为</p>
<script type="math/tex; mode=display">
x_{1}=r \cos \theta \qquad x_{2}=r \sin \theta</script><p>将极坐标为$(r \quad \alpha)^{\mathrm{T}}$的向量<script type="math/tex">\boldsymbol{x}=\left(\begin{array}{lll}x_{1} & x_{2}\end{array}\right)^{\mathrm{T}}</script>逆时针旋转$\alpha$度之后的结果向量$\boldsymbol{x}^{\prime}$的极坐标为<script type="math/tex">(r \alpha+\theta)^{\mathrm{T}}</script>，其直角坐标为</p>
<script type="math/tex; mode=display">
\begin{aligned}
\boldsymbol{x}^{\prime} & =(r \cos (\alpha+\theta) r \sin (\alpha+\theta))^{\mathrm{T}} \\
& =(r \cos (\alpha) \cos (\theta)-r \sin (\alpha) \sin (\theta) r \sin (\alpha) \cos (\theta)+r \cos (\alpha) \sin (\theta))^{\mathrm{T}} \\
& =\left(x_{1} \cos (\theta)-x_{2} \sin (\theta) x_{2} \cos (\theta)+x_{1} \sin (\theta)\right)^{\mathrm{T}} \\
& =\left(\begin{array}{cc}
\cos \theta & -\sin \theta \\
\sin \theta & \cos \theta
\end{array}\right)\left(\begin{array}{l}
x_{1} \\
x_{2}
\end{array}\right)
\end{aligned}</script><p>因此旋转变换的变换矩阵为</p>
<script type="math/tex; mode=display">
\boldsymbol{A}=\left(\begin{array}{cc}
\cos \theta & -\sin \theta \\
\sin \theta & \cos \theta
\end{array}\right)</script><blockquote>
<p>正交变换</p>
</blockquote>
<p>如果一个线性变换能保持向量之间的角度以及向量的长度不变，即变换之后两个向量的夹角不变，且向量的长度不变，则称为<code>正交变换</code>，正交变换对应的矩阵是<code>正交矩阵</code></p>
<p>下面给出证明: 如果$\boldsymbol{A}$是正交矩阵，使用它对向量$\boldsymbol{x}$进行变换之后的向量长度为</p>
<script type="math/tex; mode=display">
\|\boldsymbol{A} \boldsymbol{x}\|=\sqrt{(\boldsymbol{A x})^{\mathrm{T}}(\boldsymbol{A x})}=\sqrt{\boldsymbol{x}^{\mathrm{T}} \boldsymbol{A}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{x}}=\sqrt{\boldsymbol{x}^{\mathrm{T}}\left(\boldsymbol{A}^{\mathrm{T}} \boldsymbol{A}\right) \boldsymbol{x}}=\sqrt{\boldsymbol{x}^{\mathrm{T}} \boldsymbol{x}}=\|\boldsymbol{x}\|</script><p>变换之后向量长度不变，对向量$\boldsymbol{x}$和$\boldsymbol{y}$变换之后的内积为</p>
<script type="math/tex; mode=display">
(\boldsymbol{A} \boldsymbol{x})^{\mathrm{T}}(\boldsymbol{A} \boldsymbol{y})=\boldsymbol{x}^{\mathrm{T}} \boldsymbol{A}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{y}=\boldsymbol{x}^{\mathrm{T}}\left(\boldsymbol{A}^{\mathrm{T}} \boldsymbol{A}\right) \boldsymbol{y}=\boldsymbol{x}^{\mathrm{T}} \boldsymbol{y}</script><p>根据向量夹角公式</p>
<script type="math/tex; mode=display">
\cos \theta=\frac{\boldsymbol{x}^{\mathrm{T}} \boldsymbol{y}}{\|\boldsymbol{x}\|\|\boldsymbol{y}\|}</script><p>内积和向量长度均不变，因此保持向量夹角不变</p>
<p>旋转变换是正交变换，以二维平面的旋转矩阵为例，有</p>
<script type="math/tex; mode=display">
\begin{aligned}
\boldsymbol{A}^{\mathrm{T}} \boldsymbol{A} & =\left(\begin{array}{cc}
\cos \theta & \sin \theta \\
-\sin \theta & \cos \theta
\end{array}\right)\left(\begin{array}{cc}
\cos \theta & -\sin \theta \\
\sin \theta & \cos \theta
\end{array}\right) \\
& =\left(\begin{array}{cc}
\cos ^{2} \theta+\sin ^{2} \theta & -\cos \theta \sin \theta+\sin \theta \cos \theta \\
-\sin \theta \cos \theta+\cos \theta \sin \theta & \sin ^{2} \theta+\cos ^{2} \theta
\end{array}\right)=\left(\begin{array}{ll}
1 & 0 \\
0 & 1
\end{array}\right)
\end{aligned}</script><p>旋转变换矩阵是正交矩阵，因此旋转变换是正交变换</p>
<p>几何中的缩放变换也是一种线性变换，对于二维平面的向量<script type="math/tex">\boldsymbol{x}=\left(\begin{array}{lll}x_{1} & x_{2}\end{array}\right)^{\mathrm{T}}</script>，如果有下面的缩放变换矩阵</p>
<script type="math/tex; mode=display">
\boldsymbol{A}=\left(\begin{array}{ll}
2 & 0 \\
0 & 3
\end{array}\right)</script><p>则变换之后的向量为</p>
<script type="math/tex; mode=display">
\boldsymbol{x}^{\prime}=\boldsymbol{A} \boldsymbol{x}=\left(\begin{array}{ll}
2 & 0 \\
0 & 3
\end{array}\right)\left(\begin{array}{l}
x_{1} \\
x_{2}
\end{array}\right)=\left(\begin{array}{l}
2 x_{1} \\
3 x_{2}
\end{array}\right)</script><p>这相当于在<script type="math/tex">x_{1}</script>方向拉伸2倍，在<script type="math/tex">x_{2}</script>方向拉伸3倍</p>
<p>缩放变换对应的矩阵为对角矩阵，主对角线元素为在该方向上的拉伸倍数，如果为负，则表示反向</p>
<p>缩放变换和旋转变换被广泛应用于数字图像处理、计算机图形学，以及机器视觉等领域，实现对几何体和图像的旋转和缩放等操作</p>
<h1 id="行列式"><a href="#行列式" class="headerlink" title="行列式"></a>行列式</h1><p><code>行列式</code>(Determinant, det)是对矩阵的一种运算，它作用于方阵，将其映射成一个标量</p>
<h2 id="行列式的定义与性质"><a href="#行列式的定义与性质" class="headerlink" title="行列式的定义与性质"></a>行列式的定义与性质</h2><p>$n$阶方阵$\boldsymbol{A}$的行列式记为$|\boldsymbol{A}|$或$\operatorname{det}(\boldsymbol{A})$，称为$n$阶行列式。计算公式为</p>
<script type="math/tex; mode=display">
|\boldsymbol{A}|=\left|\begin{array}{cccc}
a_{11} & a_{12} & \cdots & a_{1 n} \\
a_{21} & a_{22} & \cdots & a_{2 n} \\
\vdots & \vdots & & \vdots \\
a_{n_{1}} & a_{n 2} & \cdots & a_{n n}
\end{array}\right|=\sum_{j_{1} j_{2} \cdots j_{n} \in S_{n}}(-1)^{\tau\left(j_{1} j_{2} \cdots j_{n}\right)} \prod_{i=1}^{n} a_{i, j j_{1}}</script><p>其中<script type="math/tex">j_{1} j_{2} \cdots j_{n}</script>为正整数$1,2, \cdots, n$的一个排列，$S_{n}$是这$n$个正整数所有排列构成的集合， 显然有<script type="math/tex">n !</script> 种排列</p>
<p>这里<script type="math/tex">\tau\left(j_{1} j_{2} \cdots j_{n}\right)</script>为排列<script type="math/tex">j_{1} j_{2} \cdots j_{n}</script>的逆序数</p>
<p>对于一个排列<script type="math/tex">j_{1} j_{2} \cdots j_{n}</script>，如果<script type="math/tex">m<n</script>，但<script type="math/tex">j_{m}>j_{n}</script>，则称为一个逆序</p>
<p>排列中所有逆序的数量称为排列的逆序数</p>
<p>下面举例说明，对于3个正整数$1,2,3$，其所有排列的集合$S_{n}$为</p>
<script type="math/tex; mode=display">
\begin{array}{lll}
1,2,3 & 1,3,2 & 2,1,3 \\
2,3,1 & 3,1,2 & 3,2,1
\end{array}</script><p>排列$3,2,1$的所有逆序为</p>
<script type="math/tex; mode=display">
(3,2),(2,1),(3,1)</script><p>因此其逆序数为3</p>
<p>排列$2,1,3$的所有逆序为</p>
<script type="math/tex; mode=display">
(2,1)</script><p>因此其逆序数为1</p>
<p>根据定义，$n$阶行列式的求和项有$n!$ 项，每个求和项中的<script type="math/tex">\prod_{i=1}^{n} a_{i, j_{i}}</script>表示按行号递增的顺序从$\boldsymbol{A}$的每一行各抽取一个元素相乘</p>
<p>且这些元素的列号不能重复，它们的列号<script type="math/tex">j_{1} j_{2} \cdots j_{n}</script>是<script type="math/tex">1,2, \cdots, n</script>的一个排列</p>
<p>这里<script type="math/tex">(-1)^{\tau\left(j_{1} j_{2} \cdots j_{n}\right)}</script>决定了求和项的符号，它意味着如果这些元素的列号排列的逆序数为偶数，则其值为1；如果为奇数，则为-1</p>
<p>$n!$ 种排列中逆序数为奇数的排列和逆序数为偶数的排列各占一半，此求和项中正号和负号各占一半</p>
<p>下面按照定义计算3阶行列式的值</p>
<script type="math/tex; mode=display">
\begin{aligned}
\left|\begin{array}{lll}
1 & 2 & 3 \\
1 & 0 & 1 \\
1 & 1 & 0
\end{array}\right|= & (-1)^{\tau(1,2,3)} a_{11} a_{22} a_{33}+(-1)^{\tau(1,3,2)} a_{11} a_{23} a_{32}+(-1)^{\tau(2,1,3)} a_{12} a_{21} a_{33} \\
& -+(-1)^{\tau(2,3,1)} a_{12} a_{23} a_{31}+(-1)^{\tau(3,1,2)} a_{13} a_{21} a_{32}+(-1)^{\tau(3,2,1)} a_{13} a_{22} a_{31} \\
= & (-1)^{0} \times 1 \times 0 \times 0+(-1)^{1} \times 1 \times 1 \times 1+(-1)^{1} \times 2 \times 1 \times 0+(-1)^{2} \times 2 \times 1 \times 1 \\
& +(-1)^{2} \times 3 \times 1 \times 0+(-1)^{3} \times 3 \times 0 \times 1 \\
= & 1
\end{aligned}</script><p>下面推导2阶和3阶行列式的计算公式，2阶矩阵的行列式的计算公式为</p>
<script type="math/tex; mode=display">
\left|\begin{array}{ll}
a_{11} & a_{12} \\
a_{21} & a_{22}
\end{array}\right|=(-1)^{\tau(1,2)} a_{11} a_{22}+(-1)^{\tau(2,1)} a_{12} a_{21}=a_{11} a_{22}-a_{12} a_{21}</script><p>下面的2阶行列式值为</p>
<script type="math/tex; mode=display">
\left|\begin{array}{ll}
1 & 2 \\
3 & 4
\end{array}\right|=1 \times 4-2 \times 3=-2</script><p>3阶矩阵的行列式的计算公式为</p>
<script type="math/tex; mode=display">
\begin{aligned}
\left|\begin{array}{lll}
a_{11} & a_{12} & a_{13} \\
a_{21} & a_{22} & a_{23} \\
a_{31} & a_{32} & a_{33}
\end{array}\right|= & (-1)^{\tau(1,2,3)} a_{11} a_{22} a_{33}+(-1)^{\tau(2,3,1)} a_{12} a_{23} a_{31}+(-1)^{\tau(3,1,2)} a_{13} a_{21} a_{32} \\
& +(-1)^{\tau(3,2,1)} a_{13} a_{22} a_{31}+(-1)^{\tau(1,3,2)} a_{11} a_{23} a_{32}+(-1)^{\tau(2,1,3)} a_{12} a_{21} a_{33} \\
= & a_{11} a_{22} a_{33}+a_{12} a_{23} a_{31}+a_{13} a_{21} a_{32}-a_{13} a_{22} a_{31}-a_{11} a_{23} a_{32}-a_{12} a_{21} a_{33}
\end{aligned}</script><p>下面的3阶行列式值为</p>
<script type="math/tex; mode=display">
\left|\begin{array}{lll}
1 & 2 & 3 \\
4 & 5 & 6 \\
1 & 2 & 2
\end{array}\right|=1 \times 5 \times 2+2 \times 6 \times 1+3 \times 4 \times 2-3 \times 5 \times 1-1 \times 6 \times 2-2 \times 4 \times 2=3</script><p>行列式可以表示平行四边形与平行六面体的有向面积和体积，也是线性变换的伸缩因子</p>
<p>如果将方阵看作线性变换，则其行列式的绝对值表示该变换导致的体积元变化系数</p>
<p><code>雅克比行列式</code>被广泛应用于多元函数微分与积分的计算，代表了多元换元后的比例量</p>
<p>按照定义，一个行列式可以按照行或列进行递归展开，称为<code>拉普拉斯展开</code>(Laplace Expan-sion)</p>
<script type="math/tex; mode=display">
|\boldsymbol{A}|=a_{i 1} A_{i 1}+a_{i 2} A_{i 2}+\cdots+a_{i n} A_{i n}=a_{1 j} A_{1 j}+a_{2 j} A_{2 j}+\cdots+a_{n j} A_{n j}</script><p>其中</p>
<script type="math/tex; mode=display">
A_{i j}=(-1)^{i+j}\left|\begin{array}{cccccc}
a_{11} & \cdots & a_{1, j-1} & a_{1, j+1} & \cdots & a_{1 n} \\
\vdots & & \vdots & \vdots & & \vdots \\
a_{i-1,1} & \cdots & a_{i-1, j-1} & a_{i-1, j+1} & \cdots & a_{i-1, n} \\
a_{i+1,1} & \cdots & a_{i+1, j-1} & a_{i+1, j+1} & \cdots & a_{i+1, n} \\
\vdots & & \vdots & \vdots & & \vdots \\
a_{n 1} & \cdots & a_{n, j-1} & a_{n, j+1} & \cdots & a_{n n}
\end{array}\right|</script><p>是去掉矩阵$\boldsymbol{A}$的第$i$行和第$j$ 后的$n-1$阶矩阵的行列式，并且带有符号$(-1)^{i+j}, i+j$为行号和列号之和，称<script type="math/tex">A_{i j}</script>为<script type="math/tex">a_{i j}</script>的<code>代数余子式</code>，不带符号的子行列式则称为余子式</p>
<p>下面的行列式可以按第一行展开为</p>
<script type="math/tex; mode=display">
\left|\begin{array}{lll}
1 & 2 & 3 \\
1 & 0 & 1 \\
1 & 1 & 0
\end{array}\right|=1 \times(-1)^{1+1} \times\left|\begin{array}{cc}
0 & 1 \\
1 & 0
\end{array}\right|+2 \times(-1)^{1+2} \times\left|\begin{array}{cc}
1 & 1 \\
1 & 0
\end{array}\right|+3 \times(-1)^{1+3} \times\left|\begin{array}{cc}
1 & 0 \\
1 & 1
\end{array}\right|</script><blockquote>
<p>特殊行列式的值</p>
</blockquote>
<p>某一行(列)全为0的行列式值为0，根据拉普拉斯展开可以得到此结论，根据行列式的定义也可以直接得到此结果，$n!$ 个求和项中每一项都必然包含某一 行列的一个元素，根据此结论，下面的行列式值为0</p>
<script type="math/tex; mode=display">
\left|\begin{array}{lll}0 & 0 & 0 \\ 1 & 2 & 3 \\ 4 & 5 & 6\end{array}\right|=0</script><p>根据定义，如果一个矩阵为对角矩阵，则其行列式为矩阵主对角线元素的乘积，这是因为$n !$ 个求和项中，除了全部由主对角线元素构成的项之外，其他的项的乘积中都含有0</p>
<script type="math/tex; mode=display">
\left|\begin{array}{ccc}
a_{11} & 0 & 0 \\
0 & \ddots & 0 \\
0 & 0 & a_{n n}
\end{array}\right|=\prod_{i=1}^{n} a_{i i}</script><p>下面的对角矩阵的行列式值为</p>
<script type="math/tex; mode=display">
\left|\begin{array}{lll}
1 & 0 & 0 \\
0 & 2 & 0 \\
0 & 0 & 3
\end{array}\right|=1 \times 2 \times 3=6</script><p>单位矩阵的行列式为1</p>
<script type="math/tex; mode=display">
|\boldsymbol{I}|=\left|\begin{array}{ccc}
1 & \cdots & 0 \\
\vdots & \ddots & \vdots \\
0 & \cdots & 1
\end{array}\right|=1 \times 1 \times \cdots \times 1=1</script><p>上三角矩阵和下三角矩阵的行列式为其主对角线元素的乘积，这是因为$n$ ! 个求和项中，除了全部由主对角线元素构成的项之外，其他的项的乘积中都含有0</p>
<script type="math/tex; mode=display">
\left|\begin{array}{ccc}
a_{11} & \cdots & a_{1 n} \\
\vdots & \ddots & \vdots \\
0 & \cdots & a_{n n}
\end{array}\right|=\prod_{i=1}^{n} a_{i i}</script><p>根据这一结论有</p>
<script type="math/tex; mode=display">
\left|\begin{array}{lll}
1 & 4 & 6 \\
0 & 2 & 5 \\
0 & 0 & 3
\end{array}\right|=1 \times 2 \times 3=6</script><blockquote>
<p>行列式的重要性质</p>
</blockquote>
<p>行列式具有多线性，可以按照某一行或列的线性组合拆分成两个行列式之和</p>
<script type="math/tex; mode=display">
\left|\begin{array}{ccc}
a_{11} & \cdots & a_{1 n} \\
\vdots & & \vdots \\
a_{i-1,1} & \cdots & a_{i-1, n} \\
\alpha a_{i 1}+\beta b_{i 1} & \cdots & \alpha a_{i n}+\beta b_{i n} \\
a_{i+1,1} & \cdots & a_{i+1, n} \\
\vdots & & \vdots \\
a_{n 1} & \cdots & a_{n n}
\end{array}\right|=\alpha\left|\begin{array}{ccc}
a_{11} & \cdots & a_{1 n} \\
\vdots & & \vdots \\
a_{i-1,1} & \cdots & a_{i-1, n} \\
a_{i 1} & \cdots & a_{i n} \\
a_{i+1,1} & \cdots & a_{i+1, n} \\
\vdots & & \vdots \\
a_{n 1} & \cdots & a_{n n}
\end{array}\right|+\beta\left|\begin{array}{ccc}
a_{11} & \cdots & a_{1 n} \\
\vdots & & \vdots \\
a_{i-1,1} & \cdots & a_{i-1, n} \\
b_{i 1} & \cdots & b_{i n} \\
a_{i+1,1} & \cdots & a_{i+1, n} \\
\vdots & & \vdots \\
a_{n 1} & \cdots & a_{n n}
\end{array}\right|</script><p>因为</p>
<script type="math/tex; mode=display">
\left|\begin{array}{ccc}a_{11} & \cdots & a_{1 n} \\ \vdots & & \vdots \\ a_{i-1,1} & \cdots & a_{i-1, n} \\ \alpha a_{i 1}+\beta b_{i 1} & \cdots & \alpha a_{i n}+\beta b_{i n} \\ a_{i+1,1} & \cdots & a_{i+1, n} \\ \vdots & & \vdots \\ a_{n 1} & \cdots & a_{n n}\end{array}\right|=\sum_{j_{1} j_{2} \cdots j_{n}}(-1)^{\tau\left(j_{1} j_{2} \cdots j_{n}\right)} a_{1 j_{1}} \cdots\left(\alpha a_{i j}+\beta b_{i j}\right) \cdots a_{n j_{n}}
\\
= \alpha \sum _{j_1j_2 \cdots j_n}{(-1)^{\tau (j_1j_2 \cdots j_n)} } \alpha_{1j_1} \cdots \alpha_{ij_i} \cdots \alpha_{nj_n} + \beta \sum _{j_1j_2 \cdots j_n}{(-1)^{\tau (j_1j_2 \cdots j_n)} } \alpha_{1j_1} \cdots \alpha_{ij_i} \cdots \alpha_{nj_n}
\\
\begin{array}{l}
=\alpha\left|\begin{array}{ccc}
a_{11} & \cdots & a_{1 n} \\
\vdots & & \vdots \\
a_{i-1,1} & \cdots & a_{i-1, n} \\
a_{i 1} & \cdots & a_{i n} \\
a_{i+1,1} & \cdots & a_{i+1, n} \\
\vdots & & \vdots \\
a_{n 1} & \cdots & a_{n n}
\end{array}\right|+\beta\left|\begin{array}{ccc}
a_{11} & \cdots & a_{1 n} \\
\vdots & & \vdots \\
a_{i-1,1} & \cdots & a_{i-1, n} \\
b_{i 1} & \cdots & b_{i n} \\
a_{i+1,1} & \cdots & a_{i+1, n} \\
\vdots & & \vdots \\
a_{n 1} & \cdots & a_{n n}
\end{array}\right| \\
\end{array}</script><p>按照这一结论有</p>
<script type="math/tex; mode=display">
\left|\begin{array}{ccc}
1+2 & 2+3 & 3+4 \\
1 & 0 & 0 \\
0 & 1 & 1
\end{array}\right|=\left|\begin{array}{ccc}
1 & 2 & 3 \\
1 & 0 & 0 \\
0 & 1 & 1
\end{array}\right|+\left|\begin{array}{ccc}
2 & 3 & 4 \\
1 & 0 & 0 \\
0 & 1 & 1
\end{array}\right|</script><p>如果行列式的两行或列相等，那么行列式的值为0，即</p>
<script type="math/tex; mode=display">
\left|\begin{array}{ccc}
a_{11} & \cdots & a_{1 n} \\
\vdots & & \vdots \\
a_{i 1} & \cdots & a_{i n} \\
\vdots & & \vdots \\
a_{i 1} & \cdots & a_{i n} \\
\vdots & & \vdots \\
a_{n 1} & \cdots & a_{n n}
\end{array}\right|=0</script><p>下面给出证明，假设行列式的第$i$行和第$k$行相等，$n!$ 个求和项可以分成两组，即</p>
<script type="math/tex; mode=display">
(-1)^{\tau\left(j_{1} \cdots j_{i} \cdots j_{k} \cdots j_{n}\right)} a_{1 j_{1}} \cdots a_{i j_{i}} \cdots a_{k j_{k}} \cdots a_{n j_{n}}</script><p>与</p>
<script type="math/tex; mode=display">
(-1)^{\tau\left(j_{1} \cdots j_{k} \cdots j_{1} \cdots j_{n}\right)} a_{1 j_{1}} \cdots a_{i j_{k}} \cdots a_{k j_{k}} \cdots a_{n j_{n}}</script><p>由于<script type="math/tex">a_{i j_{1}}=a_{k j_{1}}, a_{k j_{k}}=a_{i j_{k}}</script>且排列<script type="math/tex">j_{1} \cdots j_{i} \cdots j_{k} \cdots j_{n}</script>与<script type="math/tex">j_{1} \cdots j_{i} \cdots j_{k} \cdots j_{n}</script>的逆序数的奇偶性相反(二者通过一次置换可以互相得到)，因此这两项的符号相反，故行列式的值为0</p>
<p>根据这一结论，下面的行列式为0</p>
<script type="math/tex; mode=display">
\left|\begin{array}{lll}
1 & 2 & 3 \\
1 & 1 & 1 \\
1 & 1 & 1
\end{array}\right|=0</script><p>根据这一结论可以构造出可逆矩阵的逆矩阵，对于矩阵</p>
<script type="math/tex; mode=display">
\boldsymbol{A}=\left(\begin{array}{cccc}
a_{11} & a_{12} & \cdots & a_{1 n} \\
a_{21} & a_{22} & \cdots & a_{2 n} \\
\vdots & \vdots & & \vdots \\
a_{n 1} & a_{n 2} & \cdots & a_{n n}
\end{array}\right)</script><p>假设<script type="math/tex">A_{i j}</script>是<script type="math/tex">a_{i j}</script>的代数余子式，利用它们构造如下的伴随矩阵</p>
<script type="math/tex; mode=display">
\boldsymbol{A}^{*}=\left(\begin{array}{cccc}
A_{11} & A_{21} & \cdots & A_{n 1} \\
A_{12} & A_{22} & \cdots & A_{n 2} \\
\vdots & \vdots & & \vdots \\
A_{1 n} & A_{2 n} & \cdots & A_{n n}
\end{array}\right)</script><p>根据拉普拉斯展开，第$i$行与其代数余子式的内积为行列式本身</p>
<script type="math/tex; mode=display">
|\boldsymbol{A}|=a_{i 1} A_{i 1}+a_{i 2} A_{i 2}+\cdots+a_{i n} A_{i n}</script><p>第$i$行与第$j, j \neq i$行的代数余子式的内积为0，这是因为它是第$j$行与第$i$行相等的行列式的拉普拉斯展开，其值为0</p>
<script type="math/tex; mode=display">
0=a_{i 1} A_{j 1}+a_{i 2} A_{j 2}+\cdots+a_{i n} A_{j n}, j \neq i</script><p>因此有</p>
<script type="math/tex; mode=display">
\boldsymbol{A} \boldsymbol{A}^{*}=\left(\begin{array}{cccc}
a_{11} & a_{12} & \cdots & a_{1 n} \\
a_{21} & a_{22} & \cdots & a_{2 n} \\
\vdots & \vdots & & \vdots \\
a_{n 1} & a_{n 2} & \cdots & a_{n n}
\end{array}\right)\left(\begin{array}{cccc}
A_{11} & A_{21} & \cdots & A_{n 1} \\
A_{12} & A_{22} & \cdots & A_{n 2} \\
\vdots & \vdots & & \vdots \\
A_{1 n} & A_{2 n} & \cdots & A_{n n}
\end{array}\right)=\left(\begin{array}{cccc}
|\boldsymbol{A}| & 0 & \cdots & 0 \\
0 & |\boldsymbol{A}| & \cdots & 0 \\
\vdots & \vdots & & \vdots \\
0 & 0 & \cdots & |\boldsymbol{A}|
\end{array}\right)=|\boldsymbol{A}| \boldsymbol{I}</script><p>如果$|\boldsymbol{A}| \neq 0$，则有</p>
<script type="math/tex; mode=display">
A \frac{1}{|A|} A^{*}=I</script><p>因此</p>
<script type="math/tex; mode=display">
\boldsymbol{A}^{-1}=\frac{1}{|\boldsymbol{A}|} \boldsymbol{A}^{*}</script><p>这也证明了矩阵$\boldsymbol{A}$可逆的充分必要条件是$|\boldsymbol{A}| \neq 0$</p>
<p>如果把行列式的某一行元素都乘以$k$，则行列式变为之前的$k$倍，即</p>
<script type="math/tex; mode=display">
\left|\begin{array}{ccc}
a_{11} & \cdots & a_{1 n} \\
\vdots & & \vdots \\
k a_{i 1} & \cdots & k a_{i n} \\
\vdots & & \vdots \\
a_{n 1} & \cdots & a_{n n}
\end{array}\right|=k\left|\begin{array}{ccc}
a_{11} & \cdots & a_{1 n} \\
\vdots & & \vdots \\
a_{i 1} & \cdots & a_{i n} \\
\vdots & & \vdots \\
a_{n 1} & \cdots & a_{n n}
\end{array}\right|</script><p>如果将行列式的两行交换，行列式反号</p>
<p>如果一个行列式的两行成比例关系，其值为0</p>
<p>行列式的一行加上另一行的$k$倍，行列式值不变</p>
<p>按照这一结论，下面两个行列式的值相等</p>
<script type="math/tex; mode=display">
\left|\begin{array}{lll}
1 & 1 & 1 \\
1 & 2 & 3 \\
4 & 5 & 6
\end{array}\right|=\left|\begin{array}{ccc}
1+1 & 1+2 & 1+3 \\
1 & 2 & 3 \\
4 & 5 & 6
\end{array}\right|</script><p>可以通过这种变换将矩阵化为三角矩阵，然后计算其行列式的值</p>
<p>根据拉普拉斯展开可以证明下面的结论成立</p>
<script type="math/tex; mode=display">
\left|\begin{array}{cccccccc}
a_{11} & a_{12} & \cdots & a_{1 n} & 0 & \cdots & \cdots & 0 \\
a_{21} & a_{22} & \cdots & a_{2 n} & \cdots & \cdots & \cdots & \cdots \\
\vdots & \vdots & & \vdots & \vdots & \vdots & & \vdots \\
a_{n 1} & a_{n 2} & \cdots & a_{n n} & 0 & \cdots & \cdots & 0 \\
c_{11} & c_{12} & \cdots & c_{1 n} & b_{11} & b_{12} & \cdots & b_{1 m} \\
c_{21} & c_{22} & \cdots & c_{2 n} & b_{21} & b_{22} & \cdots & b_{2 m} \\
\vdots & \vdots & & \vdots & \vdots & \vdots & & \vdots \\
c_{m 1} & c_{m 2} & \cdots & c_{m n} & b_{m 1} & b_{m 2} & \cdots & b_{m m}
\end{array}\right|=\left|\begin{array}{ccccc}
a_{11} & a_{12} & \cdots & a_{1 n} \\
a_{21} & a_{22} & \cdots & a_{2 n} \\
\vdots & \vdots & & \vdots \\
a_{n 1} & a_{n 2} & \cdots & a_{n n}
\end{array}\right|\left|\begin{array}{cccc}
b_{11} & b_{12} & \cdots & b_{1 m} \\
b_{21} & b_{22} & \cdots & b_{2 m} \\
\vdots & \vdots & & \vdots \\
b_{m 1} & b_{m 2} & \cdots & b_{m m}
\end{array}\right|</script><p>如果矩阵$A$和$B$是尺寸相同的$n$阶矩阵，则有</p>
<script type="math/tex; mode=display">
|A B|=|A||B|</script><p>即矩阵乘积的行列式等于矩阵行列式的乘积，下面给出证明，由于</p>
<script type="math/tex; mode=display">
|\boldsymbol{A}||\boldsymbol{B}|=\left|\begin{array}{cccccccc}
a_{11} & a_{12} & \cdots & a_{1 n} & 0 & \cdots & \cdots & 0 \\
a_{21} & a_{22} & \cdots & a_{2 n} & \cdots & \cdots & \cdots & \cdots \\
\vdots & \vdots & & \vdots & \vdots & \vdots & & \vdots \\
a_{n 1} & a_{n 2} & \cdots & a_{n n} & 0 & \cdots & \cdots & 0 \\
-1 & 0 & \cdots & 0 & b_{11} & b_{12} & \cdots & b_{1 n} \\
0 & -1 & \cdots & \cdots & b_{21} & b_{22} & \cdots & b_{2 n} \\
\vdots & \vdots & & \vdots & \vdots & \vdots & & \vdots \\
0 & 0 & \cdots & -1 & b_{n 1} & b_{n 2} & \cdots & b_{n n}
\end{array}\right|</script><p>将$n+1$行乘以<script type="math/tex">a_{11}</script>加到第1行，第<script type="math/tex">n+2</script>行乘以<script type="math/tex">a_{12}</script>加到第1行，… ， 将第<script type="math/tex">2 n</script>行乘以<script type="math/tex">a_{1 n}</script>加到第1行，可以得到</p>
<script type="math/tex; mode=display">
|\boldsymbol{A}||\boldsymbol{B}|=\left|\begin{array}{cccccccc}
0 & 0 & \cdots & 0 & \sum_{k=1}^{n} a_{1 k} b_{k 1} & \cdots & \cdots & \sum_{k=1}^{n} a_{1 k} b_{k n} \\
a_{21} & a_{22} & \cdots & a_{2 n} & \cdots & \cdots & \cdots & \cdots \\
\vdots & \vdots & & \vdots & \vdots & \vdots & & \vdots \\
a_{n 1} & a_{n 2} & \cdots & a_{n n} & 0 & \cdots & \cdots & 0 \\
-1 & 0 & \cdots & 0 & b_{11} & b_{12} & \cdots & b_{1 n} \\
0 & -1 & \cdots & \cdots & b_{21} & b_{22} & \cdots & b_{2 n} \\
\vdots & \vdots & & \vdots & \vdots & \vdots & & \vdots \\
0 & 0 & \cdots & -1 & b_{n 1} & b_{n 2} & \cdots & b_{n n}
\end{array}\right|</script><p>对第$2 \sim n$行执行类似的操作，将上式右侧行列式的左上角全部消为0，最后可以得到</p>
<script type="math/tex; mode=display">
\begin{aligned}
|\boldsymbol{A}||\boldsymbol{B}| & =\left|\begin{array}{cccccccc}
0 & 0 & \cdots & 0 & \sum_{k=1}^{n} a_{1 k} b_{k 1} & \cdots & \cdots & \sum_{k=1}^{n} a_{1 k} b_{k n} \\
0 & 0 & \cdots & 0 & \sum_{k=1}^{n} a_{2 k} b_{k 1} & \cdots & \cdots & \sum_{k=1}^{n} a_{2 k} b_{k n} \\
\vdots & \vdots & & \vdots & \vdots & \vdots & & \vdots \\
0 & 0 & \cdots & 0 & \sum_{k=1}^{n} a_{n k} b_{k 1} & \cdots & \cdots & \sum_{k=1}^{n} a_{n k} b_{k n} \\
-1 & 0 & \cdots & 0 & b_{11} & b_{12} & \cdots & b_{1 n} \\
0 & -1 & \cdots & \cdots & b_{21} & b_{22} & \cdots & b_{2 n} \\
\vdots & \vdots & & \vdots & \vdots & \vdots & & \vdots \\
0 & 0 & \cdots & -1 & b_{n 1} & b_{n 2} & \cdots & b_{n n}
\end{array}\right| \\
& =\left|\begin{array}{ccc}
\mathbf{0}-1 \\
-\boldsymbol{I} & B
\end{array}\right|=(-1)^{n}\left|\begin{array}{ccc}
A B & 0 \\
B & -I
\end{array}\right|=(-1)^{n}|\boldsymbol{A B}||-\boldsymbol{I}|=(-1)^{n}|\boldsymbol{A B}|(-1)^{n}=|\boldsymbol{A B}|
\end{aligned}</script><p>上式第3步将行列式左侧的$n$列与右侧的$n$列对换，因此出现$(-1)^{n}$，第4步利用了拉普拉斯展开，第5步利用了对角矩阵的行列式计算公式，通常使用它计算矩阵乘积的行列式</p>
<p>根据上式可以直接得到下面的结论: 如果矩阵可逆，则其行列式不为0，且其逆矩阵的行列式等于行列式的逆，即</p>
<script type="math/tex; mode=display">
\left|A^{-1}\right|=|A|^{-1}</script><p>这是因为$A A^{-1}=I$，因此</p>
<script type="math/tex; mode=display">
|\boldsymbol{A}|\left|\boldsymbol{A}^{-1}\right|=|\boldsymbol{I}|=1</script><p>矩阵与标量乘法的行列式为</p>
<script type="math/tex; mode=display">
|\alpha \boldsymbol{A}|=\alpha^{n}|\boldsymbol{A}|</script><p>其中$n$为矩阵的阶数，这可以根据行列式的定义直接证明，所有求和项<script type="math/tex">(-1)^{\tau\left(j_{1} j_{2} \cdots j_{n}\right)} \prod_{i=1}^{n} a_{i, j}</script>中<script type="math/tex">a_{i, j}</script>均变为<script type="math/tex">\alpha a_{i, j i}</script>，因此最后出现$\alpha^{n}$，根据这一结论有</p>
<script type="math/tex; mode=display">
\left|\begin{array}{ccc}
2 & 4 & 6 \\
8 & 10 & 12 \\
14 & 16 & 18
\end{array}\right|=2^{3} \times\left|\begin{array}{lll}
1 & 2 & 3 \\
4 & 5 & 6 \\
7 & 8 & 9
\end{array}\right|</script><p>矩阵转置之后行列式不变</p>
<script type="math/tex; mode=display">
|\boldsymbol{A}|=\left|\boldsymbol{A}^{\mathrm{T}}\right|</script><p>这可以根据行列式的定义以及行列对换进行证明</p>
<p>正交矩阵的行列式为$\pm 1$，如果$A$是正交矩阵，则有</p>
<script type="math/tex; mode=display">
\left|\boldsymbol{A} \boldsymbol{A}^{\mathrm{T}}\right|=|\boldsymbol{A}|\left|\boldsymbol{A}^{\mathrm{T}}\right|=|\boldsymbol{A}||\boldsymbol{A}|=|\boldsymbol{I}|=1</script><p>因此$|\boldsymbol{A}|=\pm 1$</p>
<h2 id="计算方法"><a href="#计算方法" class="headerlink" title="计算方法"></a>计算方法</h2><p>行列式的计算分为手动计算与编程计算两种方式</p>
<blockquote>
<p>手动计算</p>
</blockquote>
<p>对于手动计算，重点介绍将矩阵化为<code>上三角矩阵</code>的方法</p>
<p>上三角矩阵或下三角矩阵的行列式是易于许算的，等于其主对角线元素的乘积</p>
<p>根据下面的初等行变换</p>
<ol>
<li>将行列式的两行交换</li>
<li>将行列式的某一行乘以$k$倍之后加到另外一行</li>
</ol>
<p>可以将行列式化为上三角形式，根据前面介绍的行列式的性质，第一种变换使得行列式的值反号，第二种变换保证行列式的值不变</p>
<p>下面举例说明，对于下面的行列式</p>
<script type="math/tex; mode=display">
\left|\begin{array}{lll}
1 & 2 & 3 \\
4 & 5 & 6 \\
7 & 8 & 9
\end{array}\right|</script><p>将其化为上三角矩阵，然后计算行列式的值</p>
<script type="math/tex; mode=display">
\left|\begin{array}{lll}
1 & 2 & 3 \\
4 & 5 & 6 \\
7 & 8 & 9
\end{array}\right| \stackrel{r_{2}-4 \times r_{1}, r_{3}-7 \times r_{1}}{\longrightarrow}\left|\begin{array}{ccc}
1 & 2 & 3 \\
0 & -3 & -6 \\
0 & -6 & -12
\end{array}\right| \stackrel{r_{3}-2 \times r_{2}}{\longrightarrow}\left|\begin{array}{ccc}
1 & 2 & 3 \\
0 & -3 & -6 \\
0 & 0 & 0
\end{array}\right|=0</script><blockquote>
<p>编程计算</p>
</blockquote>
<p>Python中linalg的det函数实现了计算方阵行列式的功能，下面是计算矩阵行列式的示例代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy  </span><br><span class="line">A = np.array([[<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">0</span>,<span class="number">5</span>]])</span><br><span class="line">d = np.linalg.det(A)</span><br><span class="line"><span class="built_in">print</span>(d)</span><br></pre></td></tr></table></figure>
<p>程序运行结果为5，对角矩阵的行列式为主对角线元素的乘积</p>
<h1 id="线性方程组"><a href="#线性方程组" class="headerlink" title="线性方程组"></a>线性方程组</h1><h2 id="高斯消元法"><a href="#高斯消元法" class="headerlink" title="高斯消元法"></a>高斯消元法</h2><p><code>高斯消元法</code>(Gaussian Elimination Method)即<code>加减消元法</code>，是求解线性方程组的经典方法</p>
<p>通过将一个方程减掉另一个方程的倍数消掉末知数，得到<code>阶梯型方程组</code>，然后依次解出每一个末知数</p>
<p>下面用一个简单的例子进行说明，对于如下的线性方程组</p>
<script type="math/tex; mode=display">
\left\{\begin{array}{l}
2 x_{1}+x_{2}+x_{3}=1 \\
6 x_{1}+2 x_{2}+x_{3}=-1 \\
-2 x_{1}+2 x_{2}+x_{3}=7
\end{array}\right.</script><p>先消去方程2和方程3的第一个末知数，将方程2减去方程1的3倍，将方程3加上方程1，消掉方程2和方程3中的$x_{1}$，得</p>
<script type="math/tex; mode=display">
\left\{\begin{array}{l}
2 x_{1}+x_{2}+x_{3}=1 \\
-x_{2}-2 x_{3}=-4 \\
3 x_{2}+2 x_{3}=8
\end{array}\right.</script><p>然后将方程3加上方程2的3倍，消掉方程3中的$x_{2}$，得</p>
<script type="math/tex; mode=display">
\left\{\begin{array}{l}
2 x_{1}+x_{2}+x_{3}=1 \\
-x_{2}-2 x_{3}=-4 \\
-4 x_{3}=-4
\end{array}\right.</script><p>可以解得</p>
<script type="math/tex; mode=display">
x_{1}=-1 \qquad x_{2}=2 \qquad x_{3}=1</script><p>下面用矩阵的形式描述这一求解过程，如下所示</p>
<script type="math/tex; mode=display">
\left(\begin{array}{cccc}
2 & 1 & 1 & 1 \\
6 & 2 & 1 & -1 \\
-2 & 2 & 1 & 7
\end{array}\right) \stackrel{r_{2}-3 \times r_{1}, r_{3}+r_{1}}{\longrightarrow}\left(\begin{array}{cccc}
2 & 1 & 1 & 1 \\
0 & -1 & -2 & -4 \\
0 & 3 & 2 & 8
\end{array}\right) \stackrel{r_{3}+3 \times r_{2}}{\longrightarrow}\left(\begin{array}{cccc}
2 & 1 & 1 & 1 \\
0 & -1 & -2 & -4 \\
0 & 0 & -4 & -4
\end{array}\right)</script><p>下面将这种消元法进行推广，对于任意的线性方程组，采用如下的初等变换对其进行变形，方程组的解不变</p>
<ol>
<li>交换两个方程的位置</li>
<li>用非0的常数乘以某方程的两端</li>
<li>将一个方程的常数倍加到另一个方程上去</li>
</ol>
<p>采用这种初等变换，每次消掉一个末知数，最后得到一个阶梯形方程组，即可求出方程的解</p>
<h2 id="齐次方程组"><a href="#齐次方程组" class="headerlink" title="齐次方程组"></a>齐次方程组</h2><p><code>齐次线性方程组</code>(Homogeneous Linear Equations)是常数项全部为0的线性方程组，可以写成如下形式</p>
<script type="math/tex; mode=display">
\boldsymbol{A x}=\mathbf{0}</script><p>其中$\boldsymbol{A} \in \mathbb{R}^{m \times n}, \boldsymbol{x} \in \mathbb{R}^{n}$ </p>
<p>将系数矩阵$\boldsymbol{A}$按列分块为<script type="math/tex">\left(\boldsymbol{a}_{1} \cdots \boldsymbol{a}_{n}\right)</script>，齐次方程可以写成</p>
<script type="math/tex; mode=display">
x_{1} \boldsymbol{a}_{1}+\cdots+x_{n} \boldsymbol{a}_{n}=\mathbf{0}</script><p>以解向量<script type="math/tex">\boldsymbol{x}=\left(x_{1} \cdots x_{n}\right)^{\mathrm{T}}</script>为组合系数，向量组<script type="math/tex">\boldsymbol{a}_{1}, \cdots, \boldsymbol{a}_{n}</script>的线性组合为0向量</p>
<p>显然$\boldsymbol{x}=\mathbf{0}$是方程组的解，因此齐次方程一定有解，更重要的是，除$\boldsymbol{x}=\mathbf{0}$ 外的解，称为<code>非0解</code>，下面讨论这种解的存在性</p>
<p>根据线性相关性的定义，如果向量组<script type="math/tex">\boldsymbol{a}_{1}, \cdots, \boldsymbol{a}_{n}</script>线性无关，则不存在一组不全为0的系数<script type="math/tex">\boldsymbol{x}</script>使得其线性组合为0</p>
<p>如果向量组<script type="math/tex">a_{1}, \cdots, a_{n}</script>线性相关，则存在一组不全为0的系数<script type="math/tex">x</script>使得其线性组合为0，这就是方程组的非0解</p>
<p>前者对应于矩阵$A$的秩为$n$，后者秩小于$n$，由此得到齐次方程组解的存在性判定条件，分下面两种情况</p>
<ol>
<li>如果$r(\boldsymbol{A})=n$，方程组只有0解</li>
<li>如果$r(\boldsymbol{A}) \lt n$，方程组有非0解</li>
</ol>
<p>方程组有非$\boldsymbol{0}$解的充分必要条件是$r(\boldsymbol{A})&lt;n$</p>
<p>如果$\boldsymbol{A}$是方阵，$r(\boldsymbol{A})&lt;n$等同于$\boldsymbol{A}$不可逆， 如果$m&lt;n$，即(方程的数量)小于未知数的数量，则有</p>
<script type="math/tex; mode=display">
r(\boldsymbol{A}) \leqslant \min (m, n) \leqslant m<n</script><p>此时方程组必定有非$\boldsymbol{0}$解，对于如下的线性方程组</p>
<script type="math/tex; mode=display">
\left\{\begin{array}{l}
x_{1}-x_{2}+x_{3}=0 \\
-x_{1}+x_{2}+x_{3}=0 \\
x_{1}+x_{2}-x_{3}=0
\end{array}\right.</script><p>其系数矩阵的秩为</p>
<script type="math/tex; mode=display">
r\left(\left(\begin{array}{ccc}
1 & -1 & 1 \\
-1 & 1 & 1 \\
1 & 1 & -1
\end{array}\right)\right)=3</script><p>因此方程组只有$\mathbf{0}$解，对于如下的方程组</p>
<script type="math/tex; mode=display">
\left\{\begin{array}{l}
x_{1}+x_{2}+x_{3}=0 \\
2 x_{1}+2 x_{2}+2 x_{3}=0
\end{array}\right.</script><p>其系数矩阵的秩为</p>
<script type="math/tex; mode=display">
r\left(\left(\begin{array}{lll}
1 & 1 & 1 \\
2 & 2 & 2
\end{array}\right)\right)=1</script><p>也是方程组的解，证明如下</p>
<script type="math/tex; mode=display">
\boldsymbol{A}\left(\sum_{i=1}^{l} k_{i} \boldsymbol{x}_{i}\right)=\sum_{i=1}^{l} k_{i} \boldsymbol{A} \boldsymbol{x}_{i}=\sum_{i=1}^{l} k_{i} \mathbf{0}=\mathbf{0}</script><p>假设<script type="math/tex">x_{1}, \cdots, x_{l}</script>都是方程组的解，如果这组解线性无关且方程组的任意一个解都可以由这组解线性表示，则称<script type="math/tex">x_{1}, \cdots, x_{l}</script>是方程组的一个<code>基础解系</code></p>
<p>如果$r(\boldsymbol{A})&lt;n$，则存在基础解系，且基础解系中包含$n-r(\boldsymbol{A})$个解</p>
<blockquote>
<p>齐次线性方程组的求解方法</p>
</blockquote>
<p>通常采用的是初等行变换法，对应<code>高斯消元法</code>，经过初等行变换将系数矩阵化为阶梯形矩阵之后</p>
<p>如果出现自由未知数，可以将它们设为特殊值，形成基础解系，然后得到方程组的<code>通解</code>(General Solution)</p>
<p>如果<script type="math/tex">x_{r+1}, \cdots, x_{n}</script>是自由末知数，通常将它们的值依次设为</p>
<script type="math/tex; mode=display">
\left(\begin{array}{llll}1 & 0 & \cdots & 0\end{array}\right) \qquad
\left(\begin{array}{llll}0 & 1 & \cdots & 0\end{array}\right) \qquad \cdots \qquad
\left(\begin{array}{llll}0 & 0 & \cdots & 1\end{array}\right)</script><p>这是$\mathbb{R}^{n-r}$空间一组最简单的<code>标准正交基</code>，然后根据它们的值解出其他的末知数，对于如下的方程组</p>
<script type="math/tex; mode=display">
\left\{\begin{array}{l}
x_{1}+2 x_{2}+2 x_{3}+x_{4}=0 \\
2 x_{1}+x_{2}-2 x_{3}-2 x_{4}=0 \\
x_{1}-x_{2}-4 x_{3}-3 x_{4}=0
\end{array}\right.</script><p>对其系数矩阵进行初等行变换</p>
<script type="math/tex; mode=display">
\begin{array}{l} 
A=\left(\begin{array}{cccc}
1 & 2 & 2 & 1 \\
2 & 1 & -2 & -2 \\
1 & -1 & -4 & -3
\end{array}\right) \stackrel{r_{2}-2 r_{1}, r_{3}-r_{1}}{\longrightarrow} \\
\stackrel{r_{3}-r_{2}, r_{2} \times(-1 / 3)}{\longrightarrow}\left(\begin{array}{cccc}
1 & 2 & 2 & 1 \\
0 & 1 & 2 & 4 / 3 \\
0 & -3 & -6 & -4 \\
0 & -3 & -6 & -4
\end{array}\right) \stackrel{r_{1}-2 \times r_{2}}{\longrightarrow}\left(\begin{array}{cccc}
1 & 0 & -2 & -5 / 3 \\
0 & 1 & 2 & 4 / 3 \\
0 & 0 & 0 & 0
\end{array}\right)
\end{array}</script><p>由于$r(\boldsymbol{A})=2&lt;4$，因此方程组有非$\mathbf{0}$解，最后丙个末知数为自由变量</p>
<p>令<script type="math/tex">x_{3}=1, x_{4}=0</script>，得到基础解系的第一个解</p>
<script type="math/tex; mode=display">
x_{1}=\left(\begin{array}{llll}
2 & -2 & 1 & 0
\end{array}\right)^{T}</script><p>令<script type="math/tex">x_{3}=0, x_{4}=1</script>，得到基础解系的第二个解</p>
<script type="math/tex; mode=display">
x_{2}=\left(\begin{array}{llll}
5 / 3 & -4 / 3 & 0 & 1
\end{array}\right)^{\mathrm{T}}</script><p>方程组的通解为</p>
<script type="math/tex; mode=display">
\boldsymbol{x}=k_{1} x_{1}+k_{2} x_{2}</script><p>其中<script type="math/tex">k_{1}, k_{2}</script>为任意常数</p>
<h2 id="非齐次方程组"><a href="#非齐次方程组" class="headerlink" title="非齐次方程组"></a>非齐次方程组</h2><p><code>非齐次线性方程组</code>(Non-homogeneous Linear Equations)的常数项不全为0，可写成如下形式</p>
<script type="math/tex; mode=display">
\boldsymbol{A} \boldsymbol{x}=\boldsymbol{b}</script><p>这与一元一次方程$a x=0$在形式上是统一的，方程组的增广矩阵是系数矩阵和常数向量合并构成的矩阵</p>
<script type="math/tex; mode=display">
\boldsymbol{B}=\left(\begin{array}{ll}
\boldsymbol{A} & \boldsymbol{b}
\end{array}\right)</script><p>对于如下的线性方程组</p>
<script type="math/tex; mode=display">
\left\{\begin{array}{l}
2 x_{1}-3 x_{2}+x_{3}=1 \\
4 x_{1}-2 x_{2}+x_{3}=2 \\
3 x_{1}+3 x_{2}+x_{3}=0
\end{array}\right.</script><p>其系数矩阵为</p>
<script type="math/tex; mode=display">
\left(\begin{array}{ccc}
2 & -3 & 1 \\
4 & -2 & 1 \\
3 & 3 & 1
\end{array}\right)</script><p>增广矩阵为</p>
<script type="math/tex; mode=display">
\left(\begin{array}{cccc}
2 & -3 & 1 & 1 \\
4 & -2 & 1 & 2 \\
3 & 3 & 1 & 0
\end{array}\right)</script><p>假设$\boldsymbol{A} \in \mathbb{R}^{m \times n}, \boldsymbol{x} \in \mathbb{R}^{n}$ ，系数矩阵$\boldsymbol{A}$扩列分块为<script type="math/tex">\left(\boldsymbol{a}_{1} \cdots \boldsymbol{a}_{n}\right)</script>，非齐次方程可以写成</p>
<script type="math/tex; mode=display">
x_{1} a_{1}+\cdots+x_{n} a_{n}=b</script><p>以$x$为组合系数，向量组<script type="math/tex">a_{1}, \cdots, a_{n}</script>的线性组合为向量<script type="math/tex">b</script>，如果<script type="math/tex">b</script>可以由<script type="math/tex">A</script>的列向量线性表示，则方程组有解，否则方程组无解</p>
<p>用初等行变换将增广矩阵化为阶梯矩阵</p>
<script type="math/tex; mode=display">
\left(\begin{array}{ccccccc}
1 & \cdots & c_{1 r} & c_{1, r+1} & \cdots & c_{1 n} & d_{1} \\
\vdots & & \vdots & \vdots & & \vdots & \vdots \\
0 & \cdots & 1 & c_{r, r+1} & \cdots & c_{r n} & d_{r} \\
0 & \cdots & 0 & 0 & \cdots & 0 & d_{r+1} \\
0 & \cdots & 0 & 0 & \cdots & 0 & 0 \\
\vdots & & \vdots & \vdots & & \vdots & \vdots \\
0 & \cdots & 0 & 0 & \cdots & 0 & 0
\end{array}\right)</script><p>如果<script type="math/tex">d_{r+1} \neq 0</script>，则意味着出现矛盾方程，方程无解，如果<script type="math/tex">d_{r+1}=0</script>，则方程组有解，对于第二种情况，增广矩阵的秩与系数矩阵的秩小于增广矩阵的秩，且</p>
<script type="math/tex; mode=display">
r(\boldsymbol{B})=r(\boldsymbol{A})+1</script><p>由此得到非齐次方程组解的存在性判定条件</p>
<ol>
<li>如果$r(\boldsymbol{A})=r(\boldsymbol{B})$，那么方程组的解存在</li>
<li>如果$r(\boldsymbol{A})&lt;r(\boldsymbol{B})$，那么方程组的解不存在</li>
</ol>
<p>对于第一种情况，如果$r(\boldsymbol{A})=n$，那么方程组有唯一解，如果$r(\boldsymbol{A})&lt;n$，那么方程组有无穷多组解</p>
<blockquote>
<p>解的性质与结构</p>
</blockquote>
<p>如果<script type="math/tex">x_{1}, \cdots, x_{l}</script>是非齐次方程组所对应的齐次方程的一组解，<script type="math/tex">x^{*}</script>是非齐次方程的一个解，则<script type="math/tex">\sum_{i=1}^{1} k_{i} x_{i}+x^{*}</script>是非齐次方程的解，显然</p>
<script type="math/tex; mode=display">
\boldsymbol{A}\left(\sum_{i=1}^{l} k_{i} \boldsymbol{x}_{i}+\boldsymbol{x}^{*}\right)=\sum_{i=1}^{l} k_{i} \boldsymbol{A} \boldsymbol{x}_{i}+\boldsymbol{A} \boldsymbol{x}^{*}=\sum_{i=1}^{l} k_{i} \mathbf{0}+\boldsymbol{b}=\boldsymbol{b}</script><p>如果<script type="math/tex">x_{1}, \cdots, x_{l}</script>是齐次方程组的基础解系，<script type="math/tex">x^{*}</script>是非齐次方程组的一个解，则非齐次方程组的解可以表示为</p>
<script type="math/tex; mode=display">
\sum_{i=1}^{l} k_{i} x_{i}+x^{*}</script><p>同样可以用初等行变换求解非齐次方程组，其解为对应的齐次方程组的通解加上它的一个<code>特解</code>(Particular Solution)</p>
<p>齐次方程组通解的求解方法在前面已经介绍，非齐次方程组的特解可以任意选取，通常令自由末知数的值全为0</p>
<p>用初等行变换解下面的非齐次线性方程组</p>
<script type="math/tex; mode=display">
\left\{\begin{array}{l}
x_{1}+5 x_{2}-x_{3}-x_{4}=-1 \\
x_{1}-2 x_{2}+x_{3}+3 x_{4}=3 \\
3 x_{1}+8 x_{2}-x_{3}+x_{4}=1 \\
x_{1}-9 x_{2}+3 x_{3}+7 x_{4}=7
\end{array}\right.</script><p>对其增广矩阵进行初等行变换</p>
<script type="math/tex; mode=display">
\left(\begin{array}{ccccc}1 & 5 & -1 & -1 & -1 \\ 1 & -2 & 1 & 3 & 3 \\ 3 & 8 & -1 & 1 & 1 \\ 1 & -9 & 3 & 7 & 7\end{array}\right) \rightarrow\left(\begin{array}{ccccc}1 & 5 & -1 & -1 & -1 \\ 0 & -7 & 2 & 4 & 4 \\ 0 & 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 & 0\end{array}\right) \rightarrow\left(\begin{array}{ccccc}1 & 5 & -1 & -1 & -1 \\ 0 & 1 & -2 / 7 & -4 / 7 & -4 / 7 \\ 0 & 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 & 0\end{array}\right)</script><p>这里<script type="math/tex">x_{3}, x_{4}</script>是自由未知数，令<script type="math/tex">x_{3}=x_{4}=0</script>，得到一个特解</p>
<script type="math/tex; mode=display">
\boldsymbol{x}^{*}=\left(\begin{array}{c}
13 / 7 \\
-4 / 7 \\
0 \\
0
\end{array}\right)</script><p>方次方程组的基础解系为</p>
<script type="math/tex; mode=display">
\boldsymbol{x}_{1}=\left(\begin{array}{c}
-3 / 7 \\
2 / 7 \\
1 \\
0
\end{array}\right), \boldsymbol{x}_{2}=\left(\begin{array}{c}
-13 / 7 \\
4 / 7 \\
0 \\
1
\end{array}\right)</script><p>因此方程的解为</p>
<script type="math/tex; mode=display">
\boldsymbol{x}=\boldsymbol{x}^{*}+k_{1} \boldsymbol{x}_{1}+k_{2} \boldsymbol{x}_{2}</script><p>其中<script type="math/tex">k_{1}, k_{2}</script>为任意常数</p>
<p>Python中linalg的solve函数提供了求解非齐次线性方程组的功能，函数的传人参数为系数矩阵$A$，以及常数向量$\boldsymbol{b}$，返回值是方程组$\boldsymbol{A x}=\boldsymbol{b}$的解向量$x$，对于方程组</p>
<script type="math/tex; mode=display">
\begin{array}{l}
3 x_{1}+x_{2}=9 \\
x_{1}+2 x_{2}=8
\end{array}</script><p>下面是求解该方程组的代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">A = np.array([<span class="number">3</span>,<span class="number">1</span>], [<span class="number">1</span>,<span class="number">2</span>])</span><br><span class="line">b = np.array([<span class="number">9</span>,<span class="number">8</span>])</span><br><span class="line">x = np.linalg.solve(A, b)</span><br><span class="line"><span class="built_in">print</span>(x)</span><br></pre></td></tr></table></figure>
<p>程序运行结果为$[2,3]$</p>
<h1 id="特征值和特征向量"><a href="#特征值和特征向量" class="headerlink" title="特征值和特征向量"></a>特征值和特征向量</h1><p><code>特征值</code>(Eigenvalue，也称为本征值)与<code>特征向量</code>(Eigenvector，也称为<code>本征向量</code>)决定了矩阵的很多性质</p>
<p>从几何的角度来看，持征向量是经过矩阵的线性变换仍然处于同一条直线上的向量</p>
<h2 id="特征值与特征向量"><a href="#特征值与特征向量" class="headerlink" title="特征值与特征向量"></a>特征值与特征向量</h2><blockquote>
<p>特征值与特征向量</p>
</blockquote>
<p>对于$n$阶矩阵$A$，其特征向量是经过这个矩阵的线性变换之后仍然处于同一条直线上的向量，新向量的方向可能会相反，长度可能会改变，即存在一个数$\lambda$以及非$0$向量$x$，满足</p>
<script type="math/tex; mode=display">
\boldsymbol{A} \boldsymbol{x}=\lambda \boldsymbol{x}</script><p>则称$\lambda$为矩阵$A$的<code>特征值</code>，$x$为该特征值对应的<code>特征向量</code></p>
<p>特征值是特征向量在矩阵的线性变换下的缩放代，如果持征值大于0，那么经过线性变换之后特征向量的方向不变；如果特征值小于0，那么经过线性变换之后特征向量的方向相反，如果特征值为0，则经过线性变换之后特征向量收缩回原点</p>
<blockquote>
<p>特征矩阵和特征方程</p>
</blockquote>
<p>上式变形后可以得到</p>
<script type="math/tex; mode=display">
(A-\lambda I) x=0</script><p>$A-\lambda I$ 称为<code>特征矩阵</code>，按照线性方程组的理论，上面的齐次方程有非0解的条件是系数矩阵的行列式必须为0，即</p>
<script type="math/tex; mode=display">
|\boldsymbol{A}-\lambda \boldsymbol{I}|=0</script><p>式子称为<code>特征方程</code>(Eigenvalue Equation)</p>
<p>对于矩阵</p>
<script type="math/tex; mode=display">
\boldsymbol{A}=\left(\begin{array}{cccc}
a_{11} & a_{12} & \cdots & a_{1 n} \\
a_{21} & a_{22} & \cdots & a_{2 n} \\
\vdots & \vdots & & \vdots \\
a_{n 1} & a_{n 2} & \cdots & a_{n n}
\end{array}\right)</script><p>其特征方程为</p>
<script type="math/tex; mode=display">
|\boldsymbol{A}-\lambda \boldsymbol{I}|=\left|\begin{array}{cccc}
a_{11}-\lambda & a_{12} & \cdots & a_{1 n} \\
a_{21} & a_{22}-\lambda & \cdots & a_{2 n} \\
\vdots & \vdots & & \vdots \\
a_{n 1} & a_{n 2} & \cdots & a_{n n}-\lambda
\end{array}\right|=0</script><blockquote>
<p>特征多项式</p>
</blockquote>
<p>上面的行列式展开之后是$\lambda$的$n$次多项式，称为矩阵的<code>特征多项式</code>(Characteristic Polynomial)，为如下形式</p>
<script type="math/tex; mode=display">
c_{n} \lambda^{n}+c_{n-1} \lambda^{n-1}+c_{n-2} \lambda^{n-2}+\cdots+c_{1} \lambda+c_{0}</script><p>求解这个特征多项式对应的特征方程可以得到所有特征值，方程的根可能是复数，此时的特征值为复数，特征向量为复向量</p>
<p>根据对角行列式的计算公式，对角矩阵的特征为其主对角线元素，对于如下对角矩阵</p>
<script type="math/tex; mode=display">
\boldsymbol{A}=\left(\begin{array}{cccc}
a_{11} & 0 & \cdots & 0 \\
0 & a_{22} & \cdots & 0 \\
\vdots & \vdots & & \vdots \\
0 & 0 & \cdots & a_{n n}
\end{array}\right)</script><p>其特征方程为</p>
<script type="math/tex; mode=display">
\left|\begin{array}{cccc}a_{11}-\lambda & 0 & \cdots & 0 \\ 0 & a_{22}-\lambda & \cdots & 0 \\ \vdots & \vdots & & \vdots \\ 0 & 0 & \cdots & a_{n n}-\lambda\end{array}\right|=\left(a_{11}-\lambda\right) \cdots\left(a_{n n}-\lambda\right)=0</script><p>类似地，上三角矩阵的特征值为其主对角线元素，对于如下的上三角矩阵</p>
<script type="math/tex; mode=display">
\boldsymbol{A}=\left(\begin{array}{cccc}
a_{11} & a_{12} & \cdots & a_{1 n} \\
0 & a_{22} & \cdots & a_{2 n} \\
\vdots & \vdots & & \vdots \\
0 & 0 & \cdots & a_{n n}
\end{array}\right)</script><p>其特征方程为</p>
<script type="math/tex; mode=display">
\left|\begin{array}{cccc}
a_{11}-\lambda & a_{12} & \cdots & a_{1 n} \\
0 & a_{22}-\lambda & \cdots & a_{2 n} \\
\vdots & \vdots & & \vdots \\
0 & 0 & \cdots & a_{n n}-\lambda
\end{array}\right|=\left(a_{11}-\lambda\right) \cdots\left(a_{n n}-\lambda\right)=0</script><p>对于下三角矩阵有相同的结论，一种计算特征值的方法是通过相似变换将矩阵变为上三角矩阵</p>
<blockquote>
<p>代数重数、谱</p>
</blockquote>
<p>根据多项式分解定理，特征方程可以写成</p>
<script type="math/tex; mode=display">
\left(\lambda-\lambda_{1}\right)^{n_{1}}\left(\lambda-\lambda_{2}\right)^{n_{2}} \cdots\left(\lambda-\lambda_{N_{\lambda}}\right)^{n_{N_{\lambda}}}=0</script><p>其中<script type="math/tex">n_{i}</script>称为特征值<script type="math/tex">\lambda_{i}</script>的<code>代数重数</code>(Algebraic Multiplicity)，根据代数方程的理论，有</p>
<script type="math/tex; mode=display">
\sum_{i=1}^{N_{\lambda}} n_{i}=n</script><p>所有$N_{\lambda}$个不同的特征值构成的集合称为矩阵的<code>谱</code>(Spectrum)</p>
<p>矩阵的<code>谱半径</code>(Spectral Radius)定义为所有特征值绝对值的最大值，记为</p>
<script type="math/tex; mode=display">
\rho(\boldsymbol{A})=\max \left\{\left|\lambda_{1}\right|, \cdots,\left|\lambda_{N_{\lambda}}\right|\right\}</script><p>如果矩阵$\boldsymbol{A}$不可逆，则</p>
<script type="math/tex; mode=display">
|\boldsymbol{A}|=|\boldsymbol{A}-0 \boldsymbol{I}|=0</script><p>因此0是它的特征值，反之，如果可逆，则0不是它的特征值</p>
<blockquote>
<p>几何重数</p>
</blockquote>
<p>得到每个特征值$\lambda_{i}$之后，解下面的线性方程组</p>
<script type="math/tex; mode=display">
(A - \lambda _i I)x = 0</script><p>即可得到其对应的特征向量，此方程组有$1 \leq m_i \leq n_i$，个线性无关的解，称$m_i$为$\lambda _i$的<code>几何重数</code>(Geometric Multiplicity)</p>
<p>这些线性无关的解构成的空间称为矩阵$\boldsymbol{A}$关于特征值<script type="math/tex">\lambda_{i}</script>的特征子空间，记为<script type="math/tex">V_{\lambda _i}</script></p>
<p>根据齐次线性方程组解的理论，特征子空间的维数为</p>
<script type="math/tex; mode=display">
m_{i}=n-r\left(\boldsymbol{A}-\lambda_{i} \boldsymbol{I}\right)</script><p>属于不同特征值的特征向量线性无关，矩阵所有线性无关的特征向量的数量为</p>
<script type="math/tex; mode=display">
N_{x}=\sum_{i=1}^{N_{ \lambda}} m_{i}</script><p>显然有$N_{x} \leqslant n$</p>
<blockquote>
<p>特征值与特征向量的计算</p>
</blockquote>
<p>下面用一个例子来说明特征值与特征向量的计算，对于如下矩阵</p>
<script type="math/tex; mode=display">
\boldsymbol{A}=\left(\begin{array}{cc}
1 & 2 \\
0 & -1
\end{array}\right)</script><p>其特征多项式为</p>
<script type="math/tex; mode=display">
|\boldsymbol{A}-\lambda \boldsymbol{I}|=\left|\begin{array}{cc}
1-\lambda & 2 \\
0 & -1-\lambda
\end{array}\right|=-(1-\lambda)(1+\lambda)</script><p>特征方程$-(1-\lambda)(1+\lambda)=0$的根为$\lambda=1$与$\lambda=-1$，因此该矩阵的特征值为1与-1</p>
<p>将特征值1代人，可得</p>
<script type="math/tex; mode=display">
(\boldsymbol{A}-\lambda I) \boldsymbol{x}=\left(\begin{array}{cc}
0 & 2 \\
0 & -2
\end{array}\right) \boldsymbol{x}=\mathbf{0}</script><p>该齐次方程的解为</p>
<script type="math/tex; mode=display">
\boldsymbol{x}=\left(\begin{array}{l}
1 \\
0
\end{array}\right)</script><p>此即特征值1对应的特征向量</p>
<p>将另外一个特征值-1代人，可得</p>
<script type="math/tex; mode=display">
(\boldsymbol{A}-\lambda I) \boldsymbol{x}=\left(\begin{array}{ll}
2 & 2 \\
0 & 0
\end{array}\right) \boldsymbol{x}=\mathbf{0}</script><p>该齐次方程的解为</p>
<script type="math/tex; mode=display">
\boldsymbol{x}=\left(\begin{array}{c}
1 \\
-1
\end{array}\right)</script><p>即特征值-1对应的特征向量</p>
<p>上三角矩阵的特征值为其主对角线元素，对于如下矩阵</p>
<script type="math/tex; mode=display">
\boldsymbol{A}=\left(\begin{array}{lll}
1 & 1 & 1 \\
0 & 2 & 2 \\
0 & 0 & 3
\end{array}\right)</script><p>根据前面的结论，其特征多项式为</p>
<script type="math/tex; mode=display">
|\boldsymbol{A}-\lambda \boldsymbol{I}|=\left|\begin{array}{ccc}
1-\lambda & 1 & 1 \\
0 & 2-\lambda & 2 \\
0 & 0 & 3-\lambda
\end{array}\right|=(1-\lambda)(2-\lambda)(3-\lambda)</script><p>其特征值为 $1 、 2 、 3$</p>
<p>对于不超过4阶的矩阵，可通过解特征方程得到特征值</p>
<p>但更高次方程的求根存在困难，阿贝尔-鲁菲尼(Abel-Ruffini)定理指出，4次以上的代数方程没有公式解，对于一般的高次方程，方程系数的有限次四则运算、开方运算的结果均不可能是方程的根，因此<strong>高阶矩阵的特征值只能求近似解</strong></p>
<p>直接求解特征方程并不是一种好的选择，更有效的方法是迭代法</p>
<p>Python中linalg的eig函数实现了计算矩阵的特征值与特征向量的功能，函数的输入为方阵，输出为所有的特征值以及这些特征值对应的特征向量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">A = np.array([[<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">0</span>,<span class="number">5</span>]])</span><br><span class="line">eigvalues, eigvectors = np<span class="number">.1</span>inalg.eig(A)</span><br><span class="line"><span class="built_in">print</span>(eigvalues)</span><br><span class="line"><span class="built_in">print</span>(eigvectors)</span><br></pre></td></tr></table></figure>
<p>程序运行结果为</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#  特征值</span></span><br><span class="line">[<span class="number">1.</span> <span class="number">1.</span> <span class="number">5.</span>]</span><br><span class="line"><span class="comment"># 特征向量</span></span><br><span class="line">[[<span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">1.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span>]]</span><br></pre></td></tr></table></figure>
<blockquote>
<p>矩阵的迹</p>
</blockquote>
<p>下面介绍特征值与矩阵主对角线元素以及行列式的关系，矩阵的<code>迹</code>(Trace)定义为其主对角线元素之和</p>
<script type="math/tex; mode=display">
\operatorname{tr}(\boldsymbol{A})=\sum_{i=1}^{n} a_{i i}</script><p>对于如下矩阵</p>
<script type="math/tex; mode=display">
\boldsymbol{A}=\left(\begin{array}{lll}
1 & 2 & 3 \\
4 & 5 & 6 \\
7 & 8 & 9
\end{array}\right)</script><p>其迹为</p>
<script type="math/tex; mode=display">
\operatorname{tr}(\boldsymbol{A})=a_{11}+a_{22}+a_{33}=1+5+9=15</script><p>关于矩阵的迹，有下面的公式成立</p>
<script type="math/tex; mode=display">
\operatorname{tr}(\boldsymbol{A}+\boldsymbol{B})=\operatorname{tr}(\boldsymbol{A})+\operatorname{tr}(\boldsymbol{B})
\qquad \operatorname{tr}(k \boldsymbol{A})= k \cdot \operatorname{tr}(\boldsymbol{A}) 
\qquad \operatorname{tr}(\boldsymbol{A} \boldsymbol{B})=\operatorname{tr}(\boldsymbol{B} \boldsymbol{A})</script><p>根据<code>韦达定理</code>，下面的$n$次方程</p>
<script type="math/tex; mode=display">
x^{n}+c_{n-1} x^{n-1}+\cdots+c_{1} x+c_{0}=0</script><p>所有根之和为</p>
<script type="math/tex; mode=display">
x_{1}+x_{2}+\cdots+x_{n}=-c_{n-1}</script><p>所有根的乘积为</p>
<script type="math/tex; mode=display">
x_{1} x_{2} \cdots x_{n}=(-1)^{n} c_{0}</script><p>下面计算$n$阶矩阵的特征多项式，首先将行列式写成下面的形式</p>
<script type="math/tex; mode=display">
|\boldsymbol{A}-\lambda \boldsymbol{I}|=\left|\begin{array}{cccc}
a_{11}-\lambda & a_{12}-0 & \cdots & a_{1 n}-0 \\
a_{21}-0 & a_{22}-\lambda & \cdots & a_{2 n}-0 \\
\vdots & \vdots & & \vdots \\
a_{n 1}-0 & a_{n 2}-0 & \cdots & a_{n n}-\lambda
\end{array}\right|</script><p>然后按照第1列拆开、变为两个行列式之和</p>
<script type="math/tex; mode=display">
|\boldsymbol{A}-\lambda \boldsymbol{I}|=\left|\begin{array}{cccc}
a_{11} & a_{12}-0 & \cdots & a_{1 n}-0 \\
a_{21} & a_{22}-\lambda & \cdots & a_{2 n}-0 \\
\vdots & \vdots & & \vdots \\
a_{n 1} & a_{n 2}-0 & \cdots & a_{n n}-\lambda
\end{array}\right|+\left|\begin{array}{cccc}
-\lambda & a_{12}-0 & \cdots & a_{1 n}-0 \\
-0 & a_{22}-\lambda & \cdots & a_{2 n}-0 \\
\vdots & \vdots & & \vdots \\
-0 & a_{n 2}-0 & \cdots & a_{n n}-\lambda
\end{array}\right|</script><p>接下来将这两个行列式均按照第2列拆开，变为4个行列式之和</p>
<script type="math/tex; mode=display">
\begin{aligned}
|\boldsymbol{A}-\lambda I|= & \left|\begin{array}{cccc}
a_{11} & a_{12} & \cdots & a_{1 n}-0 \\
a_{21} & a_{22} & \cdots & a_{2 n}-0 \\
\vdots & \vdots & & \vdots \\
a_{n 1} & a_{n 2} & \cdots & a_{n n}-\lambda
\end{array}\right|+\left|\begin{array}{cccc}
a_{11} & -0 & \cdots & a_{1 n}-0 \\
a_{21} & -\lambda & \cdots & a_{2 n}-0 \\
\vdots & \vdots & & \vdots \\
a_{n 1} & -0 & \cdots & a_{n n}-\lambda
\end{array}\right| \\
& +\left|\begin{array}{cccc}
-\lambda & a_{12} & \cdots & a_{1 n}-0 \\
-0 & a_{22} & \cdots & a_{2 n}-0 \\
\vdots & \vdots & & \vdots \\
-0 & a_{n 2} & \cdots & a_{n n}-\lambda
\end{array}\right|+\left|\begin{array}{cccc}
-\lambda & -0 & \cdots & a_{1 n}-0 \\
-0 & -\lambda & \cdots & a_{2 n}-0 \\
\vdots & \vdots & & \vdots \\
-0 & -0 & \cdots & a_{n n}-\lambda
\end{array}\right|
\end{aligned}</script><p>依此类推，将上一步的结果中所有行列式按照下一列拆开，最后可以得到$2^{n}$个行列式，特征值多项式是它们之和</p>
<p>这些行列式的展开结果中，含有$\lambda^{n}$的只有</p>
<script type="math/tex; mode=display">
\left|\begin{array}{ccc}
-\lambda & \cdots & 0 \\
\vdots & & \vdots \\
0 & \cdots & -\lambda
\end{array}\right|</script><p>因此特征多项式的首次项就是$(-1)^{n} \lambda^{n}$ ，含有$\lambda^{n-1}$的是下面$n$个行列式</p>
<script type="math/tex; mode=display">
\left|\begin{array}{cccc}
a_{11} & -0 & \cdots & -0 \\
a_{21} & -\lambda & \cdots & -0 \\
\vdots & \vdots & & \vdots \\
a_{n 1} & -0 & \cdots & -\lambda
\end{array}\right|,\left|\begin{array}{cccc}
-\lambda & a_{12} & \cdots & -0 \\
-0 & a_{22} & \cdots & -0 \\
\vdots & \vdots & & \vdots \\
-0 & a_{n 2} & \cdots & -\lambda
\end{array}\right| \cdots</script><p>它们之和为</p>
<script type="math/tex; mode=display">
(-1)^{n-1}\left(a_{11}+\cdots+a_{n n}\right) \lambda^{n-1}</script><p>因此特征多项式的$\lambda^{n-1}$项系数是<script type="math/tex">(-1)^{n-1} \sum_{i=1}^{n} a_{i i}</script>，不含<script type="math/tex">\lambda</script>的只有下面一个行列式</p>
<script type="math/tex; mode=display">
\left|\begin{array}{cccc}
a_{11} & a_{12} & \cdots & a_{1 n} \\
a_{21} & a_{22} & \cdots & a_{2 n} \\
\vdots & \vdots & & \vdots \\
a_{n 1} & a_{n 2} & \cdots & a_{n n}
\end{array}\right|</script><p>因此特征多项式中常数项的系数为$|\boldsymbol{A}|$，由此可以得到特征多项式为</p>
<script type="math/tex; mode=display">
(-1)^{n} \lambda^{n}+(-1)^{n-1} \operatorname{tr}(\boldsymbol{A}) \lambda^{n-1}+c_{n-2} \lambda^{n-2}+\cdots+c_{1} \lambda+|\boldsymbol{A}|</script><p>将特征多项式乘以$(-1)^{n}$可以变为</p>
<script type="math/tex; mode=display">
\lambda^{n}-\operatorname{tr}(\boldsymbol{A}) \lambda^{n-1}+c_{n-2} \lambda^{n-2}+\cdots+c_{1} \lambda+(-1)^{n}|\boldsymbol{A}|</script><p>因此矩阵所有特征值的和为矩阵的迹</p>
<script type="math/tex; mode=display">
\sum_{i=1}^{n} \lambda_{i}=\operatorname{tr}(\boldsymbol{A})</script><p>所有特征值的积为矩阵的行列式</p>
<script type="math/tex; mode=display">
\prod_{i=1}^{n} \lambda_{i}=(-1)^{n}(-1)^{n}|\boldsymbol{A}|=|\boldsymbol{A}|</script><blockquote>
<p>特征值的若干重要性质</p>
</blockquote>
<p>1️⃣如果矩阵<script type="math/tex">A</script>可逆且<script type="math/tex">\lambda</script>为它的特征值，则<script type="math/tex">\lambda^{-1}</script>是<script type="math/tex">A^{-1}</script>的特征值，根据特征值与特征向量的定义有</p>
<script type="math/tex; mode=display">
\boldsymbol{A x}=\lambda \boldsymbol{x}</script><p>上式两边同时左乘$A^{-1}$，可以得到</p>
<script type="math/tex; mode=display">
A^{-1} A x=x=\lambda A^{-1} x</script><p>即</p>
<script type="math/tex; mode=display">
\boldsymbol{A}^{-1} x=\lambda^{-1} x</script><p>因此<script type="math/tex">\lambda^{-1}</script>是<script type="math/tex">A^{-1}</script>的特征值，<script type="math/tex">x</script>为对应的特征向量</p>
<p>2️⃣如果$\lambda$是矩阵$A$的特征值，则$\lambda^{n}$是$\boldsymbol{A}^{n}$的特征值，根据特征值与特征向量的定义有</p>
<script type="math/tex; mode=display">
A x=\lambda x</script><p>反复利用此式，有</p>
<script type="math/tex; mode=display">
A^{n} x=A^{n-1} A x=A^{n-1} \lambda x=\lambda A^{n-2} A x=\lambda A^{n-2} \lambda x=\cdots=\lambda^{n} x</script><p>因此$\lambda^{n}$是$\boldsymbol{A}^{n}$的特征值，类似地可以证明如果$\lambda$是矩阵$\boldsymbol{A}$的特征值，则$k \lambda$是$k \boldsymbol{A}$的特征值，对于如下的多项式</p>
<script type="math/tex; mode=display">
f(x)=a_{n} x^{n}+a_{n-1} x^{n-1}+\cdots+a_{1} x</script><p>3️⃣如果$\lambda$是矩阵$\boldsymbol{A}$的特征值，则$f(\lambda)$是$f(\boldsymbol{A})$的特征值</p>
<p>4️⃣矩阵$A$与$A^{\mathrm{T}}$有相同的特征值，显然</p>
<script type="math/tex; mode=display">
(\boldsymbol{A}-\lambda I)^{\mathrm{T}}=A^{\mathrm{T}}-(\lambda I)^{\mathrm{T}}=A^{\mathrm{T}}-\lambda I</script><p>因此</p>
<script type="math/tex; mode=display">
|A-\lambda I|=\left|A^{\mathrm{T}}-\lambda I\right|</script><blockquote>
<p>特征向量的若干重要性</p>
</blockquote>
<p>1️⃣如果向量<script type="math/tex">x_{1}, \cdots, x_{1}</script>都是矩阵<script type="math/tex">A</script>关于同一个特征值<script type="math/tex">\lambda</script>的特征向量，则它们的非$\mathbf{0}$线性组合</p>
<script type="math/tex; mode=display">
\sum_{i=1}^{l} k_{i} x_{i}</script><p>也是矩阵$\boldsymbol{A}$关于$\lambda$的特征向量，根据特征值与特征向量的定义有</p>
<script type="math/tex; mode=display">
\boldsymbol{A}\left(\sum_{i=1}^{l} k_{i} x_{i}\right)=\sum_{i=1}^{l} k_{i} \boldsymbol{A} x_{i}=\sum_{i=1}^{l} k_{i} \lambda x_{i}=\lambda \sum_{i=1}^{l} k_{i} x_{i}</script><p>因此<script type="math/tex">\sum_{i=1}^{1} k_{i} x_{i}</script>是关于<script type="math/tex">\lambda</script>的特征向量</p>
<p>2️⃣矩阵属于不同特征值的特征向量线性无关</p>
<p>假设矩阵$A$的$l$个不同特征值为<script type="math/tex">\lambda_{1}, \cdots, \lambda_{l}</script>，它们对应的特征向量为<script type="math/tex">x_{1}, \cdots, x_{l}</script>，下面用归纳法进行证明</p>
<p>当$l=1$时结论成立，因为<script type="math/tex">x_{1} \neq \mathbf{0}</script>，如果<script type="math/tex">k_{1} x_{1}=\mathbf{0}</script>，则必定有<script type="math/tex">k_{1}=0</script></p>
<p>假设当$l=m$时结论成立，当$l=m+1$时，有</p>
<script type="math/tex; mode=display">
k_{1} x_{1}+\cdots+k_{m} x_{m}+k_{m+1} x_{m+1}=\mathbf{0}</script><p>式子两边左乘$\boldsymbol{A}$，有</p>
<script type="math/tex; mode=display">
\boldsymbol{A}\left(k_{1} x_{1}+\cdots+k_{m} \boldsymbol{x}_{m}+k_{m+1} \boldsymbol{x}_{m+1}\right)=\mathbf{0}</script><p>由于</p>
<script type="math/tex; mode=display">
A x_{i}=\lambda_{i} x_{i}</script><p>因此</p>
<script type="math/tex; mode=display">
k_{1} \lambda_{1} x_{1}+\cdots+k_{m} \lambda_{m} \boldsymbol{x}_{m}+k_{m+1} \lambda_{m+1} \boldsymbol{x}_{m+1}=\mathbf{0}</script><p>将第一个式子乘以$\lambda_{m+1}$，然后减去上式，可得</p>
<script type="math/tex; mode=display">
k_{1}\left(\lambda_{m+1}-\lambda_{1}\right) \boldsymbol{x}_{1}+\cdots+k_{m}\left(\lambda_{m+1}-\lambda_{m}\right) \boldsymbol{x}_{m}=\mathbf{0}</script><p>由于<script type="math/tex">x_{1}, \cdots, x_{m}</script>线性无关，因此</p>
<script type="math/tex; mode=display">
{i}\left(\lambda_{m+1}-\lambda_{i}\right)=0, i=1, \cdots, m</script><p>而<script type="math/tex">\lambda_{m+1} \neq \lambda_{i}, i=1, \cdots, m</script>，因此<script type="math/tex">k_{i}=0, i=1, \cdots, m</script>，将<script type="math/tex">k_{i}=0, i=1, \cdots, m</script>代入第一个式子可得</p>
<script type="math/tex; mode=display">
k_{m+1} x_{m+1}=\mathbf{0}</script><p>由于是特征向量，因此<script type="math/tex">\boldsymbol{x}_{m+1} \neq \mathbf{0}</script>，故<script type="math/tex">k_{m+1}=0</script>，因此<script type="math/tex">\boldsymbol{x}_{1}, \cdots, \boldsymbol{x}_{m+1}</script>线性无关</p>
<p>3️⃣实对称矩阵的特征值均为实数</p>
<p>首先定义矩阵的<code>共轭</code>运算，复数矩阵$\boldsymbol{A}$的共轭$\overline{\boldsymbol{A}}$为将其所有元素共轭后形成的矩阵，例如对于下面的矩阵</p>
<script type="math/tex; mode=display">
\boldsymbol{A}=\left(\begin{array}{cc}
1-i & 1 \\
1 & 1+i
\end{array}\right)</script><p>其共轭矩阵为</p>
<script type="math/tex; mode=display">
\bar{A}=\left(\begin{array}{cc}
1+i & 1 \\
1 & 1-i
\end{array}\right)</script><p>可以证明共轭运算满足下面的性质</p>
<script type="math/tex; mode=display">
\overline{A+B}=\bar{A}+\bar{B} \qquad \overline{k A}=\bar{k} \bar{B} \qquad \overline{A B}=\bar{A} \bar{B} \qquad \overline{(A B)^{T}}=\bar{B}^{T} \bar{A}^{T}</script><p>显然对于实矩阵有</p>
<script type="math/tex; mode=display">
\bar{A}=A</script><p>假设$\lambda$是实对称矩阵$\boldsymbol{A}$的特征值，$x$是对应的特征向量</p>
<p>由于是实对称矩阵，因此$\bar{A}^{\mathrm{T}}=A$，由于$A x=\lambda x$，因此</p>
<script type="math/tex; mode=display">
\overline{A x}^{\mathrm{T}}=\overline{\lambda x}^{\mathrm{T}}</script><p>上式两边同时右乘$\boldsymbol{x}$可以得到</p>
<script type="math/tex; mode=display">
\overline{\boldsymbol{A} \boldsymbol{x}}^{\mathrm{T}} \boldsymbol{x}=\overline{\boldsymbol{x}^{\mathrm{T}} \boldsymbol{A}^{\mathrm{T}}} \boldsymbol{x}=\overline{\lambda \boldsymbol{x}}^{\mathrm{T}} \boldsymbol{x}=\overline{\boldsymbol{\lambda}^{\mathrm{T}}} \boldsymbol{x}</script><p>从而有</p>
<script type="math/tex; mode=display">
\overline{\boldsymbol{x}}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{x}=\overline{\boldsymbol{x}}^{\mathrm{T}} \lambda \boldsymbol{x}=\lambda \overline{\boldsymbol{x}^{\mathrm{T}}} \boldsymbol{x}=\bar{\lambda} \overline{\boldsymbol{x}^{\mathrm{T}}} \boldsymbol{x}</script><p>由于$x \neq 0$，因此$\overline{x^T} x&gt;0$，可以得到 $\lambda=\bar{\lambda}$，这意呠着$\lambda$是实数</p>
<p>4️⃣实对称矩阵属于不同特征值的特征向量相互正交</p>
<p>假设$A$为实对称矩阵，<script type="math/tex">\lambda_{1}, \lambda_{2}</script>是它的两个不同的特征值，<script type="math/tex">x_{1}, x_{2}</script>分别为属于<script type="math/tex">\lambda_{1}, \lambda_{2}</script>的特征向量，则有</p>
<script type="math/tex; mode=display">
\begin{array}{l}
\boldsymbol{A} \boldsymbol{x}_{1}=\lambda_{1} \boldsymbol{x}_{1} \qquad
\boldsymbol{A} \boldsymbol{x}_{2}=\lambda_{2} \boldsymbol{x}_{2}
\end{array}</script><p>上式的第一式两边左乘$x_{2}^{\mathrm{T}}$可以得到</p>
<script type="math/tex; mode=display">
\boldsymbol{x}_{2}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{x}_{1}=\lambda_{1} \boldsymbol{x}_{2}^{\mathrm{T}} \boldsymbol{x}_{1}</script><p>而</p>
<script type="math/tex; mode=display">
\boldsymbol{x}_{2}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{x}_{1}=\left(\boldsymbol{A}^{\mathrm{T}} \boldsymbol{x}_{2}\right)^{\mathrm{T}} \boldsymbol{x}_{1}=\left(\boldsymbol{A} \boldsymbol{x}_{2}\right)^{\mathrm{T}} \boldsymbol{x}_{1}=\lambda_{2} \boldsymbol{x}_{2}^{\mathrm{T}} \boldsymbol{x}_{1}</script><p>因此有</p>
<script type="math/tex; mode=display">
\lambda_{1} x_{2}^{\mathrm{T}} x_{1}=\lambda_{2} x_{2}^{\mathrm{T}} x_{1}</script><p>由于<script type="math/tex">\lambda_{1} \neq \lambda_{2}</script>，因此<script type="math/tex">x_{2}^{\mathrm{T}} x_{1}=0</script></p>
<p><strong>机器学习中使用的矩阵一般为实对称矩阵，因此特征值均为实数，且不同特征值的特征向量正交</strong></p>
<p>特征值和特征向量被大量用于机器学习算法，典型的包括<code>主成分分析</code>(PCA)，<code>线性判别分析</code>(LDA)，<code>流形学习</code>等降维算法</p>
<h2 id="相似变换"><a href="#相似变换" class="headerlink" title="相似变换"></a>相似变换</h2><p>通过相似变换可以将一个矩阵变为对角矩阵</p>
<blockquote>
<p>定义</p>
</blockquote>
<p>如果有两个矩阵$A$、$B$以及一个可逆矩阵$P$满足</p>
<script type="math/tex; mode=display">
\boldsymbol{P}^{-1} \boldsymbol{A P}=\boldsymbol{B}</script><p>则称矩阵$A$，$B$相似，记为$A \sim B$，上式称为<code>相似变换</code>，$P$为<code>相似变换矩阵</code></p>
<blockquote>
<p>性质</p>
</blockquote>
<p>相似具有自反性，矩阵与其自身相似，即$A \sim A$，显然</p>
<script type="math/tex; mode=display">
I^{-1} A I=A</script><p>相似具有对称性，如果$A \sim B$，则$B \sim A$，由于</p>
<script type="math/tex; mode=display">
P^{-1} A P=B</script><p>上式两边左乘$P$，右乘$P^{-1}$，可以得到</p>
<script type="math/tex; mode=display">
\boldsymbol{A}=\boldsymbol{P B} \boldsymbol{P}^{-1}=\left(\boldsymbol{P}^{-1}\right)^{-1} \boldsymbol{B} \boldsymbol{P}^{-1}</script><p>相似具有传递性，如果$A \sim B$且$B \sim C$，则$A \sim C$，由于$A \sim B$且$B \sim C$，因此有</p>
<script type="math/tex; mode=display">
\boldsymbol{P}_{1}^{-1} \boldsymbol{A} \boldsymbol{P}_{1}=\boldsymbol{B}  \qquad

\boldsymbol{P}_{2}^{-1} \boldsymbol{B} \boldsymbol{P}_{2}=\boldsymbol{C}</script><p>从而有</p>
<script type="math/tex; mode=display">
\boldsymbol{P}_{2}^{-1} \boldsymbol{B} \boldsymbol{P}_{2}=\boldsymbol{P}_{2}^{-1}\left(\boldsymbol{P}_{1}^{-1} \boldsymbol{A P} \boldsymbol{P}_{1}\right) \boldsymbol{P}_{2}=\left(\boldsymbol{P}_{1} \boldsymbol{P}_{2}\right)^{-1} A\left(P_{1} P_{2}\right)=C</script><p>相似矩阵有相同的特征值，这意昩着相似变换保持矩阵的特征值不变</p>
<p>假设$A \sim B$，则存在可逆矩阵$\boldsymbol{P}$使得</p>
<script type="math/tex; mode=display">
P^{-1} A P=B</script><p>因此</p>
<script type="math/tex; mode=display">
\begin{aligned}
|B-\lambda I| & =|P^{-1} A P-\lambda I|=|P^{-1} A P-\lambda P^{-1} I P|=|P^{-1}(A-\lambda I) P| \\
& =|P^{-1}||A-\lambda I||P|=|A-\lambda I|
\end{aligned}</script><p>这一性质可用于求解特征值，通过相似变换将矩阵$A$变为对角矩阵或三角矩阵</p>
<p>特征值不变，对角矩阵或三角矩阵的主对角线元素即为$A$的特征值</p>
<p>如果矩阵满足一定的条件，通过相似变换可将其转为对角矩阵</p>
<p>假设<script type="math/tex">\lambda _1, \cdots , \lambda _n</script>是$n$阶矩阵$A$的$n$个特佂值，<script type="math/tex">x_{1}, \cdots, x_{n}</script>是它们对应的特征向量根据特征值与特征向量的定义有</p>
<script type="math/tex; mode=display">
\left(\begin{array}{lll}
A x_{1} & \cdots & A x_{n}
\end{array}\right)=\left(\lambda_{1} x_{1} \cdots \lambda_{n} x_{n}\right)</script><p>如果令矩阵<script type="math/tex">P=\left(x_{1} \cdots x_{n}\right)</script>，对角矩阵</p>
<script type="math/tex; mode=display">
\Lambda=\left(\begin{array}{ccc}
\lambda_{1} & \cdots & 0 \\
\vdots & & \vdots \\
0 & \cdots & \lambda_{n}
\end{array}\right)</script><p>根据右乘对角矩阵的性质有</p>
<script type="math/tex; mode=display">
\left(\begin{array}{llll}
\boldsymbol{A} \boldsymbol{x}_{1} & \cdots & \boldsymbol{A} \boldsymbol{x}_{n}
\end{array}\right)=\boldsymbol{A P}=\left(\begin{array}{llll}
\lambda_{1} \boldsymbol{x}_{1} & \cdots & \lambda_{n} \boldsymbol{x}_{n}
\end{array}\right)=\boldsymbol{P} \boldsymbol{\Lambda}</script><p>即</p>
<script type="math/tex; mode=display">
A P=P A</script><p>如果矩阵$P$可逆，那么上式两边同时左乘$P^{-1}$可以得到</p>
<script type="math/tex; mode=display">
\boldsymbol{P}^{-1} A P=P^{-1} P \boldsymbol{\Lambda}=\boldsymbol{\Lambda}</script><p>通过这种相似变换可以将矩阵化为对角矩阵，称为矩阵的<code>相似对角化</code></p>
<script type="math/tex; mode=display">
\boldsymbol{P}^{-1} A P=\Lambda</script><p>式子意味着可以以矩阵$A$的特征向量为列构造一个矩阵$P$，通过它将矩阵对角化，得到以$A$的特征值为主对角线的对角矩阵$\boldsymbol{\Lambda}$</p>
<p>这种做法成立的条件是矩阵$\boldsymbol{P}$可逆，即矩阵$A$有$n$个线性无关的特征向量</p>
<h2 id="正交变换"><a href="#正交变换" class="headerlink" title="正交变换"></a>正交变换</h2><p>对于实对称矩阵，我们可以构造一个正交的相似变换将其对角化</p>
<blockquote>
<p>用归纳法证明实对称矩阵一定可以对角化</p>
</blockquote>
<p>这意味着$n$阶实对称矩阵有$n$个线性无关的特征向量，实对称矩阵$A$属于不同特征值的特征向量是相互正交的</p>
<p>如果用<code>格拉姆-施密特</code>正交化将同一个特征值的所有特征向量正交化，然后将所有特征向量单位化，可以得到一组标准正交基<script type="math/tex">\boldsymbol{p}_{1}, \cdots, \boldsymbol{p}_{n}</script></p>
<p>以它们为列构造相似变换矩阵$\boldsymbol{P}$，则矩阵$\boldsymbol{P}$是正交矩阵，可通过正交变换(Orthogonal Transformation)将矩阵化为对角阵</p>
<script type="math/tex; mode=display">
P^{\mathrm{T}} A P=\Lambda</script><p>由于$P^{T}=P^{-1}$，因此这是一种更特殊的相似变换，实现时只需要对同一个特征值的不同特征向量正交化，然后将所有正交化之后的特征向量进行标准化即可</p>
<blockquote>
<p>例子</p>
</blockquote>
<p>将矩阵通过正交变换化为对角矩阵。对于下面的矩阵</p>
<script type="math/tex; mode=display">
\boldsymbol{A}=\left(\begin{array}{lll}
0 & 1 & 1 \\
1 & 0 & 1 \\
1 & 1 & 0
\end{array}\right)</script><p>其特征多项式为</p>
<script type="math/tex; mode=display">
|\boldsymbol{A}-\lambda \boldsymbol{I}|=\left|\begin{array}{ccc}
-\lambda & 1 & 1 \\
1 & -\lambda & 1 \\
1 & 1 & -\lambda
\end{array}\right|=-(\lambda-2)(\lambda+1)^{2}</script><p>因此其特征值为$2,-1 ，-1$，当$\lambda=2$时，有</p>
<script type="math/tex; mode=display">
(\boldsymbol{A}-2 \boldsymbol{I}) \boldsymbol{x}=\mathbf{0}</script><p>解得</p>
<script type="math/tex; mode=display">
\boldsymbol{x}_{1}=\left(\begin{array}{lll}
1 & 1 & 1
\end{array}\right)^{\mathrm{T}}</script><p>当$\lambda=-1$时，有</p>
<script type="math/tex; mode=display">
(\boldsymbol{I}+\boldsymbol{A}) \boldsymbol{x}=\mathbf{0}</script><p>解得</p>
<script type="math/tex; mode=display">
\begin{array}{llll}
x_{2}=\left(\begin{array}{lll}
-1 & 1 & 0
\end{array}\right)^{\mathrm{T}} \qquad x_{3}=\left(\begin{array}{lll}
-1 & 0 & 1
\end{array}\right)^{\mathrm{T}}
\end{array}</script><p>正交单位化之后为</p>
<script type="math/tex; mode=display">
\begin{array}{l} 
p_{1}=\frac{1}{\sqrt{3}}\left(\begin{array}{llll}
1 & 1 & 1
\end{array}\right)^{\mathrm{T}} \qquad p_{2}=\frac{1}{\sqrt{2}}\left(\begin{array}{ccc}
-1 & 1 & 0
\end{array}\right)^{\mathrm{T}} \qquad p_{3}=\frac{1}{\sqrt{6}}(-1 & -1 & 2)^T
\end{array}</script><p>令</p>
<script type="math/tex; mode=display">
\begin{array}{l} 
\boldsymbol{P}=\left(\begin{array}{lll}
p_{1} & \boldsymbol{p}_{2} & \boldsymbol{p}_{3}
\end{array}\right)=\left(\begin{array}{ccc}
\frac{1}{\sqrt{3}} & -\frac{1}{\sqrt{2}} & -\frac{1}{\sqrt{6}} \\
\frac{1}{\sqrt{3}} & \frac{1}{\sqrt{2}} & -\frac{1}{\sqrt{6}} \\
\frac{1}{\sqrt{3}} & 0 & \frac{2}{\sqrt{6}}
\end{array}\right)
\end{array}</script><p>则有</p>
<script type="math/tex; mode=display">
\boldsymbol{P}^{-1} \boldsymbol{A P}=\boldsymbol{P}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{P}=\left(\begin{array}{ccc}
2 & 0 & 0 \\
0 & -1 & 0 \\
0 & 0 & -1
\end{array}\right)</script><p><strong>正交变换具有一个优良的性质，它可以保持矩阵的对称性</strong></p>
<p>假设$A$是对称矩阵，$P$是正交矩阵，使用下面的正交变换</p>
<script type="math/tex; mode=display">
\boldsymbol{B}=\boldsymbol{P}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{P}</script><p>$B$仍然是对称矩阵，下面给出证明，显然有</p>
<script type="math/tex; mode=display">
\boldsymbol{B}^{\mathrm{T}}=\left(\boldsymbol{P}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{P}\right)^{\mathrm{T}}=\boldsymbol{P}^{\mathrm{T}} \boldsymbol{A}^{\mathrm{T}}\left(\boldsymbol{P}^{\mathrm{T}}\right)^{\mathrm{T}}=\boldsymbol{P}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{P}=\boldsymbol{B}</script><blockquote>
<p>豪斯霍尔德(Householder)变换</p>
</blockquote>
<p>特殊的正交变换<code>豪斯霍尔德</code>(Householder)变换，它在QR算法以及其他矩阵算法中有重要的应用</p>
<p>首先定义Householder矩阵，为如下形式</p>
<script type="math/tex; mode=display">
P=I-2 w \boldsymbol{w}^{\mathrm{T}}</script><p>其中$\boldsymbol{w}$是$n$维非0列向量，且有$|\boldsymbol{w}|=1$，显然矩阵$\boldsymbol{P}$是对称矩阵，并且是正交矩阵</p>
<p>由于$P$是对称矩阵，因此有</p>
<script type="math/tex; mode=display">
P^{\mathrm{T}} \boldsymbol{P}=\boldsymbol{P P}=\left(\boldsymbol{I}-2 \boldsymbol{w} \boldsymbol{w}^{\mathrm{T}}\right)\left(\boldsymbol{I}-2 \boldsymbol{w} \boldsymbol{w}^{\mathrm{T}}\right)=\boldsymbol{I}-4 \boldsymbol{w} \boldsymbol{w}^{\mathrm{T}}+4 \boldsymbol{w}\left(\boldsymbol{w}^{\mathrm{T}} \boldsymbol{w}\right) \boldsymbol{w}^{\mathrm{T}}=\boldsymbol{I}</script><p>故该矩阵是正交矩阵，通常将$P$写成如下形式</p>
<script type="math/tex; mode=display">
\boldsymbol{P}=\boldsymbol{I}-\frac{\boldsymbol{u} \boldsymbol{u}^{\mathrm{T}}}{H}</script><p>其中$u$为任意非$\mathbf{0}$向量且</p>
<script type="math/tex; mode=display">
H=\frac{1}{2}\|\boldsymbol{u}\|^{2}</script><p>这里用$H$对$u$进行了标准化</p>
<p>对于$n$维列向量$\boldsymbol{x}$，构造下面的向量</p>
<script type="math/tex; mode=display">
\boldsymbol{u}=\boldsymbol{x} \mp\|x\| \boldsymbol{e}_{1}</script><p>其中单位向量$\boldsymbol{e}_{1}=\left(\begin{array}{llll}1 &amp; 0 &amp; \cdots &amp; 0\end{array}\right)^{\mathrm{T}}$</p>
<p>根据$\boldsymbol{u}$用上面的式子构造Householder矩阵$\boldsymbol{P}$，下面将向量$x$左乘$P$的结果</p>
<script type="math/tex; mode=display">
\begin{aligned}
\boldsymbol{P} \boldsymbol{x} & =\left(\boldsymbol{I}-\frac{\boldsymbol{u} u^{\mathrm{T}}}{H}\right) \boldsymbol{x}=\boldsymbol{x}-\frac{\boldsymbol{u}}{H}\left(\boldsymbol{x} \mp\|\boldsymbol{x}\| \boldsymbol{e}_{1}\right)^{\mathrm{T}} \boldsymbol{x}=\boldsymbol{x}-\frac{2 \boldsymbol{u}\left(\|\boldsymbol{x}\|^{2} \mp\|\boldsymbol{x}\| x_{1}\right)}{\left(\boldsymbol{x} \mp\|\boldsymbol{x}\| \boldsymbol{e}_{1}\right)^{\mathrm{T}}\left(\boldsymbol{x} \mp\|\boldsymbol{x}\| \boldsymbol{e}_{1}\right)} \\
& =\boldsymbol{x}-\frac{2 \boldsymbol{u}\left(\|\boldsymbol{x}\|^{2} \mp\|\boldsymbol{x}\| x_{1}\right)}{2\|\boldsymbol{x}\|^{2} \mp 2\|x\| x_{1}}=\boldsymbol{x}-\boldsymbol{u}=\pm\|\boldsymbol{x}\| \boldsymbol{e}_{1}
\end{aligned}</script><p>其中$x_{1}$是$x$的第1个分量</p>
<p>这表明将列向量$\boldsymbol{x}$左乘$\boldsymbol{P}$之后将零化$\boldsymbol{x}$除第1个元素之外的所有元素，同时保持向量的长度不变，将行向量右乘该矩阵之后有类似的效果</p>
<p>根据这一特性，我们可以构造以Householder矩阵为基础的正交变换，将矩阵转化为类似对角矩阵的形式，零化主对角线之外的元素</p>
<p>对于对称矩阵$\boldsymbol{A}$，使用它的第1列计算向量$u$，按照上面的式子构造Householder矩阵$P$</p>
<p>然后对$A$进行正交变换，这里的正交变换通过将矩阵$A$先左乘$P$，然后右乘$P$实现</p>
<script type="math/tex; mode=display">
\boldsymbol{P}^{\mathrm{T}} \boldsymbol{A P}=\boldsymbol{P A P}</script><p>左乘$P$实现$A$的第1列的零化，右乘$P$实现$A$的第1行的零化</p>
<p>下面来看矩阵$P$的构造</p>
<p>如果用$A$的整个第1列作为向量，按照上面的式子构造$P$，虽然可在左乘$P$之后将$A$的第1列除第1个元素之外的所有元素全部零化，但会改变$A$的第1行所有元素的值</p>
<p>接下来在右乘$P$的时候无法保证将$P A$的第1行零化，因此$P$需要保证将$A$的第1列的元素零化的同时确保$A$的第1行的元素不变，以便在右乘$P$的时候将这个行零化</p>
<p>我们可以按照下面的形式构造$P$</p>
<script type="math/tex; mode=display">
\boldsymbol{P}=\left(\begin{array}{ccccc}
1 & 0 & 0 & \cdots & 0 \\
0 & p_{22} & p_{23} & \cdots & p_{2 n} \\
0 & p_{32} & p_{33} & \cdots & p_{3 n} \\
\cdots & \cdots & \cdots & & \cdots \\
0 & p_{n 2} & p_{n 3} & \cdots & p_{n n}
\end{array}\right)=\left(\begin{array}{cc}
\boldsymbol{I}_{1 \times 1} & \mathbf{0}_{1 \times(n-1)} \\
\mathbf{0}_{(n-1) \times 1} & \boldsymbol{P}_{(n-1) \times(n-1)}
\end{array}\right)</script><p>其中</p>
<script type="math/tex; mode=display">
\left(\begin{array}{cccc}
p_{22} & p_{23} & \cdots & p_{2 n} \\
p_{32} & p_{33} & \cdots & p_{3 n} \\
\vdots & \vdots & \vdots & \vdots \\
p_{n 2} & p_{n 3} & \cdots & p_{n n}
\end{array}\right)</script><p>是用$\boldsymbol{A}$的第1列的后面$n-1$个元素按照上面式子构造的</p>
<p>我们将上上式的矩阵作为第1次豪斯霍尔德变换的矩阵，记为<script type="math/tex">P_{1}</script>，将<script type="math/tex">A</script>左乘<script type="math/tex">P_{1}</script>之后可以保证<script type="math/tex">A</script>的第1行元素不变，同时将<script type="math/tex">A</script>的第1列的后面<script type="math/tex">n-1</script>个元素全部变为0</p>
<p>接下来右乘<script type="math/tex">P_{1}</script>，由于<script type="math/tex">A</script>是对称矩阵，因此第1列和第1行相同，右乘<script type="math/tex">P_{1}</script>可以将第1行后面<script type="math/tex">n-2</script>个元素全部变为0，并且不改变第1列所有元素的值，因此不会破坏前面的列零化结果</p>
<script type="math/tex; mode=display">
\begin{aligned}
\boldsymbol{A}_{1}=\boldsymbol{P}_{1} \boldsymbol{A} \boldsymbol{P}_{1} & =\left(\begin{array}{ccccc}
a_{11} & a_{12} & a_{13} & \cdots & a_{1 n} \\
k & * & * & \cdots & * \\
0 & * & * & \cdots & * \\
\vdots & \vdots & \vdots & & \vdots \\
0 & * & * & \cdots & *
\end{array}\right)\left(\begin{array}{ccccc}
1 & 0 & 0 & \cdots & 0 \\
0 & p_{22} & p_{23} & \cdots & p_{2 n} \\
0 & p_{32} & p_{33} & \cdots & p_{3 n} \\
\cdots & \cdots & \cdots & \cdots & \cdots \\
0 & p_{n 2} & p_{n 3} & \cdots & p_{n n}
\end{array}\right) \\
& =\left(\begin{array}{ccccc}
a_{11} & k & 0 & \cdots & 0 \\
k & * & * & \cdots & * \\
0 & * & * & \cdots & * \\
\vdots & \vdots & \vdots & & \vdots \\
0 & * & * & \cdots & *
\end{array}\right)
\end{aligned}</script><p>然后进行第2次豪斯霍尔德变换</p>
<p>由于正交变换可以保持矩阵的对称性，因此<script type="math/tex">\boldsymbol{A}_{1}</script>仍然是对称矩阵，用<script type="math/tex">A_{1}</script>的第2列的后面<script type="math/tex">n-2</script>个元素构造<script type="math/tex">P_{2}</script></p>
<script type="math/tex; mode=display">
p_{2}=\left(\begin{array}{ccccc}
1 & 0 & 0 & \cdots & 0 \\
0 & 1 & 0 & \cdots & 0 \\
0 & 0 & p_{33} & \cdots & p_{3 n} \\
\vdots & \vdots & \vdots & & \vdots \\
0 & 0 & p_{n 3} & \cdots & p_{n n}
\end{array}\right)=\left(\begin{array}{cc}
\boldsymbol{I}_{2 \times 2} & \mathbf{0}_{2 \times(n-2)} \\
\mathbf{0}_{(n-2) \times 2} & \boldsymbol{P}_{(n-2) \times(n-2)}
\end{array}\right)</script><p>其中</p>
<script type="math/tex; mode=display">
\left(\begin{array}{ccc}
p_{33} & \cdots & p_{3 n} \\
\vdots & & \vdots \\
p_{n 3} & \cdots & p_{n n}
\end{array}\right)</script><p>根据$A_{1}$的第2列的后面$n-2$个元素按照上面的式子构造</p>
<p>经过第2次豪斯霍尔德变换可以将$A_{1}$的第2列的后面$n-3$个元素，第2行的后面$n-3$个元素全部变为0</p>
<script type="math/tex; mode=display">
\boldsymbol{A}_{2}=\boldsymbol{P}_{2} \boldsymbol{A}_{1} \boldsymbol{P}_{2}=\left(\begin{array}{ccccc}
a_{11} & k & 0 & \ldots & 0 \\
k & s & t & \ldots & 0 \\
0 & t & * & \ldots & * \\
\vdots & \vdots & \vdots & \vdots & \vdots \\
0 & 0 & * & \ldots & *
\end{array}\right)</script><p>依此类推，经过$n-2$次豪斯霍尔德变换，可以将对称矩阵化为如下的对称三对角矩阵(Tridiagonal Matrix)</p>
<script type="math/tex; mode=display">
\left(\begin{array}{ccccc}
b_{11} & b_{12} & \cdots & \cdots & 0 \\
b_{21} & b_{22} & b_{23} & \cdots & 0 \\
0 & b_{32} & b_{33} & \cdots & 0 \\
\cdots & \cdots & \cdots & \cdots & \cdots \\
0 & 0 & \cdots & b_{n, n-1} & b_{n n}
\end{array}\right)</script><p>这种矩阵除主对角线、主对角线以上及以下的对角线之外，其他元素均为0</p>
<p>对于一般的$n$阶矩阵$\boldsymbol{A}$，用同样的方法构造豪斯霍尔德矩阵</p>
<p>左乘$P$之后将$A$的第1列后面$n-2$个元素零化，同时保持$\boldsymbol{A}$的第1行元素不变</p>
<p>由于$\boldsymbol{A}$不是对角矩阵，其行和列不相等，因此右乘$\boldsymbol{P}$ 时候无法将其第1行元素零化</p>
<p>同样不能用完整的列构造豪斯霍尔德变换矩 阵，否则右乘该矩阵的时候会破坏前面零化的结果</p>
<p>用和对称矩阵相同的方法构造变换矩阵，第一次豪斯霍尔德变换之后的结果为</p>
<script type="math/tex; mode=display">
A_{1}=P_{1} A P_{1}=\left(\begin{array}{ccccc}
a_{11} & * & * & \cdots & * \\
k & * & * & \cdots & * \\
0 & * & * & \cdots & * \\
\vdots & \vdots & \vdots & & \vdots \\
0 & * & * & \cdots & *
\end{array}\right)</script><p>第二次豪斯霍尔德变换可以将第2列的后面$n-3$个元素零化，变换之后的结果为</p>
<script type="math/tex; mode=display">
\boldsymbol{A}_{2}=\boldsymbol{P}_{2} \boldsymbol{A}_{1} \boldsymbol{P}_{2}=\left(\begin{array}{cccccc}
a_{11} & * & * & * & \cdots & * \\
k & * & * & * & \cdots & * \\
0 & s & * & * & \cdots & * \\
0 & 0 & * & * & \cdots & * \\
\vdots & \vdots & \vdots & \vdots & & \vdots \\
0 & 0 & * & * & \cdots & *
\end{array}\right)</script><p>依次类推，通过$n-2$次豪斯霍尔德变换可以将$A$化为如下形式的<code>上海森堡矩阵</code>(upper-Hessenberg form)</p>
<script type="math/tex; mode=display">
\left(\begin{array}{cccccc}
b_{11} & b_{12} & b_{13} & b_{14} & \cdots & b_{1 n} \\
b_{21} & b_{22} & b_{23} & b_{24} & \cdots & b_{2 n} \\
0 & b_{32} & b_{33} & b_{34} & \cdots & b_{3 n} \\
0 & 0 & b_{43} & b_{44} & \cdots & b_{4 n} \\
\vdots & \vdots & \vdots & \vdots & & \vdots \\
0 & 0 & 0 & 0 & \cdots & b_{n n}
\end{array}\right)</script><p>这种矩阵除主对角线及以上，主对角线下面的对角线的元素外，其他的元素均为0</p>
<h2 id="QR-算法"><a href="#QR-算法" class="headerlink" title="QR 算法"></a>QR 算法</h2><p>下面介绍求解高阶矩阵特征值的<code>QR筫法</code>，它被誉为20世纪十大算法之一</p>
<p>它依赖于$\mathrm{QR}$分解，对于一个矩阵$A$，$\mathrm{QR}$分解将其化为一个正交矩阵$Q$与一个上三角矩阵$R$的乘积</p>
<script type="math/tex; mode=display">
\boldsymbol{A}=\boldsymbol{Q R}</script><p>$\mathrm{QR}$算法是一种迭代法，从矩阵<script type="math/tex">\boldsymbol{A}_{0}=\boldsymbol{A}</script>开始，每次构造一个相似变换，将<script type="math/tex">\boldsymbol{A}_{k-1}</script>变换为<script type="math/tex">\boldsymbol{A}_{k}</script>，最后<script type="math/tex">A_{k}</script>收敛到一个上角矩阵，主对角线元素即为其特征值</p>
<p>由于矩阵<script type="math/tex">A</script>与<script type="math/tex">A_{k}</script>相似，因此它们有相同的特征值，得到了<script type="math/tex">A_{k}</script>的特征值即得到了<script type="math/tex">A</script>的特征值</p>
<p>问题的核心是如何构造这种相似变换，这借助于$\mathrm{QR}$分解实现，每次迭代时，首先对$\boldsymbol{A}_{k}$进行$\mathrm{QR}$分解</p>
<script type="math/tex; mode=display">
\boldsymbol{A}_{k}=\boldsymbol{Q}_{k} \boldsymbol{R}_{k}</script><p>然后用分解结果构造一个新的矩阵$\boldsymbol{A}_{k+1}$，这里将$\mathrm{QR}$分解的结果矩阵交换顺序后相乘</p>
<script type="math/tex; mode=display">
\boldsymbol{A}_{k+1}=\boldsymbol{R}_{k} \boldsymbol{Q}_{k}</script><p>上面两个式子给出了根据当前矩阵构造下一个矩阵的方式，称为$\mathrm{QR}$迭代</p>
<p>因为<script type="math/tex">A_{k}</script>与<script type="math/tex">A_{k+1}</script>是相似的，式<script type="math/tex">A_k</script>两边同时左乘<script type="math/tex">Q_{k}^{-1}</script>可以得到</p>
<script type="math/tex; mode=display">
\boldsymbol{R}_{k}=\boldsymbol{Q}_{k}^{-1} \boldsymbol{A}_{k}</script><p>将其代人式$A_{k+1}$可得</p>
<script type="math/tex; mode=display">
\boldsymbol{A}_{k+1}=\boldsymbol{R}_{k} \boldsymbol{Q}_{k}=\boldsymbol{Q}_{k}^{-1} \boldsymbol{A}_{k} \boldsymbol{Q}_{k}</script><p>由于相似具有传递性，因此$A$与$A_{k}, k=1, \cdots, n$相似</p>
<p>如果$\boldsymbol{A}$满足一定的条件，那么$\mathrm{QR}$迭代所产生的矩阵序列${\boldsymbol{A}_{k}}$将收敛到一个上三角矩阵，主对角线元素即为$\boldsymbol{A}$的特征值</p>
<p>$Q R$迭代是正交变换，如果$A$是对称矩阵，这种变换将保持对称性，且收敛到上三角矩阵，因此最终会收敛到对角矩阵</p>
<p>对于实对称矩阵$A$，$Q R$迭代代产生的所有正交矩阵$Q_{k}$的乘积的所有列，即为$\boldsymbol{A}$的特征向量，由于</p>
<script type="math/tex; mode=display">
\boldsymbol{A}_{k+1}=Q_{k}^{-1} A_{k} Q_{k}</script><p>因此</p>
<script type="math/tex; mode=display">
\begin{aligned}
\Lambda & =A_{k}=Q_{k-1}^{-1} A_{k-1} Q_{k-1}=Q_{k-1}^{-1} Q_{k-2}^{-1} A_{k-2} Q_{k-2} Q_{k-1}=\cdots \\
& =Q_{k-1}^{-1} Q_{k-2}^{-1} \cdots Q_{0}^{-1} A_{0} Q_{0} \cdots Q_{k-2} Q_{k-1}=\left(Q_{0} \cdots Q_{k-2} Q_{k-1}\right)^{-1} A_{0}\left(Q_{0} \cdots Q_{k-2} Q_{k-1}\right) \\
& =\left(Q_{0} \cdots Q_{k-2} Q_{k-1}\right)^{-1} A\left(Q_{0} \cdots Q_{k-2} Q_{k-1}\right)
\end{aligned}</script><p>如果令</p>
<script type="math/tex; mode=display">
P=Q_{0} \ldots Q_{k-2} Q_{k-1}</script><p>则</p>
<script type="math/tex; mode=display">
\Lambda=P^{-1} A P</script><p>因此$P$的列为$A$的特征向量<br>下面来看$\mathrm{QR}$算法的一个例子，对于如下矩阵</p>
<script type="math/tex; mode=display">
A=\left(\begin{array}{ccc}
-149 & -50 & -154 \\
537 & 180 & 546 \\
-27 & -9 & -25
\end{array}\right)</script><p>$Q R$算法第1次迭代的结果为</p>
<script type="math/tex; mode=display">
\boldsymbol{A}_{1}=\boldsymbol{R}_{0} \boldsymbol{Q}_{0}=\left(\begin{array}{ccc}
28.8263 & -259.8671 & 773.9292 \\
1.0353 & -8.6686 & 33.1759 \\
-0.5973 & 5.5786 & -14.1578
\end{array}\right)</script><p>再经过5次迭代后的结果为</p>
<script type="math/tex; mode=display">
\boldsymbol{A}_{6}=\boldsymbol{R}_{5} \boldsymbol{Q}_{5}=\left(\begin{array}{ccc}
3.0321 & -8.0851 & 804.6651 \\
0.0017 & 0.9931 & 145.5046 \\
-0.0001 & 0.0005 & 1.9749
\end{array}\right)</script><p>此时矩阵$A_{6}$已经接近于上三角矩阵，主对角线元素接近于$A$的特征值，事实上，矩阵$A$的特征值为$1,2,3$ </p>
<p>为了加速收敛，通常采用带位移的$QR$算法(Shifted QR Algorithm)，在第$k$次迭代时，对于设定的移位常数$s_{k}$，迭代公式为</p>
<script type="math/tex; mode=display">
\boldsymbol{A}_{k}-s_{k} I=\boldsymbol{Q}_{k} \boldsymbol{R}_{k} \qquad \boldsymbol{A}_{k+1}=\boldsymbol{R}_{k} \boldsymbol{Q}_{k}+s_{k} \boldsymbol{I}</script><p>即先将矩阵<script type="math/tex">\boldsymbol{A}_{k}</script>减掉<script type="math/tex">s_{k} \boldsymbol{I}</script>后再进行<script type="math/tex">\mathrm{QR}</script>分解，在构造<script type="math/tex">\boldsymbol{A}_{k+1}</script>时再将<script type="math/tex">s_{k} \boldsymbol{I}</script>加回来</p>
<p>按照这种迭代公式，<script type="math/tex">\boldsymbol{A}_{k}</script>与<script type="math/tex">\boldsymbol{A}_{k+1}</script>也是相似的，根据上式的1式有</p>
<script type="math/tex; mode=display">
\boldsymbol{R}_{k}=\boldsymbol{Q}_{k}^{-1}\left(\boldsymbol{A}_{k}-s_{k} \boldsymbol{I}\right)</script><p>将其代人上式的2式，可得</p>
<script type="math/tex; mode=display">
A_{k+1}=R_{k} Q_{k}+s_{k} I=Q_{k}^{-1}\left(A_{k}-s_{k} I\right) Q_{k}+s_{k} I=Q_{k}^{-1} A_{k} Q_{k}-Q_{k}^{-1} s_{k} I Q_{k}+s_{k} I=Q_{k}^{-1} A_{k} Q_{k}</script><p>因此<script type="math/tex">\boldsymbol{A}_{k}</script>与<script type="math/tex">\boldsymbol{A}_{k+1}</script>相似</p>
<blockquote>
<p>移位系数$s_{k}$的计算</p>
</blockquote>
<p>一种方案是选择<script type="math/tex">\boldsymbol{A}_{k}</script>右下角<script type="math/tex">2 \times 2</script>子矩阵的两个特征值中接近于<script type="math/tex">\boldsymbol{A}_{k}</script>元素<script type="math/tex">a_{n, n-1}</script>的那个特征值，以便于使得经过此次<script type="math/tex">\mathrm{QR}</script>迭代后<script type="math/tex">\boldsymbol{A}_{k+1}</script>的<script type="math/tex">a_{n, n-1}</script>变为0</p>
<p>计算此子矩阵的特征值可以通过求解特征方程实现</p>
<script type="math/tex; mode=display">
\left|\begin{array}{cc}
a_{n-1, n-1}-\lambda & a_{n-1, n} \\
a_{n, n-1} & a_{n, n}-\lambda
\end{array}\right|=0</script><p>这里<script type="math/tex">\boldsymbol{A}_{k+1}</script>的<script type="math/tex">a_{n n}</script>即为<script type="math/tex">\boldsymbol{A}</script>的一个特征值，对剩下的<script type="math/tex">(n-1) \times(n-1)</script>矩阵继续进行<script type="math/tex">\mathrm{QR}</script>算法迭代， 得到所有的特征值</p>
<p>对于一般的矩阵，QR算法的收敛速度可能很慢，如果将矩阵变换成接近于三角阵，则能加快收敛速度</p>
<p>如果是对称矩阵，可先用豪斯霍尔德变换将其化为对称三对角矩阵，然后用$Q R$算法进行达代，收敛到对角矩阵</p>
<p>求解特征值的整个流程为: 对称矩阵$\rightarrow$对称三对角矩阵$\rightarrow$对角矩阵</p>
<p>对于普通矩阵，可用豪斯霍尔德变换将其化为上海森堡矩阵，然后用QR算法进行迭代，收敛到上三角矩阵</p>
<p>整个流程为: 普通矩阵$\rightarrow$上海森堡矩阵$\rightarrow$三角矩阵</p>
<h2 id="广义特征值"><a href="#广义特征值" class="headerlink" title="广义特征值"></a>广义特征值</h2><p><code>广义特征值</code>(Generalized Eigenvalue)是特征值的推广，定义于两个矩阵之上</p>
<p>对于方阵$A$和$B$，如果存在一个数$\lambda$及非0向量$\boldsymbol{x}$，满足</p>
<script type="math/tex; mode=display">
\boldsymbol{A x}=\lambda \boldsymbol{B x}</script><p>则称$\lambda$为广义特征值，$x$为广义特征向量，类似的有特征方程</p>
<script type="math/tex; mode=display">
|A-\lambda B|=0</script><p>如果矩阵$B$可逆，对第一个式子左乘$B^{-1}$，则式1的问题等价于下面的特征值问题</p>
<script type="math/tex; mode=display">
B^{-1} \boldsymbol{A x}=\lambda \boldsymbol{x}</script><p>广义特征值在机器学习中被广泛使用，包括流形学习、谱聚类算法，以及线性判别分析等</p>
<h2 id="瑞利商"><a href="#瑞利商" class="headerlink" title="瑞利商"></a>瑞利商</h2><blockquote>
<p>瑞利商</p>
</blockquote>
<p>方阵$A$和非0向量$x$的<code>瑞利商</code>(Rayleigh Quotient)定义为如下比值</p>
<script type="math/tex; mode=display">
R(\boldsymbol{A}, \boldsymbol{x})=\frac{\boldsymbol{x}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{x}}{\boldsymbol{x}^{\mathrm{T}} \boldsymbol{x}}</script><p>根据式子的定义，对于任意的非0实数$k$，有</p>
<script type="math/tex; mode=display">
R(\boldsymbol{A}, k \boldsymbol{x})=R(\boldsymbol{A}, \boldsymbol{x})</script><p>即对向量缩放之后其瑞利商不变，瑞利商存在冗余，证明如下</p>
<script type="math/tex; mode=display">
R(\boldsymbol{A}, k \boldsymbol{x})=\frac{(k \boldsymbol{x})^{\mathrm{T}} \boldsymbol{A}(k \boldsymbol{x})}{(k \boldsymbol{x})^{\mathrm{T}}(k \boldsymbol{x})}=\frac{k^{2} \boldsymbol{x}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{x}}{k^{2} \boldsymbol{x}^{\mathrm{T}} \boldsymbol{x}}=\frac{\boldsymbol{x}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{x}}{\boldsymbol{x}^{\mathrm{T}} \boldsymbol{x}}</script><p>假设<script type="math/tex">\lambda_{\text {min }}</script>是矩阵<script type="math/tex">\boldsymbol{A}</script>的最小特征值，<script type="math/tex">\lambda_{\max }</script>是最大特征值，则有</p>
<script type="math/tex; mode=display">
\lambda_{\min } \leqslant R(\boldsymbol{A}, \boldsymbol{x}) \leqslant \lambda_{\max }</script><p>即瑞利商的最小值为矩阵的最小特征值，最大值为矩阵的最大特征值</p>
<p>并且当$x$分别为最小和最大的特征值对应的特征向量的时候取得这两个值，可以用<code>拉格朗日乘数法</code>证明</p>
<p>由于将向量乘以非0系数之后瑞利商不变，因此式1极值问题的解不唯一</p>
<p>为此增加一个约束条件以保证解的唯一性，同时简化问题的表述，限定$x$为单位向量，有下面的等式约束</p>
<script type="math/tex; mode=display">
\boldsymbol{x}^{\mathrm{T}} \boldsymbol{x}=1</script><p>增加此约束之后，瑞利商变为</p>
<script type="math/tex; mode=display">
R(\boldsymbol{A}, \boldsymbol{x})=\boldsymbol{x}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{x}</script><p>构造拉格朗日乘子函数</p>
<script type="math/tex; mode=display">
L(\boldsymbol{x}, \lambda)=\boldsymbol{x}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{x}+\lambda\left(\boldsymbol{x}^{\mathrm{T}} \boldsymbol{x}-1\right)</script><p>对$\boldsymbol{x}$求样度并令栖度为$\boldsymbol{0}$可以得到</p>
<script type="math/tex; mode=display">
2 A x+2 \lambda x=0</script><p>这里利用了矩阵与向量求导公式，上式等价于</p>
<script type="math/tex; mode=display">
A \boldsymbol{x}=\lambda \boldsymbol{x}</script><p>此结果意味着瑞利商的所有极值在矩阵的特征值与特征向量处取得</p>
<p>假设<script type="math/tex">\lambda_{i}</script>是<script type="math/tex">A</script>的第<script type="math/tex">i</script>个待征值、<script type="math/tex">x_{i}</script>是其对应的特征向量，将它们代人瑞利商的定义，可以得到</p>
<script type="math/tex; mode=display">
R\left(\boldsymbol{A}, \boldsymbol{x}_{i}\right)=\frac{\boldsymbol{x}_{i}^{\mathrm{T}}\left(\boldsymbol{A} \boldsymbol{x}_{i}\right)}{\boldsymbol{x}_{i}^{\mathrm{T}} \boldsymbol{x}_{i}}=\frac{\boldsymbol{x}_{i}^{\mathrm{T}}\left(\lambda_{i} \boldsymbol{x}_{i}\right)}{\boldsymbol{x}_{i}^{\mathrm{T}} \boldsymbol{x}_{i}}=\frac{\lambda_{i} \boldsymbol{x}_{i}^{\mathrm{T}} \boldsymbol{x}_{i}}{\boldsymbol{x}_{i}^{\mathrm{T}} \boldsymbol{x}_{i}}=\lambda_{i}</script><p>因此，在最大的特征值处，瑞利商有最大值；在最小的特征值处，瑞利商有最小值</p>
<p>瑞利商在机器学习领域的典型应用是<code>主成分分析</code></p>
<blockquote>
<p>广义瑞利商</p>
</blockquote>
<p>对瑞利商进行推广，得到<code>广义瑞利商</code>，定义为</p>
<script type="math/tex; mode=display">
R(\boldsymbol{A}, \boldsymbol{B}, \boldsymbol{x})=\frac{\boldsymbol{x}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{x}}{\boldsymbol{x}^{\mathrm{T}} \boldsymbol{B} \boldsymbol{x}}</script><p>同样，广义瑞利商存在余，将向量$x$缩放之后广义瑞利商不变</p>
<p>假设对任意的非0向量$x$，有$\boldsymbol{x}^{\mathrm{T}} B x&gt;0$</p>
<p>如果令$B=C C^{\mathrm{T}}$，这是对矩阵$B$的<code>楚列斯基</code>(Cholesky)分解，同时令$x=\left(C^{\mathrm{T}}\right)^{-1} y$，则可以将广义瑞利商转化成瑞利商的形式</p>
<script type="math/tex; mode=display">
\frac{\boldsymbol{x}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{x}}{\boldsymbol{x}^{\mathrm{T}} \boldsymbol{B} \boldsymbol{x}}=\frac{\left(\left(\boldsymbol{C}^{\mathrm{T}}\right)^{-1} \boldsymbol{y}\right)^{\mathrm{T}} \boldsymbol{A}\left(\left(\boldsymbol{C}^{\mathrm{T}}\right)^{-1} \boldsymbol{y}\right)}{\left(\left(\boldsymbol{C}^{\mathrm{T}}\right)^{-1} \boldsymbol{y}\right)^{\mathrm{T}} \boldsymbol{C} \boldsymbol{C}^{\mathrm{T}}\left(\left(\boldsymbol{C}^{\mathrm{T}}\right)^{-1} \boldsymbol{y}\right)}=\frac{\boldsymbol{y}^{\mathrm{T}} \boldsymbol{C}^{-1} \boldsymbol{A}\left(\boldsymbol{C}^{\mathrm{T}}\right)^{-1} \boldsymbol{y}}{\boldsymbol{y}^{\mathrm{T}} \boldsymbol{C}^{-1} \boldsymbol{C} \boldsymbol{C}^{\mathrm{T}}\left(\boldsymbol{C}^{\mathrm{T}}\right)^{-1} \boldsymbol{y}}=\frac{\boldsymbol{y}^{\mathrm{T}} \boldsymbol{C}^{-1} \boldsymbol{A}\left(\boldsymbol{C}^{\mathrm{T}}\right)^{-1} \boldsymbol{y}}{\boldsymbol{y}^{\mathrm{T}} \boldsymbol{y}}</script><p>根据瑞利商的结论，广义瑞利商的最大值和最小值由矩阵$C^{-1} A\left(C^{\mathrm{T}}\right)^{-1}$的最大和最小特佂值决定</p>
<p>也可以直接通过广义特征值得到广义瑞利商的极值，与瑞利商类似，加上等式约束消掉最优解的冗余</p>
<script type="math/tex; mode=display">
\boldsymbol{x}^{\mathrm{T}} \boldsymbol{B} \boldsymbol{x}=1</script><p>广义瑞利商变为</p>
<script type="math/tex; mode=display">
R(\boldsymbol{A}, \boldsymbol{B}, \boldsymbol{x})=\boldsymbol{x}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{x}</script><p>可以用<code>拉格朗日乘数法</code>求解，构造拉格朗日乘子函数</p>
<script type="math/tex; mode=display">
L(\boldsymbol{x}, \boldsymbol{\lambda})=\boldsymbol{x}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{x}+\boldsymbol{\lambda}\left(\boldsymbol{x}^{\mathrm{T}} \boldsymbol{B} \boldsymbol{x}-1\right)</script><p>对$\boldsymbol{x}$求梯度并令梯度为$\boldsymbol{0}$，可以得到</p>
<script type="math/tex; mode=display">
2 A x+2 \lambda B x=0</script><p>这等价于</p>
<script type="math/tex; mode=display">
\boldsymbol{A} \boldsymbol{x}=\lambda \boldsymbol{B x}</script><p>这是广义特征值问题，如果矩阵$\boldsymbol{B}$可逆，那么上式两边同乘以其逆矩阵可以得到</p>
<script type="math/tex; mode=display">
B^{-1} A x=\lambda x</script><p>因此广义瑞利商的所有极值在上面的广义特征值处取得，假设<script type="math/tex">\lambda_{i}</script>是第<script type="math/tex">i</script>个广义特征值，<script type="math/tex">\boldsymbol{x}_{i}</script>是其对应的特征向量，将它们代人广义瑞利商的定义，可以得到</p>
<script type="math/tex; mode=display">
R\left(\boldsymbol{A}, \boldsymbol{B}, \boldsymbol{x}_{i}\right)=\frac{\boldsymbol{x}_{i}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{x}_{i}}{\boldsymbol{x}_{i}^{\mathrm{T}} \boldsymbol{B} \boldsymbol{x}_{i}}=\frac{\boldsymbol{x}_{i}^{\mathrm{T}} \lambda_{i} B x_{i}}{\boldsymbol{x}_{i}^{\mathrm{T}} \boldsymbol{B} \boldsymbol{x}_{i}}=\lambda_{i}</script><p>因此广义瑞利商的极大值在最大广义特征值处取得，极小值在最小广义特征值处取得</p>
<p><strong>线性判別分析的优化目标函数即为广义瑞利商</strong></p>
<h2 id="谱范数与特征值的关系"><a href="#谱范数与特征值的关系" class="headerlink" title="谱范数与特征值的关系"></a>谱范数与特征值的关系</h2><p>前面定义了谱范数的概念，可以证明矩阵$\boldsymbol{W}$的谱范数等于$\boldsymbol{W}^{\mathrm{T}} \boldsymbol{W}$的最大特征值的平方根，即$\boldsymbol{W}$最大的奇异值</p>
<script type="math/tex; mode=display">
\|\boldsymbol{W}\|_{2}=\max \left\{\sigma_{1}，\cdots，\sigma_{n}\right\}</script><p>其中<script type="math/tex">\sigma_{1}，\cdots，\sigma_{n}</script>为<script type="math/tex">\boldsymbol{W}</script>的奇异值，是<script type="math/tex">\boldsymbol{W}^{\mathrm{T}} \boldsymbol{W}</script>的特征值的平方根，奇异值将在后面详细介绍，根据定义，谱范数的平方为</p>
<script type="math/tex; mode=display">
|\boldsymbol{W}\|_{2}^{2}=\max _{\boldsymbol{x} \neq 0} \frac{\boldsymbol{x}^{\mathrm{T}} \boldsymbol{W}^{\mathrm{T}} \boldsymbol{W} \boldsymbol{x}}{\boldsymbol{x}^{\mathrm{T}} \boldsymbol{x}}</script><p>它就是瑞利商的极大值，上一节已经证明了这一最优化问题的解是矩阵$\boldsymbol{W}^{\mathrm{T}} \boldsymbol{W}$的最大特征值，因此结论成立</p>
<p>Python中linalg的norm函数提供了计算矩阵范数的功能，函数的输人参数为要计算的矩阵，以及范数的类型，如果类型值为2，则计算谱范数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">A = np.array([[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>],[<span class="number">8</span>,<span class="number">9</span>,<span class="number">10</span>,<span class="number">11</span>]])</span><br><span class="line"><span class="built_in">print</span>(n)</span><br></pre></td></tr></table></figure>
<p>程序运行结果为22</p>
<h2 id="条件数"><a href="#条件数" class="headerlink" title="条件数"></a>条件数</h2><p>如果矩阵$W$可逆，条件数(Condition Number)定义为它的范数与它的逆矩阵范数的乘积</p>
<script type="math/tex; mode=display">
\operatorname{cond}(\boldsymbol{W})=\|\boldsymbol{W}\| \cdot\left\|\boldsymbol{W}^{-1}\right\|</script><p>这里的范数可以是任何一种范数</p>
<p>如果使用谱范数，则$|\boldsymbol{W}|$等于$\boldsymbol{W}$的最大奇异值，$\left|\boldsymbol{W}^{-1}\right|$等于$W$最小奇异值的逆，根据谱范数的定义有</p>
<script type="math/tex; mode=display">
\left\|\boldsymbol{W}^{-1}\right\|=\max _{\boldsymbol{y} \neq 0} \frac{\left\|\boldsymbol{W}^{-1} y\right\|}{\|\boldsymbol{y}\|}=\max _{\boldsymbol{x} \neq 0} \frac{\|\boldsymbol{x}\|}{\|\boldsymbol{W} \boldsymbol{x}\|}=\frac{1}{\min _{\boldsymbol{x} \neq 0} \frac{\|\boldsymbol{W} \boldsymbol{x}\|}{\|\boldsymbol{x}\|}}</script><p>上式第二步进行了换元，令$\boldsymbol{W}^{-1} y=x$，根据前二节的结论，$\frac{|\boldsymbol{W} \boldsymbol{x}|}{|\boldsymbol{x}|}$的最小奇异值</p>
<p>此时条件数等于矩阵的最大奇异值与最小奇异值的比值</p>
<script type="math/tex; mode=display">
\operatorname{cond}(\boldsymbol{W})=\frac{\max \left\{\sigma_{1},\cdots,\sigma_{n}\right\}}{\min \left\{\sigma_{1},\cdots,\sigma_{n}\right\}}</script><p>其中<script type="math/tex">\sigma_{1}, \cdots, \sigma_{n}</script>为<script type="math/tex">W</script>的奇异值，显然矩阵的条件数总是大于或等于1</p>
<p><strong>条件数决定了矩阵的稳定性</strong>，一个矩阵的条件数越大，则它越接近于不可逆矩阵，矩阵越”病态”</p>
<p>条件数在诸多算法的稳定性分析中有重要的作用，Python中linalg的cond函数实现了计算矩阵条件数的功能</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">A = np.array([[<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">0</span>,<span class="number">5</span>]])</span><br><span class="line">c = np.linalg.cond(A)</span><br><span class="line"><span class="built_in">print</span>(c)</span><br></pre></td></tr></table></figure>
<p>程序运行结果为$5.0$，是该矩阵最大特征值与最小特征值的比值，在这里奇异值等于特征值</p>
<h2 id="应用——谱归一化与谱正则化"><a href="#应用——谱归一化与谱正则化" class="headerlink" title="应用——谱归一化与谱正则化"></a>应用——谱归一化与谱正则化</h2><blockquote>
<p>正则化</p>
</blockquote>
<p>正则化是机器学习中减轻过拟合的一种技术，它迫使模型的参数值很小，使模型变得更简单，一般情况下，简单的模型有更好的泛化性能</p>
<p>正则化可以通过在目标函数中增加正则化项实现，正则化项通常为参数向量的L1范数，或L2范数的平方</p>
<p><code>谱正则化</code>(Spectral Regularization)用谱范数构造正则化项</p>
<p>另外一种技术是<code>谱归一化</code>(Spectral Normalization)，通过用谱范数对线性映射的矩阵进行谱归一化而确保映射有较小的李普希茨常数，从而保证机器学习模型对输人数据的扰动不敏感</p>
<p>神经网络中用权重矩阵$\boldsymbol{W}$与偏置向量$\boldsymbol{b}$对输人数据$\boldsymbol{x}$进行映射，得到输出结果$W x+b$，如果此映射满足李普希茨条件(这里将其推广到多元函数，将绝对值改为向量的范数)，则有</p>
<script type="math/tex; mode=display">
\left\|\boldsymbol{W} x_{1}+b-W x_{2}-b\right\|=\left\|\boldsymbol{W} x_{1}-\boldsymbol{W} x_{2}\right\| \leqslant K\left\|x_{1}-x_{2}\right\|</script><p>其中$K$为李普希茨常数，将式子变形后可以得到</p>
<script type="math/tex; mode=display">
\frac{\left\|\boldsymbol{W}\left(\boldsymbol{x}_{1}-\boldsymbol{x}_{2}\right)\right\|}{\left\|\boldsymbol{x}_{1}-\boldsymbol{x}_{2}\right\|} \leqslant K</script><p>上式左侧部分的极大值就是权重矩阵的谱范数</p>
<p>如果权重矩阵的谱范数存在一个较小的上界，则神经网络该层的映射有较小的李普希茨常数，从而保证输人值的较小改变不会导致输出值的突变，映射更为平滑</p>
<p>假设权重矩阵的谱范数为$\sigma(\boldsymbol{W})$，如果用它对矩阵进行归一化</p>
<script type="math/tex; mode=display">
\overline {W}_{\mathrm{SN}}(\boldsymbol{W})=\boldsymbol{W} / \sigma(\boldsymbol{W})</script><p>则能保证归一化之后的权重矩阵满足$\sigma(\boldsymbol{W})=1$，这由矩阵乘以常数之后的特征值的性质保证</p>
<p>前两节已经证明谱范数是矩阵$W$的最大奇异值，计算矩阵奇异值的代价太大，因此在实现时需要对谱范数$\sigma(\boldsymbol{W})$的值近似计算，可以采用幂迭代法</p>
<p>接下来考虑如何用谱范数为神经网络的目标函数构造正则化项(Spectral Norm Regularizer)</p>
<p>给定训练样本集<script type="math/tex">\left(\boldsymbol{x}_{i}, \boldsymbol{y}_{i}\right), i=1, \cdots, N, \boldsymbol{x}_{i}</script>为输人向量，<script type="math/tex">\boldsymbol{y}_{i}</script>为标签向量，加上谱正则化项后的目标函数为</p>
<script type="math/tex; mode=display">
\frac{1}{N} \sum_{i=1}^{N} L\left(\boldsymbol{x}_{i}, \boldsymbol{y}_{i}\right)+\frac{\lambda}{2} \sum_{i=1}^{l} \sigma\left(\boldsymbol{W}^{(i)}\right)^{2}</script><p>其中<script type="math/tex">L\left(\boldsymbol{x}_{i}, \boldsymbol{y}_{i}\right)</script>为对单个样本的损失函数，<script type="math/tex">l</script>为神经网络的层数，<script type="math/tex">\boldsymbol{W}^{(i)}</script>为第<script type="math/tex">i</script>层的权重矩阵</p>
<p>上式第2项为谱正则化项，$\lambda&gt;0$为正则化项的权重，谱正则化项由神经网络所有层权重矩阵的谱范数平方之和构成</p>
<p>可以防止权重矩阵出现大的谱范数，从而保证神经网络的映射有较小的李普希茨常数</p>
<h1 id="二次型"><a href="#二次型" class="headerlink" title="二次型"></a>二次型</h1><p>二次型是一种特殊的二次函数，只含有二次项，它在线性代数与多元函数微积分中被广泛使用</p>
<p>在机器学习中二次型经常作为目标函数出现</p>
<h2 id="基本概念-2"><a href="#基本概念-2" class="headerlink" title="基本概念"></a>基本概念</h2><p><code>二次型</code>(Quadric Form) 是由纯二次项构成的函数，即二次齐次多项式，如下面的函数</p>
<script type="math/tex; mode=display">
2 x^{2}-3 x y+y^{2}+z^{2}</script><p>二次型可以写成矩阵形式</p>
<script type="math/tex; mode=display">
x^{\mathrm{T}} \boldsymbol{A x}</script><p>其中$\boldsymbol{A}$是$n$阶对称矩阵，$\boldsymbol{x}$是一个列向量，上面的二次型展开之后为</p>
<script type="math/tex; mode=display">
\sum_{i=1}^{n} \sum_{j=1}^{n} a_{i j} x_{i} x_{j}</script><p>这里要求<script type="math/tex">a_{i j}=a_{j i}</script>，需要注意的是，一般的二次函数不一定是二次型，它可能有一次项和常数项</p>
<p>上式的二次型对应的矩阵为</p>
<script type="math/tex; mode=display">
\left(\begin{array}{ccc}
2 & -1.5 & 0 \\
-1.5 & 1 & 0 \\
0 & 0 & 1
\end{array}\right)</script><p>平方项<script type="math/tex">a x_{i}^{2}</script>的系数是矩阵的主对角线元素，交叉乘积项<script type="math/tex">a x_{i} x_{j}</script>的系数由<script type="math/tex">a_{i j}</script>与<script type="math/tex">a_{j i}</script>均分，实对称矩阵与二次型一一对应</p>
<h2 id="正定二次型与正定矩阵"><a href="#正定二次型与正定矩阵" class="headerlink" title="正定二次型与正定矩阵"></a>正定二次型与正定矩阵</h2><p>在某些数学证明或计算中，会将二次函数配方成完全平方的形式以得到想要的结果，如下面的例子</p>
<script type="math/tex; mode=display">
\left(x_{1}-2\right)^{2}+\left(x_{2}+5\right)^{2}+\left(x_{3}-7\right)^{2}</script><p>平方项是非负的，$(2,-5,7)$是该函数的极小值，由此引入二次型和矩阵正定的概念，如果一个二次型对于任意非$\boldsymbol{0}$向量$\boldsymbol{x}$都有</p>
<script type="math/tex; mode=display">
\boldsymbol{x}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{x}>0</script><p>则称该二次型为<code>正定</code>(Positive Definite)二次型，矩阵$\boldsymbol{A}$为正定矩阵，如果对于任意非$\boldsymbol{0}$向量$\boldsymbol{x}$都有</p>
<script type="math/tex; mode=display">
\boldsymbol{x}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{x} \geqslant 0</script><p>则该二次型为<code>半正定</code>(Positive Semi-definite)二次型，矩阵$\boldsymbol{A}$为半正定矩阵，如果对于任意非0向量$\boldsymbol{x}$都在</p>
<script type="math/tex; mode=display">
\boldsymbol{x}^{\mathrm{T}} \boldsymbol{A x}<0</script><p>则该二次型为<code>负定</code>(Negative Definite)二次型，矩阵$A$为负定矩阵，类似地可以定义半负定的概念</p>
<p>如果既不正定也不负定，则称为<code>不定</code></p>
<p>下面的二次型为正定二次型</p>
<script type="math/tex; mode=display">
f\left(x_{1},x_{2},x_{3}\right)=x_{1}^{2}+2 x_{2}^{2}+x_{3}^{2}</script><p>其对应的矩阵为正定矩阵</p>
<script type="math/tex; mode=display">
\left(\begin{array}{lll}
1 & 0 & 0 \\
0 & 2 & 0 \\
0 & 0 & 1
\end{array}\right)</script><p>下面的二次型为半正定二次型</p>
<script type="math/tex; mode=display">
f\left(x_{1},x_{2},x_{3}\right)=x_{1}^{2}+2 x_{2}^{2}</script><p>其对应的矩阵为半正定矩阵</p>
<script type="math/tex; mode=display">
\left(\begin{array}{lll}
1 & 0 & 0 \\
0 & 2 & 0 \\
0 & 0 & 0
\end{array}\right)</script><p>如果令<script type="math/tex">x_{1}=0，x_{2}=0，x_{3}=1</script>，二次型的值为0</p>
<p>下面的二次型是负定二次型</p>
<script type="math/tex; mode=display">
f\left(x_{1},x_{2},x_{3}\right)=-x_{1}^{2}-2 x_{2}^{2}-x_{3}^{2}</script><p>其对应的矩阵为负定矩阵</p>
<script type="math/tex; mode=display">
\left(\begin{array}{ccc}
-1 & 0 & 0 \\
0 & -2 & 0 \\
0 & 0 & -1
\end{array}\right)</script><p><strong>正定二次型被用于多元函数极值的判定法则</strong></p>
<p>正定矩阵的所有主对角线元素$a_{i i}&gt;0，i=1，\cdots，n$</p>
<p>根据正定的定义，由于对于任意非0向量$\boldsymbol{x}$都有$\boldsymbol{x}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{x}&gt;0$，因此可以构造一个第$i$个分量为1，其他分量均为0的向量$\boldsymbol{x}$</p>
<script type="math/tex; mode=display">
\left(\begin{array}{lllll}
0 & \cdots & 1 & \cdots & 0
\end{array}\right)^{\mathrm{T}}</script><p>则有</p>
<script type="math/tex; mode=display">
\boldsymbol{x}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{x}=a_{i i}>0</script><p>因此结论成立</p>
<p>证明一个对称矩阵$\boldsymbol{A}$正定可以按照定义进行，除此之外，还可以采用下面的方法</p>
<ol>
<li>矩阵<script type="math/tex">\boldsymbol{A}</script>的<script type="math/tex">n</script>个特征值<script type="math/tex">\lambda_{1}，\cdots，\lambda_{n}</script>均大于0</li>
<li>存在可逆矩阵$\boldsymbol{P}$使得$\boldsymbol{A}=\boldsymbol{P}^{\mathrm{T}} \boldsymbol{P}$</li>
<li>如果$\boldsymbol{A}$是正定矩阵，则$\boldsymbol{A}^{\mathrm{T}}$也是正定矩阵</li>
<li>矩阵$\boldsymbol{A}$的所有顺序主子式均为正</li>
</ol>
<p>第一条判定规则可以通过正交变换将二次型化为标准型证明，化为标准型(对应于对角矩阵)之后为正定二次型</p>
<p>下面证明第2条判定规则，对于任意曲$\boldsymbol{\theta}$向量$\boldsymbol{x}$在</p>
<script type="math/tex; mode=display">
\boldsymbol{x}^{\mathrm{T}} A \boldsymbol{x}=\boldsymbol{x}^{\mathrm{T}} \boldsymbol{P}^{\mathrm{T}} \boldsymbol{P} \boldsymbol{x}=\left(\boldsymbol{P}_{\boldsymbol{x}}\right)^{\mathrm{T}} \boldsymbol{P} \boldsymbol{x}>0</script><p>因为$P$可逆，对于任意非$\boldsymbol{0}$向量$\boldsymbol{x}$有$\boldsymbol{P x} \neq \mathbf{0}$</p>
<p>下面证明第3条判定规则，如果$A$是正定矩阵，对于任意非0向量$x$都有$x^{\mathrm{T}} A \boldsymbol{x}&gt;0$，对于任意非$\boldsymbol{0}$向量$\boldsymbol{x}$有</p>
<script type="math/tex; mode=display">
\left(\boldsymbol{x}^{\mathrm{T}} \boldsymbol{A}^{\mathrm{T}} \boldsymbol{x}\right)^{\mathrm{T}}=\boldsymbol{x}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{x}>0</script><p>对于$n$阶矩阵$A$</p>
<script type="math/tex; mode=display">
\boldsymbol{A}=\left(\begin{array}{cccc}
a_{11} & a_{12} & \cdots & a_{1 n} \\
a_{21} & a_{22} & \cdots & a_{2 n} \\
\vdots & \vdots & \ddots & \vdots \\
a_{n 1} & a_{n 2} & \cdots & a_{n n}
\end{array}\right)</script><p>其前$k, 1 \leqslant k \leqslant n$行前$k$列元素形成的行列式</p>
<script type="math/tex; mode=display">
\left|\begin{array}{ccc}
a_{11} & \cdots & a_{1 k} \\
\vdots & \ddots & \vdots \\
a_{k 1} & \cdots & a_{k k}
\end{array}\right|</script><p>称为<code>顺序主子式</code>，这是矩阵左上角的子方阵形成的行列式，对于下面的4阶矩阵</p>
<script type="math/tex; mode=display">
\boldsymbol{A}=\left(\begin{array}{cccc}
1 & 2 & 3 & 4 \\
5 & 6 & 7 & 8 \\
9 & 10 & 11 & 12 \\
13 & 14 & 15 & 16
\end{array}\right)</script><p>其1阶顺序主子式为</p>
<script type="math/tex; mode=display">
|1|</script><p>2阶顺序主子式为</p>
<script type="math/tex; mode=display">
\left|\begin{array}{ll}
1 & 2 \\
5 & 6
\end{array}\right|</script><p>3阶顺序主子式为</p>
<script type="math/tex; mode=display">
\left|\begin{array}{ccc}
1 & 2 & 3 \\
5 & 6 & 7 \\
9 & 10 & 11
\end{array}\right|</script><p>4阶顺序主子式为</p>
<script type="math/tex; mode=display">
\left|\begin{array}{cccc}
1 & 2 & 3 & 4 \\
5 & 6 & 7 & 8 \\
9 & 10 & 11 & 12 \\
13 & 14 & 15 & 16
\end{array}\right|</script><p>矩阵$A$不是正定的，因为其二阶顺序主子式为负</p>
<script type="math/tex; mode=display">
\left|\begin{array}{ll}
1 & 2 \\
5 & 6
\end{array}\right|=1 \times 6-2 \times 5<0</script><p>对于任意的$m \times n$矩阵$\boldsymbol{A}$，$\boldsymbol{A}^{\mathrm{T}} \boldsymbol{A}$是对称半正定矩阵，下面给出证明，显然该矩阵是对称的</p>
<script type="math/tex; mode=display">
\left(\boldsymbol{A}^{\mathrm{T}} \boldsymbol{A}\right)^{\mathrm{T}}=\boldsymbol{A}^{\mathrm{T}}\left(\boldsymbol{A}^{\mathrm{T}}\right)^{\mathrm{T}}=\boldsymbol{A}^{\mathrm{T}} \boldsymbol{A}</script><p>对于任意非$\boldsymbol{0}$向量$\boldsymbol{x}$，有</p>
<script type="math/tex; mode=display">
\boldsymbol{x}^{\mathrm{T}} \boldsymbol{A}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{x}=(\boldsymbol{A} \boldsymbol{x})^{\mathrm{T}}(\boldsymbol{A} \boldsymbol{x}) \geqslant 0</script><p>类似地可以证明$\boldsymbol{A A ^ { \mathrm { T } }}$也是对称半正定矩阵</p>
<p>在机器学习中，这种矩阵经常出现，如向量组的格拉姆矩阵，包括线性回归、支持向量机以及logistic回归等线性模型</p>
<p>它们目标函数的黑塞矩阵为这种类型的矩阵，因此是凸函数，可以保证求得全局极小值点</p>
<p>类似地，实对称矩阵负定可以通过下面的方法进行判定</p>
<ol>
<li>矩阵<script type="math/tex">A</script>的<script type="math/tex">n</script>个特征值<script type="math/tex">\lambda_{1}, \cdots, \lambda_{n}</script>均小于0</li>
<li>存在可逆矩阵$\boldsymbol{P}$使得$\boldsymbol{A}=-\boldsymbol{P}^{\mathrm{T}} \boldsymbol{P}$</li>
<li>矩阵$A$的所有奇数阶顺序主子式均为负，偶数阶顺序主子式均为正</li>
</ol>
<h2 id="标准型"><a href="#标准型" class="headerlink" title="标准型"></a>标准型</h2><p>标准型指对于任意的<script type="math/tex">i \neq j</script>，二次型中项<script type="math/tex">a_{i j} x_{i} x_{j}</script>的系数均为0，二次型由纯平方项构成，可写成如下形式</p>
<script type="math/tex; mode=display">
\boldsymbol{x}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{x}=d_{1} x_{1}^{2}+d_{2} x_{2}^{2}+\cdots+d_{n} x_{n}^{2}</script><p>下面是一个标准型</p>
<script type="math/tex; mode=display">
x_{1}^{2}-3 x_{2}^{2}+x_{3}^{2}</script><p>标准型对应的矩阵为对角矩阵，上面的标准型对应的矩阵为</p>
<script type="math/tex; mode=display">
\left(\begin{array}{ccc}
1 & 0 & 0 \\
0 & -3 & 0 \\
0 & 0 & 1
\end{array}\right)</script><p>在标准型中，正平方项的数量称为<code>正惯性指数</code>，负平方项的数量称为<code>负惯性指数</code></p>
<p>上面的标准型的正惯性指数为2，负惯性指数为1</p>
<p>由于二次型的矩阵为对称矩阵，因此一定可以对角化</p>
<p>通过正交变换可以将二次型化为标准型，与实对称矩阵的正交变换对角化相同</p>
<p>对于二次型$x^{\mathrm{T}} A \boldsymbol{x}$，通过正交变换将$A$化为对角矩阵</p>
<script type="math/tex; mode=display">
\boldsymbol{A}=\boldsymbol{P} \boldsymbol{\Lambda} \boldsymbol{P}^{\mathrm{T}}</script><p>从而有</p>
<script type="math/tex; mode=display">
\boldsymbol{x}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{x}=\boldsymbol{x}^{\mathrm{T}} \boldsymbol{P} \boldsymbol{\Lambda} \boldsymbol{P}^{\mathrm{T}} \boldsymbol{x}=\left(\boldsymbol{P}^{\mathrm{T}} \boldsymbol{x}\right)^{\mathrm{T}} \boldsymbol{\Lambda}\left(\boldsymbol{P}^{\mathrm{T}} \boldsymbol{x}\right)</script><p>这里$\boldsymbol{P}$是正交矩阵，如果令$\boldsymbol{y}=\boldsymbol{P}^{\mathrm{T}} \boldsymbol{x}$或者$\boldsymbol{x}=\boldsymbol{P} \boldsymbol{y}$，则$\boldsymbol{y}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{y}$是标准型</p>
<p>这对应于通过将$\boldsymbol{x}$换元为$y$，使得换元之后的二次型为标准型</p>
<p>如果矩阵<script type="math/tex">\boldsymbol{A}</script>的<script type="math/tex">n</script>个特征值<script type="math/tex">\lambda_{1}, \cdots, \lambda_{n}</script>均大于0，则矩阵<script type="math/tex">\boldsymbol{A}</script>正定</p>
<p>对于任意非0向量$x$，由于$P$是正交矩阵，$y=P^{\mathrm{T}} x \neq 0$，因此$A$正定</p>
<p>下面举例说明，对于下面的二次型</p>
<script type="math/tex; mode=display">
x_{1}^{2}+5 x_{2}^{2}+5 x_{3}^{2}+2 x_{1} x_{2}-4 x_{1} x_{3}</script><p>其对应的系数矩阵为</p>
<script type="math/tex; mode=display">
A=\left(\begin{array}{ccc}
1 & 1 & -2 \\
1 & 5 & 0 \\
-2 & 0 & 5
\end{array}\right)</script><p>特征多项式为</p>
<script type="math/tex; mode=display">
\begin{array}{l}
|A-\lambda I| 
=\left|\begin{array}{ccc}
1-\lambda & 1 & -2 \\
1 & 5-\lambda & 0 \\
-2 & 0 & 5-\lambda
\end{array}\right| \stackrel{r_{3}+2 r_{2}}{\longrightarrow}\left|\begin{array}{ccc}
1-\lambda & 1 & -2 \\
1 & 5-\lambda & 0 \\
0 & 2(5-\lambda) & 5-\lambda
\end{array}\right| \stackrel{c_{2}-2 \times c_{3}}{\longrightarrow}\left|\begin{array}{cccc}
1-\lambda & 5 & -2 \\
1 & 5-\lambda & 0 \\
0 & 0 & 5-\lambda
\end{array}\right| \\
=(5-\lambda)\left(\lambda^{2}-6 \lambda\right)
\end{array}</script><p>解得特征值为$0,5,6$</p>
<p>当$\lambda=5$时，有</p>
<script type="math/tex; mode=display">
A-\lambda I=\left(\begin{array}{ccc}
-4 & 1 & -2 \\
1 & 0 & 0 \\
-2 & 0 & 0
\end{array}\right) \rightarrow\left(\begin{array}{ccc}
1 & 0 & 0 \\
0 & 1 & -2 \\
0 & 0 & 0
\end{array}\right)</script><p>方程$(A-\lambda I) x=0$的解为</p>
<script type="math/tex; mode=display">
\boldsymbol{x}_{1}=\left(\begin{array}{lll}
0 & 2 & 1
\end{array}\right)^{\mathrm{T}}</script><p>当$\lambda=6$时，有</p>
<script type="math/tex; mode=display">
\boldsymbol{A}-\lambda \boldsymbol{I}=\left(\begin{array}{ccc}
-5 & 1 & -2 \\
1 & -1 & 0 \\
-2 & 0 & -1
\end{array}\right) \rightarrow\left(\begin{array}{ccc}
1 & 0 & 1 / 2 \\
0 & 1 & 1 / 2 \\
0 & 0 & 0
\end{array}\right)</script><p>方程$(A-\lambda I) x=0$的解为</p>
<script type="math/tex; mode=display">
x_{2}=\left(\begin{array}{lll}
1 & 1 & -2
\end{array}\right)^{\mathrm{T}}</script><p>当$\lambda=0$时，有</p>
<script type="math/tex; mode=display">
\boldsymbol{A}-\lambda I=\left(\begin{array}{ccc}
1 & 1 & -2 \\
1 & 5 & 0 \\
-2 & 0 & 5
\end{array}\right) \rightarrow\left(\begin{array}{ccc}
1 & 0 & -5 / 2 \\
0 & 1 & 1 / 2 \\
0 & 0 & 0
\end{array}\right)</script><p>方程$(A-\lambda I) x=0$的解为</p>
<script type="math/tex; mode=display">
\boldsymbol{x}_{3}=\left(\begin{array}{lll}
5 & -1 & 2
\end{array}\right)^{\mathrm{T}}</script><p>由于二次型的系数矩阵是实对称矩阵，其不同特征值对应的特征向量相互正交，因此只需要将这些特征向量单位化即可</p>
<script type="math/tex; mode=display">
\alpha_{1}=\frac{1}{\sqrt{5}}\left(\begin{array}{l}
0 \\
2 \\
1
\end{array}\right), \alpha_{2}=\frac{1}{\sqrt{6}}\left(\begin{array}{c}
1 \\
1 \\
-2
\end{array}\right), \alpha_{3}=\frac{1}{\sqrt{30}}\left(\begin{array}{c}
5 \\
-1 \\
2
\end{array}\right)</script><p>令</p>
<script type="math/tex; mode=display">
P=\left(\begin{array}{ccc}
0 & \frac{1}{\sqrt{6}} & \frac{5}{\sqrt{30}} \\
\frac{2}{\sqrt{5}} & \frac{1}{\sqrt{6}} & -\frac{1}{\sqrt{30}} \\
\frac{1}{\sqrt{5}} & -\frac{2}{\sqrt{6}} & \frac{2}{\sqrt{30}}
\end{array}\right)</script><p>通过正交变换$x=\boldsymbol{P y}$可将二次型化为如下的标准型</p>
<script type="math/tex; mode=display">
5 y_{1}^{2}+6 y_{2}^{2}</script><h1 id="矩阵分解"><a href="#矩阵分解" class="headerlink" title="矩阵分解"></a>矩阵分解</h1><p>矩阵分解是矩阵分析的重要内容，这种技术将一个矩阵分解为若干矩阵的乘积，通常为2个或3个矩阵的乘积</p>
<p>在求解线性方程组，计算逆矩阵、行列式以及特征值，多重积分换元等问题上，矩阵分解有广泛的应用</p>
<h2 id="楚列斯基分解"><a href="#楚列斯基分解" class="headerlink" title="楚列斯基分解"></a>楚列斯基分解</h2><p>对于$n$阶对称半正定矩阵$\boldsymbol{A}$，<code>楚列斯基</code>(Cholesky)分解将其分解为$n$阶下三角矩阵$L$以及其转置$L^{\mathrm{T}}$的乘积</p>
<script type="math/tex; mode=display">
\boldsymbol{A}=\boldsymbol{L} \boldsymbol{L}^{\mathrm{T}}</script><p>如果$A$是实对称正定矩阵，则上式的分解唯一</p>
<p>下面是对称矩阵楚列斯基分解的一个 例子</p>
<script type="math/tex; mode=display">
\left(\begin{array}{ccc}
4 & 12 & -16 \\
12 & 37 & -43 \\
-16 & -43 & 98
\end{array}\right)=\left(\begin{array}{ccc}
2 & 0 & 0 \\
6 & 1 & 0 \\
-8 & 5 & 3
\end{array}\right)\left(\begin{array}{ccc}
2 & 6 & -8 \\
0 & 1 & 5 \\
0 & 0 & 3
\end{array}\right)</script><p>楚列斯基分解可用于求解线性方程组，对于如下的线性方程组</p>
<script type="math/tex; mode=display">
\boldsymbol{A x}=\boldsymbol{b}</script><p>如果$A$是对称正定矩阵，它可以分解为$L L^{\mathrm{T}}$，则有</p>
<script type="math/tex; mode=display">
\boldsymbol{L} \boldsymbol{L}^{\mathrm{T}} \boldsymbol{x}=\boldsymbol{b}</script><p>如果令</p>
<script type="math/tex; mode=display">
\boldsymbol{L}^{\mathrm{T}} \boldsymbol{x}=\boldsymbol{y}</script><p>则可先求解线性方程组</p>
<script type="math/tex; mode=display">
L y=b</script><p>得到$y$。然后求解</p>
<script type="math/tex; mode=display">
\boldsymbol{L}^{\mathrm{T}} \boldsymbol{x}=\boldsymbol{y}</script><p>得到$x$，这两个方程组的系数矩阵分别为下三角和上三角矩阵，均可高效地求解</p>
<p>在实际应用中，如果系数矩阵$A$不变而常数向量$b$会改变，则预先将$A$进行楚列斯基分解，每次对于不同的$b$均可高效地求解</p>
<p>在求解最优化问题的拟牛顿法中，需要求解如下的方程组</p>
<script type="math/tex; mode=display">
\boldsymbol{B}_{k} \boldsymbol{d}=-\boldsymbol{g}_{k}</script><p>其中<script type="math/tex">B_{k}</script>为第<script type="math/tex">k</script>次迭代时的黑塞(Hessian)矩阵的近似矩阵，<script type="math/tex">d</script>为牛顿方向，<script type="math/tex">g_{k}</script>为第<script type="math/tex">k</script>次迭代时的梯度值</p>
<p>此方程可以使用楚列斯基分解求解</p>
<blockquote>
<p>楚列斯基分解还可以用于检查矩阵的正定性</p>
</blockquote>
<p>对一个矩阵进行楚列斯基分解，如果分解失败，则说明矩阵不是半正定矩阵；否则为半正定矩阵</p>
<p>下面以3阶矩阵为例推导楚列斯基分解的计算公式，如果</p>
<script type="math/tex; mode=display">
\boldsymbol{A}=\left(\begin{array}{lll}
a_{11} & a_{21} & a_{31} \\
a_{21} & a_{22} & a_{32} \\
a_{31} & a_{32} & a_{33}
\end{array}\right)=\boldsymbol{L} \boldsymbol{L}^{\mathrm{T}}=\left(\begin{array}{ccc}
l_{11} & 0 & 0 \\
l_{21} & l_{22} & 0 \\
l_{31} & l_{32} & l_{33}
\end{array}\right)\left(\begin{array}{ccc}
l_{11} & l_{21} & l_{31} \\
0 & l_{22} & l_{32} \\
0 & 0 & l_{33}
\end{array}\right)</script><p>则有</p>
<script type="math/tex; mode=display">
\left(\begin{array}{ccc}
l_{11}^{2} & l_{21} l_{11} & l_{31} l_{11} \\
l_{21} l_{11} & l_{21}^{2}+l_{22}^{2} & l_{31} l_{21}+l_{32} l_{22} \\
l_{31} l_{11} & l_{31} l_{21}+l_{32} l_{22} & l_{31}^{2}+l_{32}^{2}+l_{33}^{2}
\end{array}\right)=\left(\begin{array}{lll}
a_{11} & a_{21} & a_{31} \\
a_{21} & a_{22} & a_{32} \\
a_{31} & a_{32} & a_{33}
\end{array}\right)</script><p>首先可以得到主对角的第一个元素</p>
<script type="math/tex; mode=display">
l_{11}=\sqrt{a_{11}}</script><p>根据$l_{11}$可以得到第2行的所有元素</p>
<script type="math/tex; mode=display">
l_{21}=\frac{a_{21}}{l_{11}}, l_{22}=\sqrt{a_{22}-l_{21}^{2}}</script><p>进一步得到第3行的元素</p>
<script type="math/tex; mode=display">
l_{31}=\frac{a_{31}}{l_{11}}, l_{32}=\frac{1}{l_{22}}\left(a_{32}-l_{31} l_{21}\right), l_{33}=\sqrt{a_{33}-\left(l_{31}^{2}+l_{32}^{2}\right)}</script><p>所有元素逐行算出，首先计算出第1行的元素<script type="math/tex">l_{11}</script>，然后计算第2行的元素<script type="math/tex">l_{21}, l_{22}</script>，接下来计算<script type="math/tex">l_{31}, l_{32}, l_{33}</script>，依此类推</p>
<p>这里<script type="math/tex">l_{i j}, 1<j \leqslant i</script>与<script type="math/tex">l_{p q}, p \leqslant i, q<j</script>有关，这些值已经被算出</p>
<p>对于$n$阶矩阵，楚列斯基分解的计算公式为</p>
<script type="math/tex; mode=display">
l_{i i}=\left(a_{i i}-\sum_{k=1}^{i-1} l_{i k}^{2}\right)^{\frac{1}{2}} \qquad l_{j i}=\frac{1}{l_{i i}}\left(a_{j i}-\sum_{k=1}^{i-1} l_{i k} l_{j k}\right), j=i+1, \cdots, n</script><p>Python中linalg的cholesky函数实现了对称正定矩阵的楚列斯基分解</p>
<p>函数的输入是被分解矩阵$\boldsymbol{A}$，输出为下三角矩阵$\boldsymbol{L}$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">A = np.array([[<span class="number">6</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">8</span>],[<span class="number">3</span>,<span class="number">6</span>,<span class="number">5</span>,<span class="number">1</span>],[<span class="number">4</span>,<span class="number">5</span>,<span class="number">10</span>,<span class="number">7</span>],[<span class="number">8</span>,<span class="number">1</span>,<span class="number">7</span>,<span class="number">25</span>]])</span><br><span class="line">L = np<span class="number">.1</span>inalg.cholesky(A)</span><br><span class="line"><span class="built_in">print</span>(L)</span><br></pre></td></tr></table></figure>
<p>程序输出结果为</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">2.44948974</span>  <span class="number">0.0</span>         <span class="number">0.0</span>         <span class="number">0.0</span> ],</span><br><span class="line"> [<span class="number">1.22474487</span>  <span class="number">2.12132034</span>  <span class="number">0.0</span>         <span class="number">0.0</span>],</span><br><span class="line"> [<span class="number">1.63299316</span>  <span class="number">1.41421356</span>  <span class="number">2.30940108</span>  <span class="number">0.0</span>],</span><br><span class="line"> [<span class="number">3.26598632</span>  -<span class="number">1.41421356</span> <span class="number">1.58771324</span>  <span class="number">3.13249102</span>]]</span><br></pre></td></tr></table></figure>
<p>可以验证矩阵$\boldsymbol{L}$与其转置的乘积即为矩阵$\boldsymbol{A}$</p>
<h2 id="QR-分解"><a href="#QR-分解" class="headerlink" title="QR 分解"></a>QR 分解</h2><p><code>QR分解</code>(正交三角分解)将矩阵分解为正交矩阵与上三角矩阵的乘积，这种分解被广泛地应用于求解某些问题，如矩阵的特征值</p>
<p>事实上，$\mathrm{QR}$分解是格拉姆-施密特正交化的另外一种表现形式</p>
<p>首先考虑方阵的情况，对于任意的$n$阶方阵$\boldsymbol{A}$，$\mathrm{QR}$分解将其分解为一个$n$阶正交矩阵$\boldsymbol{Q}$与一个$n$阶上三角矩阵$\boldsymbol{R}$的乘积</p>
<script type="math/tex; mode=display">
A=Q R</script><p>如果矩阵$\boldsymbol{A}$可逆且要求矩阵$\boldsymbol{R}$的主对角元为正，则上式的分解唯一</p>
<p>如果$\boldsymbol{A}$有$m(m \leqslant n$) 个线性无关的列，则$\boldsymbol{Q}$的前$m$个列构成$\boldsymbol{A}$的列空间的标准正交基</p>
<p>下面来看$\mathrm{QR}$分解的实际例子，对于如下矩阵</p>
<script type="math/tex; mode=display">
\boldsymbol{A}=\left(\begin{array}{ll}
7 & 2 \\
2 & 4
\end{array}\right)</script><p>其$\mathrm{QR}$分解的结果为</p>
<script type="math/tex; mode=display">
\boldsymbol{A}=\boldsymbol{Q R}=\left(\begin{array}{ll}
7 & 2 \\
2 & 4
\end{array}\right)=\left(\begin{array}{cc}
0.962 & -0.275 \\
0.275 & 0.962
\end{array}\right)\left(\begin{array}{cc}
7.28 & 3.02 \\
0 & 3.30
\end{array}\right)</script><p>下面考虑非方阵的情况，对于$m \times n, m&gt;n$的矩阵$\boldsymbol{A}$，QR 分解将其分解为一个$m$阶正交矩阵与如下形式的$m \times n$矩阵$\boldsymbol{R}$的乘积</p>
<script type="math/tex; mode=display">
\boldsymbol{A}=\boldsymbol{Q} \boldsymbol{R}=\boldsymbol{Q}\left(\begin{array}{c}
\boldsymbol{R}_{n} \\
\boldsymbol{0}_{(m-n) \times n}
\end{array}\right)</script><p>其中$\boldsymbol{R}_{n}$是$n$阶上三角矩阵，$\boldsymbol{0}$是一个$(m-n) \times n$的零矩阵。 如果$m&lt;n$, 则分解的结果为</p>
<script type="math/tex; mode=display">
\boldsymbol{A}=\boldsymbol{Q R}=\boldsymbol{Q}\left(\boldsymbol{R}_{m} \boldsymbol{B}_{m \times(n-m)}\right)</script><p>其中$\boldsymbol{Q}$是一个$m$阶正交矩阵，<script type="math/tex">\boldsymbol{R}_{m}</script>是<script type="math/tex">m</script>阶上三角矩阵，<script type="math/tex">\boldsymbol{B}_{m \times(n-m)}</script>是一个<script type="math/tex">m \times(n-m)</script>的矩阵</p>
<blockquote>
<p>$\mathrm{QR}$分解有 3 种实现方式</p>
</blockquote>
<p>分别是格拉姆-施密特正交化、豪斯霍尔德变换以及吉文斯(Givens)旋转</p>
<p>下面介绍格拉姆-施密特正交化以及豪斯霍尔德变换</p>
<p>考虑$A$为$n$阶方阵的情况，使用格拉姆-施密特正交化技术对矩阵$A$的列进行正交化，将矩阵$\boldsymbol{A}$按列分块</p>
<script type="math/tex; mode=display">
\boldsymbol{A}=\left(\begin{array}{lll}
a_{1} & \cdots & a_{n}
\end{array}\right)</script><p>假设这些列向量线性无关，首先将它的列正交化</p>
<script type="math/tex; mode=display">
\begin{array}{ll}
u_{1}=\boldsymbol{a}_{1} \qquad \boldsymbol{u}_{2}=\boldsymbol{a}_{2}-\frac{\boldsymbol{a}_{2}^{\mathrm{T}} \boldsymbol{u}_{1}}{\boldsymbol{u}_{1}^{\mathrm{T}} \boldsymbol{u}_{1}} \boldsymbol{u}_{1} \qquad \boldsymbol{u}_{3}=\boldsymbol{a}_{3}-\frac{\boldsymbol{a}_{3}^{\mathrm{T}} \boldsymbol{u}_{1}}{\boldsymbol{u}_{1}^{\mathrm{T}} \boldsymbol{u}_{1}} \boldsymbol{u}_{1}-\frac{\boldsymbol{a}_{3}^{\mathrm{T}} \boldsymbol{u}_{2}}{\boldsymbol{u}_{2}^{\mathrm{T}} \boldsymbol{u}_{2}} \boldsymbol{u}_{2} \\
\ldots \qquad \boldsymbol{u}_{n}=\boldsymbol{a}_{n}-\sum_{i=1}^{n-1} \frac{\boldsymbol{a}_{n}^{\mathrm{T}} \boldsymbol{u}_{i}}{\boldsymbol{u}_{i}^{\mathrm{T}} \boldsymbol{u}_{i}} \boldsymbol{u}_{i}
\end{array}</script><p>然后进行单位化</p>
<script type="math/tex; mode=display">
\boldsymbol{e}_{i}=\frac{\boldsymbol{u}_{i}}{\left\|\boldsymbol{u}_{i}\right\|^{\prime}}, i=1, \cdots, n</script><p>$A$的各个列向量在标准正交基下的坐标为其在各个基向量上的投影，由于在进行格拉姆-施密特正交化时<script type="math/tex">e_{i}</script>只与<script type="math/tex">a_{1}, \cdots, a_{i}</script>有关</p>
<p>因此<script type="math/tex">a_{i}</script>在<script type="math/tex">e_{i+1}, \cdots, e_{n}</script>方向的投影均为0，有</p>
<script type="math/tex; mode=display">
\begin{array}{l}
\boldsymbol{a}_{1}=\boldsymbol{a}_{1}^{\mathrm{T}} \boldsymbol{e}_{1} \boldsymbol{e}_{1} \qquad \boldsymbol{a}_{2}=\boldsymbol{a}_{2}^{\mathrm{T}} \boldsymbol{e}_{1} \boldsymbol{e}_{1}+\boldsymbol{a}_{2}^{\mathrm{T}} \boldsymbol{e}_{2} \boldsymbol{e}_{2} \qquad \boldsymbol{a}_{3}=\boldsymbol{a}_{3}^{\mathrm{T}} \boldsymbol{e}_{1} \boldsymbol{e}_{1}+\boldsymbol{a}_{3}^{\mathrm{T}} \boldsymbol{e}_{2} \boldsymbol{e}_{2}+\boldsymbol{a}_{3}^{\mathrm{T}} \boldsymbol{e}_{3} \boldsymbol{e}_{3}
\\
\ldots  \qquad \boldsymbol{a}_{n}=\sum_{i=1}^{n} \boldsymbol{a}_{n}^{\mathrm{T}} e_{i} e_{i} \\
\end{array}</script><p>写成矩阵形式为</p>
<script type="math/tex; mode=display">
\left(a_{1} \cdots a_{n}\right)=\left(\begin{array}{lll}e_{1} & \cdots & e_{n}\end{array}\right)\left(\begin{array}{cccc}\boldsymbol{a}_{1}^{\mathrm{T}} \boldsymbol{e}_{1} & \boldsymbol{a}_{2}^{\mathrm{T}} \boldsymbol{e}_{1} & \boldsymbol{a}_{3}^{\mathrm{T}} \boldsymbol{e}_{1} & \cdots \\ 0 & \boldsymbol{a}_{2}^{\mathrm{T}} \boldsymbol{e}_{2} & \boldsymbol{a}_{3}^{\mathrm{T}} \boldsymbol{e}_{2} & \cdots \\ 0 & 0 & \boldsymbol{a}_{3}^{\mathrm{T}} \boldsymbol{e}_{3} & \cdots \\ \vdots & \vdots & \vdots & \end{array}\right)</script><p>令<script type="math/tex">Q=\left(e_{1} \cdots e_{n}\right)</script>，以及</p>
<script type="math/tex; mode=display">
\boldsymbol{R}=\left(\begin{array}{cccc}
\boldsymbol{a}_{1}^{\mathrm{T}} \boldsymbol{e}_{1} & \boldsymbol{a}_{2}^{\mathrm{T}} \boldsymbol{e}_{1} & \boldsymbol{a}_{3}^{\mathrm{T}} \boldsymbol{e}_{1} & \cdots \\
0 & \boldsymbol{a}_{2}^{\mathrm{T}} \boldsymbol{e}_{2} & \boldsymbol{a}_{3}^{\mathrm{T}} \boldsymbol{e}_{2} & \cdots \\
0 & 0 & \boldsymbol{a}_{3}^{\mathrm{T}} \boldsymbol{e}_{3} & \cdots \\
\vdots & \vdots & \vdots &
\end{array}\right)</script><p>$Q$的列是用$A$的列构造的标准正交基，$R$的第$i$列为$\boldsymbol{A}$的第$i$列在前$i$个基向量方向的投影，此即$Q R$分解结果</p>
<blockquote>
<p>例子</p>
</blockquote>
<p>下面举例说明，对于如下的矩阵</p>
<script type="math/tex; mode=display">
\boldsymbol{A}=\left(\begin{array}{ccc}
12 & -51 & 4 \\
6 & 167 & -68 \\
-4 & 24 & -41
\end{array}\right)</script><p>首先对它的列向量进行正交化，得到如下矩阵</p>
<script type="math/tex; mode=display">
\boldsymbol{U}=\left(\begin{array}{lll}
\boldsymbol{u}_{1} & \boldsymbol{u}_{2} & \boldsymbol{u}_{3}
\end{array}\right)=\left(\begin{array}{ccc}
12 & -69 & -58 / 5 \\
6 & 158 & 6 / 5 \\
-4 & 30 & -33
\end{array}\right)</script><p>然后将该矩阵的列单位化，可以得到</p>
<script type="math/tex; mode=display">
\boldsymbol{Q}=\left(\begin{array}{lll}
\frac{\boldsymbol{u}_{1}}{\left\|\boldsymbol{u}_{1}\right\|} & \frac{\boldsymbol{u}_{2}}{\left\|\boldsymbol{u}_{2}\right\|} & \frac{\boldsymbol{u}_{3}}{\left\|\boldsymbol{u}_{3}\right\|}
\end{array}\right)=\left(\begin{array}{ccc}
6 / 7 & -69 / 175 & -58 / 175 \\
3 / 7 & 158 / 175 & 6 / 175 \\
-2 / 7 & 6 / 35 & -33 / 35
\end{array}\right)</script><p>由此可以得到上三角矩阵</p>
<script type="math/tex; mode=display">
\boldsymbol{R}=\boldsymbol{Q}^{\mathrm{T}} \boldsymbol{A}=\left(\begin{array}{ccc}
14 & 21 & -14 \\
0 & 175 & -70 \\
0 & 0 & 35
\end{array}\right)</script><p>用豪斯霍尔德变换进行$Q R$分解的思路与之前讲述的类似，首先用矩阵$A$的第1列构造第1个豪斯霍尔德矩阵$\boldsymbol{P}_{1}$</p>
<script type="math/tex; mode=display">
\left(\begin{array}{cccc}
p_{11} & p_{12} & \cdots & p_{1 n} \\
p_{21} & p_{22} & \cdots & p_{2 n} \\
\vdots & \vdots & & \vdots \\
p_{n 1} & p_{n 2} & \cdots & p_{n n}
\end{array}\right)</script><p>左乘该矩阵将$\boldsymbol{A}$的第1列后面$n-1$个元素全部零化</p>
<script type="math/tex; mode=display">
\boldsymbol{P}_{1} \boldsymbol{A}=\left(\begin{array}{cccc}
a_{11} & a_{12} & \cdots & a_{1 n} \\
0 & a_{22} & \cdots & a_{2 n} \\
\vdots & \vdots & & \vdots \\
0 & a_{n 2} & \cdots & a_{n n}
\end{array}\right)</script><p>接下来构造第2个豪斯霍尔德矩阵$P_{2}$，为如下形式</p>
<script type="math/tex; mode=display">
\left(\begin{array}{cccc}
1 & 0 & \cdots & 0 \\
0 & p_{22} & \cdots & p_{2 n} \\
\vdots & \vdots & & \vdots \\
0 & p_{n 2} & \cdots & p_{n n}
\end{array}\right)</script><p>其中</p>
<script type="math/tex; mode=display">
\left(\begin{array}{ccc}
p_{22} & \cdots & p_{2 n} \\
\vdots & & \vdots \\
p_{n 2} & \cdots & p_{n n}
\end{array}\right)</script><p>使用<script type="math/tex">P_{1} \boldsymbol{A}</script>的第2列的后面<script type="math/tex">n-1</script>个元素构造，将<script type="math/tex">P_{1} A</script>左乘<script type="math/tex">P_{2}</script>，可以将其第2列后面<script type="math/tex">n-2</script>个元素零化</p>
<script type="math/tex; mode=display">
\boldsymbol{P}_{2} \boldsymbol{P}_{1} \boldsymbol{A}=\left(\begin{array}{ccccc}
a_{11} & a_{12} & a_{13} & \cdots & a_{1 n} \\
0 & a_{22} & a_{23} & \cdots & a_{2 n} \\
0 & 0 & a_{33} & \cdots & a_{3 n} \\
\vdots & \vdots & \vdots & & \vdots \\
0 & 0 & a_{n 3} & \cdots & a_{n n}
\end{array}\right)</script><p>构造第3个豪斯霍尔德矩阵$\boldsymbol{P}_{3}$，为如下形式</p>
<script type="math/tex; mode=display">
\left(\begin{array}{ccccc}
1 & 0 & 0 & \cdots & 0 \\
0 & 1 & 0 & \cdots & 0 \\
0 & 0 & p_{33} & \cdots & p_{3 n} \\
\vdots & \vdots & \vdots & & \vdots \\
0 & 0 & p_{n 3} & \cdots & p_{n n}
\end{array}\right)</script><p>其中</p>
<script type="math/tex; mode=display">
\left(\begin{array}{ccc}
p_{33} & \cdots & p_{3 n} \\
\vdots & & \vdots \\
p_{n 3} & \cdots & p_{n n}
\end{array}\right)</script><p>用<script type="math/tex">P_{2} P_{1} A</script>的第3列的后面<script type="math/tex">n-2</script>个元素构造，将<script type="math/tex">P_{2} P_{1} A</script>左乘<script type="math/tex">P_{3}</script>，可以将其第3列后面<script type="math/tex">n-3</script>个元素零化</p>
<script type="math/tex; mode=display">
\boldsymbol{P}_{3} \boldsymbol{P}_{2} \boldsymbol{P}_{1} \boldsymbol{A}=\left(\begin{array}{cccccc}
a_{11} & a_{12} & a_{13} & a_{14} & \cdots & a_{1 n} \\
0 & a_{22} & a_{23} & a_{24} & \cdots & a_{2 n} \\
0 & 0 & a_{33} & a_{34} & \cdots & a_{3 n} \\
0 & 0 & 0 & a_{44} & \cdots & a_{4 n} \\
\vdots & \vdots & \vdots & \vdots & & \vdots \\
0 & 0 & 0 & a_{n 4} & \cdots & a_{n n}
\end{array}\right)</script><p>依此类推，经过$n-1$次豪斯霍尔德变换，可以将$\boldsymbol{A}$化为上三角矩阵</p>
<script type="math/tex; mode=display">
P_{n-1} \cdots P_{2} P_{1} A=R</script><p>令</p>
<script type="math/tex; mode=display">
Q=\left(P_{n-1} \cdots P_{2} P_{1}\right)^{-1}=P_{1}^{-1} P_{2}^{-1} \cdots P_{n-1}^{-1}=P_{1} P_{2} P_{n-1}</script><p>由于$P_{0}, i=1, \cdots, n-1$都是正交矩阵，因此$Q$也是一个正交矩阵，这就是$\mathrm{QR}$分解的结果</p>
<p>$\mathrm{QR}$分解可以由Python中linalg的qr函数实现，函数的输入为被分解矩阵$A$，输出为正交矩阵$Q$和上三角矩阵$R$</p>
<p>下面用例子进行说明，首先考虑方阵，对于如下的方阵</p>
<script type="math/tex; mode=display">
\boldsymbol{A}=\left(\begin{array}{lll}
1 & 2 & 3 \\
4 & 5 & 6 \\
7 & 8 & 9
\end{array}\right)</script><p>其$\mathrm{QR}$分解的代码如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">A = np.array([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>],[<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>]])</span><br><span class="line">Q, R = np.linalg.qr(A)</span><br><span class="line"><span class="built_in">print</span>(Q)</span><br><span class="line"><span class="built_in">print</span>(R)</span><br></pre></td></tr></table></figure>
<p>程序运行结果如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[[-<span class="number">0.12309149</span>  <span class="number">0.90453403</span>    <span class="number">0.40824829</span>],</span><br><span class="line"> [-<span class="number">0.49236596</span>  <span class="number">0.30151134</span>    -<span class="number">0.81649658</span>],</span><br><span class="line"> [-<span class="number">0.86164044</span>  -<span class="number">0.301511340</span>  <span class="number">0.40824829</span>]]</span><br><span class="line"></span><br><span class="line">[[-<span class="number">8.12403840e+00</span>  -<span class="number">9.60113630e+00</span>  -<span class="number">1.10782342e+01</span>],</span><br><span class="line"> [<span class="number">0.00000000e+00</span>   <span class="number">9.04534034e-01</span>   <span class="number">1.80906807e+00</span>],</span><br><span class="line"> [<span class="number">0.00000000e+00</span>   <span class="number">0.00000000e+00</span>   -<span class="number">8.88178420e-16</span>]] </span><br></pre></td></tr></table></figure>
<p>可以验证这两个矩阵的乘积就是原始矩阵$\boldsymbol{A}$，接下来考虑不是方阵的情况，对于如下的矩阵</p>
<script type="math/tex; mode=display">
\boldsymbol{A}=\left(\begin{array}{lll}
1 & 2 & 3 \\
4 & 5 & 6
\end{array}\right)</script><p>其$\mathrm{QR}$分解的代码如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">A = np.array([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]])</span><br><span class="line">Q, R = np.linalg.qr(A)</span><br><span class="line"><span class="built_in">print</span>(Q)</span><br><span class="line"><span class="built_in">print</span>(R)</span><br></pre></td></tr></table></figure>
<p>程序运行结果如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[[-<span class="number">0.24253563</span>-<span class="number">0.9701425</span>]</span><br><span class="line"> [-<span class="number">0.97014250</span> <span class="number">.24253563</span>]]</span><br><span class="line"></span><br><span class="line">[[-<span class="number">4.12310563</span>-<span class="number">5.33578375</span>-<span class="number">6.54846188</span>]</span><br><span class="line"> [<span class="number">0</span>,-<span class="number">0.72760688</span>-<span class="number">1.45521375</span>]]</span><br></pre></td></tr></table></figure>
<h2 id="特征值分解"><a href="#特征值分解" class="headerlink" title="特征值分解"></a>特征值分解</h2><blockquote>
<p>定义</p>
</blockquote>
<p><code>特征值分解</code>(Eigen Decomposition)也称为<code>谱分解</code>(Spectral Decomposition)，是矩阵相似对角化的另一种表述</p>
<p>对于$n$阶矩阵$\boldsymbol{A}$，如果它有$n$个线性无关的特征向量，则可将其分解为如下3个矩阵的乘积</p>
<script type="math/tex; mode=display">
\boldsymbol{A}=\boldsymbol{Q} \Lambda \boldsymbol{Q}^{-1}</script><p>其中$\Lambda$为对角矩阵，矩阵$\Lambda$的对角线元素为矩阵$A$的特征值</p>
<script type="math/tex; mode=display">
\Lambda=\left(\begin{array}{lll}
\lambda_{1} & & \\
& \ddots & \\
& & \lambda_{n}
\end{array}\right)</script><p>$Q$为$n$阶矩阵，它的列为$A$的特征向量，与对角矩阵中特征值的排列顺序一致</p>
<script type="math/tex; mode=display">
\boldsymbol{Q}=\left(\begin{array}{lll}
x_{1} & \cdots & \boldsymbol{x}_{n}
\end{array}\right)</script><p>一个$n$阶矩阵可以进行特征值分解的充分必要条件是它有$n$个线性无关的特征向量，通常情况下，这些特征向量$x_{i}$都是单位化的</p>
<blockquote>
<p>用于计算逆矩阵</p>
</blockquote>
<p>特征值分解可以用于计算逆矩阵，如果矩阵$\boldsymbol{A}$可以进行特征值分解，且其所有特征值都非0，则</p>
<script type="math/tex; mode=display">
A=Q \Lambda Q^{-1}</script><p>其逆矩阵为</p>
<script type="math/tex; mode=display">
\boldsymbol{A}^{-1}=\left(\boldsymbol{Q} \boldsymbol{A} \boldsymbol{Q}^{-1}\right)^{-1}=\boldsymbol{Q} \boldsymbol{\Lambda}^{-1} \boldsymbol{Q}^{-1}</script><p>对角矩阵的逆矩阵容易计算，是主对角线所有元素的倒数</p>
<p>特征值分解还可用于计算矩阵的多项式或者幂，对于如下多项式</p>
<script type="math/tex; mode=display">
f(x)=a_{n} x^{n}+a_{n-1} x^{n-1}+\cdots+a_{1} x</script><p>如果矩阵$\boldsymbol{A}$可以进行特征值分解，且</p>
<script type="math/tex; mode=display">
\boldsymbol{A}=\boldsymbol{Q A} \boldsymbol{Q}^{-1}</script><p>则有</p>
<script type="math/tex; mode=display">
\begin{aligned}
f(\boldsymbol{A}) & =f\left(\boldsymbol{Q \Lambda} \boldsymbol{Q}^{-1}\right)=a_{1} \boldsymbol{Q \Lambda} Q^{-1}+a_{2} \boldsymbol{Q \Lambda} Q^{-1} Q \Lambda Q^{-1}+\cdots=a_{1} \boldsymbol{Q} \boldsymbol{\Lambda} Q^{-1}+a_{2} \boldsymbol{Q} \boldsymbol{\Lambda}^{2} Q^{-1}+\cdots \\
& =\boldsymbol{Q}\left(a_{1} \boldsymbol{\Lambda}+a_{2} \Lambda^{2}+\cdots\right) Q^{-1}=Q f(\boldsymbol{\Lambda}) Q^{-1}
\end{aligned}</script><p>对角矩阵的幂仍然是对角矩阵，是主对角线元素分别求幂，因此有</p>
<script type="math/tex; mode=display">
f(\boldsymbol{\Lambda})_{i i}=f\left(\Lambda_{i i}\right)</script><p>借助于特征值分解，可以高效地计算出$f(A)$，特别地，有</p>
<script type="math/tex; mode=display">
A^{n}=Q A^{n} Q^{-1}</script><p>如果$A$是实对称矩阵，可对其特征向量进行正交化，特征值分解为</p>
<script type="math/tex; mode=display">
\boldsymbol{A}=Q \Lambda Q^{\mathrm{T}}</script><p>其中$Q$为正交矩阵，它的列是$A$的正交化特征向量，$A$同样为$A$的所有特征值构成的对角矩阵</p>
<p>特征值分解可以借助于$\mathrm{QR}$箕法实现，机器学习中常用的矩阵如协方差矩阵等都是实对称矩阵，因此都可以进行特征值分解</p>
<p>特征值分解可以由Python中linalg的eig函数实现，函数的输入为被分解矩阵$A$，输出为所有特征值，以及这些特征值对应的单位化特征向量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">A = np.array([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>],[<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>]])</span><br><span class="line">V, U = np.linalg.eig(A)</span><br><span class="line"><span class="built_in">print</span>(U)</span><br><span class="line"><span class="built_in">print</span>(V)</span><br></pre></td></tr></table></figure>
<p>程序结果如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[[-<span class="number">0.23197069</span>-<span class="number">0.785830240</span> <span class="number">.40824829</span>]</span><br><span class="line"> [-<span class="number">0.52532209</span>-<span class="number">0.08675134</span>-<span class="number">0.81649658</span>]</span><br><span class="line"> [-<span class="number">0.81867350</span> <span class="number">.612327560</span> <span class="number">.40824829</span>]]</span><br><span class="line"></span><br><span class="line">[<span class="number">1.61168440e+01</span>   -<span class="number">1.11684397e+00</span>  -<span class="number">1.30367773e-15</span>]</span><br></pre></td></tr></table></figure>
<p>这里的V所有特征值形成的向量，U的列是单位化的特征向量</p>
<h2 id="奇异值分解"><a href="#奇异值分解" class="headerlink" title="奇异值分解"></a>奇异值分解</h2><p>特征值分解只适用于方阵，且要求方阵有$n$个线性无关的特征向量</p>
<p><code>奇异值分解</code>(Singular Value Decomposition, SVD)是对它的推广，对于任意的矩阵均可用特征值与特征向量进行分解</p>
<p>其思路是对$A A^{\mathrm{T}}$和$\boldsymbol{A}^{\mathrm{T}} \boldsymbol{A}$进行特征值分解，对于任意矩阵$\boldsymbol{A}$，这两个矩阵都是<code>对称半正定矩阵</code>，一定能进行特征值分解</p>
<p>并且这两个矩阵的特征值都是非负的，后面将会证明它们有相同的非0特征值</p>
<p>假设$A \in \mathbb{R}^{m \times n}$，其中$m \geqslant n$，则有</p>
<script type="math/tex; mode=display">
\boldsymbol{U}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{V}=\mathbf{\Sigma}</script><p>其中$\boldsymbol{U}$为$m$阶正交矩阵，其列称为矩阵$\boldsymbol{A}$的左奇异向量，也是$\boldsymbol{A} \boldsymbol{A}^{\mathrm{T}}$的特征向量，$\boldsymbol{\Sigma}$为如下形式的$m \times n$矩阵</p>
<script type="math/tex; mode=display">
\boldsymbol{\Sigma}=\left(\begin{array}{cccc}
\sigma_{1} & 0 & \cdots & 0 \\
0 & \sigma_{2} & \cdots & 0 \\
\vdots & \vdots & \vdots & \vdots \\
0 & 0 & \cdots & \sigma_{n} \\
0 & 0 & \cdots & 0 \\
\vdots & \vdots & \vdots & \vdots \\
0 & 0 & \cdots & \cdots
\end{array}\right)=\left(\begin{array}{c}
\boldsymbol{\Sigma}_{n} \\
\mathbf{0}_{(m-n) \times n}
\end{array}\right)</script><p>其尺寸与$\boldsymbol{A}$相同，在这里$\boldsymbol{\Sigma}_{n}$是$n$阶对角矩阵且主对角线元素按照其值大小降序排列</p>
<script type="math/tex; mode=display">
\boldsymbol{\Sigma}_{n}=\operatorname{diag}\left(\sigma_{1}, \cdots, \sigma_{n}\right), \sigma_{1} \geqslant \sigma_{2} \geqslant \cdots \geqslant \sigma_{n} \geqslant 0</script><p>$\sigma_{i}$称为$\boldsymbol{A}$的奇异值，是$\boldsymbol{A} \boldsymbol{A}^{\mathrm{T}}$特征值的非负平方根，也是$\boldsymbol{A}^{\mathrm{T}} \boldsymbol{A}$特征值的非负平方根</p>
<p>$\boldsymbol{V}$为$n$阶正交矩阵，其行称为矩阵$\boldsymbol{A}$的右奇异向量，也是$\boldsymbol{A}^{\mathrm{T}} \boldsymbol{A}$的特征向量</p>
<p>式1两边左乘$\boldsymbol{U}$，右乘$\boldsymbol{V}^{\mathrm{T}}$，由于$\boldsymbol{U}$、$\boldsymbol{V}$都是正交矩阵，因此有</p>
<script type="math/tex; mode=display">
\boldsymbol{A}=\boldsymbol{U} \boldsymbol{\Sigma} \boldsymbol{\boldsymbol { V } ^ { \mathrm { T } }}</script><p>上式称为矩阵的<code>奇异值分解</code>，对于$m \leqslant n$的情况，有类似的结果，此时</p>
<script type="math/tex; mode=display">
\boldsymbol{\Sigma}=\left(\begin{array}{ccccccc}
\sigma_{1} & 0 & \cdots & 0 & 0 & \cdots & \cdots \\
0 & \sigma_{2} & \cdots & 0 & 0 & \cdots & \cdots \\
\cdots & \cdots & \cdots & \cdots & 0 & \cdots & \cdots \\
0 & 0 & \cdots & \sigma_{m} & 0 & \cdots & \cdots
\end{array}\right)=\left(\boldsymbol{\Sigma}_{m} \mathbf{0}_{m \times(n-m)}\right)</script><p>下面证明$\boldsymbol{A} A^{\mathrm{T}}$与$\boldsymbol{A}^{\mathrm{T}} \boldsymbol{A}$有相同的非0特征值，假设$\lambda \neq 0$是$A A^{\mathrm{T}}$的特征值,$\boldsymbol{x}$是对应的特征向量，则有</p>
<script type="math/tex; mode=display">
\boldsymbol{A} \boldsymbol{A}^{\mathrm{T}} \boldsymbol{x}=\lambda \boldsymbol{x}</script><p>上式两边同时左乘$\boldsymbol{A}^{\mathrm{T}}$可以得到</p>
<script type="math/tex; mode=display">
\boldsymbol{A}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{A}^{\mathrm{T}} \boldsymbol{x}=\boldsymbol{A}^{\mathrm{T}} \lambda \boldsymbol{x}</script><p>即</p>
<script type="math/tex; mode=display">
\boldsymbol{A}^{\mathrm{T}} \boldsymbol{A}\left(\boldsymbol{A}^{\mathrm{T}} \boldsymbol{x}\right)=\lambda\left(\boldsymbol{A}^{\mathrm{T}} \boldsymbol{x}\right)</script><p>下面证明$\boldsymbol{A}^{\mathrm{T}} \boldsymbol{x} \neq \mathbf{0}$，式 (2.65) 两边同时左乘$\boldsymbol{x}^{\mathrm{T}}$, 由于$\lambda \neq 0, \boldsymbol{x} \neq \mathbf{0}$</p>
<script type="math/tex; mode=display">
\boldsymbol{x}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{A}^{\mathrm{T}} \boldsymbol{x}=\left(\boldsymbol{A}^{\mathrm{T}} \boldsymbol{x}\right)^{\mathrm{T}} \boldsymbol{A}^{\mathrm{T}} \boldsymbol{x}=\lambda \boldsymbol{x}^{\mathrm{T}} \boldsymbol{x}>0</script><p>因此$A^{\mathrm{T}} x \neq 0$，$\lambda$是$A^{\mathrm{T}} A$的特征值，$\boldsymbol{A}^{\mathrm{T}} \boldsymbol{x}$是对应的特征向量</p>
<p>同样，如果$\lambda \neq 0$是$A^{\mathrm{T}} A$的特征值,$\boldsymbol{x}$是对应的特征向量，则有</p>
<script type="math/tex; mode=display">
\boldsymbol{A}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{x}=\lambda \boldsymbol{x}</script><p>上式两边同时左乘$\boldsymbol{A}$可以得到</p>
<script type="math/tex; mode=display">
\boldsymbol{A} \boldsymbol{A}^{\mathrm{T}} \boldsymbol{A x}=\boldsymbol{A} \lambda \boldsymbol{x}</script><p>即</p>
<script type="math/tex; mode=display">
\boldsymbol{A} \boldsymbol{A}^{\mathrm{T}}(\boldsymbol{A} \boldsymbol{x})=\lambda(\boldsymbol{A} \boldsymbol{x})</script><p>下面证明$A x \neq 0$，上上上式两边同时左乘$x^{\mathrm{T}}$，由于$\lambda \neq 0, x \neq 0$</p>
<script type="math/tex; mode=display">
\boldsymbol{x}^{\mathrm{T}} \boldsymbol{A}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{x}=(\boldsymbol{A} \boldsymbol{x})^{\mathrm{T}} \boldsymbol{A} \boldsymbol{x}=\boldsymbol{\lambda} \boldsymbol{x}^{\mathrm{T}} \boldsymbol{x}>0</script><p>因此$A x \neq 0$，$\lambda$是$A A^{\mathrm{T}}$的特征值，$A \boldsymbol{x}$是对应的特征向量</p>
<p>需要注意的是，$\boldsymbol{A A ^ { \mathrm { T } }}$的0特征值不一定是$A^{\mathrm{T}} \boldsymbol{A}$的0特征值，下面举例说明，对于如下的矩阵</p>
<script type="math/tex; mode=display">
\boldsymbol{A}=\left(\begin{array}{ll}
1 & 0 \\
0 & 1 \\
0 & 0
\end{array}\right)</script><p>有</p>
<script type="math/tex; mode=display">
\boldsymbol{A} \boldsymbol{A}^{\mathrm{T}}=\left(\begin{array}{ll}
1 & 0 \\
0 & 1 \\
0 & 0
\end{array}\right)\left(\begin{array}{lll}
1 & 0 & 0 \\
0 & 1 & 0
\end{array}\right)=\left(\begin{array}{lll}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & 0
\end{array}\right)</script><p>$A A^{\mathrm{T}}$的特征值为<script type="math/tex">\lambda_{1}=1, \lambda_{2}=1, \lambda_{3}=0</script></p>
<script type="math/tex; mode=display">
\boldsymbol{A}^{\mathrm{T}} \boldsymbol{A}=\left(\begin{array}{lll}
1 & 0 & 0 \\
0 & 1 & 0
\end{array}\right)\left(\begin{array}{ll}
1 & 0 \\
0 & 1 \\
0 & 0
\end{array}\right)=\left(\begin{array}{ll}
1 & 0 \\
0 & 1
\end{array}\right)</script><p>可知<script type="math/tex">\boldsymbol{A}^{\mathrm{T}} \boldsymbol{A}</script>特征值为<script type="math/tex">\lambda_{1}=1, \lambda_{2}=1</script>，0是<script type="math/tex">\boldsymbol{A} \boldsymbol{A}^{\mathrm{T}}</script>的特征值但不是<script type="math/tex">\boldsymbol{A}^{\mathrm{T}} \boldsymbol{A}</script>的特征值</p>
<p>下面来看奇异值分解的一个例子。对于如下的矩阵</p>
<script type="math/tex; mode=display">
\boldsymbol{A}=\left(\begin{array}{cc}
-1 & 3 \\
3 & 1 \\
1 & 1
\end{array}\right)</script><p>有</p>
<script type="math/tex; mode=display">
\boldsymbol{A} \boldsymbol{A}^{\mathrm{T}}=\left(\begin{array}{ccc}
10 & 0 & 2 \\
0 & 10 & 4 \\
2 & 4 & 2
\end{array}\right)</script><p>以及</p>
<script type="math/tex; mode=display">
\boldsymbol{A}^{\mathrm{T}} \boldsymbol{A}=\left(\begin{array}{cc}
11 & 1 \\
1 & 11
\end{array}\right)</script><p>这里<script type="math/tex">A A^{\mathrm{T}}</script>的特征值为<script type="math/tex">\lambda_{1}=12, \lambda_{2}=10, \lambda_{3}=0</script>，<script type="math/tex">\boldsymbol{A}^{\mathrm{T}} \boldsymbol{A}</script>的特征值为<script type="math/tex">\lambda_{1}=12, \lambda_{2}=10</script></p>
<p>因此$\boldsymbol{A}$的非0奇异值为<script type="math/tex">\sigma_{1}=\sqrt{12}</script>、<script type="math/tex">\sigma_{2}=\sqrt{10}</script></p>
<p>计算$\boldsymbol{A} \boldsymbol{A}^{\mathrm{T}}$与$\boldsymbol{A}^{\mathrm{T}} \boldsymbol{A}$的特征向量并进行单位化，最后得到奇异值分解结果为</p>
<script type="math/tex; mode=display">
\boldsymbol{U}^{\mathrm{T}} \boldsymbol{A} \boldsymbol{V}=\left(\begin{array}{ccc}
\frac{1}{\sqrt{6}} & \frac{2}{\sqrt{6}} & \frac{1}{\sqrt{6}} \\
\frac{2}{\sqrt{5}} & -\frac{1}{\sqrt{5}} & 0 \\
\frac{1}{\sqrt{30}} & \frac{2}{\sqrt{30}} & -\frac{5}{\sqrt{30}}
\end{array}\right)^{\mathrm{T}}\left(\begin{array}{cc}
-1 & 3 \\
3 & 1 \\
1 & 1
\end{array}\right)\left(\begin{array}{cc}
\frac{1}{\sqrt{2}} & \frac{1}{\sqrt{2}} \\
\frac{1}{\sqrt{2}} & -\frac{1}{\sqrt{2}}
\end{array}\right)=\left(\begin{array}{cc}
\sqrt{12} & 0 \\
0 & \sqrt{10} \\
0 & 0
\end{array}\right)</script><p>如果$m \geqslant n$</p>
<script type="math/tex; mode=display">
\boldsymbol{A}^{\mathrm{T}} \boldsymbol{A}=\left(\boldsymbol{U} \boldsymbol{\Sigma} \boldsymbol{V}^{\mathrm{T}}\right)^{\mathrm{T}} \boldsymbol{U} \boldsymbol{\Sigma} \boldsymbol{V}^{\mathrm{T}}=\boldsymbol{V} \boldsymbol{\Sigma}^{\mathrm{T}} \boldsymbol{U}^{\mathrm{T}} \boldsymbol{U} \boldsymbol{\Sigma} \boldsymbol{V}^{\mathrm{T}}=\boldsymbol{V} \boldsymbol{\Sigma}^{\mathrm{T}} \boldsymbol{\Sigma} \boldsymbol{V}^{\mathrm{T}}</script><p>即</p>
<script type="math/tex; mode=display">
\boldsymbol{A}^{\mathrm{T}} \boldsymbol{A}=\boldsymbol{V} \boldsymbol{\Sigma}^{\mathrm{T}} \boldsymbol{\Sigma} \boldsymbol{V}^{\mathrm{T}}</script><p>在这里</p>
<script type="math/tex; mode=display">
\boldsymbol{\Sigma}^{\mathrm{T}} \boldsymbol{\Sigma}=\left(\begin{array}{c}
\boldsymbol{\Sigma}_{n} \\
\mathbf{0}_{(m-n) \times n}
\end{array}\right)^{\mathrm{T}}\left(\begin{array}{c}
\boldsymbol{\Sigma}_{n} \\
\mathbf{0}_{(m-n) \times n}
\end{array}\right)=\left(\boldsymbol{\Sigma}_{n} \mathbf{0}_{n \times(m-n)}\right)\left(\begin{array}{c}
\boldsymbol{\Sigma}_{n} \\
\mathbf{0}_{(m-n) \times n}
\end{array}\right)=\boldsymbol{\Sigma}_{n}^{2}</script><p>是$n$阶对角阵，上式就是$A^{\mathrm{T}} \boldsymbol{A}$的特征值分解</p>
<p>类似地有</p>
<script type="math/tex; mode=display">
\boldsymbol{A} \boldsymbol{A}^{\mathrm{T}}=\boldsymbol{U} \boldsymbol{\Sigma} \boldsymbol{V}^{\mathrm{T}}\left(\boldsymbol{U} \boldsymbol{\Sigma} \boldsymbol{V}^{\mathrm{T}}\right)^{\mathrm{T}}=\boldsymbol{U} \boldsymbol{\Sigma} \boldsymbol{V}^{\mathrm{T}} \boldsymbol{V} \boldsymbol{\Sigma}^{\mathrm{T}} \boldsymbol{U}^{\mathrm{T}}=\boldsymbol{U} \boldsymbol{\Sigma} \boldsymbol{\Sigma}^{\mathrm{T}} \boldsymbol{U}^{\mathrm{T}}</script><p>即</p>
<script type="math/tex; mode=display">
\boldsymbol{A} \boldsymbol{A}^{\mathrm{T}}=\boldsymbol{U} \boldsymbol{\Sigma} \boldsymbol{\Sigma}^{\mathrm{T}} \boldsymbol{U}^{\mathrm{T}}</script><p>在这里</p>
<script type="math/tex; mode=display">
\begin{aligned}
\boldsymbol{\Sigma} \boldsymbol{\Sigma}^{\mathrm{T}} & =\left(\begin{array}{c}
\boldsymbol{\Sigma}_{n} \\
\mathbf{0}_{(m-n) \times n}
\end{array}\right)\left(\begin{array}{c}
\boldsymbol{\Sigma}_{n} \\
\mathbf{0}_{(m-n) \times n}
\end{array}\right)^{\mathrm{T}}=\left(\begin{array}{c}
\boldsymbol{\Sigma}_{n} \\
\mathbf{0}_{(m-n) \times n}
\end{array}\right)\left(\begin{array}{cc}
\boldsymbol{\Sigma}_{n} & \mathbf{0}_{n \times(m-n)}
\end{array}\right) \\
& =\left(\begin{array}{cc}
\boldsymbol{\Sigma}_{n}^{2} & \boldsymbol{\Sigma}_{n} \times \boldsymbol{0}_{n \times(m-n)} \\
\mathbf{0}_{(m-n) \times n} \times \boldsymbol{\Sigma}_{n} & \mathbf{0}_{(m-n) \times n} \times \mathbf{0}_{n \times(m-n)}
\end{array}\right)=\left(\begin{array}{cc}
\boldsymbol{\Sigma}_{n}^{2} & \boldsymbol{0}_{n \times(m-n)} \\
\mathbf{0}_{(m-n) \times n} & \mathbf{0}_{(m-n) \times(m-n)}
\end{array}\right)
\end{aligned}</script><p>是$m$阶对角阵，上上式就是$A A^{\mathrm{T}}$的特征值分解，对于$m \leqslant n$有相同的结论</p>
<p>如果$A$是对称矩阵，则$A^{\mathrm{T}} A=A A^{\mathrm{T}}=A \boldsymbol{A}$，因此$A^{\mathrm{T}} A$和$\boldsymbol{A} \boldsymbol{A}^{\mathrm{T}}$的特征值分解是相同的，这意味着$U$和$V$相同</p>
<p>假设$\lambda$是$A$的特征值，根据特征值的性质，$\lambda^{2}$是$A^{\mathrm{T}} \boldsymbol{A}$与$\boldsymbol{A A ^ { \mathrm { T } }}$的特征值，因此$A$的奇异值为其特征值的绝对值</p>
<script type="math/tex; mode=display">
\sigma=\sqrt{\lambda^{2}}=|\lambda|</script><p>Python中linalg的svd函数实现了奇异值分解，函数的输入值为被分解矩阵$A$，输出为正交矩阵$U$和$V^{\mathrm{T}}$，以及非0奇异值$\sigma_{i}$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">data = [[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]]</span><br><span class="line">u, sigma, vt = linalg.svd(data)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(u)</span><br><span class="line"><span class="built_in">print</span>(sigma)</span><br><span class="line"><span class="built_in">print</span>(vt)</span><br></pre></td></tr></table></figure>
<p>输出结果如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[[-<span class="number">0.3863177</span>   -<span class="number">0.92236578</span>]</span><br><span class="line"> [-<span class="number">0.92236578</span>   <span class="number">0.3863177</span>]</span><br><span class="line"> [<span class="number">9.508032</span>      <span class="number">0.77286964</span>]] </span><br><span class="line"> </span><br><span class="line">[[-<span class="number">0.42866713</span>   -<span class="number">0.56630692</span>   -<span class="number">0.7039467</span>]</span><br><span class="line"> [<span class="number">0.80596391</span>    <span class="number">0.11238241</span>    -<span class="number">0.58119908</span>]</span><br><span class="line"> [<span class="number">0.40824829</span>   -<span class="number">0.81649658</span>    <span class="number">0.40824829</span>]]  </span><br></pre></td></tr></table></figure>
<p>这里的u是公式中的$U$，$\mathrm{vt}$是公式中的$V^{\mathrm{T}}$，sigma是所有非0奇异值，它们构成如下$2 \times 3$的矩阵$\boldsymbol{\Sigma}$</p>
<script type="math/tex; mode=display">
\left(\begin{array}{ccc}
9.508032 & 0 & 0 \\
0 & 0.7728694 & 0
\end{array}\right)</script><p>可以验证，这3个矩阵的乘积为原始矩阵</p>
<blockquote>
<p>奇异值分解的几何意义</p>
</blockquote>
<p>向量$\boldsymbol{x}$左乘任意矩阵$\boldsymbol{A}$所实现的线性变换可以分解为3次变换</p>
<script type="math/tex; mode=display">
\boldsymbol{A} \boldsymbol{x}=\boldsymbol{U} \boldsymbol{\Sigma} \boldsymbol{V}^{\mathrm{T}} \boldsymbol{x}</script><p>首先是$\boldsymbol{x}$左乘正交矩阵$V^{\mathrm{T}}$所代表的旋转变换，接下来是$V^{\mathrm{T}} x$左乘矩阵$\boldsymbol{\Sigma}$所代表的拉伸变换</p>
<p>最后是$\Sigma V^{\mathrm{T}} x$左乘正交矩阵$U$所代表的旋转变换</p>
<p>奇异值分解揭示了矩阵的本质特征，对分析矩阵的性质有重要的价值</p>
<p>在对人工神经网络权重矩阵的理论分析中，奇异值和奇异向量经常被使用，在图像压缩与推荐系统中，奇异值分解也有应用</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/narutohyc">narutohyc</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://study.hycbook.com/article/47032.html">https://study.hycbook.com/article/47032.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="external nofollow noreferrer" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://study.hycbook.com" target="_blank">兼一书虫</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/python/">python</a><a class="post-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B0%E5%AD%A6/">机器学习数学</a><a class="post-meta__tags" href="/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/">线性代数</a><a class="post-meta__tags" href="/tags/%E7%9F%A9%E9%98%B5%E8%AE%BA/">矩阵论</a></div><div class="post_share"><div class="social-share" data-image="https://pic.hycbook.com/i/hexo/post_cover/蕾姆1.webp" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><link rel="stylesheet" href="/" media="defer" onload="this.media='all'"/><div class="post-reward"><button class="tip-button reward-button"><span class="tip-button__text">打赏</span><div class="coin-wrapper"><div class="coin"><div class="coin__middle"></div><div class="coin__back"></div><div class="coin__front"></div></div></div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="https://pic.hycbook.com/i//hexo/qr_codes/hyc_wechat.webp" rel="external nofollow noreferrer" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i//hexo/qr_codes/hyc_wechat.webp" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="https://pic.hycbook.com/i//hexo/qr_codes/hyc_alipay.webp" rel="external nofollow noreferrer" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i//hexo/qr_codes/hyc_alipay.webp" alt="alipay"/></a><div class="post-qr-code-desc">alipay</div></li></ul></div></button></div><audio id="coinAudio" src="https://s1.vika.cn/space/2022/10/29/6db0ad2bccf949f09054b3b206dcc66f?attname=马里奥游戏投币叮当.mp3"></audio><script defer="defer" src="/"></script><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/article/50622.html"><img class="prev-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i/hexo/post_cover/蕾姆5.webp" onerror="onerror=null;src='https://pic.hycbook.com/i/hexo/config_imgs/404.svg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">docker基本使用</div></div></a></div><div class="next-post pull-right"><a href="/article/21745.html"><img class="next-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i//hexo/post_cover/蕾姆6.webp" onerror="onerror=null;src='https://pic.hycbook.com/i/hexo/config_imgs/404.svg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">md数学公式和emoji表情</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/article/10706.html" title="机器学习_一元函数微积分"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i/hexo/post_cover/蕾姆0.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-09-10</div><div class="title">机器学习_一元函数微积分</div></div></a></div><div><a href="/article/4071.html" title="枚举类Enum"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i//hexo/post_cover/蕾姆12.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-09-10</div><div class="title">枚举类Enum</div></div></a></div><div><a href="/article/62278.html" title="pandas小记"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i/hexo/post_cover/蕾姆2.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-09-10</div><div class="title">pandas小记</div></div></a></div><div><a href="/article/30791.html" title="numpy小记"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i/hexo/post_cover/蕾姆3.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-09-10</div><div class="title">numpy小记</div></div></a></div><div><a href="/article/27292.html" title="python_pipe包管道包学习"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i/hexo/post_cover/蕾姆4.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-09-10</div><div class="title">python_pipe包管道包学习</div></div></a></div><div><a href="/article/65108.html" title="Python增强提案PEP"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i/hexo/post_cover/蕾姆5.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-09-10</div><div class="title">Python增强提案PEP</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div><div id="comment-switch"><span class="first-comment">Twikoo</span><span class="switch-btn"></span><span class="second-comment">Valine</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%90%91%E9%87%8F%E5%8F%8A%E5%85%B6%E8%BF%90%E7%AE%97"><span class="toc-number">1.</span> <span class="toc-text">向量及其运算</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5"><span class="toc-number">1.1.</span> <span class="toc-text">基本概念</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E8%BF%90%E7%AE%97"><span class="toc-number">1.2.</span> <span class="toc-text">基本运算</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%90%91%E9%87%8F%E7%9A%84%E8%8C%83%E6%95%B0"><span class="toc-number">1.3.</span> <span class="toc-text">向量的范数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A7%A3%E6%9E%90%E5%87%A0%E4%BD%95"><span class="toc-number">1.4.</span> <span class="toc-text">解析几何</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BA%BF%E6%80%A7%E7%9B%B8%E5%85%B3%E6%80%A7"><span class="toc-number">1.5.</span> <span class="toc-text">线性相关性</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%90%91%E9%87%8F%E7%A9%BA%E9%97%B4"><span class="toc-number">1.6.</span> <span class="toc-text">向量空间</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BA%94%E7%94%A8%E4%B9%8B%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="toc-number">1.7.</span> <span class="toc-text">应用之线性回归</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BA%94%E7%94%A8%E4%B9%8B%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB%E5%99%A8%E4%B8%8E%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA"><span class="toc-number">1.8.</span> <span class="toc-text">应用之线性分类器与支持向量机</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%9F%A9%E9%98%B5%E5%8F%8A%E5%85%B6%E8%BF%90%E7%AE%97"><span class="toc-number">2.</span> <span class="toc-text">矩阵及其运算</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5-1"><span class="toc-number">2.1.</span> <span class="toc-text">基本概念</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E8%BF%90%E7%AE%97-1"><span class="toc-number">2.2.</span> <span class="toc-text">基本运算</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%80%86%E7%9F%A9%E9%98%B5"><span class="toc-number">2.3.</span> <span class="toc-text">逆矩阵</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9F%A9%E9%98%B5%E7%9A%84%E8%8C%83%E6%95%B0"><span class="toc-number">2.4.</span> <span class="toc-text">矩阵的范数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2"><span class="toc-number">2.5.</span> <span class="toc-text">线性变换</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%A1%8C%E5%88%97%E5%BC%8F"><span class="toc-number">3.</span> <span class="toc-text">行列式</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A1%8C%E5%88%97%E5%BC%8F%E7%9A%84%E5%AE%9A%E4%B9%89%E4%B8%8E%E6%80%A7%E8%B4%A8"><span class="toc-number">3.1.</span> <span class="toc-text">行列式的定义与性质</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%A1%E7%AE%97%E6%96%B9%E6%B3%95"><span class="toc-number">3.2.</span> <span class="toc-text">计算方法</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84"><span class="toc-number">4.</span> <span class="toc-text">线性方程组</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%AB%98%E6%96%AF%E6%B6%88%E5%85%83%E6%B3%95"><span class="toc-number">4.1.</span> <span class="toc-text">高斯消元法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%BD%90%E6%AC%A1%E6%96%B9%E7%A8%8B%E7%BB%84"><span class="toc-number">4.2.</span> <span class="toc-text">齐次方程组</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9D%9E%E9%BD%90%E6%AC%A1%E6%96%B9%E7%A8%8B%E7%BB%84"><span class="toc-number">4.3.</span> <span class="toc-text">非齐次方程组</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E5%80%BC%E5%92%8C%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F"><span class="toc-number">5.</span> <span class="toc-text">特征值和特征向量</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E5%80%BC%E4%B8%8E%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F"><span class="toc-number">5.1.</span> <span class="toc-text">特征值与特征向量</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9B%B8%E4%BC%BC%E5%8F%98%E6%8D%A2"><span class="toc-number">5.2.</span> <span class="toc-text">相似变换</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%AD%A3%E4%BA%A4%E5%8F%98%E6%8D%A2"><span class="toc-number">5.3.</span> <span class="toc-text">正交变换</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#QR-%E7%AE%97%E6%B3%95"><span class="toc-number">5.4.</span> <span class="toc-text">QR 算法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B9%BF%E4%B9%89%E7%89%B9%E5%BE%81%E5%80%BC"><span class="toc-number">5.5.</span> <span class="toc-text">广义特征值</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%91%9E%E5%88%A9%E5%95%86"><span class="toc-number">5.6.</span> <span class="toc-text">瑞利商</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%B0%B1%E8%8C%83%E6%95%B0%E4%B8%8E%E7%89%B9%E5%BE%81%E5%80%BC%E7%9A%84%E5%85%B3%E7%B3%BB"><span class="toc-number">5.7.</span> <span class="toc-text">谱范数与特征值的关系</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9D%A1%E4%BB%B6%E6%95%B0"><span class="toc-number">5.8.</span> <span class="toc-text">条件数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BA%94%E7%94%A8%E2%80%94%E2%80%94%E8%B0%B1%E5%BD%92%E4%B8%80%E5%8C%96%E4%B8%8E%E8%B0%B1%E6%AD%A3%E5%88%99%E5%8C%96"><span class="toc-number">5.9.</span> <span class="toc-text">应用——谱归一化与谱正则化</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%8C%E6%AC%A1%E5%9E%8B"><span class="toc-number">6.</span> <span class="toc-text">二次型</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5-2"><span class="toc-number">6.1.</span> <span class="toc-text">基本概念</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%AD%A3%E5%AE%9A%E4%BA%8C%E6%AC%A1%E5%9E%8B%E4%B8%8E%E6%AD%A3%E5%AE%9A%E7%9F%A9%E9%98%B5"><span class="toc-number">6.2.</span> <span class="toc-text">正定二次型与正定矩阵</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A0%87%E5%87%86%E5%9E%8B"><span class="toc-number">6.3.</span> <span class="toc-text">标准型</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3"><span class="toc-number">7.</span> <span class="toc-text">矩阵分解</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A5%9A%E5%88%97%E6%96%AF%E5%9F%BA%E5%88%86%E8%A7%A3"><span class="toc-number">7.1.</span> <span class="toc-text">楚列斯基分解</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#QR-%E5%88%86%E8%A7%A3"><span class="toc-number">7.2.</span> <span class="toc-text">QR 分解</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E5%80%BC%E5%88%86%E8%A7%A3"><span class="toc-number">7.3.</span> <span class="toc-text">特征值分解</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A3"><span class="toc-number">7.4.</span> <span class="toc-text">奇异值分解</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer" style="background-image: url('https://pic.hycbook.com/i/hexo/config_imgs/footer_bg.webp')"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2023 By narutohyc</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener external nofollow noreferrer" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text"><p><a target="_blank" href="https://hexo.io/" rel="external nofollow noreferrer"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&logo=hexo" title="博客框架为Hexo"></a>&nbsp;<a target="_blank" href="https://demo.jerryc.me/" rel="external nofollow noreferrer"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&logo=bitdefender" title="主题采用butterfly"></a>&nbsp;<a target="_blank" href="https://vercel.com/ " rel="external nofollow noreferrer"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Hosted-Vervel-brightgreen?style=flat&logo=Vercel" title="本站采用双线部署，默认线路托管于Vercel"></a>&nbsp;<a target="_blank" href="https://github.com/" rel="external nofollow noreferrer"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&logo=GitHub" title="本站项目由Gtihub托管"></a>&nbsp;<a target="_blank" href="https://zixiaoyun.com" rel="external nofollow noreferrer"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/图床-薄荷图床-green" title="薄荷图床"></a></p><a target="_blank" href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=35020502000647" rel="external nofollow noreferrer"><img style="position:relative;top:4px" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.hycbook.com/i//hexo/config_imgs//备案图标.webp" alt="ICP"/>闽公网安备35020502000647号  </a><a href="https://beian.miit.gov.cn/" rel="external nofollow noreferrer" target="_blank">闽ICP备2022013843号-1</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">简</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div id="rightMenu"><div class="rightMenu-group rightMenu-small"><div class="rightMenu-item" id="menu-backward"><i class="fa-solid fa-arrow-left"></i></div><div class="rightMenu-item" id="menu-forward"><i class="fa-solid fa-arrow-right"></i></div><div class="rightMenu-item" id="menu-refresh"><i class="fa-solid fa-arrow-rotate-right"></i></div><div class="rightMenu-item" id="menu-home"><i class="fa-solid fa-house"></i></div></div><div class="rightMenu-group rightMenu-line hide" id="menu-text"><a class="rightMenu-item" href="javascript:window.open(&quot;https://www.baidu.com/s?wd=&quot;+window.getSelection().toString());window.location.reload();" rel="external nofollow noreferrer"><i class="fas fa-comment"></i><span>百度搜索</span></a></div><div class="rightMenu-group rightMenu-line rightMenuOther"><a class="rightMenu-item menu-link" href="/archives/"><i class="fa-solid fa-archive"></i><span>文章归档</span></a><a class="rightMenu-item menu-link" href="/categories/"><i class="fa-solid fa-folder-open"></i><span>文章分类</span></a><a class="rightMenu-item menu-link" href="/tags/"><i class="fa-solid fa-tags"></i><span>文章标签</span></a></div><div class="rightMenu-group rightMenu-line rightMenuNormal"><a class="rightMenu-item menu-link" id="menu-radompage"><i class="fa-solid fa-shoe-prints"></i><span>随便逛逛</span></a><div class="rightMenu-item" id="menu-translate"><i class="fa-solid fa-earth-asia"></i><span>繁简切换</span></div><div class="rightMenu-item" id="menu-darkmode"><i class="fa-solid fa-moon"></i><span>切换模式</span></div></div></div><div id="rightmenu-mask"></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script>(() => {
  const $mermaidWrap = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaidWrap.length) {
    window.runMermaid = () => {
      window.loadMermaid = true
      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? '' : ''

      Array.from($mermaidWrap).forEach((item, index) => {
        const mermaidSrc = item.firstElementChild
        const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
        const mermaidID = 'mermaid-' + index
        const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent
        mermaid.mermaidAPI.render(mermaidID, mermaidDefinition, (svgCode) => {
          mermaidSrc.insertAdjacentHTML('afterend', svgCode)
        })
      })
    }

    const loadMermaid = () => {
      window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
    }

    window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
  }
})()</script><script>(()=>{
  const init = () => {
    twikoo.init(Object.assign({
      el: '#twikoo-wrap',
      envId: 'https://vercel.hycbook.com',
      region: '',
      onCommentLoaded: function () {
        btf.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.tk-owo-emotion)'))
      }
    }, null))
  }

  const getCount = () => {
    const countELement = document.getElementById('twikoo-count')
    if(!countELement) return
    twikoo.getCommentsCount({
      envId: 'https://vercel.hycbook.com',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      countELement.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const runFn = () => {
    init()
    GLOBAL_CONFIG_SITE.isPost && getCount()
  }

  const loadTwikoo = () => {
    if (typeof twikoo === 'object') {
      setTimeout(runFn,0)
      return
    } 
    getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(runFn)
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo()
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script><script>function loadValine () {
  function initValine () {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: 'ncn88uooQf0IO2rrGE7Vniwp-gzGzoHsz',
      appKey: 'Yghpzg1QfBMFJ0MxxHubVzKL',
      avatar: 'monsterid',
      serverURLs: '',
      emojiMaps: "",
      path: window.location.pathname,
      visitor: true
    }, null))
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
}

if ('Twikoo' === 'Valine' || !false) {
  if (false) btf.loadComment(document.getElementById('vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script></div><script>window.addEventListener('load', () => {
  const changeContent = (content) => {
    if (content === '') return content

    content = content.replace(/<img.*?src="(.*?)"?[^\>]+>/ig, '[图片]') // replace image link
    content = content.replace(/<a[^>]+?href=["']?([^"']+)["']?[^>]*>([^<]+)<\/a>/gi, '[链接]') // replace url
    content = content.replace(/<pre><code>.*?<\/pre>/gi, '[代码]') // replace code
    content = content.replace(/<[^>]+>/g,"") // remove html tag

    if (content.length > 150) {
      content = content.substring(0,150) + '...'
    }
    return content
  }

  const getComment = () => {
    const runTwikoo = () => {
      twikoo.getRecentComments({
        envId: 'https://vercel.hycbook.com',
        region: '',
        pageSize: 3,
        includeReply: true
      }).then(function (res) {
        const twikooArray = res.map(e => {
          return {
            'content': changeContent(e.comment),
            'avatar': e.avatar,
            'nick': e.nick,
            'url': e.url + '#' + e.id,
            'date': new Date(e.created).toISOString()
          }
        })

        saveToLocal.set('twikoo-newest-comments', JSON.stringify(twikooArray), 10/(60*24))
        generateHtml(twikooArray)
      }).catch(function (err) {
        const $dom = document.querySelector('#card-newest-comments .aside-list')
        $dom.innerHTML= "无法获取评论，请确认相关配置是否正确"
      })
    }

    if (typeof twikoo === 'object') {
      runTwikoo()
    } else {
      getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(runTwikoo)
    }
  }

  const generateHtml = array => {
    let result = ''

    if (array.length) {
      for (let i = 0; i < array.length; i++) {
        result += '<div class=\'aside-list-item\'>'

        if (true) {
          const name = 'data-lazy-src'
          result += `<a href='${array[i].url}' class='thumbnail'><img ${name}='${array[i].avatar}' alt='${array[i].nick}'></a>`
        }
        
        result += `<div class='content'>
        <a class='comment' href='${array[i].url}' title='${array[i].content}'>${array[i].content}</a>
        <div class='name'><span>${array[i].nick} / </span><time datetime="${array[i].date}">${btf.diffDate(array[i].date, true)}</time></div>
        </div></div>`
      }
    } else {
      result += '没有评论'
    }

    let $dom = document.querySelector('#card-newest-comments .aside-list')
    $dom.innerHTML= result
    window.lazyLoadInstance && window.lazyLoadInstance.update()
    window.pjax && window.pjax.refresh($dom)
  }

  const newestCommentInit = () => {
    if (document.querySelector('#card-newest-comments .aside-list')) {
      const data = saveToLocal.get('twikoo-newest-comments')
      if (data) {
        generateHtml(JSON.parse(data))
      } else {
        getComment()
      }
    }
  }

  newestCommentInit()
  document.addEventListener('pjax:complete', newestCommentInit)
})</script><script defer src="https://npm.elemecdn.com/jquery@latest/dist/jquery.min.js"></script><script defer data-pjax src="/js/rightMenu.js"></script><script defer data-pjax src="/js/udf_mouse.js"></script><script defer data-pjax src="/js/udf_js.js"></script><script defer data-pjax src="/zhheo/random.js"></script><script data-pjax src="/js/coin.js"></script><script defer src="https://npm.elemecdn.com/vue@2.6.11"></script><script async src="//at.alicdn.com/t/c/font_3670467_a0sijt8frxo.js"></script><script defer src="/live2d-widget/autoload.js"></script><script defer src="/js/udf_js.js"></script><script defer src="https://cdnjs.cloudflare.com/ajax/libs/toastr.js/latest/toastr.min.js"></script><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-fluttering-ribbon.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = false;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-heart.min.js" async="async" mobile="true"></script><script>window.$crisp = [];
window.CRISP_WEBSITE_ID = "561b80db-3f0f-45cb-b3b1-aae7355939e6";
(function () {
  d = document;
  s = d.createElement("script");
  s.src = "https://client.crisp.chat/l.js";
  s.async = 1;
  d.getElementsByTagName("head")[0].appendChild(s);
})();
$crisp.push(["safe", true])

if (false) {
  $crisp.push(["do", "chat:hide"])
  $crisp.push(["on", "chat:closed", function() {
    $crisp.push(["do", "chat:hide"])
  }])
  var chatBtnFn = () => {
    var chatBtn = document.getElementById("chat_btn")
    chatBtn.addEventListener("click", function(){
      $crisp.push(["do", "chat:show"])
      $crisp.push(["do", "chat:open"])

    });
  }
  chatBtnFn()
} else {
  if (false) {
    function chatBtnHide () {
      $crisp.push(["do", "chat:hide"])
    }
    function chatBtnShow () {
      $crisp.push(["do", "chat:show"])
    }
  }
}</script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener scroll 
  window.tocScrollFn && window.removeEventListener('scroll', window.tocScrollFn)
  window.scrollCollect && window.removeEventListener('scroll', scrollCollect)

  typeof preloader === 'object' && preloader.initLoading()
  document.getElementById('rightside').style.cssText = "opacity: ''; transform: ''"
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

  typeof disqusjs === 'object' && disqusjs.destroy()
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()

  typeof preloader === 'object' && preloader.endLoading()
})

document.addEventListener('pjax:error', (e) => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div class="app-refresh" id="app-refresh" style="position: fixed;top: -2.2rem;left: 0;right: 0;z-index: 99999;padding: 0 1rem;font-size: 15px;height: 2.2rem;transition: all 0.3s ease;"><div class="app-refresh-wrap" style=" display: flex;color: #fff;height: 100%;align-items: center;justify-content: center;"><label>✨ 兼一书虫上新啦！ 👉</label><a href="javascript:void(0)" rel="external nofollow noreferrer" onclick="location.reload()"><span style="color: #fff;text-decoration: underline;cursor: pointer;">🍭查看新品🍬</span></a></div></div><script>if ('serviceWorker' in navigator) {
  if (navigator.serviceWorker.controller) {
    navigator.serviceWorker.addEventListener('controllerchange', function() {
      showNotification()
    })
  }
  window.addEventListener('load', function() {
    navigator.serviceWorker.register('/sw.js')
  })
}

function showNotification() {
  if (GLOBAL_CONFIG.Snackbar) {
    var snackbarBg =
      document.documentElement.getAttribute('data-theme') === 'light' ?
      GLOBAL_CONFIG.Snackbar.bgLight :
      GLOBAL_CONFIG.Snackbar.bgDark
    var snackbarPos = GLOBAL_CONFIG.Snackbar.position
    Snackbar.show({
      text: '✨ 兼一书虫上新啦！ 👉',
      backgroundColor: snackbarBg,
      duration: 500000,
      pos: snackbarPos,
      actionText: '🍭查看新品🍬',
      actionTextColor: '#fff',
      onActionClick: function(e) {
        location.reload()
      },
    })
  } else {
    var showBg =
      document.documentElement.getAttribute('data-theme') === 'light' ?
      '#49b1f5' :
      '#1f1f1f'
    var cssText = `top: 0; background: ${showBg};`
    document.getElementById('app-refresh')
      .style.cssText = cssText
  }
}</script></div><!-- hexo injector body_end start --><script async src="//at.alicdn.com/t/font_2032782_8d5kxvn09md.js"></script><!-- hexo injector body_end end --></body></html>